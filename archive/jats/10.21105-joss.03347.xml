<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3347</article-id>
<article-id pub-id-type="doi">10.21105/joss.03347</article-id>
<title-group>
<article-title>ConTEXT Explorer: a web-based text analysis tool for
exploring and visualizing concepts across time</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7705-3280</contrib-id>
<string-name>Ziying Yang</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7386-4155</contrib-id>
<string-name>Gosia Mikolajczak</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Andrew Turpin</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University of Melbourne</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-04-19">
<day>19</day>
<month>4</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>68</issue>
<fpage>3347</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Dash</kwd>
<kwd>Data Analysis</kwd>
<kwd>Data Visulization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><bold>ConTEXT Explorer</bold> is an open Web-based system that
  assists in exploring the context of concepts (combinations of
  co-occurring words and phrases) over time in text documents. It
  provides a user-friendly interface for the analysis of user-provided
  text data and integrates functionalities of the Whoosh search engine,
  Spacy, Gensim, and Plotly Python libraries. By providing suggestions
  for query expansion and producing interactive plots,
  <monospace>ConTEXT Explorer</monospace> facilitates exploratory data
  analysis, which can serve as the basis for subsequent text
  classification.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>With the availability of digital sources of data and associated
  tools, automated text analysis is becoming increasingly popular in the
  humanities and social sciences. While for very large corpora,
  unsupervised text mining methods like topic modelling
  (<xref alt="Blei et al., 2003" rid="ref-lda" ref-type="bibr">Blei et
  al., 2003</xref>) can provide some useful summaries of data, many
  social science and humanities applications require analysis of data in
  context. That is, simple “bags of words” automatically mined and
  presented in isolation from the original text are often not meaningful
  for complex questions involving human behaviour and society.
  Inevitably, human interpretation is required to make sense of such
  patterns. For corpora with more than several hundred documents, there
  is a need for computational tools that can assist researchers in
  exploring the context in which “bags of words” (we will call them
  concepts from now on) occurs.</p>
  <p>Similarly, there is a need for tools that assist in the manual
  construction of concepts from text corpora. In particular, manual
  intervention to judge the semantic intent of words (e.g., word sense
  disambiguation) is usually needed to filter keywords to add to
  concepts that might be generated by automatic methods such as query
  expansion
  (<xref alt="Buckley et al., 1994" rid="ref-QE" ref-type="bibr">Buckley
  et al., 1994</xref>) or comparison of word embeddings
  (<xref alt="Mikolov et al., 2013" rid="ref-word2vec" ref-type="bibr">Mikolov
  et al., 2013</xref>). For example, if a researcher is interested in
  finding articles about same sex marriage, they might start with
  “same_sex marriage”<xref ref-type="fn" rid="fn1">1</xref> as a
  concept. Automated methods processing a corpus of news articles might
  suggest related words like ‘matrimony’, ‘union’, ‘erosion’, and
  ‘puzzlement’<xref ref-type="fn" rid="fn2">2</xref>. Depending on the
  research question and the context of these words, some might be
  relevant to the concept and should be included, while others are not.
  It requires complex human judgement to make the distinction.
  <monospace>ConTEXT Explorer</monospace> is a tool to assist the
  construction of such concepts in context.</p>
  <p>Most existing computational methods underlying automated text
  processing require at least a working knowledge of relevant methods
  and programming languages (such as R or Python).
  <monospace>ConTEXT Explorer</monospace> is designed to lower these
  barriers to entry, particularly for humanities and social science
  researchers, by allowing an application of information retrieval and
  machine learning methods to text analysis without programming
  knowledge.</p>
</sec>
<sec id="comparison-with-other-tools">
  <title>Comparison with other tools</title>
  <p>Current text analysis tools require either previous knowledge of
  programming (e.g., R, Python), or are commercial products (e.g.,
  <bold>RapidMiner</bold>
  (<xref alt="RapidMiner, 2021" rid="ref-rapidminer" ref-type="bibr">RapidMiner,
  2021</xref>), <bold>Google Cloud Natural Language API</bold>
  (<xref alt="Google, 2021" rid="ref-googlenlp" ref-type="bibr">Google,
  2021</xref>)). One exception that we are aware of is <bold>Voyant
  Tools</bold>
  (<xref alt="Sinclair &amp; Voyant Tools Team, 2012" rid="ref-voyant" ref-type="bibr">Sinclair
  &amp; Voyant Tools Team, 2012</xref>), which is an open-source
  web-based text analysis tool built in Java. It allows the users to
  explore their data using some basic text analysis techniques such as
  word frequencies (at the document level), word cloud, and word context
  (words appearing around a chosen term).
  <monospace>ConTEXT Explorer</monospace> provides several
  functionalities that give a user a deeper understanding of the text,
  which are currently not available in Voyant Tools, such as concept
  suggestions, sentence ranking and concept grouping. It includes models
  allowing discovery of similar terms, and a search engine allowing
  retrieval of sentences relevant to concept terms, which can be used
  for concept expansion, and visualization of concepts over time. One
  key feature is that a concept can be either conjunction or disjunction
  of bags of words.</p>
  <p>Compared to commercial text analysis systems such as
  <bold>RapidMiner</bold>
  (<xref alt="RapidMiner, 2021" rid="ref-rapidminer" ref-type="bibr">RapidMiner,
  2021</xref>), which include some complex analysis techniques,
  <monospace>ConTEXT Explorer</monospace> is open-source (free) and easy
  to install. It enables researchers to browse text interactively for
  concepts (bags of words) in their corpus before mining the text in
  machine learning-driven systems.</p>
  <p><monospace>ConTEXT Explorer</monospace> is designed to help users
  interested in defining concepts, and exploring their trends over time.
  This could be particularly helpful as an input for some popular text
  analysis systems such as <bold>MonkeyLearn</bold>
  (<xref alt="MonkeyLearn, 2021" rid="ref-monkeylearn" ref-type="bibr">MonkeyLearn,
  2021</xref>), which enable text classification, tagging, and training
  AI machine learning models but require prior knowledge of the
  data.</p>
  <p><monospace>ConTEXT Explorer</monospace> is engineered to allow for
  the integration of other Python packages into the analysis process. It
  can be easily combined with other Python APIs (such as MonkeyLearn),
  once the concept groups are defined.</p>
</sec>
<sec id="key-features">
  <title>Key features</title>
  <p><monospace>ConTEXT Explorer</monospace> is developed using
  <bold>Dash</bold>
  (<xref alt="Plotly Technologies Inc., 2015" rid="ref-plotly" ref-type="bibr">Plotly
  Technologies Inc., 2015</xref>) in Python, and integrates the
  following packages.</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Spacy</bold> pipeline
      (<xref alt="Honnibal et al., 2020" rid="ref-spacy" ref-type="bibr">Honnibal
      et al., 2020</xref>) - for pre-processing the text corpora
      uploaded by users.</p>
    </list-item>
    <list-item>
      <p><bold>Whoosh</bold>
      (<xref alt="Whoosh, 2021" rid="ref-whoosh" ref-type="bibr">Whoosh,
      2021</xref>) - for building a search engine, which allows ranking
      of sentences relevant to the given concepts, and word frequency
      analysis at the sentence and document level.</p>
    </list-item>
    <list-item>
      <p><bold>Gensim</bold>
      (<xref alt="Řehůřek &amp; Sojka, 2010" rid="ref-gensim" ref-type="bibr">Řehůřek
      &amp; Sojka, 2010</xref>) - for training a word2vec
      (<xref alt="Mikolov et al., 2013" rid="ref-word2vec" ref-type="bibr">Mikolov
      et al., 2013</xref>) model for the uploaded corpus, which allows
      the user to find words related to other words for expanding
      concepts.</p>
    </list-item>
    <list-item>
      <p><bold>Plotly</bold>
      (<xref alt="Plotly Technologies Inc., 2015" rid="ref-plotly" ref-type="bibr">Plotly
      Technologies Inc., 2015</xref>) - for visualizing results in
      interactive graphs, which can be customized and saved as PNG
      files.</p>
    </list-item>
  </list>
  <p><monospace>ConTEXT Explorer</monospace> has been tested locally
  under macOS and as a server running under Ubuntu and continuous
  integration tests are performed using Travis CI.</p>
  <sec id="build-a-corpus">
    <title>Build a corpus</title>
    <p>Users are asked to format their text documents as a CSV file
    (with each document saved in a separate row), before uploading this
    file into <monospace>ConTEXT Explorer</monospace>. At a minimum,
    users are asked to provide document text and publication year. Users
    can also upload columns with additional document information (such
    as document author, title, and so on).</p>
    <p><monospace>ConTEXT Explorer</monospace> processes the submitted
    file in the following steps.</p>
    <list list-type="order">
      <list-item>
        <p>Sentenize and tokenize English text using Spacy
        (<xref alt="Honnibal et al., 2020" rid="ref-spacy" ref-type="bibr">Honnibal
        et al., 2020</xref>). This allows ranking of documents and
        speeds up document search.</p>
      </list-item>
      <list-item>
        <p>Index the documents, and build a search engine for the corpus
        using Whoosh
        (<xref alt="Whoosh, 2021" rid="ref-whoosh" ref-type="bibr">Whoosh,
        2021</xref>) and the Okapi BM25F
        (<xref alt="Robertson &amp; Zaragoza, 2009" rid="ref-BM25F" ref-type="bibr">Robertson
        &amp; Zaragoza, 2009</xref>) ranking function.</p>
      </list-item>
      <list-item>
        <p>Remove stop words, lemmatize remaining words, and generate a
        word2vec
        (<xref alt="Mikolov et al., 2013" rid="ref-word2vec" ref-type="bibr">Mikolov
        et al., 2013</xref>) model for the corpus using Gensim
        (<xref alt="Řehůřek &amp; Sojka, 2010" rid="ref-gensim" ref-type="bibr">Řehůřek
        &amp; Sojka, 2010</xref>).</p>
      </list-item>
    </list>
    <p>For each corpus, users can create a new analysis, or load a
    pre-saved analysis to the dashboard.</p>
  </sec>
  <sec id="dashboard">
    <title>Dashboard</title>
    <fig>
      <caption><p>The starting dashboard.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="https://paper-attachments.dropbox.com/s_BF58715651395C8B59D508B9A7AFBDF87128C0D6732F3C5CB80FFC81F0067860_1618206868822_overview.png" xlink:title="" />
    </fig>
    <p>As shown in Figure 1, the dashboard interface has two panes. On
    the left-hand side, users can:</p>
    <list list-type="bullet">
      <list-item>
        <p>select the year range of documents to be displayed in search
        results;</p>
      </list-item>
      <list-item>
        <p>add or delete query terms (single words or phrases) to create
        a concept;</p>
      </list-item>
      <list-item>
        <p>save the current query as a new analysis; and</p>
      </list-item>
      <list-item>
        <p>download the subset of the corpus filtered by the query
        terms.</p>
      </list-item>
    </list>
    <p><bold>Overview</bold>. The overview tab summarizes the corpus
    information such as the total number of documents, year range,
    document length, most frequent words in the corpus, and most
    frequent values for selected metadata.</p>
    <fig>
      <caption><p>The sentences tab of the dashboard, with some query
      terms shown in the left pane.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="https://paper-attachments.dropbox.com/s_BF58715651395C8B59D508B9A7AFBDF87128C0D6732F3C5CB80FFC81F0067860_1624346302562_Screen+Shot+2021-06-22+at+5.18.01+pm.png" xlink:title="" />
    </fig>
    <p><bold>Sentences</bold>. This tab shows the ranking of relevant
    sentences based on query terms defined in the left pane. Sentences
    are ranked by the Okapi BM25F ranking function, and the computed
    similarity score for each sentence is shown in the “SCORE” column.
    The table can be sorted and filtered by column values. Users can
    click on each sentence to see its full content in a pop-up window,
    which also allows checking of the frequency of individual terms and
    adding them to the query.</p>
    <fig>
      <caption><p>The grouping tab of the dashboard, showing the term
      frequency of the added terms across time (top), and some examples
      of query groups (bottom).</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="https://paper-attachments.dropbox.com/s_BF58715651395C8B59D508B9A7AFBDF87128C0D6732F3C5CB80FFC81F0067860_1618281338713_grouping.png" xlink:title="" />
    </fig>
    <p><bold>Grouping</bold>. The top part of this tab shows the number
    of sentences containing each query term within the user-defined year
    range. In the bottom part, users can group the query terms using
    “Any” or “All” operators. Groups can be further combined into more
    complex groups.</p>
    <fig>
      <caption><p>‘Graphs’ tab, showing the aggregated graph for all
      groups (top) and individual graph for each group
      (bottom).</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="https://paper-attachments.dropbox.com/s_BF58715651395C8B59D508B9A7AFBDF87128C0D6732F3C5CB80FFC81F0067860_1618282796027_graphs.png" xlink:title="" />
    </fig>
    <p><bold>Graphs</bold>. Based on the query groups generated in the
    previous tab, this page displays aggregated and individual plots,
    which allow comparing groups (top) and individual terms within each
    group (bottom). Users can choose the number of relevant documents,
    the number of sentences, or the proportion of documents as the
    y-axis of the graphs. All graphs are plotted by Plotly
    (<xref alt="Plotly Technologies Inc., 2015" rid="ref-plotly" ref-type="bibr">Plotly
    Technologies Inc., 2015</xref>) which allows users to interact with
    every trace in the graphs.</p>
  </sec>
  <sec id="save-and-reload-an-analysis">
    <title>Save and reload an analysis</title>
    <p>As mentioned in the section above, users are able to save the
    details of their analysis (including added terms and generated
    groups) and reload it to view all of the ranking, groups and graphs
    from the index page.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The development of <monospace>ConTEXT Explorer</monospace> has been
  supported by the Australian Research Council Discovery Project
  (DP180101711) “Understanding Political Debate and Policy Decisions
  Using Big Data” awarded to the third author.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-spacy">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Honnibal</surname><given-names>Matthew</given-names></name>
          <name><surname>Montani</surname><given-names>Ines</given-names></name>
          <name><surname>Van Landeghem</surname><given-names>Sofie</given-names></name>
          <name><surname>Boyd</surname><given-names>Adriane</given-names></name>
        </person-group>
        <source>spaCy: Industrial-strength natural language processing in Python</source>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <uri>https://doi.org/10.5281/zenodo.1212303</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1212303</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-whoosh">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Whoosh</surname></name>
        </person-group>
        <article-title>Whoosh, a pure Python search engine library</article-title>
        <year iso-8601-date="2021">2021</year>
        <uri>https://whoosh.readthedocs.io/en/latest/intro.html</uri>
      </element-citation>
    </ref>
    <ref id="ref-monkeylearn">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>MonkeyLearn</surname></name>
        </person-group>
        <article-title>How MonkeyLearn works</article-title>
        <year iso-8601-date="2021">2021</year>
        <uri>https://monkeylearn.com/how-it-works/</uri>
      </element-citation>
    </ref>
    <ref id="ref-rapidminer">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>RapidMiner</surname></name>
        </person-group>
        <article-title>Best data science &amp; machine learning platform</article-title>
        <year iso-8601-date="2021">2021</year>
        <uri>https://rapidminer.com/</uri>
      </element-citation>
    </ref>
    <ref id="ref-googlenlp">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Google</surname></name>
        </person-group>
        <article-title>Cloud natural language – Google Cloud</article-title>
        <year iso-8601-date="2021">2021</year>
        <uri>https://cloud.google.com/natural-language/</uri>
      </element-citation>
    </ref>
    <ref id="ref-BM25F">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Robertson</surname><given-names>Stephen</given-names></name>
          <name><surname>Zaragoza</surname><given-names>Hugo</given-names></name>
        </person-group>
        <article-title>The probabilistic relevance framework: BM25 and beyond</article-title>
        <source>Foundations and Trends in Information Retrieval</source>
        <year iso-8601-date="2009">2009</year>
        <volume>3</volume>
        <issue>4</issue>
        <uri>http://dx.doi.org/10.1561/1500000019</uri>
        <pub-id pub-id-type="doi">10.1561/1500000019</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gensim">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Řehůřek</surname><given-names>Radim</given-names></name>
          <name><surname>Sojka</surname><given-names>Petr</given-names></name>
        </person-group>
        <article-title>Software framework for topic modelling with large corpora</article-title>
        <source>Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</source>
        <publisher-name>ELRA</publisher-name>
        <year iso-8601-date="2010">2010</year>
      </element-citation>
    </ref>
    <ref id="ref-plotly">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <string-name>Plotly Technologies Inc.</string-name>
        </person-group>
        <article-title>Collaborative data science</article-title>
        <publisher-name>Plotly Technologies Inc.</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <uri>https://plot.ly</uri>
      </element-citation>
    </ref>
    <ref id="ref-voyant">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>Sinclair</surname><given-names>Geoffrey Rockwell</given-names><suffix>Stéfan</suffix></name>
          <name><surname>Voyant Tools Team</surname></name>
        </person-group>
        <article-title>Voyant tools (web application)</article-title>
        <year iso-8601-date="2012">2012</year>
        <uri>https://voyant-tools.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-word2vec">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Mikolov</surname><given-names>Tomás</given-names></name>
          <name><surname>Chen</surname><given-names>Kai</given-names></name>
          <name><surname>Corrado</surname><given-names>Greg</given-names></name>
          <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
        </person-group>
        <article-title>Efficient estimation of word representations in vector space</article-title>
        <source>1st international conference on learning representations, ICLR 2013, scottsdale, arizona, USA, may 2-4, 2013, workshop track proceedings</source>
        <year iso-8601-date="2013">2013</year>
        <uri>http://arxiv.org/abs/1301.3781</uri>
      </element-citation>
    </ref>
    <ref id="ref-QE">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Buckley</surname><given-names>Chris</given-names></name>
          <name><surname>Salton</surname><given-names>Gerard</given-names></name>
          <name><surname>Allan</surname><given-names>James</given-names></name>
        </person-group>
        <article-title>The effect of adding relevance information in a relevance feedback environment</article-title>
        <source>SIGIR ’94</source>
        <publisher-name>Springer London</publisher-name>
        <year iso-8601-date="1994">1994</year>
        <isbn>978-1-4471-2099-5</isbn>
        <pub-id pub-id-type="doi">10.1007/978-1-4471-2099-5_30</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-lda">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Blei</surname><given-names>David M.</given-names></name>
          <name><surname>Ng</surname><given-names>Andrew Y.</given-names></name>
          <name><surname>Jordan</surname><given-names>Michael I.</given-names></name>
        </person-group>
        <article-title>Latent Dirichlet allocation</article-title>
        <source>The Journal of Machine Learning Research</source>
        <year iso-8601-date="2003">2003</year>
        <volume>3</volume>
        <issn>1532-4435</issn>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>We use underscore to join multiple words into a
    single phrase.</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>This is an example where we apply
    <monospace>ConTEXT Explorer</monospace> in the Australian Research
    Council Discovery Project (DP180101711) “Understanding Political
    Debate and Policy Decisions Using Big Data”.</p>
  </fn>
</fn-group>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3784</article-id>
<article-id pub-id-type="doi">10.21105/joss.03784</article-id>
<title-group>
<article-title>EDO.js: A comprehensive JavaScript library for
interaction with musical set theory in any tuning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6061-0674</contrib-id>
<string-name>Michael Seltenreich</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Music, New York University, New York, New
York 10003</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-09-23">
<day>23</day>
<month>9</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>67</issue>
<fpage>3784</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>music theory</kwd>
<kwd>music analysis</kwd>
<kwd>music perception</kwd>
<kwd>set theory</kwd>
<kwd>diatonic set theory</kwd>
<kwd>equal divisions of the octave</kwd>
<kwd>TET</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>EDO.js is a JavaScript library for generating, analyzing, and
  visualizing pitch-collections within any tuning system of Equal
  Divisions of an Octave (EDO). The current focus is on psychological
  experiments pertaining to musical scale perception and pitch-centric
  music research more broadly. EDO.js implements major algorithms
  presented in the music theory and music cognition literature (e.g.,
  <xref alt="Balzano, 1982" rid="ref-BalzanoU003A1982" ref-type="bibr">Balzano,
  1982</xref>;
  <xref alt="Carey, 2007" rid="ref-carey2007coherence" ref-type="bibr">Carey,
  2007</xref>;
  <xref alt="Carey &amp; Clampitt, 1989" rid="ref-clampitt" ref-type="bibr">Carey
  &amp; Clampitt, 1989</xref>;
  <xref alt="Lerdahl, 2001" rid="ref-lerdahl2001tonal" ref-type="bibr">Lerdahl,
  2001</xref>;
  <xref alt="Rahn, 1991" rid="ref-rahn1991coordination" ref-type="bibr">Rahn,
  1991</xref>;
  <xref alt="Vassilakis, 2001" rid="ref-vassilakis2001auditory" ref-type="bibr">Vassilakis,
  2001</xref>), alongside a wide array of additional tools for analyzing
  and manipulating midi-data and melodies in the framework of musical
  set theory
  (<xref alt="Forte, 1973" rid="ref-forte1973structure" ref-type="bibr">Forte,
  1973</xref>) and diatonic set theory. EDO.js sets itself apart from
  existing music analysis libraries (such as, music21
  (<xref alt="Cuthbert &amp; Ariza, 2010" rid="ref-music21" ref-type="bibr">Cuthbert
  &amp; Ariza, 2010</xref>)), in that while most libraries are centered
  around engaging with the canon of Western music through the lens of
  applied (and adopted) music-theoretical concepts (e.g., figured bass,
  roman numerals, etc.), EDO.js is approaching music from a more
  fundamental level and is aimed at engaging with music’s primitives
  from a cognitive and psycho-acoustical point of view. As such, EDO.js
  provides analytical tools that can be applied also to non-Western
  music, making the library more exploratory in nature. Most critically,
  EDO.js is, to the best of our knowledge, the most comprehensive
  library to support non-standard tuning to date.</p>
  <p>Two classes are at the core of the package. The EDO class, and a
  daughter class, the Scale class. The EDO class and the Scale class
  conceptually diverge only on a single aspect: pitches in the Scale
  class are regarded as pitch-classes (exist only within an octave) and
  they have an enharmonic meaning. However, in the EDO class pitches are
  regarded as specific, and are not confined to a single octave. That is
  to say, while the Scale class treats C3 and C4 simply as “C”, the EDO
  class would regard them as separate entities. As such, the Scale class
  is better suited to engage with scales, their properties, and their
  structures, while the EDO class is an implementation of useful
  functions for engaging with more abstract musical structures.</p>
  <sec id="the-edo-class">
    <title>The EDO Class</title>
    <p>The class contains eight sets of functions:</p>
    <list list-type="bullet">
      <list-item>
        <p>Functions used for converting between equivalent
        representations of the input in various formats (cents, ratios,
        pitches, intervals, frequencies, etc.)</p>
      </list-item>
      <list-item>
        <p>Functions used for quantifying various parameters of a given
        input (e.g., the number of common tones between two inputs).</p>
      </list-item>
      <list-item>
        <p>Boolean assertations on input data (e.g., is a set of pitches
        a transposition of another?)</p>
      </list-item>
      <list-item>
        <p>Functions used for visualization (e.g., contours, fractal
        trees, necklaces, fractal necklaces, nested necklaces,
        etc.).</p>
      </list-item>
      <list-item>
        <p>Functions used for importing and processing of midi
        files.</p>
      </list-item>
      <list-item>
        <p>Functions used for importing and processing MusicXml
        files.</p>
      </list-item>
      <list-item>
        <p>Functions used for exporting data in various formats (e.g.,
        images).</p>
      </list-item>
      <list-item>
        <p>Other functions for analysis, and manipulation (e.g.,
        extracting motives, extracting contour, generating harmonic
        progressions, extracting pitch distribution, generating
        pseudo-random melodies, and more).</p>
      </list-item>
    </list>
  </sec>
  <sec id="the-scale-class">
    <title>The Scale Class</title>
    <p>The class contains six sets of functions:</p>
    <list list-type="bullet">
      <list-item>
        <p>Functions for converting between equivalent representations
        of the scale (e.g., for converting pitches to step sizes).</p>
      </list-item>
      <list-item>
        <p>Functions for quantifying various parameters of a given scale
        (cardinality, trichords, dissonance, coherence, and others).</p>
      </list-item>
      <list-item>
        <p>Boolean assertations about the scale (e.g., is it invertible?
        Is it a mode-of-limited-transposition?)</p>
      </list-item>
      <list-item>
        <p>Functions used for exporting (e.g., Scala files).</p>
      </list-item>
      <list-item>
        <p>Functions used for scale structure visualization (e.g.,
        scalar fractal trees).</p>
      </list-item>
      <list-item>
        <p>Analysis, manipulation, and generation functions (e.g.,
        calculating the coherence quotient, extracting diatonic motives,
        returning the Rothernberg Propriety, calculating Vassilakis
        Roughness, retrieving available n-chords, etc.).</p>
      </list-item>
    </list>
    <p>In addition to the sets of functions described above, the Scale
    class also contains five chainable methods commonly used in
    set-theory.</p>
    <list list-type="bullet">
      <list-item>
        <p><monospace>Scale.invert()</monospace> returns the inversion
        of the original set.</p>
      </list-item>
      <list-item>
        <p><monospace>Scale.mode(n)</monospace> returns the nth mode of
        the original set.</p>
      </list-item>
      <list-item>
        <p><monospace>Scale.normal()</monospace> returns the set in
        normal order.</p>
      </list-item>
      <list-item>
        <p><monospace>Scale.prime()</monospace> returns the set in its
        prime form.</p>
      </list-item>
      <list-item>
        <p><monospace>Scale.complement()</monospace> returns the
        complement of the set in the current EDO.</p>
      </list-item>
    </list>
    <p>For instance,
    <monospace>Scale.mode(3).invert().complement()</monospace> will
    return an instance of a Scale that is equivalent to the complement
    scale of the inversion of the 3rd mode of the original scale.</p>
  </sec>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p><monospace>Edo.js</monospace> is written in JavaScript for
  deployment on a Node.js server or in a web-browser. The full
  documentation for the package is available
  <ext-link ext-link-type="uri" xlink:href="https://michaelsel.github.io/edoJS">here</ext-link>,
  and the package is available on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/MichaelSel/edoJS">GitHub</ext-link>
  or in Node Package Manager
  (<ext-link ext-link-type="uri" xlink:href="https://www.npmjs.com/package/edo.js">NPM</ext-link>).</p>
  <p>This library is aimed at music theorists, musicologists, and
  cognitive scientists working on pitch-centric musical research, for
  the creation of stimuli for experiments, and for the analysis of
  musical structures within and outside of standard tuning systems.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-BalzanoU003A1982">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Balzano</surname><given-names>J. G.</given-names></name>
        </person-group>
        <source>The Pitch Set as a Level of Description for Studying Musical Pitch Perception</source>
        <publisher-name>Springer, Boston, MA</publisher-name>
        <year iso-8601-date="1982">1982</year>
        <uri>https://doi.org/10.1007/978-1-4684-8917-0_17</uri>
        <pub-id pub-id-type="doi">10.1007/978-1-4684-8917-0_17</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-clampitt">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Carey</surname><given-names>Norman</given-names></name>
          <name><surname>Clampitt</surname><given-names>David</given-names></name>
        </person-group>
        <article-title>Aspects of Well-Formed Scales</article-title>
        <source>Music Theory Spectrum</source>
        <year iso-8601-date="1989-10">1989</year><month>10</month>
        <volume>11</volume>
        <issue>2</issue>
        <issn>0195-6167</issn>
        <uri>https://doi.org/10.2307/745935</uri>
        <pub-id pub-id-type="doi">10.2307/745935</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-rahn1991coordination">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Rahn</surname><given-names>Jay</given-names></name>
        </person-group>
        <article-title>Coordination of interval sizes in seven-tone collections</article-title>
        <source>Journal of Music Theory</source>
        <publisher-name>JSTOR</publisher-name>
        <year iso-8601-date="1991">1991</year>
        <volume>35</volume>
        <issue>1/2</issue>
        <pub-id pub-id-type="doi">10.2307/843809</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-vassilakis2001auditory">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Vassilakis</surname><given-names>Pantelis</given-names></name>
        </person-group>
        <article-title>Auditory roughness estimation of complex spectra—roughness degrees and dissonance ratings of harmonic intervals revisited</article-title>
        <source>The Journal of the Acoustical Society of America</source>
        <publisher-name>Acoustical Society of America</publisher-name>
        <year iso-8601-date="2001">2001</year>
        <volume>110</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1121/1.4777600</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-lerdahl2001tonal">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Lerdahl</surname><given-names>Fred</given-names></name>
        </person-group>
        <source>Tonal pitch space</source>
        <publisher-name>Oxford University Press, USA</publisher-name>
        <year iso-8601-date="2001">2001</year>
        <pub-id pub-id-type="doi">10.1093/acprof:oso/9780195178296.001.0001</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-carey2007coherence">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Carey</surname><given-names>Norman</given-names></name>
        </person-group>
        <article-title>Coherence and sameness in well-formed and pairwise well-formed scales</article-title>
        <source>Journal of Mathematics and Music</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2007">2007</year>
        <volume>1</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1080/17459730701376743</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-forte1973structure">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Forte</surname><given-names>Allen</given-names></name>
        </person-group>
        <source>The structure of atonal music</source>
        <publisher-name>Yale University Press</publisher-name>
        <year iso-8601-date="1973">1973</year>
        <volume>304</volume>
        <isbn>9780300021202</isbn>
      </element-citation>
    </ref>
    <ref id="ref-music21">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Cuthbert</surname><given-names>Michael Scott</given-names></name>
          <name><surname>Ariza</surname><given-names>Christopher</given-names></name>
        </person-group>
        <article-title>Music21: A toolkit for computer-aided musicology and symbolic music data.</article-title>
        <source>ISMIR</source>
        <person-group person-group-type="editor">
          <name><surname>Downie</surname><given-names>J. Stephen</given-names></name>
          <name><surname>Veltkamp</surname><given-names>Remco C.</given-names></name>
        </person-group>
        <publisher-name>International Society for Music Information Retrieval</publisher-name>
        <year iso-8601-date="2010">2010</year>
        <isbn>978-90-393-53813</isbn>
        <uri>http://dblp.uni-trier.de/db/conf/ismir/ismir2010.html#CuthbertA10</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1416114</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

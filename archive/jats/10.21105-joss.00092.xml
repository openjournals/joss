<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">92</article-id>
<article-id pub-id-type="doi">10.21105/joss.00092</article-id>
<title-group>
<article-title>edarf: Exploratory Data Analysis using Random
Forests</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7523-0471</contrib-id>
<string-name>Zachary M. Jones</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0499-0676</contrib-id>
<string-name>Fridolin J. Linder</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Pennsylvania State University</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2016-10-06">
<day>6</day>
<month>10</month>
<year>2016</year>
</pub-date>
<volume>1</volume>
<issue>6</issue>
<fpage>92</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>random forests</kwd>
<kwd>machine learning</kwd>
<kwd>exploratory data analysis</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>This package contains functions useful for exploratory data
  analysis using random forests, which can be fit using the
  <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=randomForest">randomForest</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=randomForestSRC">randomForestSRC</ext-link>,
  or
  <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=party">party</ext-link>
  packages
  (<xref alt="Hothorn et al., 2006" rid="ref-party" ref-type="bibr">Hothorn
  et al., 2006</xref>;
  <xref alt="Ishwaran &amp; Kogalur, 2013" rid="ref-randomForestSRC" ref-type="bibr">Ishwaran
  &amp; Kogalur, 2013</xref>;
  <xref alt="Liaw &amp; Wiener, 2002" rid="ref-randomForest" ref-type="bibr">Liaw
  &amp; Wiener, 2002</xref>). These functions can compute the partial
  dependence of covariates (individually or in combination) on the
  fitted forests’ predictions, the permutation importance of covariates,
  as well as the distance between data points according to the fitted
  model.</p>
  <p>Random forests are an attractive method for social scientists.
  Random forests have only a few important tuning parameters and can be
  adapted to do classification, regression, and clustering. Many
  research tasks require interpretable models, and, although methods for
  interpreting random forests exist, in the most popular packages for
  fitting random forests these methods are available inconsistently. For
  example although there are methods for computing permutation
  importance in the <monospace>randomForest</monospace>,
  <monospace>randomForestSRC</monospace> and
  <monospace>party</monospace> packages, only
  <monospace>randomForest</monospace> can compute local importance. None
  of the packages can compute permutation importance for groups of
  covariates. Similarly partial dependence is only implemented in
  <monospace>randomForest</monospace>, and it has limited functionality
  compared to the functions provided herein. This software has been used
  in Jones &amp; Linder
  (<xref alt="2015" rid="ref-jones2015exploratory" ref-type="bibr">2015</xref>);
  Jones &amp; Lupu
  (<xref alt="2016" rid="ref-jones2016there" ref-type="bibr">2016</xref>).</p>
  <fig>
    <caption><p>The partial dependence of several covariates (each
    considered separately) on the probability that a convict voted in
    the 2012 presidential election, given that they had registered to do
    so. Data is from Gerber et al.
    (<xref alt="2015" rid="ref-gerber2014can" ref-type="bibr">2015</xref>).</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="partial_dependence.png" xlink:title="" />
  </fig>
  <p>Partial dependence, as described by Friedman
  (<xref alt="2001" rid="ref-friedman2001greedy" ref-type="bibr">2001</xref>),
  estimates the marginal relationship between a subset of the covariates
  and the model’s predictions by averaging over the marginal
  distribution of the compliment of this subset of the covariates. This
  approximation allows the display of the relationship between this
  subset of the covariates and the model’s predictions even when there
  are many covariates which may interact. This functionality works with
  models fit by any of the aforementioned packages to any of the
  supported types of outcome variables.
  <monospace>partial_dependence</monospace> can be parallelized and also
  contains a number of additional parameters which allow the user to
  control this approximation. There is an associated plot function
  <monospace>plot_pd</monospace> which constructs plots for a wide
  variety of possible outputs from
  <monospace>partial_dependence</monospace> (e.g., when pairs of
  covariates are considered jointly, when each covariate is considered
  separately, when the outcome variable is categorical, etc).</p>
  <fig>
    <caption><p>The permutation importance of the same
    covariates.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="importance.png" xlink:title="" />
  </fig>
  <p>Permutation importance estimates the importance of a covariate by
  randomly shuffling its values, breaking any dependence between said
  covariate and the outcome, and then computing the difference between
  the predictions made by the model with that covariate shuffled and the
  predictions made when the covariate was not shuffled. If the covariate
  was useful in generating predictions then the prediction errors will
  increase in expectation when the covariate is shuffled, whereas no
  such increase can be expected when the covariate has no influence.
  Although all three of the random forest packages provide at least one
  method of assessing variable importance,
  <monospace>variable_importance</monospace> provides a consistent way
  to compute permutation importance across all packages.
  <monospace>variable_importance</monospace> can also compute local
  importance. Rather than computing the average difference in prediction
  errors between the permuted and unpermuted data across all the
  training data (giving one number for each covariate), local importance
  computes the average change in the prediction error for each
  observation. This can be examined directly, or, in the case of a
  categorical outcome variable, can be aggregated to each class level.
  In the case of a continuous outcome variable the change in the
  prediction errors can be smoothed at different values of the outcome
  variable, giving a similar display. Lastly,
  <monospace>variable_importance</monospace> can operate on multiple
  variables simultaneously, giving the joint permutation importance of a
  set of covariates. This can be used to detect interactions by
  comparing the permutation importance of, for example, two covariates,
  by computing their joint permutation importance and comparing that to
  the sum of their individual permutation importance estimates.
  <monospace>plot_imp</monospace> provides a visualizations for all
  possible outputs.</p>
  <fig>
    <caption><p>The proximity of the training data, colored according to
    the encouragement condition implemented by Gerber et al.
    (<xref alt="2015" rid="ref-gerber2014can" ref-type="bibr">2015</xref>),
    with the shape of the points mapped to whether the individual had
    voted in the 2008 election and the size of the point mapped to the
    individual’s age.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="proximity.png" xlink:title="" />
  </fig>
  <p>Due to the tree-structure of a random forest, there is a natural
  way to define a distance between data points: the proportion of times
  that the data points were in the same terminal node. This is called
  “proximity” and can be used do model-based clustering when the random
  forest was unsupervised, and can be used to visualize the model in the
  supervised case. Making generic the compuation of the proxmity matrix
  would require a consistent API for accessing information in the
  individual trees in the random forest, which does not exist, however,
  <monospace>extract_proximity</monospace> can extract a proximity
  matrix computed by one of the supported packages. These matrices are
  too high dimensional to be visualized directly, so
  <monospace>plot_prox</monospace> supports the visualization of two of
  the principal components of this matrix, as estimated by
  <monospace>prcomp</monospace> (included in the base distribution of
  <monospace>R</monospace>). <monospace>plot_prox</monospace> provides
  arguments which additionally allow the user to change the color,
  shape, and size of points according to auxillary information, such as
  the observed class label for categorical outcomes, or a covariates,
  which may aid the aforementioned visualization tasks.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-friedman2001greedy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>Jerome H.</given-names></name>
        </person-group>
        <article-title>Greedy function approximation: A gradient boosting machine.</article-title>
        <source>The Annals of Statistics</source>
        <publisher-name>The Institute of Mathematical Statistics</publisher-name>
        <year iso-8601-date="2001-10">2001</year><month>10</month>
        <volume>29</volume>
        <issue>5</issue>
        <uri>http://dx.doi.org/10.1214/aos/1013203451</uri>
        <pub-id pub-id-type="doi">10.1214/aos/1013203451</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gerber2014can">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Gerber</surname><given-names>Alan S.</given-names></name>
          <name><surname>Huber</surname><given-names>Gregory A.</given-names></name>
          <name><surname>Meredith</surname><given-names>Marc</given-names></name>
          <name><surname>Biggers</surname><given-names>Daniel R.</given-names></name>
          <name><surname>Hendry</surname><given-names>David J.</given-names></name>
        </person-group>
        <article-title>Can incarcerated felons be (re)integrated into the political system? Results from a field experiment</article-title>
        <source>American Journal of Political Science</source>
        <year iso-8601-date="2015">2015</year>
        <volume>59</volume>
        <issue>4</issue>
        <issn>1540-5907</issn>
        <uri>http://dx.doi.org/10.1111/ajps.12166</uri>
        <pub-id pub-id-type="doi">10.1111/ajps.12166</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-jones2015exploratory">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Jones</surname><given-names>Zachary M.</given-names></name>
          <name><surname>Linder</surname><given-names>Fridolin</given-names></name>
        </person-group>
        <article-title>Exploratory data analysis using random forests</article-title>
        <source>Proceedings of the 73rd annual MPSA conference</source>
        <year iso-8601-date="2015">2015</year>
        <uri>http://zmjones.com/static/papers/rfss_manuscript.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-jones2016there">
      <element-citation publication-type="manuscript">
        <person-group person-group-type="author">
          <name><surname>Jones</surname><given-names>Zachary M.</given-names></name>
          <name><surname>Lupu</surname><given-names>Yonatan</given-names></name>
        </person-group>
        <article-title>Is there more violence in the middle?</article-title>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-randomForest">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Liaw</surname><given-names>Andy</given-names></name>
          <name><surname>Wiener</surname><given-names>Matthew</given-names></name>
        </person-group>
        <article-title>Classification and regression by randomForest</article-title>
        <source>R News</source>
        <year iso-8601-date="2002">2002</year>
        <volume>2</volume>
        <issue>3</issue>
        <uri>http://CRAN.R-project.org/doc/Rnews/</uri>
      </element-citation>
    </ref>
    <ref id="ref-randomForestSRC">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Ishwaran</surname><given-names>H</given-names></name>
          <name><surname>Kogalur</surname><given-names>U</given-names></name>
        </person-group>
        <article-title>Random forests for survival, regression and classification (RF-SRC)</article-title>
        <source>URL http://cran.r-project.org/web/packages/randomForestSRC/. R package version</source>
        <year iso-8601-date="2013">2013</year>
        <volume>1</volume>
      </element-citation>
    </ref>
    <ref id="ref-party">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hothorn</surname><given-names>Torsten</given-names></name>
          <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
          <name><surname>Zeileis</surname><given-names>Achim</given-names></name>
        </person-group>
        <article-title>Unbiased recursive partitioning: A conditional inference framework</article-title>
        <source>Journal of Computational and Graphical statistics</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2006">2006</year>
        <volume>15</volume>
        <issue>3</issue>
        <uri>http://dx.doi.org/10.1198/106186006X133933</uri>
        <pub-id pub-id-type="doi">10.1198/106186006X133933</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

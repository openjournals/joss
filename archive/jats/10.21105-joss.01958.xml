<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1958</article-id>
<article-id pub-id-type="doi">10.21105/joss.01958</article-id>
<title-group>
<article-title>LFSpy: A Python Implementation of Local Feature Selection
for Data Classification with scikit-learn Compatibility</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-4849-732X</contrib-id>
<string-name>Kiret Dhindsa</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-5511-094X</contrib-id>
<string-name>Oliver Cook</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6213-2111</contrib-id>
<string-name>Thomas Mudway</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-4528-9146</contrib-id>
<string-name>Areeb Khawaja</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7922-0641</contrib-id>
<string-name>Ron Harwood</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8318-5714</contrib-id>
<string-name>Ranil Sonnadara</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Research and High Performance Computing, McMaster
University</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Vector Institute</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Surgery, McMaster University</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-12-12">
<day>12</day>
<month>12</month>
<year>2019</year>
</pub-date>
<volume>5</volume>
<issue>49</issue>
<fpage>1958</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Machine Learning</kwd>
<kwd>Feature Selection</kwd>
<kwd>Classification</kwd>
<kwd>Data Science</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="background">
  <title>Background</title>
  <p>Successful machine learning depends on inputting features, or
  variables, that provide information that is useful for solving the
  problem at hand. Supervised classification, where the goal is to label
  or categorize new data based on patterns identified in labeled
  training data, is the most commonly applied task in machine learning.
  For these problems, the features used to train a machine learning
  model must help discriminate between different categories of data
  samples. However, it is not always possible to know a priori which of
  the available features are informative, and which are not. The
  presence of uninformative features can contribute noise and reduce the
  robustness and performance of classification models. Therefore, an
  important step in machine learning is the selection of informative
  features and the omission of uninformative features.</p>
</sec>
<sec id="summary">
  <title>Summary</title>
  <p>Where typical feature selection methods find an optimal feature
  subset that is applied globally to all data samples, Local Feature
  Selection (LFS) finds optimal feature subsets for each local region of
  a data space. In this way, LFS is better able to adapt to regional
  variability and non-stationarity in a sample space. In addition, the
  method is paired with a simple classifier based on class similarity
  which can account for the fact that different samples may be modeled
  using different feature subsets.</p>
  <p>Local feature selection is performed by promoting class-wise
  clustering in the neighbourhood around each point, i.e., by finding
  the subset of available features that minimizes the average distance
  between points belonging to the same class, while maximizing the
  distances between classes. Thus, a feature subspace is identified that
  maximizes classifiability locally around each point. However, since
  this feature space can be different for each local region, standard
  classifiers cannot be readily applied. Instead, a notion of similarity
  between samples is introduced that intuitively lends itself to
  classification. Since LFS defines a local region for each sample, the
  regions are overlapping. Therefore, each point is represented in a
  number of feature spaces. Therefore, a class label can be assigned by
  accumulating the class labels of the nearest neighbours to a sample in
  each of these feature spaces. Full details of LFS, including
  experimental results demonstrating its effectiveness compared to other
  feature selection and classification methods on several datasets, are
  given in
  (<xref alt="Armanfard et al., 2015" rid="ref-ArmanfardU003A2015" ref-type="bibr">Armanfard
  et al., 2015</xref>) and
  (<xref alt="Armanfard et al., 2017" rid="ref-ArmanfardU003A2017" ref-type="bibr">Armanfard
  et al., 2017</xref>).</p>
  <p><monospace>LFSpy</monospace> was designed to be used for
  researchers working on any supervised learning problem, but is
  especially powerful for data that are non-stationary, non-ergodic, or
  that otherwise do not cluster well into classes. A prominant example
  of data with these properties is electroencephalography (EEG)
  time-series. In this field, LFS has been used to continuously detect
  characteristic brain responses to auditory stimuli in coma patients
  (<xref alt="Armanfard et al., 2018" rid="ref-ArmanfardU003A2019" ref-type="bibr">Armanfard
  et al., 2018</xref>), and is being tested for detection of traumatic
  brain injury
  (<xref alt="Boshra et al., 2019" rid="ref-BoshraU003A2019" ref-type="bibr">Boshra
  et al., 2019</xref>).</p>
</sec>
<sec id="usage">
  <title>Usage</title>
  <p><monospace>LFSpy</monospace> is a Python implementation of LFS that
  follows the <monospace>scikit-learn</monospace>
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikit-learn" ref-type="bibr">Pedregosa
  et al., 2011</xref>) class structure, and can therefore be used as
  part of a <monospace>scikit-learn</monospace> Pipeline like other
  classifiers. Open-source code, full documentation, and a demo using
  sample data are available at https://github.com/McMasterRS/LFSpy.
  Using LFS to train a model and test on new data is made simple with
  <monospace>LFSpy</monospace> and can be done in just a few lines of
  code. Usage follows the standard format used for
  <monospace>scikit-learn</monospace> classifiers. First, an LFS object
  is created to hold the model configuration, parameters, and once
  trained, the trained model itself. The implementation is flexible in
  that it gives the user control over a number of optional parameters,
  including for example, the size of the local region used for feature
  selection. The following training and testing functions can then be
  called from that object:</p>
  <list list-type="bullet">
    <list-item>
      <p><monospace>lfs.fit</monospace>: trains an LFS model given
      training data and corresponding training labels</p>
    </list-item>
    <list-item>
      <p><monospace>lfs.predict</monospace>: for a trained model,
      outputs class label predictions given testing data</p>
    </list-item>
    <list-item>
      <p><monospace>lfs.score</monospace>: outputs the classification
      error for the testing data in total, and by class, given testing
      data and ground truth testing labels</p>
    </list-item>
  </list>
  <p>Given training and testing data that are compatible with
  <monospace>scikit-learn</monospace> models, a typical example of model
  training and testing is as follows:</p>
  <code language="python">from LFSpy import LocalFeatureSelection
lfs = LocalFeatureSelection(alpha=19,
                            gamma=0.2,
                            tau=2,
                            sigma=1,
                            n_beta=20,
                            nrrp=2000,
                            knn=1)
lfs.fit(training_data, training_labels)
predicted_labels = lfs.predict(testing_data)
total_error, class_error = lfs.score(testing_data, testing_labels)</code>
  <p><monospace>LFSpy</monospace> is also fully compatible with the
  <monospace>scikit-learn</monospace> Pipeline method:</p>
  <code language="python">from LFSpy import LocalFeatureSelection
from sklearn.pipeline import Pipeline
lfs = LocalFeatureSelection(alpha=19,
                            gamma=0.2,
                            tau=2,
                            sigma=1,
                            n_beta=20,
                            nrrp=2000,
                            knn=1)
pipeline = Pipeline([('lfs', lfs)])
pipeline.fit(training_data, training_labels)
predicted_labels = pipeline.predict(testing_data)
total_error, class_error = pipeline.score(testing_data, testing_labels)</code>
  <p>The dependencies for <monospace>LFSpy</monospace> are as
  follows:</p>
  <list list-type="bullet">
    <list-item>
      <p>Python 3</p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://numpy.org/">NumPy</ext-link>&gt;=1.14</p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://www.scipy.org/">SciPy</ext-link>&gt;=1.1</p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/index.html">Scikit-learn</ext-link>&gt;=0.18.2</p>
    </list-item>
  </list>
</sec>
<sec id="comparison-to-other-classifiers">
  <title>Comparison to Other Classifiers</title>
  <p>A comparison of classification accuracies obtained with LFS and two
  standard <monospace>scikit-learn</monospace> pipelines are shown
  below. The Random Forest classifier (RFC) and a linear Support Vector
  Machine (SVM) with univariate feature selection using the F-statistic
  are used for comparison. For all tests, we use default settings. For
  consistency, none of the methods are provided with a priori
  information about the number of informative features to select. Both
  LFS and RFC choose the number of appropriate features internally. The
  SVM must be given a number of features to choose, so we set the number
  of features to 25% of the total number of available features for this
  example.</p>
  <p>Results are obtained with two sample datasets that are
  representative of the intended use case of LFS. The first is a sample
  dataset used to illustrate the utility of LFS. This dataset is
  synthetically generated with 100 training samples and 108 test
  samples. The number of informative vs. uninformative features in this
  dataset are unknown. The second dataset is the Iris dataset included
  with <monospace>scikit-learn</monospace>, which contains 100 samples
  and four features (50 are used for training, and 50 are used for
  testing; all four features are informative). To illustrate the value
  of LFS, we show the classification accuracy of each method after
  appending increasing numbers of up to 1000 non-informative Guassian
  features. Each feature was randomly generated with zero mean and a
  standard deviation between 0 and 3, sampled from a uniform
  distribution.</p>
  <p>It can be seen that with both datasets LFS outperforms the other
  two methods, particularly when the number of non-informative features
  becomes large. LFS remains relatively stable in classification
  performance, whereas RFC and SVM experience significant degradation as
  the number of non-informative features grows well past 100.</p>
  <sec id="classification-accuracies-with-the-sample-synthetic-dataset">
    <title>Classification accuracies with the sample synthetic
    dataset</title>
    <fig>
      <caption><p>Comparison of classification accuracies obtained with
      different classifiers using the sample synthetic dataset available
      with the LFSpy package.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="SampleData_Results.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="classification-accuracies-with-the-iris-dataset">
    <title>Classification accuracies with the Iris dataset</title>
    <fig>
      <caption><p>Comparison of classification accuracies obtained with
      different classifiers and increasing numbers of non-informative
      features using the Fisher Iris dataset available in
      <monospace>scikit-learn</monospace>.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="IrisData_Results.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="comparison-using-data-generated-with-scikit-learn">
    <title>Comparison using data generated with
    <monospace>scikit-learn</monospace></title>
    <p>For this comparison we use the same classifiers with the same
    configurations as described above, but instead make use of
    <monospace>make_classification</monospace> function in
    <monospace>scikit-learn</monospace>. This function provides us with
    more control so we can generate a dataset with properties that
    illustrate in more detail where <monospace>LFSpy</monospace> is
    particularly useful. In this example, we generate synthetic datasets
    to simulate a two-class classification problem with 50 samples (40
    used for training, and 10 used for testing). In total, 12 datasets
    are created with varying degrees of complexity introduced through
    different properties. First, each class can be distributed over one,
    two, or three clusters (i.e., if each class is represented by three
    clusters, then it is made up of three distinct distributions with
    different statistics). Four datasets are created within each of
    these cases: 1) a simple problem with 5 informative features and
    zero non-informative features, 2) five informative features with 40
    redundant features, (<monospace>r=40</monospace>) made up as
    combinations of the five informative features, 3) five informative
    features with 40 repeated features (<monospace>s=40</monospace>)
    made up as copies of the five redundant features, and 4) five
    informative features with 20 redundant features and 20 repeated
    features (<monospace>r=20, s=20</monospace>). All datasets were
    generated with 5% noisy labels (i.e., for 5% of the samples, the
    true class was assigned randomly), and a class separability of
    1.0.</p>
    <p>The results of this experiment, shown below, demonstrate how
    <monospace>LFSpy</monospace> can have an advantage in increasingly
    complex classification problems with large numbers of
    non-informative features of different kinds. In particular, its
    strategy of breaking up a classification problem into many small
    local problems instead of attempting to find a global solution
    allows LFS to perform well when each class is represented by
    multiple clusters with different statistics.</p>
    <fig>
      <caption><p>Comparison of classification accuracies obtained with
      different classifiers and different kinds of complexities using
      data generated with
      <monospace>scikit-learn.datasets.make_classification</monospace>.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="GenData_Results.png" xlink:title="" />
    </fig>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>Funding for this project was obtained through the CANARIE Research
  Software Program Local Support Initiative.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-ArmanfardU003A2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Armanfard</surname><given-names>Narges</given-names></name>
          <name><surname>Reilly</surname><given-names>James P</given-names></name>
          <name><surname>Komeili</surname><given-names>Majid</given-names></name>
        </person-group>
        <article-title>Local feature selection for data classification</article-title>
        <source>IEEE transactions on pattern analysis and machine intelligence</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>38</volume>
        <issue>6</issue>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2015.2478471</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-ArmanfardU003A2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Armanfard</surname><given-names>Narges</given-names></name>
          <name><surname>Reilly</surname><given-names>James P</given-names></name>
          <name><surname>Komeili</surname><given-names>Majid</given-names></name>
        </person-group>
        <article-title>Logistic localized modeling of the sample space for feature selection and classification</article-title>
        <source>IEEE transactions on neural networks and learning systems</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <volume>29</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1109/TNNLS.2017.2676101</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-scikit-learn">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-ArmanfardU003A2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Armanfard</surname><given-names>Narges</given-names></name>
          <name><surname>Komeili</surname><given-names>Majid</given-names></name>
          <name><surname>Reilly</surname><given-names>James P</given-names></name>
          <name><surname>Connoly</surname><given-names>John</given-names></name>
        </person-group>
        <article-title>A machine learning framework for automatic and continuous MMN detection with preliminary results for coma outcome prediction</article-title>
        <source>IEEE journal of biomedical and health informatics</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1109/JBHI.2018.2877738</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-BoshraU003A2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Boshra</surname><given-names>Rober</given-names></name>
          <name><surname>Dhindsa</surname><given-names>Kiret</given-names></name>
          <name><surname>Boursalie</surname><given-names>Omar</given-names></name>
          <name><surname>Ruiter</surname><given-names>Kyle I</given-names></name>
          <name><surname>Sonnadara</surname><given-names>Ranil</given-names></name>
          <name><surname>Samavi</surname><given-names>Reza</given-names></name>
          <name><surname>Doyle</surname><given-names>Thomas E</given-names></name>
          <name><surname>Reilly</surname><given-names>James P</given-names></name>
          <name><surname>Connolly</surname><given-names>John F</given-names></name>
        </person-group>
        <article-title>From group-level statistics to single-subject prediction: Machine learning detection of concussion in retired athletes</article-title>
        <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>27</volume>
        <issue>7</issue>
        <pub-id pub-id-type="doi">10.1109/TNSRE.2019.2922553</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3297</article-id>
<article-id pub-id-type="doi">10.21105/joss.03297</article-id>
<title-group>
<article-title>tfaip - a Generic and Powerful Research Framework for
Deep Learning based on Tensorflow</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3958-6240</contrib-id>
<string-name>Christoph Wick</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Benjamin Kühn</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Gundram Leifert</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Konrad Sperfeld</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Tobias Strauß</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3889-6629</contrib-id>
<string-name>Jochen Zöllner</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0031-4942</contrib-id>
<string-name>Tobias Grüning</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Planet AI GmbH, Warnowufer 60, 18059 Rostock,
Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Institute of Mathematics, University of Rostock, 18051
Rostock, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-03-29">
<day>29</day>
<month>3</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>62</issue>
<fpage>3297</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Deep Learning</kwd>
<kwd>Tensorflow</kwd>
<kwd>Keras</kwd>
<kwd>Research</kwd>
<kwd>High-Level Framework</kwd>
<kwd>Generic</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><italic>tfaip</italic> is a Python-based research framework for
  developing, structuring, and deploying Deep Learning projects powered
  by Tensorflow
  (<xref alt="Abadi et al., 2015" rid="ref-tensorflow2015-whitepaper" ref-type="bibr">Abadi
  et al., 2015</xref>) and is intended for scientists of universities or
  organizations who research, develop, and optionally deploy Deep
  Learning models. <italic>tfaip</italic> enables both simple and
  complex implementation scenarios, such as image classification, object
  detection, text recognition, natural language processing, or speech
  recognition. Each scenario is highly configurable by parameters that
  can directly be modified by the command line or the API.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The implementation of a scenario during research and development
  typically comprises several tasks, for example setting up the graph
  (e.g., the network architecture), the training (e.g., the optimizer or
  learning rate schedule), and the data pipeline (e.g., the data
  sources). In most current frameworks such as Tensorflow or Keras (see
  next Section), the implementation is realized by one or several
  (unstructured) files in Python which can become difficult to maintain
  and read for bigger scenarios. Furthermore, comparable frameworks also
  only provide basic functionality which is why recurrent obstacles
  during research and development are typically redundant for each
  scenario. <italic>tfaip</italic> resolves the following different
  aspects in an elegant and robust way.</p>
  <p>During research, a scenario is usually configured via a command
  line interface (CLI) which usually must be implemented by the user
  itself. <italic>tfaip</italic> already provides a powerful CLI which
  is dynamically created upon runtime by parsing a nested dataclass
  hierarchy. To add a new parameter or even a new set of sub parameters,
  a user simply has to add a new field to the respective dataclass.
  Compared to other approached where all possible parameters are
  simultaneously available in the CLI, the dynamic approach of
  <italic>tfaip</italic> only shows the available arguments. This
  prevents users from making mistakes by setting parameters without
  effect for the current configuration (e.g., setting the factor for an
  Adam optimizer even though RMSprop was selected). The default CLI of
  <italic>tfaip</italic> provides commands to adapt various
  hyper-parameters such as the learning rate and its schedule, the
  optimizer, logging, debugging, profiling, or early stopping.
  Furthermore, each component of the scenario can itself be fully
  customized which allows, for example, to dynamically configure the
  network architecture, e.g., by inserting layers or changing their
  parameters. This feature helps researchers to set up various
  experiments for example to optimize hyper-parameters or test novel
  ideas.</p>
  <p>In comparison to other frameworks such as Tensorflow,
  <italic>tfaip</italic> requires users to implement their scenarios in
  an object-oriented way and encourages them to annotate their code with
  types. This is particularly advantageous for larger, more complex
  scenarios where the codebase grows accordingly. Using
  <italic>tfaip</italic> leads to a clean, structured, modularized, and
  readable code limiting poor coding styles and facilitating
  maintenance. In practice, each scenario is created by implementing
  predefined interfaces (e.g., loss-function or the graph
  construction).</p>
  <p>During research and development, a tedious step is data preparation
  which often comprises the conversion of data into the format required
  by the framework. The Tensorflow-backed <italic>tfaip</italic> allows
  integrating Python code in the data pipeline which is however not run
  (truly) in parallel by multiple processes and results quite often in a
  bottleneck. To speed-up Tensorflow, a user has to transform Python
  into Tensorflow operations which is laborious, and sometimes even
  impossible, and complicates debugging. <italic>tfaip</italic> tackles
  this issue by providing a sophisticated pipeline setup based on “data
  processors” which apply simple transformation operations in pure
  Python code and are automatically executed in parallel.</p>
  <p>Another important step which is simplified by
  <italic>tfaip</italic> is the deployment of a scenario. Other
  frameworks such as plain Tensorflow or Keras allow to easily load a
  trained model for prediction which does however not include data
  processing. The prediction API of <italic>tfaip</italic> instead
  automatically applies pre-processing, infer the trained model, and
  optionally transform the output by a post-processing pipeline in one
  step. The information about the pipeline-construction is embedded
  within the model which enables to store and load models with a
  different data pipeline even for the same scenario. This is handy if,
  for example, certain pre-processing steps are not required for one
  specific model or other inputs are expected.</p>
  <p>Finally, <italic>tfaip</italic> will automatically log the training
  process using the Tensorboard and provides utility scripts to resume a
  crashed or stopped training, or to set up an array of training
  configurations via an Excel sheet.</p>
</sec>
<sec id="state-of-the-field">
  <title>State of the Field</title>
  <p>Efficient research in the area of Deep Learning requires the
  integration of highly sophisticated Open-Source frameworks such as
  Tensorflow
  (<xref alt="Abadi et al., 2015" rid="ref-tensorflow2015-whitepaper" ref-type="bibr">Abadi
  et al., 2015</xref>), PyTorch
  (<xref alt="Paszke et al., 2019" rid="ref-pytorch_2019" ref-type="bibr">Paszke
  et al., 2019</xref>), Caffe
  (<xref alt="Jia et al., 2014" rid="ref-jia2014caffe" ref-type="bibr">Jia
  et al., 2014</xref>), CNTK
  (<xref alt="Seide &amp; Agarwal, 2016" rid="ref-cntk2016" ref-type="bibr">Seide
  &amp; Agarwal, 2016</xref>), or Trax
  (<xref alt="Google Inc., 2021" rid="ref-trax2021" ref-type="bibr">Google
  Inc., 2021</xref>). These frameworks provide efficient tools to freely
  design Deep Learning scenario of any size and complexity. However, as
  the number of lines of code grows, a project has to be structured into
  meaningful components to be maintainable. These components are almost
  identical for each Deep Learning scenario: there are modules for the
  graph, the model, the data, the training, the validation, and the
  prediction (i.e., the application of a trained model). Furthermore,
  support for dynamic parameter adaption for instance via the command
  line is desirable for efficient research. Therefore, to obtain a clean
  code base, it is highly desirable to only implement abstract templates
  that already set up the interaction among the modules by providing
  basic functionality that is required in any use-case.
  <italic>tfaip</italic> which is an extension to Tensorflow solves this
  and thus helps developers to efficiently handle and maintain small but
  also large-scale projects in research environments.</p>
  <p>Recently, several AutoML approaches have emerged, e.g., by Google
  Cloud or Microsoft Azure. AutoML targets developers with limited
  machine learning expertise and enables them to train their own models
  by automating processes like network construction, feature
  engineering, or hyperparameter tuning. In contrast,
  <italic>tfaip</italic> targets researchers with expertise in deep
  learning who actually design new network architectures, data
  processing pipelines, and setup training, but with only limited
  experience in or capacity for software engineering.
  <italic>tfaip</italic> helps to structure and maintain the code bases,
  and hereby also solves some recurrent problems that will likely occur
  during development (see next Section).</p>
</sec>
<sec id="tfaip-functionality">
  <title><italic>tfaip</italic> Functionality</title>
  <p>In the following, we highlight the main functionality of
  <italic>tfaip</italic>.</p>
  <p>A basic concept of <italic>tfaip</italic> is to split parameters
  and their actual object whereby the parameters are used to instantiate
  the corresponding object. This allows to build a hierarchical
  parameter tree where each node can be replaced with other parameters.
  Each parameter and also the replacements can be defined via the
  command line which enables to dynamically adapt, for example, even
  complete graphs of a model. In a research environment this simplifies
  hyper-parameter search and the setup of experiments.</p>
  <p>Class-templates define the logical structure of a real-world
  scenario. Each scenario requires the definition of a model and a data
  class whereby basic functionality such as training, exporting, or
  loading of a model using the data is already provided.</p>
  <p>To set up the data pipeline, a data generator and a list of data
  processors have to be implemented that define how raw data flows. The
  prepared data is then automatically fed into the neural network. Since
  each data processor is written in pure Python, it is simple to set up
  and debug the data processing pipeline. To speed up the data sample
  generation the pipeline can automatically be run in parallel.</p>
  <p>The model comprises information about the loss, metrics, and the
  graph of the scenario. Its template hereby requires the user to
  implement methods, the superordinate modules are then connected
  automatically.</p>
  <p><italic>tfaip</italic> tracks the training and validation process
  by utilizing the Tensorboard provided by Tensorflow. The Tensorboard
  can be extended by custom data, for example by plotting
  Precision-Recall (PR) curves or rendering images.</p>
  <p>The prediction module loads a trained scenario so that it can
  easily be applied on new data during deployment. Since a model stores
  its pre- and post-processing pipeline no additional data handling has
  to be performed.</p>
  <p>Because each scenario follows a predefined setup, shared research
  code is clearer and consequently can be easier reviewed, extended, or
  applied. For example, this modularity simplifies the process if
  several users are working together on the same scenario.</p>
  <p>An important feature of <italic>tfaip</italic> is the consistent
  use of Python’s typing module including type checks. This leads to
  clean understandable code and fewer errors during development.
  Furthermore, this enables IDEs such as PyCharm
  (<xref alt="JetBrains, 2021" rid="ref-pycharm2021" ref-type="bibr">JetBrains,
  2021</xref>) to perform autocompletion.</p>
  <p>In some rare cases, the highly generic API of
  <italic>tfaip</italic> might not be sufficient. To tackle this, each
  scenario can optionally customize any functionality by implementing
  the base classes, for example the trainer or the data pipeline.</p>
</sec>
<sec id="tfaip-documentation-and-tutorials">
  <title><italic>tfaip</italic> Documentation and Tutorials</title>
  <p>To help new users to become familiar with <italic>tfaip</italic>, a
  comprehensive documentation, several tutorials, and example scenarios
  with real-world use-cases are available. First, <italic>tfaip</italic>
  provides two tutorials that solve the classification of MNIST: the
  <italic>minimal</italic> scenario shows the minimal implementation
  that is required to implement the common MNIST-tutorial in
  <italic>tfaip</italic>, the <italic>full</italic> scenario implements
  the same use-case and highlights different advanced features of
  <italic>tfaip</italic>.</p>
  <p>Some more examples are provided by transferring official Tensorflow
  tutorials in the <italic>tfaip</italic> framework. These scenarios
  show the power of the framework as complex scenarios are logically
  split into meaningful parts and components. The examples comprise
  Automatic Text Recognition (ATR) of single text line images, Image
  Classification, and Fine Tuning of a BERT.</p>
  <p>Finally, templates for two basic scenarios allow setting up a new
  scenario by copying basic code and modifying it afterwards. All
  required files and classes are already set up, solely the abstract
  methods have to be implemented and classes should be renamed.</p>
</sec>
<sec id="usage-of-tfaip-in-research">
  <title>Usage of <italic>tfaip</italic> in Research</title>
  <p>Diverse active research projects are already based on
  <italic>tfaip</italic>. Zöllner et al.
  (<xref alt="2021" rid="ref-zoellner2021" ref-type="bibr">2021</xref>)
  integrated <italic>tfaip</italic> to solve Natural Language Processing
  (NLP) problems. Since its 2.0 release, the open-source ATR engine
  Calamari by Wick et al.
  (<xref alt="2020" rid="ref-wick_calamari_2020" ref-type="bibr">2020</xref>)
  is based on <italic>tfaip</italic>. Our research, for example a recent
  publication on ATR using Transformers, uses <italic>tfaip</italic>
  (<xref alt="Wick et al., 2021" rid="ref-wick_bidirectional_2021" ref-type="bibr">Wick
  et al., 2021</xref>).</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>The authors would like to thank the open-source community,
  especially the developers and maintainers of Python, Tensorflow, and
  Numpy, since these packages empower <italic>tfaip</italic>.</p>
  <p>This work was partially funded by the European Social Fund (ESF)
  and the Ministry of Education, Science and Culture of
  Mecklenburg-Western Pomerania (Germany) within the project NEISS under
  grant no ESF/14-BM-A55-0006/19.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-wick_calamari_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wick</surname><given-names>Christoph</given-names></name>
          <name><surname>Reul</surname><given-names>Christian</given-names></name>
          <name><surname>Puppe</surname><given-names>Frank</given-names></name>
        </person-group>
        <article-title>Calamari - A High-Performance Tensorflow-based Deep Learning Package for Optical Character Recognition</article-title>
        <source>Digital Humanities Quarterly</source>
        <year iso-8601-date="2020">2020</year>
        <volume>14</volume>
        <issue>1</issue>
      </element-citation>
    </ref>
    <ref id="ref-wick_bidirectional_2021">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Wick</surname><given-names>Christoph</given-names></name>
          <name><surname>Zöllner</surname><given-names>Jochen</given-names></name>
          <name><surname>Grüning</surname><given-names>Tobias</given-names></name>
        </person-group>
        <article-title>Bidirectional Transformer for Handwritten Text Recognition</article-title>
        <source>16th International Conference on Document Analysis and Recognition (ICDAR)</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2021">2021</year>
        <volume>accepted for</volume>
      </element-citation>
    </ref>
    <ref id="ref-tensorflow2015-whitepaper">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Abadi</surname><given-names>Martı́n</given-names></name>
          <name><surname>Agarwal</surname><given-names>Ashish</given-names></name>
          <name><surname>Barham</surname><given-names>Paul</given-names></name>
          <name><surname>Brevdo</surname><given-names>Eugene</given-names></name>
          <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>
          <name><surname>Citro</surname><given-names>Craig</given-names></name>
          <name><surname>Corrado</surname><given-names>Greg S.</given-names></name>
          <name><surname>Davis</surname><given-names>Andy</given-names></name>
          <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
          <name><surname>Devin</surname><given-names>Matthieu</given-names></name>
          <name><surname>Ghemawat</surname><given-names>Sanjay</given-names></name>
          <name><surname>Goodfellow</surname><given-names>Ian</given-names></name>
          <name><surname>Harp</surname><given-names>Andrew</given-names></name>
          <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
          <name><surname>Isard</surname><given-names>Michael</given-names></name>
          <name><surname>Jia</surname><given-names>Yangqing</given-names></name>
          <name><surname>Jozefowicz</surname><given-names>Rafal</given-names></name>
          <name><surname>Kaiser</surname><given-names>Lukasz</given-names></name>
          <name><surname>Kudlur</surname><given-names>Manjunath</given-names></name>
          <name><surname>Levenberg</surname><given-names>Josh</given-names></name>
          <name><surname>Mané</surname><given-names>Dandelion</given-names></name>
          <name><surname>Monga</surname><given-names>Rajat</given-names></name>
          <name><surname>Moore</surname><given-names>Sherry</given-names></name>
          <name><surname>Murray</surname><given-names>Derek</given-names></name>
          <name><surname>Olah</surname><given-names>Chris</given-names></name>
          <name><surname>Schuster</surname><given-names>Mike</given-names></name>
          <name><surname>Shlens</surname><given-names>Jonathon</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>
          <name><surname>Talwar</surname><given-names>Kunal</given-names></name>
          <name><surname>Tucker</surname><given-names>Paul</given-names></name>
          <name><surname>Vanhoucke</surname><given-names>Vincent</given-names></name>
          <name><surname>Vasudevan</surname><given-names>Vijay</given-names></name>
          <name><surname>Viégas</surname><given-names>Fernanda</given-names></name>
          <name><surname>Vinyals</surname><given-names>Oriol</given-names></name>
          <name><surname>Warden</surname><given-names>Pete</given-names></name>
          <name><surname>Wattenberg</surname><given-names>Martin</given-names></name>
          <name><surname>Wicke</surname><given-names>Martin</given-names></name>
          <name><surname>Yu</surname><given-names>Yuan</given-names></name>
          <name><surname>Zheng</surname><given-names>Xiaoqiang</given-names></name>
        </person-group>
        <article-title>TensorFlow: Large-scale machine learning on heterogeneous systems</article-title>
        <year iso-8601-date="2015">2015</year>
        <uri>https://www.tensorflow.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-pytorch_2019">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Paszke</surname><given-names>Adam</given-names></name>
          <name><surname>Gross</surname><given-names>Sam</given-names></name>
          <name><surname>Massa</surname><given-names>Francisco</given-names></name>
          <name><surname>Lerer</surname><given-names>Adam</given-names></name>
          <name><surname>Bradbury</surname><given-names>James</given-names></name>
          <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
          <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
          <name><surname>Lin</surname><given-names>Zeming</given-names></name>
          <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
          <name><surname>Antiga</surname><given-names>Luca</given-names></name>
          <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
          <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
          <name><surname>Yang</surname><given-names>Edward</given-names></name>
          <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
          <name><surname>Raison</surname><given-names>Martin</given-names></name>
          <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
          <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Fang</surname><given-names>Lu</given-names></name>
          <name><surname>Bai</surname><given-names>Junjie</given-names></name>
          <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
        </person-group>
        <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
        <source>Advances in neural information processing systems 32</source>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <uri>http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-jia2014caffe">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jia</surname><given-names>Yangqing</given-names></name>
          <name><surname>Shelhamer</surname><given-names>Evan</given-names></name>
          <name><surname>Donahue</surname><given-names>Jeff</given-names></name>
          <name><surname>Karayev</surname><given-names>Sergey</given-names></name>
          <name><surname>Long</surname><given-names>Jonathan</given-names></name>
          <name><surname>Girshick</surname><given-names>Ross</given-names></name>
          <name><surname>Guadarrama</surname><given-names>Sergio</given-names></name>
          <name><surname>Darrell</surname><given-names>Trevor</given-names></name>
        </person-group>
        <article-title>Caffe: Convolutional architecture for fast feature embedding</article-title>
        <source>arXiv preprint arXiv:1408.5093</source>
        <year iso-8601-date="2014">2014</year>
      </element-citation>
    </ref>
    <ref id="ref-cntk2016">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Seide</surname><given-names>Frank</given-names></name>
          <name><surname>Agarwal</surname><given-names>Amit</given-names></name>
        </person-group>
        <article-title>CNTK: Microsoft’s open-source deep-learning toolkit</article-title>
        <year iso-8601-date="2016-08">2016</year><month>08</month>
        <pub-id pub-id-type="doi">10.1145/2939672.2945397</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-trax2021">
      <element-citation>
        <person-group person-group-type="author">
          <string-name>Google Inc.</string-name>
        </person-group>
        <article-title>Trax</article-title>
        <source>GitHub repository</source>
        <publisher-name>https://github.com/google/trax; GitHub</publisher-name>
        <year iso-8601-date="2021">2021</year>
      </element-citation>
    </ref>
    <ref id="ref-pycharm2021">
      <element-citation>
        <person-group person-group-type="author">
          <string-name>JetBrains</string-name>
        </person-group>
        <article-title>PyCharm</article-title>
        <publisher-name>https://jetbrains.com/pycharm</publisher-name>
        <year iso-8601-date="2021">2021</year>
      </element-citation>
    </ref>
    <ref id="ref-zoellner2021">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zöllner</surname><given-names>Jochen</given-names></name>
          <name><surname>Sperfeld</surname><given-names>Konrad</given-names></name>
          <name><surname>Wick</surname><given-names>Christoph</given-names></name>
          <name><surname>Labahn</surname><given-names>Roger</given-names></name>
        </person-group>
        <article-title>Optimizing small BERTs trained for german NER</article-title>
        <source>Computational Linguistics</source>
        <year iso-8601-date="2021">2021</year>
        <volume>submitted to</volume>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

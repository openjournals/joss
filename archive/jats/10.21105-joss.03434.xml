<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3434</article-id>
<article-id pub-id-type="doi">10.21105/joss.03434</article-id>
<title-group>
<article-title>Sync Toolbox: A Python Package for Efficient, Robust, and
Accurate Music Synchronization</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6062-7524</contrib-id>
<string-name>Meinard Müller</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2235-8655</contrib-id>
<string-name>Yigitcan Özer</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7194-0719</contrib-id>
<string-name>Michael Krause</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Thomas Prätzlich</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Jonathan Driedger</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>International Audio Laboratories Erlangen</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-06-01">
<day>1</day>
<month>6</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>64</issue>
<fpage>3434</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Music information retrieval</kwd>
<kwd>Music synchronization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Music can be described and represented in many different ways,
  including as sheet music, symbolic representations, and audio
  recordings
  (<xref alt="Müller, 2015" rid="ref-Mueller15_FMP_SPRINGER" ref-type="bibr">Müller,
  2015</xref>). For each of these representations, different versions
  (e.g., recordings performed by different orchestras and conductors)
  that correspond to the same musical work may exist. Music information
  retrieval (MIR) aims at developing techniques and tools for
  organizing, understanding, and searching this information in a robust,
  efficient, and intelligent manner. In this context, various alignment
  and synchronization procedures have been developed with the common
  goal of automatically linking several types of music representations,
  thus coordinating the multiple information sources related to a given
  musical work. In the design and implementation of synchronization
  algorithms, one has to deal with a delicate tradeoff between
  efficiency, robustness, and accuracy—requirements leading to various
  approaches with many design choices. In this contribution, we
  introduce a Python package called <italic>Sync Toolbox</italic> that
  provides open-source reference implementations for full-fledged music
  synchronization pipelines and yields state-of-the-art alignment
  results for a wide range of Western music. Using suitable feature
  representations and cost measures, the toolbox’s core technology is
  based on <italic>dynamic time warping</italic> (DTW), which brings the
  feature sequences into temporal correspondence. To account for
  efficiency, robustness and, accuracy, our toolbox integrates and
  combines techniques such as multiscale DTW (MsDTW)
  (<xref alt="Müller et al., 2006" rid="ref-MuellerMK06_EfficientMultiscaleApproach_ISMIR" ref-type="bibr">Müller
  et al., 2006</xref>;
  <xref alt="Salvador &amp; Chan, 2004" rid="ref-SalvadorC04_fastDTW" ref-type="bibr">Salvador
  &amp; Chan, 2004</xref>), memory-restricted MsDTW (MrMsDTW)
  (<xref alt="Prätzlich et al., 2016" rid="ref-PraetzlichDM16_MsDTW_ICASSP" ref-type="bibr">Prätzlich
  et al., 2016</xref>), and high-resolution music synchronization
  (<xref alt="Ewert et al., 2009" rid="ref-EwertMG09_HighResAudioSync_ICASSP" ref-type="bibr">Ewert
  et al., 2009</xref>). While realizing a complete system with presets
  that allow users to reproduce research results from the literature,
  our toolbox also provides well-documented functions for all basic
  building blocks required for feature extraction and alignment.
  Furthermore, the toolbox contains example code for visualizing,
  sonifying, and evaluating synchronization results, thus deepening the
  understanding of the techniques and data.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The task of finding an alignment between two feature sequences has
  received a large amount of research interest in the past, in the
  context of MIR and beyond. In the music domain, alignment techniques
  are central for applications such as score following, content-based
  retrieval, automatic accompaniment, and performance analysis
  (<xref alt="Arzt, 2016" rid="ref-Arzt16_MusicTracking_PhD" ref-type="bibr">Arzt,
  2016</xref>;
  <xref alt="Müller, 2015" rid="ref-Mueller15_FMP_SPRINGER" ref-type="bibr">Müller,
  2015</xref>). Beyond these classical applications, alignment
  techniques have gained in importance in view of recent data-driven
  machine learning techniques. In particular, music synchronization has
  shown the potential for facilitating data annotation, data
  augmentation, and model evaluation. To be more specific, for certain
  types of music one often has a score-like symbolic representation that
  explicitly encodes information such as note events, measure positions,
  lyrics, and other types of metadata. Furthermore, music experts often
  provide their harmonic, structural, or rhythmic analyses using such
  symbolic reference representations. Music synchronization techniques
  then allow for (semi-)automatically transferring these manually
  generated annotations from the reference to other symbolic or audio
  representations. This is particularly beneficial for music, where one
  has many recorded performances of a given piece. Thus, using music
  synchronization techniques, one may simplify the annotation process
  and substantially increase the number of annotated training and test
  versions. For example, in Zalkow et al.
  (<xref alt="2017" rid="ref-ZalkowWPAM17_MeasureTransfer_AES" ref-type="bibr">2017</xref>),
  a multi-version approach for transferring measure annotations between
  music recordings (Wagner operas) is described. The “Schubert
  Winterreise Dataset” provides another example where automated
  techniques were applied to transfer measure, chord, local key,
  structure, and lyrics annotations
  (<xref alt="Weiß et al., 2021" rid="ref-WeissZAGKVM20_WinterreiseDataset_ACM-JOCCH" ref-type="bibr">Weiß
  et al., 2021</xref>). Including nine performances (versions) of
  Schubert’s song cycle, this cross-version dataset was used in Weiß et
  al.
  (<xref alt="2020" rid="ref-WeissSM20_LocalKey_TASLP" ref-type="bibr">2020</xref>)
  for training and evaluating data-driven approaches for local key
  estimation, where the different dataset splits across songs and
  performances provided new insights into the algorithms’ generalization
  capabilities.</p>
  <p>Being a central task, there are a many software packages for
  sequence alignment of general time series. In the audio domain, the
  librosa Python package by McFee et al.
  (<xref alt="2015" rid="ref-McFeeRLEMBN15_librosa_Python" ref-type="bibr">2015</xref>)
  offers a basic DTW-based pipeline for synchronizing music recordings.
  Since the complexity of alignment techniques such as DTW is
  proportional to the product of the feature sequences’ lengths, runtime
  and memory requirements become issues when dealing with long feature
  sequences. Using a fast online time warping (OLTW) algorithm as
  described by Dixon &amp; Widmer
  (<xref alt="2005" rid="ref-DixonW05_MATCH_ISMIR" ref-type="bibr">2005</xref>),
  the software <xref ref-type="fn" rid="fn1">1</xref> (Music Alignment
  Tool CHest) allows for an efficient alignment of audio files. While
  being efficient, such online approaches are prone to local deviations
  in the sequences to be aligned. An efficient yet robust alternative is
  offered by offline procedures based on multiscale strategies such as
  MsDTW
  (<xref alt="Müller et al., 2006" rid="ref-MuellerMK06_EfficientMultiscaleApproach_ISMIR" ref-type="bibr">Müller
  et al., 2006</xref>;
  <xref alt="Salvador &amp; Chan, 2004" rid="ref-SalvadorC04_fastDTW" ref-type="bibr">Salvador
  &amp; Chan, 2004</xref>). The recent Python package linmdtw
  <xref ref-type="fn" rid="fn2">2</xref> contains an implementation of
  MsDTW as well as a linear memory DTW variant described in Tralie &amp;
  Dempsey
  (<xref alt="2020" rid="ref-TralieD20_DTW_ISMIR" ref-type="bibr">2020</xref>).
  Another important issue in music synchronization is the temporal
  accuracy of the alignments, which may be achieved by considering
  additional local cues such as onset features
  (<xref alt="Ewert et al., 2009" rid="ref-EwertMG09_HighResAudioSync_ICASSP" ref-type="bibr">Ewert
  et al., 2009</xref>). Improving the accuracy, however, often goes
  along with an increase in computational complexity and a decrease in
  overall robustness.</p>
  <p>With our <italic>Sync Toolbox</italic>, we offer a Python package
  that provides all components needed to realize a music synchronization
  pipeline that is robust, efficient, and accurate. First, to account
  for robustness and efficiency, it implements the memory-restricted
  MsDTW approach from Prätzlich et al.
  (<xref alt="2016" rid="ref-PraetzlichDM16_MsDTW_ICASSP" ref-type="bibr">2016</xref>)
  as its algorithmic core component. Second, to account for accuracy, it
  integrates the high-resolution strategy from Ewert et al.
  (<xref alt="2009" rid="ref-EwertMG09_HighResAudioSync_ICASSP" ref-type="bibr">2009</xref>)
  in the finest MsDTW layer. Third, the toolbox contains all feature
  extractions methods (including chroma and onset features) needed to
  reproduce the results from the research literature. Fourth, we also
  provide functions required for quantitative and qualitative
  evaluations (including visualization and sonification methods). Even
  though it overlaps the previously mentioned software (e.g., librosa
  and linmdtw), the Sync Toolbox provides, for the first time, an
  open-source Python package for offline music synchronization that
  produces state-of-the-art alignment results regarding efficiency and
  accuracy. Thus, with the publicly available and well-documented Sync
  Toolbox, we hope to fill a gap between theory and practice for an
  important MIR task, while providing a useful pre-processing,
  annotation, and evaluation tool for data-driven machine learning.</p>
</sec>
<sec id="design-choices">
  <title>Design Choices</title>
  <p>When we designed the Sync Toolbox, we had a number of different
  objectives in mind. First, we tried to keep a close connection to the
  research articles by Ewert et al.
  (<xref alt="2009" rid="ref-EwertMG09_HighResAudioSync_ICASSP" ref-type="bibr">2009</xref>)
  and Prätzlich et al.
  (<xref alt="2016" rid="ref-PraetzlichDM16_MsDTW_ICASSP" ref-type="bibr">2016</xref>).
  Second, we reimplemented and included all required components (e.g.,
  feature extractors, DTW), even though such basic functionality is also
  covered by other packages such as librosa and linmdtw. This way, along
  with a specification of meaningful variable presets, the Sync Toolbox
  provides reference implementations that can exactly reproduce
  previously published research results and experiments. Third, we
  followed many of the design principles suggested by librosa
  (<xref alt="McFee et al., 2015" rid="ref-McFeeRLEMBN15_librosa_Python" ref-type="bibr">McFee
  et al., 2015</xref>), which allows users to easily combine the
  different Python packages. The Sync Toolbox code along with API
  documentation is hosted in a publicly available GitHub repository.
  <xref ref-type="fn" rid="fn3">3</xref> Finally, we included the
  synctoolbox package in the Python package index PyPI, which makes it
  possible to install synctoolbox with the standard Python package
  manager pip. <xref ref-type="fn" rid="fn4">4</xref></p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The synctoolbox package builds on results, material, and insights
  that have been obtained in close collaboration with different people.
  We would like to express our gratitude to former and current students,
  collaborators, and colleagues who have influenced and supported us in
  creating this package, including Vlora Arifi-Müller, Michael Clausen,
  Sebastian Ewert, Christian Fremerey, and Frank Kurth. We also thank
  the German Research Foundation (DFG) for various research grants that
  allowed us for conducting fundamental research in music processing (in
  particular, MU 2686/7-2, DFG-MU 2686/14-1). The International Audio
  Laboratories Erlangen are a joint institution of the
  Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU) and Fraunhofer
  Institute for Integrated Circuits IIS.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Mueller15_FMP_SPRINGER">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
        </person-group>
        <source>Fundamentals of music processing</source>
        <publisher-name>Springer Verlag</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1007/978-3-319-21945-5</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-MuellerMK06_EfficientMultiscaleApproach_ISMIR">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
          <name><surname>Mattes</surname><given-names>Henning</given-names></name>
          <name><surname>Kurth</surname><given-names>Frank</given-names></name>
        </person-group>
        <article-title>An efficient multiscale approach to audio synchronization</article-title>
        <source>Proceedings of the international society for music information retrieval conference (ISMIR)</source>
        <publisher-loc>Victoria, Canada</publisher-loc>
        <year iso-8601-date="2006-10">2006</year><month>10</month>
      </element-citation>
    </ref>
    <ref id="ref-SalvadorC04_fastDTW">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Salvador</surname><given-names>Stan</given-names></name>
          <name><surname>Chan</surname><given-names>Philip</given-names></name>
        </person-group>
        <article-title>FastDTW: Toward accurate dynamic time warping in linear time and space</article-title>
        <source>Proceedings of the KDD workshop on mining temporal and sequential data</source>
        <year iso-8601-date="2004">2004</year>
      </element-citation>
    </ref>
    <ref id="ref-PraetzlichDM16_MsDTW_ICASSP">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Prätzlich</surname><given-names>Thomas</given-names></name>
          <name><surname>Driedger</surname><given-names>Jonathan</given-names></name>
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
        </person-group>
        <article-title>Memory-restricted multiscale dynamic time warping</article-title>
        <source>Proceedings of the IEEE international conference on acoustics, speech, and signal processing (ICASSP)</source>
        <publisher-loc>Shanghai, China</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1109/ICASSP.2016.7471739</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-EwertMG09_HighResAudioSync_ICASSP">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Ewert</surname><given-names>Sebastian</given-names></name>
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
          <name><surname>Grosche</surname><given-names>Peter</given-names></name>
        </person-group>
        <article-title>High resolution audio synchronization using chroma onset features</article-title>
        <source>Proceedings of IEEE international conference on acoustics, speech, and signal processing (ICASSP)</source>
        <publisher-loc>Taipei, Taiwan</publisher-loc>
        <year iso-8601-date="2009-04">2009</year><month>04</month>
        <isbn>978-1-4244-2354-5</isbn>
        <issn>1520-6149</issn>
        <pub-id pub-id-type="doi">10.1109/icassp.2009.4959972</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Arzt16_MusicTracking_PhD">
      <element-citation publication-type="thesis">
        <person-group person-group-type="author">
          <name><surname>Arzt</surname><given-names>Andreas</given-names></name>
        </person-group>
        <article-title>Flexible and robust music tracking</article-title>
        <publisher-name>Universität Linz</publisher-name>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-ZalkowWPAM17_MeasureTransfer_AES">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Zalkow</surname><given-names>Frank</given-names></name>
          <name><surname>Weiß</surname><given-names>Christof</given-names></name>
          <name><surname>Prätzlich</surname><given-names>Thomas</given-names></name>
          <name><surname>Arifi-Müller</surname><given-names>Vlora</given-names></name>
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
        </person-group>
        <article-title>A multi-version approach for transferring measure annotations between music recordings</article-title>
        <source>Proceedings of the AES international conference on semantic audio</source>
        <publisher-loc>Erlangen, Germany</publisher-loc>
        <year iso-8601-date="2017">2017</year>
      </element-citation>
    </ref>
    <ref id="ref-WeissZAGKVM20_WinterreiseDataset_ACM-JOCCH">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Weiß</surname><given-names>Christof</given-names></name>
          <name><surname>Zalkow</surname><given-names>Frank</given-names></name>
          <name><surname>Arifi-Müller</surname><given-names>Vlora</given-names></name>
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
          <name><surname>Koops</surname><given-names>Hendrik Vincent</given-names></name>
          <name><surname>Volk</surname><given-names>Anja</given-names></name>
          <name><surname>Grohganz</surname><given-names>Harald G.</given-names></name>
        </person-group>
        <article-title>Schubert Winterreise dataset: A multimodal scenario for music analysis</article-title>
        <source>ACM Journal on Computing and Cultural Heritage (JOCCH)</source>
        <year iso-8601-date="2021">2021</year>
        <volume>14</volume>
        <issue>2</issue>
        <uri>https://dl.acm.org/doi/10.1145/3429743</uri>
        <pub-id pub-id-type="doi">10.1145/3429743</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-WeissSM20_LocalKey_TASLP">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Weiß</surname><given-names>Christof</given-names></name>
          <name><surname>Schreiber</surname><given-names>Hendrik</given-names></name>
          <name><surname>Müller</surname><given-names>Meinard</given-names></name>
        </person-group>
        <article-title>Local key estimation in music recordings: A case study across songs, versions, and annotators</article-title>
        <source>IEEE/ACM Transactions on Audio, Speech &amp; Language Processing</source>
        <year iso-8601-date="2020">2020</year>
        <volume>28</volume>
        <issue></issue>
        <pub-id pub-id-type="doi">10.1109/TASLP.2020.3030485</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-McFeeRLEMBN15_librosa_Python">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>McFee</surname><given-names>Brian</given-names></name>
          <name><surname>Raffel</surname><given-names>Colin</given-names></name>
          <name><surname>Liang</surname><given-names>Dawen</given-names></name>
          <name><surname>Ellis</surname><given-names>Daniel P. W.</given-names></name>
          <name><surname>McVicar</surname><given-names>Matt</given-names></name>
          <name><surname>Battenberg</surname><given-names>Eric</given-names></name>
          <name><surname>Nieto</surname><given-names>Oriol</given-names></name>
        </person-group>
        <article-title>Librosa: Audio and music signal analysis in Python</article-title>
        <source>Proceedings the python science conference</source>
        <publisher-loc>Austin, Texas, USA</publisher-loc>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.25080/Majora-7b98e3ed-003</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DixonW05_MATCH_ISMIR">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Dixon</surname><given-names>Simon</given-names></name>
          <name><surname>Widmer</surname><given-names>Gerhard</given-names></name>
        </person-group>
        <article-title>MATCH: A music alignment tool chest</article-title>
        <source>Proceedings of the international society for music information retrieval conference (ISMIR)</source>
        <publisher-loc>London, UK</publisher-loc>
        <year iso-8601-date="2005">2005</year>
        <pub-id pub-id-type="doi">10.5281/zenodo.1416951</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-TralieD20_DTW_ISMIR">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Tralie</surname><given-names>Christopher J.</given-names></name>
          <name><surname>Dempsey</surname><given-names>Elizabeth</given-names></name>
        </person-group>
        <article-title>Exact, parallelizable dynamic time warping alignment with linear memory</article-title>
        <source>Proceedings of the international society for music information retrieval conference (ISMIR)</source>
        <publisher-loc>Montréal, Canada</publisher-loc>
        <year iso-8601-date="2020">2020</year>
        <pub-id pub-id-type="doi">10.5281/zenodo.4245470</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p><ext-link ext-link-type="uri" xlink:href="http://www.eecs.qmul.ac.uk/~simond/match/">http://www.eecs.qmul.ac.uk/~simond/match/</ext-link></p>
  </fn>
  <fn id="fn2">
    <label>2</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/ctralie/linmdtw">https://github.com/ctralie/linmdtw</ext-link></p>
  </fn>
  <fn id="fn3">
    <label>3</label><p><ext-link ext-link-type="uri" xlink:href="https://github.com/meinardmueller/synctoolbox">https://github.com/meinardmueller/synctoolbox</ext-link></p>
  </fn>
  <fn id="fn4">
    <label>4</label><p><ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/synctoolbox">https://pypi.org/project/synctoolbox</ext-link></p>
  </fn>
</fn-group>
</back>
</article>

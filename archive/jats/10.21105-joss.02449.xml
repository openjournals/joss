<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2449</article-id>
<article-id pub-id-type="doi">10.21105/joss.02449</article-id>
<title-group>
<article-title>Sit2StandPy: An Open-Source Python Package for Detecting
and Quantifying Sit-to-Stand Transitions Using an Accelerometer on the
Lower Back</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Lukas Adamowicz</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Shyamal Patel</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Pfizer, Inc. 610 Main Street, Cambridge MA, USA
02139</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>5</volume>
<issue>52</issue>
<fpage>2449</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Biomechanics</kwd>
<kwd>Digital Biomarkers</kwd>
<kwd>Digital Medicine</kwd>
<kwd>Accelerometer</kwd>
<kwd>Inertial Sensors</kwd>
<kwd>Wearable Sensors</kwd>
<kwd>Human Motion</kwd>
<kwd>Activity Recognition</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Sit-to-stand transitions have been used to assess mobility for a
  broad range of conditions, such as Parkinson’s Disease
  (<xref alt="Buckley et al., 2009" rid="ref-buckleyU003A2008" ref-type="bibr">Buckley
  et al., 2009</xref>) and knee osteoarthritis
  (<xref alt="Bolink et al., 2012" rid="ref-bolinkU003A2012" ref-type="bibr">Bolink
  et al., 2012</xref>). Assessments are typically performed in the
  clinic using timed performance tests like the timed-up-and-go
  (<xref alt="Nguyen et al., 2015" rid="ref-nguyenU003A2015" ref-type="bibr">Nguyen
  et al., 2015</xref>,
  <xref alt="2017" rid="ref-nguyenU003A2017" ref-type="bibr">2017</xref>)
  and chair stand tests
  (<xref alt="Guralnik, 1994" rid="ref-guralnikU003A1994" ref-type="bibr">Guralnik,
  1994</xref>). While these assessment tools have demonstrated good
  psychometric properties, they have two key limitations: (1)
  assessments are performed episodically as they need to be administered
  by trained examiners, and (2) assessments performed in the clinic
  might not provide an adequate measure of real-world mobility.
  Therefore, there is a growing interest
  (<xref alt="Martinez-Hernandez &amp; Dehghani-Sanij, 2019" rid="ref-martinez-hernandezU003A2019" ref-type="bibr">Martinez-Hernandez
  &amp; Dehghani-Sanij, 2019</xref>;
  <xref alt="Pham et al., 2018" rid="ref-phamU003A2018" ref-type="bibr">Pham
  et al., 2018</xref>) in the use of wearable devices to detect
  sit-to-stand transitions that occur during daily life and quantify the
  quality of mobility during these transitions. While some commercial
  wearable sensor systems have sit-to-stand algorithms (e.g., APDM), and
  some previous papers have released code
  (<xref alt="Martinez-Hernandez &amp; Dehghani-Sanij, 2019" rid="ref-martinez-hernandezU003A2019" ref-type="bibr">Martinez-Hernandez
  &amp; Dehghani-Sanij, 2019</xref>), to the authors’ knowledge there
  are no commonly used, open source, and easy to use and configure,
  implementations of sit-to-stand algorithms available.</p>
  <fig>
    <caption><p>Location of the wearable device on the lower
    back.<styled-content id="figU003Asensor_loc"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="sensor_location.png" xlink:title="" />
  </fig>
  <p><monospace>Sit2StandPy</monospace> is an open source Python package
  that implements novel heuristics-based algorithms to detect
  Sit-to-Stand transitions from accelerometer data captured using a
  single wearable device mounted on the lower back
  (<xref alt="Figure 1" rid="figU003Asensor_loc">Figure 1</xref>). For
  each detected transition, the package also calculates objective
  features to assess quality of the transition. Features include
  duration, maximum acceleration, minimum acceleration, and spectral arc
  length (SPARC)
  (<xref alt="Balasubramanian et al., 2015" rid="ref-balasubramanianU003A2015" ref-type="bibr">Balasubramanian
  et al., 2015</xref>). While most previous works have focused on either
  in-clinic applications
  (<xref alt="Nguyen et al., 2015" rid="ref-nguyenU003A2015" ref-type="bibr">Nguyen
  et al., 2015</xref>,
  <xref alt="2017" rid="ref-nguyenU003A2017" ref-type="bibr">2017</xref>;
  <xref alt="van Lummel et al., 2013" rid="ref-van_lummelU003A2013" ref-type="bibr">van
  Lummel et al., 2013</xref>) or the use of multiple sensors
  (<xref alt="Nguyen et al., 2015" rid="ref-nguyenU003A2015" ref-type="bibr">Nguyen
  et al., 2015</xref>,
  <xref alt="2017" rid="ref-nguyenU003A2017" ref-type="bibr">2017</xref>),
  the algorithms in this package can handle data collected under
  free-living conditions as well as prescribed tasks (e.g., 30-second
  chair stand task), and it uses only the acceleration data from a
  single sensor on the lower back with unconstrained device orientation.
  The practicality of a single-accelerometer approach, which affords a
  long battery life and improved wearability, makes it well suited for
  long-term, continuous monitoring at home.</p>
  <fig>
    <caption><p>A high-level illustration of the input, output, and main
    processing steps of
    <monospace>Sit2StandPy</monospace>.<styled-content id="figU003Aproc_steps"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="alg-overview.png" xlink:title="" />
  </fig>
  <p>As illustrated in
  <xref alt="Figure 2" rid="figU003Aproc_steps">Figure 2</xref>,
  <monospace>Sit2StandPy</monospace> takes raw accelerometer data with
  timestamps as input and returns detected sit-to-stand transitions.
  Data can be windowed by full days, or parts of days can be selected
  for each window (e.g., window from 08:00 to 20:00). A high-level
  interface is provided, which allows the user to access all adjustable
  parameters. Users provide raw data as input and get detected
  transitions along with the computed features as output. Additionally,
  the lower-level methods that are called during the detection are
  available as well for more fine-grained control.</p>
  <p>With this framework, users can control many parameters of
  transition detection. In addition, the separation of processing steps
  and modularity of the sub-processes allows for easy customization if
  desired. For example, users can easily customize functions for
  generating additional features to assess quality of a transition.</p>
</sec>
<sec id="availability">
  <title>Availability</title>
  <p><monospace>Sit2StandPy</monospace> is distributed under the MIT
  License and is published on PyPI, the Python Package Index, and can be
  installed by running the following in the terminal:</p>
  <preformat>pip install sit2standpy  # install with checking for dependencies
# or
# installation without checking for installed dependencies
pip install sit2standpy --no-deps</preformat>
  <p>Sit2StandPy requires the following Python packages:</p>
  <list list-type="bullet">
    <list-item>
      <p>Python &gt;=3.7</p>
    </list-item>
    <list-item>
      <p>NumPy -
      (<xref alt="van der Walt et al., 2011" rid="ref-numpy" ref-type="bibr">van
      der Walt et al., 2011</xref>)</p>
    </list-item>
    <list-item>
      <p>SciPy -
      (<xref alt="Jones et al., 2001" rid="ref-scipy" ref-type="bibr">Jones
      et al., 2001</xref>)</p>
    </list-item>
    <list-item>
      <p>pandas -
      (<xref alt="The pandas development team, 2020" rid="ref-pandas" ref-type="bibr">The
      pandas development team, 2020</xref>)</p>
    </list-item>
    <list-item>
      <p>PyWavelets -
      (<xref alt="Lee et al., 2019" rid="ref-pywavelets" ref-type="bibr">Lee
      et al., 2019</xref>)</p>
    </list-item>
    <list-item>
      <p>udatetime</p>
    </list-item>
  </list>
  <p><monospace>Sit2StandPy</monospace> contains example code with
  sample data in its GitHub repository. Full documentation with usage
  examples, installation instructions, and API reference are all
  available at
  <ext-link ext-link-type="uri" xlink:href="https://sit2standpy.readthedocs.io/en/latest/">https://sit2standpy.readthedocs.io/en/latest/</ext-link></p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The Digital Medicine &amp; Translational Imaging group at Pfizer,
  Inc supported the development of this package.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-bolinkU003A2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bolink</surname><given-names>S. A. A. N.</given-names></name>
          <name><surname>van Laarhoven</surname><given-names>S. N.</given-names></name>
          <name><surname>Lipperts</surname><given-names>M.</given-names></name>
          <name><surname>Heyligers</surname><given-names>I. C.</given-names></name>
          <name><surname>Grimm</surname><given-names>B.</given-names></name>
        </person-group>
        <article-title>Inertial sensor motion analysis of gait, sit–stand transfers and step-up transfers: Differentiating knee patients from healthy controls</article-title>
        <source>Physiological Measurement</source>
        <year iso-8601-date="2012">2012</year>
        <volume>33</volume>
        <issue>11</issue>
        <pub-id pub-id-type="doi">10.1088/0967-3334/33/11/1947</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-buckleyU003A2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Buckley</surname><given-names>T.</given-names></name>
          <name><surname>Pitsikoulis</surname><given-names>C.</given-names></name>
          <name><surname>Barthelemy</surname><suffix>E.</suffix></name>
          <name><surname>Hass</surname><given-names>C. J.</given-names></name>
        </person-group>
        <article-title>Age impairs sit-to-walk motor performance</article-title>
        <source>Journal of Biomechanics</source>
        <year iso-8601-date="2009">2009</year>
        <volume>42</volume>
        <issue>14</issue>
        <pub-id pub-id-type="doi">10.1016/j.jbiomech.2009.06.023</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-balasubramanianU003A2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Balasubramanian</surname><given-names>S.</given-names></name>
          <name><surname>Melendez-Calderon</surname><given-names>A.</given-names></name>
          <name><surname>Roby-Brami</surname><given-names>A.</given-names></name>
          <name><surname>Burdet</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>On the analysis of movement smoothness</article-title>
        <source>Journal of NeuroEngineering Rehabilitation</source>
        <year iso-8601-date="2015">2015</year>
        <volume>12</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1186/s12984-015-0090-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-van_lummelU003A2013">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>van Lummel</surname><given-names>R. C.</given-names></name>
          <name><surname>Ainsworth</surname><given-names>E.</given-names></name>
          <name><surname>Lindemann</surname><given-names>U.</given-names></name>
          <name><surname>Zijlstra</surname><given-names>W.</given-names></name>
          <name><surname>Chiari</surname><given-names>L.</given-names></name>
          <name><surname>Van Campen</surname><given-names>P.</given-names></name>
          <name><surname>Hausdorff</surname><given-names>J. M.</given-names></name>
        </person-group>
        <article-title>Automated approach for quantifying the repeated sit-to-stand using one body fixed sensor in young and older adults</article-title>
        <source>Gait &amp; Posture</source>
        <year iso-8601-date="2013">2013</year>
        <volume>38</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1016/j.gaitpost.2012.10.008</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-nguyenU003A2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Nguyen</surname><given-names>H. P.</given-names></name>
          <name><surname>Lebel</surname><given-names>K.</given-names></name>
          <name><surname>Boissy</surname><given-names>P.</given-names></name>
          <name><surname>Bogard</surname><given-names>S.</given-names></name>
          <name><surname>Goubault</surname><given-names>E.</given-names></name>
          <name><surname>Duval</surname><given-names>C.</given-names></name>
        </person-group>
        <article-title>Auto detection and segmentation of daily living activities during a timed up and go task in people with parkinson’s disease using multiple inertial sensors</article-title>
        <source>Journal of NeuroEngineering and Rehabilitation</source>
        <year iso-8601-date="2017">2017</year>
        <volume>14</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1186/s12984-017-0241-2</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-nguyenU003A2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Nguyen</surname><given-names>H. P.</given-names></name>
          <name><surname>Ayachi</surname><given-names>F.</given-names></name>
          <name><surname>Lavigne–Pelletier</surname><given-names>C.</given-names></name>
          <name><surname>Blamoutier</surname><given-names>M.</given-names></name>
          <name><surname>Rahimi</surname><given-names>F.</given-names></name>
          <name><surname>Boissy</surname><given-names>P.</given-names></name>
          <name><surname>Mandar</surname><given-names>J.</given-names></name>
          <name><surname>Duval</surname><given-names>C.</given-names></name>
        </person-group>
        <article-title>Auto detection and segmentation of physical activities during a timed-up-and-go (TUG) task in healthy older adults using multiple inertial sensors</article-title>
        <source>Journal of NeuroEngineering and Rehabilitation</source>
        <year iso-8601-date="2015">2015</year>
        <volume>12</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1186/s12984-015-0026-4</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-phamU003A2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pham</surname><given-names>M. H.</given-names></name>
          <name><surname>Warmerdam</surname><given-names>E.</given-names></name>
          <name><surname>Elshehabi</surname><given-names>M.</given-names></name>
          <name><surname>Schlenstedt</surname><given-names>C.</given-names></name>
          <name><surname>Bergeest</surname><given-names>L. et. al.</given-names></name>
        </person-group>
        <article-title>Validation of a lower back wearable-based sit-to-stand and stand-to-sit algorithm for patients with parkinson’s disease and older adults in a home-like environment</article-title>
        <source>Frontiers in Neurology</source>
        <year iso-8601-date="2018">2018</year>
        <volume>9:652</volume>
        <pub-id pub-id-type="doi">10.3389/fneur.2018.00652</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-martinez-hernandezU003A2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Martinez-Hernandez</surname><given-names>U.</given-names></name>
          <name><surname>Dehghani-Sanij</surname><given-names>A. A.</given-names></name>
        </person-group>
        <article-title>Probabilistic identification of sit-to-stand and stand-to-sit with a wearable sensor</article-title>
        <source>Pattern Recognition Letters</source>
        <year iso-8601-date="2019">2019</year>
        <volume>118</volume>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2018.03.020</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-guralnikU003A1994">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Guralnik</surname><given-names>et al.</given-names><suffix>J. M.</suffix></name>
        </person-group>
        <article-title>A short physical performance battery assessing lower extremity function: Association with self-reported disability and prediction of mortality and nursing home admission</article-title>
        <source>Journal of Gerontology</source>
        <year iso-8601-date="1994">1994</year>
        <volume>49</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1093/geronj/49.2.m85</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-numpy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>van der Walt</surname><given-names>S.</given-names></name>
          <name><surname>Colbert</surname><given-names>S. C.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
        </person-group>
        <article-title>The NumPy array: A structure for efficient numerical computation</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <year iso-8601-date="2011">2011</year>
        <volume>13</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-scipy">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Jones</surname><given-names>E.</given-names></name>
          <name><surname>Oliphant</surname><given-names>T.</given-names></name>
          <name><surname>Peterson</surname><given-names>et al.</given-names><suffix>P.</suffix></name>
        </person-group>
        <article-title>SciPy: Open source scientific tools for Python</article-title>
        <year iso-8601-date="2001">2001</year>
        <uri>http://www.scipy.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-pywavelets">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Lee</surname><given-names>G. R.</given-names></name>
          <name><surname>Gommers</surname><given-names>R.</given-names></name>
          <name><surname>Wasilewsky</surname><given-names>F.</given-names></name>
          <name><surname>Wohlfahrt</surname><given-names>K.</given-names></name>
          <name><surname>O’Leary</surname><given-names>A.</given-names></name>
        </person-group>
        <article-title>PyWavelets: A Python package for wavelet analysis</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2019">2019</year>
        <volume>13</volume>
        <pub-id pub-id-type="doi">10.21105/joss.01237</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-pandas">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>The pandas development team</string-name>
        </person-group>
        <source>Pandas-dev/pandas: Pandas 1.0.5</source>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2020-06">2020</year><month>06</month>
        <uri>https://doi.org/10.5281/zenodo.3898987</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.3898987</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

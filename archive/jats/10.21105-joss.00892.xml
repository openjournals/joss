<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">892</article-id>
<article-id pub-id-type="doi">10.21105/joss.00892</article-id>
<title-group>
<article-title>YAD: A Learning-based Inductive Logic Programming
Tool</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Ali Kamandi</string-name>
<email>kamandi@ut.ac.ir</email>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9132-593X</contrib-id>
<string-name>Hamed Karimi</string-name>
<email>ha.karimi@ut.ac.ir</email>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>School of Engineering Science, College of Engineering,
University of Tehran, Tehran, Iran</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-07-09">
<day>9</day>
<month>7</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>30</issue>
<fpage>892</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Learning</kwd>
<kwd>Inductive Logic Programming</kwd>
<kwd>General Logical Rule</kwd>
<kwd>CSharp</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Inductive logic learning is considered as one of the most prominent
  approaches for multi-dimensional and multi-tabular learning by relying
  on first-order logic to describe train data in the form of positive
  and negative examples which can find a set of existing rules and
  relations and can propose them in first-order logic format
  (<xref alt="Muggleton, 1995" rid="ref-Muggleton1995" ref-type="bibr">Muggleton,
  1995</xref>),
  (<xref alt="Lavrač &amp; Džeroski, 1994" rid="ref-Lavrac1994" ref-type="bibr">Lavrač
  &amp; Džeroski, 1994</xref>).</p>
  <p>Generally, the inductive learning problem is defined as
  follows:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Input:</bold></p>
      <list list-type="bullet">
        <list-item>
          <p>Background knowledge <italic>B</italic>, a set of Horn
          clauses.</p>
        </list-item>
        <list-item>
          <p>Positive examples <inline-formula><alternatives>
          <tex-math><![CDATA[E^+]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>E</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula>,
          a set of Horn clauses (typically ground literals).</p>
        </list-item>
        <list-item>
          <p>Negative examples <inline-formula><alternatives>
          <tex-math><![CDATA[E^-]]></tex-math>
          <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>E</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:math></alternatives></inline-formula>,
          a set of Horn clauses (typically ground literals).</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p><bold>Output:</bold></p>
      <list list-type="bullet">
        <list-item>
          <p>A hypothesis <italic>H</italic>, a set of Horn clauses.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p><bold>Problem Conditions:</bold></p>
      <list list-type="bullet">
        <list-item>
          <p>All the positive examples should be producible from
          combination of background knowledge and <italic>H</italic>,
          which it indicates the completeness criterion:</p>
          <p><disp-formula><alternatives>
          <tex-math><![CDATA[\forall e \in E^+\colon B \wedge H \rightarrow e \quad \text{(Completeness)}]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>∀</mml:mo><mml:mi>e</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>∧</mml:mo><mml:mi>H</mml:mi><mml:mo>→</mml:mo><mml:mi>e</mml:mi><mml:mspace width="1.0em"></mml:mspace><mml:mtext mathvariant="normal">(Completeness)</mml:mtext></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
        <list-item>
          <p>None of the negative examples should be producible, which
          it indicates the consistency criterion and also obviously
          keeps the Precision measure high:</p>
          <p><disp-formula><alternatives>
          <tex-math><![CDATA[\forall e \in E^-\colon B \wedge H \nrightarrow e \quad \text{(Consistency)}]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo>∀</mml:mo><mml:mi>e</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mo>−</mml:mo></mml:msup><mml:mo>:</mml:mo><mml:mi>B</mml:mi><mml:mo>∧</mml:mo><mml:mi>H</mml:mi><mml:mo>↛</mml:mo><mml:mi>e</mml:mi><mml:mspace width="1.0em"></mml:mspace><mml:mtext mathvariant="normal">(Consistency)</mml:mtext></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
      </list>
    </list-item>
  </list>
  <p>It is remarkable to say that the symbols
  <inline-formula><alternatives>
  <tex-math><![CDATA[E^+]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>E</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[E^-]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>E</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:math></alternatives></inline-formula>,
  <italic>B</italic>, and <italic>H</italic> are proposed in first-order
  logic format.</p>
  <p>Due to the expressiveness and high flexibility of first-order
  logic, the inductive learning approach has high capability in
  discovering the relations. Also, since the set of logic’s rules is not
  restricted to a specific table or structure, it can be used in
  widespread areas and problems like finding relationships in social
  networks and discovering communication patterns in protein structures
  (bioinformatics problems).</p>
  <p>Despite of all the advantages that learning based on inductive
  logic has; in practice, it becomes a problem to search and find the
  optimal solution which with respect to the vastness of search space,
  it has no polynomial and deterministic solution. So, in order to solve
  it, we need to the heuristic and randomized algorithms.</p>
  <p>In recent years, many researches were performed in this area and
  numerous algorithms and tools were proposed such as FOIL
  (<xref alt="Quinlan &amp; Cameron-Jones, 1993" rid="ref-Quinlan1993" ref-type="bibr">Quinlan
  &amp; Cameron-Jones, 1993</xref>),
  (<xref alt="Quinlan, 1990" rid="ref-Quinlan1990" ref-type="bibr">Quinlan,
  1990</xref>), Golem, ProGolem
  (<xref alt="Muggleton et al., 2010" rid="ref-Muggleton2010" ref-type="bibr">Muggleton
  et al., 2010</xref>), Aleph
  (<xref alt="Srinivasan, 2007" rid="ref-Srinivasan2007" ref-type="bibr">Srinivasan,
  2007</xref>), and CIGOL. The algorithms provided so far for this
  problem, can be classified into two categories: top-down and bottom-up
  algorithms.</p>
  <p>In top-down algorithms, some relations are guessed (they are
  constructed) based on heuristic criteria and then, their validity is
  tested on train data. While learning algorithm conditions are
  satisfied, that relation is accepted. In bottom-up algorithms, the
  work is started from positive examples and the algorithm endeavors to
  find a more general form of a fact. In the other words, the desired
  relation is generalized and then, a more generic form of it is
  created. This work is continued until the generated rule covers none
  of the negative examples.</p>
  <p>The tool YAD, is an implementation of a new bottom-up inductive
  logic learning algorithm. Its main purpose is to reduce learning time.
  This is done in such a way that in every step, in order to choose some
  rules that can create more general rules with their own combinations,
  instead of quite random choice, choosing is performed from a set of
  relations (rules) that have a higher chance to generate the relevant
  rules.</p>
  <p>Generally, this algorithm (Algorithm 1) has been presented as
  follows:</p>
  <p><bold>Algorithm 1.</bold> The proposed induction algorithm used in
  YAD ILP tool</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="https://github.com/hamedmx/YAD-ILP-Tool/raw/master/algorithm%201.PNG" />
  <italic>* Constructing a generalized logical rule using inverse
  resolution on a predicate P with background knowledge B and a hash map
  h.</italic></p>
  <p>This tool has been implemented in C# and a screenshot of its GUI is
  depicted in Figure 1. The input arguments of YAD are:</p>
  <list list-type="bullet">
    <list-item>
      <p>The percentage of Train Examples (the remaining percentage will
      be Test Examples percentage for testing the generated generic
      logical rules on the data-set).</p>
    </list-item>
    <list-item>
      <p>The number of steps (typically, it is set to the default value
      4) which is used to generate a general predicate in every step of
      induce function (inverse resolution operations) in order to
      produce generic logical rules. So, for example, with four steps,
      the tool can produce general logical rules with at most four
      predicates in their right-hand side.</p>
    </list-item>
    <list-item>
      <p>Try Count (typically, it is set to the default value 5) is the
      number of endeavors that the tool performs to create and generate
      a general logical rule.</p>
    </list-item>
    <list-item>
      <p>Negative Threshold (typically, it is set to a low amount
      e.g. the default value 5) is the percentage of the whole negative
      examples that every produced generic logical rule can produce
      negative examples equal or lower than the selected percentage,
      otherwise, the produced logical rule is useless and it is not
      considered as an output generic logical rule.</p>
    </list-item>
  </list>
  <p>Also, the use cases and functions of this tool are as follows
  (respectively in use):</p>
  <list list-type="order">
    <list-item>
      <p><bold>Open:</bold> Opening a file (typically, a text file)
      consists of Background Knowledge lines (the lines should start
      with ‘B’ with a white-space after), Positive Examples lines (the
      lines should start with ‘+’ with a white-space after), and
      Negative Examples lines (the lines should start with ‘-’ with a
      white-space after) in first-order logic format as logical
      rules.</p>
    </list-item>
    <list-item>
      <p><bold>Induce:</bold> Producing general logical rules by
      inducing (using inverse resolution) on background knowledge.</p>
    </list-item>
    <list-item>
      <p><bold>Prune:</bold> Computing the measures such as Precision,
      Recall, Accuracy, and F-Measure for evaluation and comparison.</p>
    </list-item>
    <list-item>
      <p><bold>Result Filtering:</bold> Colorizing and filtering the
      results, i.e., Train and Test Examples in order to determine their
      coverage.</p>
    </list-item>
  </list>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="https://github.com/hamedmx/YAD-ILP-Tool/raw/master/fig%201.PNG" />
  <bold>Figure 1.</bold> A screenshot of YAD</p>
</sec>
<sec id="software-architecture">
  <title>Software Architecture</title>
  <p>The architecture of this ILP tool is shown in Figure 2. As it is
  obvious in this figure, the system consists of the following
  components:</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="https://github.com/hamedmx/YAD-ILP-Tool/raw/master/fig%202.PNG" />
  <bold>Figure 2.</bold> YAD ILP tool architecture</p>
  <p><bold>User Interface:</bold> It provides some necessary facilities
  and UI in order to present the input data and configure the model
  parameters for user. These user-configurable parameters were mentioned
  before in previous sections.</p>
  <p><bold>Rule Preparation:</bold> This section has some tasks to read
  the input file, parse the information, and produce background
  knowledge and positive and negative examples set in appropriate form
  of the first-order logic format. All of the examples (positive and
  negative examples) are located in the format of a set of objects.
  Also, the division of the input data into the train and test sets is
  accomplished by this module.</p>
  <p><bold>Induction Engine:</bold> This section forms the main part of
  the tool, which consists of three subsections:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold><italic>Generalizer:</italic></bold> This subsection has
      a task to produce more general logical rules from positive
      examples. In the other words, this module receives a positive
      example and tries to generalize it as much as possible.</p>
    </list-item>
    <list-item>
      <p><bold><italic>Rule Checker:</italic></bold> The logical rules
      that are generated by generalizer, are controlled by this module
      to determine whether they satisfy the problem conditions (covering
      the positive examples and not covering the negative examples) or
      not. So, if the conditions of the desired logical rule are not
      covered, then it will not be accepted.</p>
    </list-item>
    <list-item>
      <p><bold><italic>Pruning Module:</italic></bold> This module has a
      task to prevent from the over-fitting of the model, otherwise, we
      probably have many logical rules that each of them satisfies only
      one or two positive examples, i.e. they do not have an adequate
      generality. Pruning operates in such a way that not only we can
      achieve the best results in terms of precision, but also the
      number of logical rules will be minimized.</p>
    </list-item>
  </list>
  <p><bold>Evaluation Module:</bold> It has a task to execute the
  logical rules produced by induction module on the test data and
  evaluates the results. For this reason, the various measurements such
  as Precision, Recall, Accuracy, and F-Measure are computed and
  reported.</p>
  <p><bold>Shared Data:</bold> The sections we have mentioned before,
  have access to a set of data which is the input and output data of ILP
  algorithm such as background knowledge set, positive and negative
  examples, and the set of produced logical rules by the algorithm.</p>
</sec>
<sec id="applications">
  <title>Applications</title>
  <p>This tool can be used in solving many various problems which need
  to discover some relationships between different phenomena. We
  previously have used this ILP tool in a prominent area of new web
  science called Semantic Web for Ontology Alignment (Ontology Mapping)
  problem using inductive logic programming
  (<xref alt="Karimi &amp; Kamandi, 2018" rid="ref-Karimi2018" ref-type="bibr">Karimi
  &amp; Kamandi, 2018</xref>). We used anatomical data-sets to evaluate
  our new proposed approach for ontology alignment as a key problem in
  semantic web and its infrastructure using ILP by YAD. This ILP tool
  could generate some efficient generic logical rules to find some valid
  alignments between anatomical concepts and therefore, we could
  averagely achieve a high F-Measure with respect to acceptable
  percentage of Precision and Recall, among similar matching tools in
  2017.</p>
  <p>Also, the ILP tool can be used in many different problems such as
  bioinformatics and protein bonds analysis as well as informatics
  chemistry to discover chemical bonds. In addition, it can be used in
  social networks analysis and to discover the communications between
  individuals, rules, and concepts. Generally, the application of this
  tool is in networks analysis (networks of individuals, molecules,
  proteins, and etc.).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Muggleton1995">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Muggleton</surname><given-names>Stephen</given-names></name>
        </person-group>
        <article-title>Inverse entailment and progol</article-title>
        <source>New Generation Computing</source>
        <year iso-8601-date="1995-12">1995</year><month>12</month>
        <volume>13</volume>
        <issue>3-4</issue>
        <issn>0288-3635</issn>
        <uri>http://link.springer.com/10.1007/BF03037227</uri>
        <pub-id pub-id-type="doi">10.1007/BF03037227</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Lavrac1994">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Lavrač</surname><given-names>Nada.</given-names></name>
          <name><surname>Džeroski</surname><given-names>Sašo</given-names></name>
        </person-group>
        <source>Inductive logic programming : techniques and applications</source>
        <publisher-name>E. Horwood</publisher-name>
        <year iso-8601-date="1994">1994</year>
        <isbn>0134578708</isbn>
      </element-citation>
    </ref>
    <ref id="ref-Muggleton2010">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Muggleton</surname><given-names>Stephen</given-names></name>
          <name><surname>Santos</surname><given-names>José</given-names></name>
          <name><surname>Tamaddoni-Nezhad</surname><given-names>Alireza</given-names></name>
        </person-group>
        <article-title>ProGolem: A System Based on Relative Minimal Generalisation</article-title>
        <year iso-8601-date="2010">2010</year>
        <uri>http://link.springer.com/10.1007/978-3-642-13840-9{\_}13</uri>
        <pub-id pub-id-type="doi">10.1007/978-3-642-13840-9_13</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Karimi2018">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Karimi</surname><given-names>Hamed</given-names></name>
          <name><surname>Kamandi</surname><given-names>Ali</given-names></name>
        </person-group>
        <article-title>Ontology alignment using inductive logic programming</article-title>
        <source>2018 4th international conference on web research (ICWR)</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2018-04">2018</year><month>04</month>
        <isbn>978-1-5386-5364-7</isbn>
        <uri>https://ieeexplore.ieee.org/document/8387247/</uri>
        <pub-id pub-id-type="doi">10.1109/ICWR.2018.8387247</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Srinivasan2007">
      <element-citation publication-type="report">
        <person-group person-group-type="author">
          <name><surname>Srinivasan</surname><given-names>Ashwin</given-names></name>
        </person-group>
        <article-title>The Aleph Manual</article-title>
        <year iso-8601-date="2007">2007</year>
      </element-citation>
    </ref>
    <ref id="ref-Quinlan1993">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Quinlan</surname><given-names>J. R.</given-names></name>
          <name><surname>Cameron-Jones</surname><given-names>R. M.</given-names></name>
        </person-group>
        <article-title>FOIL: A midterm report</article-title>
        <publisher-name>Springer, Berlin, Heidelberg</publisher-name>
        <year iso-8601-date="1993">1993</year>
        <uri>http://link.springer.com/10.1007/3-540-56602-3{\_}124</uri>
        <pub-id pub-id-type="doi">10.1007/3-540-56602-3_124</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Quinlan1990">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Quinlan</surname><given-names>J. R.</given-names></name>
        </person-group>
        <article-title>Learning logical definitions from relations</article-title>
        <source>Machine Learning</source>
        <year iso-8601-date="1990-08">1990</year><month>08</month>
        <volume>5</volume>
        <issue>3</issue>
        <issn>0885-6125</issn>
        <uri>http://link.springer.com/10.1007/BF00117105</uri>
        <pub-id pub-id-type="doi">10.1007/BF00117105</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

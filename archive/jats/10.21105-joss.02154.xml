<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2154</article-id>
<article-id pub-id-type="doi">10.21105/joss.02154</article-id>
<title-group>
<article-title>Spleeter: a fast and efficient music source separation
tool with pre-trained models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8158-5562</contrib-id>
<string-name>Romain Hennequin</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Anis Khlif</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Felix Voituret</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0886-5423</contrib-id>
<string-name>Manuel Moussallam</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Deezer Research, Paris</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-03-04">
<day>4</day>
<month>3</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>50</issue>
<fpage>2154</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>musical signal processing</kwd>
<kwd>source separation</kwd>
<kwd>vocal isolation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We present and release a new tool for music source separation with
  pre-trained models called Spleeter. Spleeter was designed with ease of
  use, separation performance, and speed in mind. Spleeter is based on
  Tensorflow
  (<xref alt="Abadi, 2015" rid="ref-tensorflow2015-whitepaper" ref-type="bibr">Abadi,
  2015</xref>) and makes it possible to:</p>
  <list list-type="bullet">
    <list-item>
      <p>split music audio files into several stems with a single
      command line using pre-trained models. A music audio file can be
      separated into <inline-formula><alternatives>
      <tex-math><![CDATA[2]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2</mml:mn></mml:math></alternatives></inline-formula>
      stems (vocals and accompaniments), <inline-formula><alternatives>
      <tex-math><![CDATA[4]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>
      stems (vocals, drums, bass, and other) or
      <inline-formula><alternatives>
      <tex-math><![CDATA[5]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>5</mml:mn></mml:math></alternatives></inline-formula>
      stems (vocals, drums, bass, piano and other).</p>
    </list-item>
    <list-item>
      <p>train source separation models or fine-tune pre-trained ones
      with Tensorflow (provided you have a dataset of isolated
      sources).</p>
    </list-item>
  </list>
  <p>The performance of the pre-trained models are very close to the
  published state-of-the-art and is one of the best performing
  <inline-formula><alternatives>
  <tex-math><![CDATA[4]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>
  stems separation model on the common musdb18 benchmark
  (<xref alt="Rafii et al., 2017" rid="ref-musdb18" ref-type="bibr">Rafii
  et al., 2017</xref>) to be publicly released. Spleeter is also very
  fast as it can separate a mix audio file into
  <inline-formula><alternatives>
  <tex-math><![CDATA[4]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>
  stems <inline-formula><alternatives>
  <tex-math><![CDATA[100]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>100</mml:mn></mml:math></alternatives></inline-formula>
  times faster than real-time (we note, though, that the model cannot be
  applied in real-time as it needs buffering) on a single Graphics
  Processing Unit (GPU) using the pre-trained
  <inline-formula><alternatives>
  <tex-math><![CDATA[4]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>-stems
  model.</p>
</sec>
<sec id="purpose">
  <title>Purpose</title>
  <p>We release Spleeter with pre-trained state-of-the-art models in
  order to help the Music Information Retrieval (MIR) research community
  leverage the power of source separation in various MIR tasks, such as
  vocal lyrics analysis from audio (audio/lyrics alignment, lyrics
  transcription…), music transcription (chord transcription, drums
  transcription, bass transcription, chord estimation, beat tracking),
  singer identification, any type of multilabel classification
  (mood/genre…), vocal melody extraction or cover detection. We believe
  that source separation has reached a level of maturity that makes it
  worth considering for these tasks and that specific features computed
  from isolated vocals, drums or bass may help increase performances,
  especially in low data availability scenarios (small datasets, limited
  annotation availability) for which supervised learning might be
  difficult. Spleeter also makes it possible to fine-tune the provided
  state-of-the-art models in order to adapt the system to a specific
  use-case. Finally, having an available source separation tool such as
  Spleeter will allow researchers to compare performances of their new
  models to a state-of-the-art one on their private datasets instead of
  musdb18, which is usually the only used dataset for reporting
  separation performances for unreleased models. Note that we cannot
  release the training data for copyright reasons, and thus, sharing
  pre-trained models were the only way to make these results available
  to the community.</p>
</sec>
<sec id="implementation-details">
  <title>Implementation details</title>
  <p>Spleeter contains pre-trained models for:</p>
  <list list-type="bullet">
    <list-item>
      <p>vocals/accompaniment separation.</p>
    </list-item>
    <list-item>
      <p><inline-formula><alternatives>
      <tex-math><![CDATA[4]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>
      stems separation as in SiSec
      (<xref alt="Stöter et al., 2018" rid="ref-SISEC18" ref-type="bibr">Stöter
      et al., 2018</xref>) (vocals, bass, drums and other).</p>
    </list-item>
    <list-item>
      <p><inline-formula><alternatives>
      <tex-math><![CDATA[5]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>5</mml:mn></mml:math></alternatives></inline-formula>
      stems separation with an extra piano stem (vocals, bass, drums,
      piano, and other). It is, to the authors’ knowledge, the first
      released model to perform such a separation.</p>
    </list-item>
  </list>
  <p>The pre-trained models are U-nets
  (<xref alt="Jansson et al., 2017" rid="ref-unet2017" ref-type="bibr">Jansson
  et al., 2017</xref>) and follow similar specifications as in
  (<xref alt="Prétet et al., 2019" rid="ref-deezerICASSP2019" ref-type="bibr">Prétet
  et al., 2019</xref>). The U-net is an encoder/decoder Convolutional
  Neural Network (CNN) architecture with skip connections. We used
  <inline-formula><alternatives>
  <tex-math><![CDATA[12]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>12</mml:mn></mml:math></alternatives></inline-formula>-layer
  U-nets (<inline-formula><alternatives>
  <tex-math><![CDATA[6]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>6</mml:mn></mml:math></alternatives></inline-formula>
  layers for the encoder and <inline-formula><alternatives>
  <tex-math><![CDATA[6]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>6</mml:mn></mml:math></alternatives></inline-formula>
  for the decoder). A U-net is used for estimating a soft mask for each
  source (stem). Training loss is a <inline-formula><alternatives>
  <tex-math><![CDATA[L_1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>-norm
  between masked input mix spectrograms and source-target spectrograms.
  The models were trained on Deezer’s internal datasets (noteworthily
  the Bean dataset that was used in
  (<xref alt="Prétet et al., 2019" rid="ref-deezerICASSP2019" ref-type="bibr">Prétet
  et al., 2019</xref>)) using Adam
  (<xref alt="Kingma &amp; Ba, 2014" rid="ref-Adam" ref-type="bibr">Kingma
  &amp; Ba, 2014</xref>). Training time took approximately a full week
  on a single GPU. Separation is then done from estimated source
  spectrograms using soft masking or multi-channel Wiener filtering.</p>
  <p>Training and inference are implemented in Tensorflow which makes it
  possible to run the code on Central Processing Unit (CPU) or GPU.</p>
</sec>
<sec id="speed">
  <title>Speed</title>
  <p>As the whole separation pipeline can be run on a GPU and the model
  is based on a CNN, computations are efficiently parallelized and model
  inference is very fast. For instance, Spleeter is able to separate the
  whole musdb18 test dataset (about <inline-formula><alternatives>
  <tex-math><![CDATA[3]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>3</mml:mn></mml:math></alternatives></inline-formula>
  hours and <inline-formula><alternatives>
  <tex-math><![CDATA[27]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>27</mml:mn></mml:math></alternatives></inline-formula>
  minutes of audio) into <inline-formula><alternatives>
  <tex-math><![CDATA[4]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>4</mml:mn></mml:math></alternatives></inline-formula>
  stems in less than <inline-formula><alternatives>
  <tex-math><![CDATA[2]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>2</mml:mn></mml:math></alternatives></inline-formula>
  minutes, including model loading time (about
  <inline-formula><alternatives>
  <tex-math><![CDATA[15]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>15</mml:mn></mml:math></alternatives></inline-formula>
  seconds), and audio wav files export, using a single GeForce RTX 2080
  GPU, and a double Intel Xeon Gold 6134 CPU @ 3.20GHz (CPU is used for
  mix files loading and stem files export only). In this setup, Spleeter
  is able to process <inline-formula><alternatives>
  <tex-math><![CDATA[100]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>100</mml:mn></mml:math></alternatives></inline-formula>
  seconds of stereo audio in less than <inline-formula><alternatives>
  <tex-math><![CDATA[1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>
  second, which makes it very useful for efficiently processing large
  datasets.</p>
</sec>
<sec id="separation-performances">
  <title>Separation performances</title>
  <p>The models compete with the state-of-the-art on the standard
  musdb18 dataset
  (<xref alt="Rafii et al., 2017" rid="ref-musdb18" ref-type="bibr">Rafii
  et al., 2017</xref>) while it was not trained, validated or optimized
  in any way with musdb18 data. We report results in terms of standard
  source separation metrics
  (<xref alt="Vincent et al., 2006" rid="ref-separation_metrics" ref-type="bibr">Vincent
  et al., 2006</xref>), namely Signal to Distortion Ratio (SDR), Signal
  to Artifacts Ratio (SAR), Signal to Interference Ratio (SIR) and
  source Image to Spatial distortion Ratio (ISR), are presented in the
  following table compared to Open-Unmix
  (<xref alt="Stöter et al., 2019" rid="ref-Open-Unmix" ref-type="bibr">Stöter
  et al., 2019</xref>) and Demucs
  (<xref alt="Défossez et al., 2019" rid="ref-demucs" ref-type="bibr">Défossez
  et al., 2019</xref>) (only SDR are reported for Demucs since other
  metrics are not available in the paper) which are, to the authors’
  knowledge, the only released system that performs near
  state-of-the-art performances. We present results for soft masking and
  for multi-channel Wiener filtering (applied using Norbert
  (<xref alt="Liutkus &amp; Stöter, 2019" rid="ref-Norbert" ref-type="bibr">Liutkus
  &amp; Stöter, 2019</xref>)). As can be seen, for most metrics Spleeter
  is competitive with Open-Unmix and especially on SDR for all
  instruments, and is almost on par with Demucs.</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th></th>
          <th>Spleeter Mask</th>
          <th>Spleeter MWF</th>
          <th>Open-Unmix</th>
          <th>Demucs</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Vocals SDR</td>
          <td>6.55</td>
          <td>6.86</td>
          <td>6.32</td>
          <td>7.05 </td>
        </tr>
        <tr>
          <td>Vocals SIR</td>
          <td>15.19</td>
          <td>15.86</td>
          <td>13.33</td>
          <td>13.94</td>
        </tr>
        <tr>
          <td>Vocals SAR</td>
          <td>6.44</td>
          <td>6.99</td>
          <td>6.52</td>
          <td>7.00</td>
        </tr>
        <tr>
          <td>Vocals ISR</td>
          <td>12.01</td>
          <td>11.95</td>
          <td>11.93</td>
          <td>12.04</td>
        </tr>
        <tr>
          <td>Bass SDR</td>
          <td>5.10</td>
          <td>5.51</td>
          <td>5.23</td>
          <td>6.70 </td>
        </tr>
        <tr>
          <td>Bass SIR</td>
          <td>10.01</td>
          <td>10.30</td>
          <td>10.93</td>
          <td>13.03</td>
        </tr>
        <tr>
          <td>Bass SAR</td>
          <td>5.15</td>
          <td>5.96</td>
          <td>6.34</td>
          <td>6.68 </td>
        </tr>
        <tr>
          <td>Bass ISR</td>
          <td>9.18</td>
          <td>9.61</td>
          <td>9.23</td>
          <td>9.99</td>
        </tr>
        <tr>
          <td>Drums SDR</td>
          <td>5.93</td>
          <td>6.71</td>
          <td>5.73</td>
          <td>7.08 </td>
        </tr>
        <tr>
          <td>Drums SIR</td>
          <td>12.24</td>
          <td>13.67</td>
          <td>11.12</td>
          <td>13.74</td>
        </tr>
        <tr>
          <td>Drums SAR</td>
          <td>5.78</td>
          <td>6.54</td>
          <td>6.02</td>
          <td>7.04</td>
        </tr>
        <tr>
          <td>Drums ISR</td>
          <td>10.50</td>
          <td>10.69</td>
          <td>10.51</td>
          <td>11.96</td>
        </tr>
        <tr>
          <td>Other SDR</td>
          <td>4.24</td>
          <td>4.55</td>
          <td>4.02</td>
          <td>4.47 </td>
        </tr>
        <tr>
          <td>Other SIR</td>
          <td>7.86</td>
          <td>8.16</td>
          <td>6.59</td>
          <td>7.11</td>
        </tr>
        <tr>
          <td>Other SAR</td>
          <td>4.63</td>
          <td>4.88</td>
          <td>4.74</td>
          <td>5.26</td>
        </tr>
        <tr>
          <td>Other ISR</td>
          <td>9.83</td>
          <td>9.87</td>
          <td>9.31</td>
          <td>10.86</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>Spleeter
  (<xref alt="Hennequin et al., 2019" rid="ref-spleeter" ref-type="bibr">Hennequin
  et al., 2019</xref>) source code and pre-trained models are available
  on
  <ext-link ext-link-type="uri" xlink:href="https://www.github.com/deezer/spleeter">github</ext-link>
  and distributed under a MIT license. This repository will eventually
  be used for releasing other models with improved performances or
  models separating into more than <inline-formula><alternatives>
  <tex-math><![CDATA[5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>5</mml:mn></mml:math></alternatives></inline-formula>
  stems in the future.</p>
</sec>
<sec id="distribution">
  <title>Distribution</title>
  <p>Spleeter is available as a standalone Python package, and also
  provided as a
  <ext-link ext-link-type="uri" xlink:href="https://github.com/conda-forge/spleeter-feedstock">conda</ext-link>
  recipe and self-contained
  <ext-link ext-link-type="uri" xlink:href="https://hub.docker.com/r/researchdeezer/spleeter">Dockers</ext-link>
  which makes it usable as-is on various platforms.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge contributions from Laure Pretet who trained first
  models and wrote the first piece of code that lead to Spleeter.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-SISEC18">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Stöter</surname><given-names>Fabian-Robert</given-names></name>
          <name><surname>Liutkus</surname><given-names>Antoine</given-names></name>
          <name><surname>Ito</surname><given-names>Nobutaka</given-names></name>
        </person-group>
        <article-title>The 2018 signal separation evaluation campaign</article-title>
        <source>Latent variable analysis and signal separation. LVA/ICA</source>
        <publisher-name>Springer, Cham</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1007/978-3-319-93764-9_28</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-unet2017">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Jansson</surname><given-names>Andreas</given-names></name>
          <name><surname>Humphrey</surname><given-names>Eric J.</given-names></name>
          <name><surname>Montecchio</surname><given-names>Nicola</given-names></name>
          <name><surname>Bittner</surname><given-names>Rachel</given-names></name>
          <name><surname>Kumar</surname><given-names>Aparna</given-names></name>
          <name><surname>Weyde</surname><given-names>Tillman</given-names></name>
        </person-group>
        <article-title>Singing voice separation with deep u-net convolutional networks</article-title>
        <source>Proceedings of the international society for music information retrieval conference (ISMIR)</source>
        <year iso-8601-date="2017">2017</year>
      </element-citation>
    </ref>
    <ref id="ref-deezerICASSP2019">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Prétet</surname><given-names>Laure</given-names></name>
          <name><surname>Hennequin</surname><given-names>Romain</given-names></name>
          <name><surname>Royo-Letelier</surname><given-names>Jimena</given-names></name>
          <name><surname>Vaglio</surname><given-names>Andrea</given-names></name>
        </person-group>
        <article-title>Singing voice separation: A study on training data</article-title>
        <source>ICASSP 2019 - 2019 IEEE international conference on acoustics, speech and signal processing (ICASSP)</source>
        <year iso-8601-date="2019-05">2019</year><month>05</month>
        <volume></volume>
        <issn></issn>
        <pub-id pub-id-type="doi">10.1109/ICASSP.2019.8683555</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Norbert">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Liutkus</surname><given-names>Antoine</given-names></name>
          <name><surname>Stöter</surname><given-names>Fabian-Robert</given-names></name>
        </person-group>
        <article-title>Sigsep/norbert: First official norbert release</article-title>
        <year iso-8601-date="2019-07">2019</year><month>07</month>
        <uri>https://doi.org/10.5281/zenodo.3269749</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.3269749</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-separation_metrics">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Vincent</surname><given-names>Emmanuel</given-names></name>
          <name><surname>Gribonval</surname><given-names>Remi</given-names></name>
          <name><surname>Fevotte</surname><given-names>Cedric</given-names></name>
        </person-group>
        <article-title>Performance measurement in blind audio source separation</article-title>
        <source>IEEE Transactions on Audio, Speech, and Language Processing</source>
        <year iso-8601-date="2006">2006</year>
        <volume>14</volume>
        <issue>4</issue>
        <issn></issn>
        <pub-id pub-id-type="doi">10.1109/TSA.2005.858005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-musdb18">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Rafii</surname><given-names>Zafar</given-names></name>
          <name><surname>Liutkus</surname><given-names>Antoine</given-names></name>
          <name><surname>Stöter</surname><given-names>Fabian-Robert</given-names></name>
          <name><surname>Mimilakis</surname><given-names>Stylianos Ioannis</given-names></name>
          <name><surname>Bittner</surname><given-names>Rachel</given-names></name>
        </person-group>
        <article-title>The MUSDB18 corpus for music separation</article-title>
        <year iso-8601-date="2017-12">2017</year><month>12</month>
        <uri>https://doi.org/10.5281/zenodo.1117372</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1117372</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-tensorflow2015-whitepaper">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Abadi</surname><given-names>Martı́n et al.</given-names></name>
        </person-group>
        <article-title>TensorFlow: Large-scale machine learning on heterogeneous systems</article-title>
        <year iso-8601-date="2015">2015</year>
        <uri>https://www.tensorflow.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-Adam">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kingma</surname><given-names>Diederik P.</given-names></name>
          <name><surname>Ba</surname><given-names>Jimmy</given-names></name>
        </person-group>
        <article-title>Adam: A Method for Stochastic Optimization</article-title>
        <source>arXiv e-prints</source>
        <year iso-8601-date="2014-12">2014</year><month>12</month>
        <uri>https://arxiv.org/abs/1412.6980</uri>
      </element-citation>
    </ref>
    <ref id="ref-Open-Unmix">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Stöter</surname><given-names>Fabian-Robert</given-names></name>
          <name><surname>Uhlich</surname><given-names>Stefan</given-names></name>
          <name><surname>Liutkus</surname><given-names>Antoine</given-names></name>
          <name><surname>Mitsufuji</surname><given-names>Yuki</given-names></name>
        </person-group>
        <article-title>Open-unmix - a reference implementation for music source separation</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://doi.org/10.21105/joss.01667</uri>
        <pub-id pub-id-type="doi">10.21105/joss.01667</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-spleeter">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Hennequin</surname><given-names>Romain</given-names></name>
          <name><surname>Khlif</surname><given-names>Anis</given-names></name>
          <name><surname>Voituret</surname><given-names>Felix</given-names></name>
          <name><surname>Moussallam</surname><given-names>Manuel</given-names></name>
        </person-group>
        <article-title>Spleeter</article-title>
        <year iso-8601-date="2019">2019</year>
        <uri>https://www.github.com/deezer/spleeter</uri>
      </element-citation>
    </ref>
    <ref id="ref-demucs">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Défossez</surname><given-names>Alexandre</given-names></name>
          <name><surname>Usunier</surname><given-names>Nicolas</given-names></name>
          <name><surname>Bottou</surname><given-names>Léon</given-names></name>
          <name><surname>Bach</surname><given-names>Francis</given-names></name>
        </person-group>
        <article-title>Music source separation in the waveform domain</article-title>
        <year iso-8601-date="2019">2019</year>
        <uri>https://arxiv.org/abs/1911.13254</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

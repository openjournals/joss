<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3642</article-id>
<article-id pub-id-type="doi">10.21105/joss.03642</article-id>
<title-group>
<article-title>Feature-engine: A Python package for feature engineering
for machine learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Soledad Galli</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Train in Data</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-08-06">
<day>6</day>
<month>8</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>65</issue>
<fpage>3642</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>python</kwd>
<kwd>feature engineering</kwd>
<kwd>feature selection</kwd>
<kwd>machine learning</kwd>
<kwd>data science</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Feature-engine is an open source Python library with the most
  exhaustive battery of transformations to engineer and select features
  for use in machine learning. Feature-engine supports several
  techniques to impute missing data, encode categorical variables,
  transform variables mathematically, perform discretization, remove or
  censor outliers, and combine variables into new features.
  Feature-engine also hosts an array of algorithms for feature
  selection.</p>
  <p>The primary goal of Feature-engine is to make commonly used data
  transformation procedures accessible to researchers and data
  scientists, focusing on creating user-friendly and intuitive classes,
  compatible with existing machine learning libraries, like Scikit-learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-sklearn" ref-type="bibr">Pedregosa
  et al., 2011</xref>) and Pandas
  (<xref alt="McKinney, 2010" rid="ref-pandas" ref-type="bibr">McKinney,
  2010</xref>).</p>
  <p>Many feature transformation techniques learn parameters from data,
  like the values for imputation or the mappings for encoding.
  Feature-engine classes learn these parameters from the data and store
  them in their attributes to transform future data. Feature-engine’s
  transformers preserve Scikit-learn’s functionality with the methods
  fit() and transform() to learn parameters from and then transform
  data. Feature-engine’s transformers can be incorporated into a
  Scikit-learn Pipeline to streamline data transformation and facilitate
  model deployment, by allowing the serialization of the entire pipeline
  in one pickle.</p>
  <p>When pre-processing a dataset different feature transformations are
  applied to different variable groups. Feature-engine classes allow the
  user to select which variables to transform within each class,
  therefore, while taking the entire dataframe as input, only the
  indicated variables are modified. Data pre-processing and feature
  engineering are commonly done together with data exploration.
  Feature-engine transformers return dataframes as output, thus, users
  can continue to leverage the power of Pandas for data analysis and
  visualization after transforming the data set.</p>
  <p>In summary, Feature-engine supports a large variety of commonly
  used data transformation techniques
  (<xref alt="Box &amp; Cox, 1964" rid="ref-boxcox" ref-type="bibr">Box
  &amp; Cox, 1964</xref>;
  <xref alt="Dong, 2015" rid="ref-beatingkaggle" ref-type="bibr">Dong,
  2015</xref>;
  <xref alt="Dror et al., 2011" rid="ref-kdd_2009_competition" ref-type="bibr">Dror
  et al., 2011</xref>;
  <xref alt="Kotsiantis et al., 2006" rid="ref-data_prep" ref-type="bibr">Kotsiantis
  et al., 2006</xref>;
  <xref alt="Micci-Barreca, 2001" rid="ref-micci_mean_encoder" ref-type="bibr">Micci-Barreca,
  2001</xref>;
  <xref alt="Yeo &amp; Johnson, 2000" rid="ref-yeojohnson" ref-type="bibr">Yeo
  &amp; Johnson, 2000</xref>), as well as techniques that were developed
  in data science competitions
  (<xref alt="Niculescu-Mizil et al., 2009" rid="ref-niculescu09_kdd" ref-type="bibr">Niculescu-Mizil
  et al., 2009</xref>), including those for feature selection
  (<xref alt="Miller et al., 2009" rid="ref-miller09_kdd" ref-type="bibr">Miller
  et al., 2009</xref>). Thus, Feature-engine builds upon and extends the
  capabilities of Python’s current scientific computing stack and makes
  accessible transformations that are otherwise not easy to find,
  understand or code, to data scientist and data practitioners.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Data scientists spend an enormous amount of time on data
  pre-processing and transformation ahead of training machine learning
  models
  (<xref alt="Domingos, 2012" rid="ref-domingos" ref-type="bibr">Domingos,
  2012</xref>). While some feature engineering processes can be
  domain-specific, a large variety of transformations are commonly
  applied across datasets. For example, data scientists need to impute
  or remove missing values or transform categories into numbers, to
  train machine learning models using Scikit-learn, the main library for
  machine learning. Yet, depending on the nature of the variable and the
  characteristics of the machine learning model, they may need to use
  different techniques.</p>
  <p>Feature-engine gathers the most frequently used data pre-processing
  techniques, as well as bespoke techniques developed in data science
  competitions, in a library, from which users can pick and choose the
  transformation that they need, and use it just like they would use any
  other Scikit-learn class. As a result, users are spared of manually
  creating a lot of code, which is often repetitive, as the same
  procedures are applied to different datasets. In addition,
  Feature-engine classes are written to production standards, which
  ensures classes return the expected result, and maximizes
  reproducibility between research and production environments through
  version control.</p>
  <p>In the last few years, a number of open source Python libraries
  that support feature engineering techniques have emerged, highlighting
  the importance of making feature engineering and creation accessible
  and, as much as possible, automated. Among these, Featuretools
  (<xref alt="Kanter &amp; Veeramachaneni, 2015" rid="ref-kanter2015deep" ref-type="bibr">Kanter
  &amp; Veeramachaneni, 2015</xref>) creates features from temporal and
  relational datasets, tsfresh
  (<xref alt="Christ et al., 2018" rid="ref-christ_tsfresh" ref-type="bibr">Christ
  et al., 2018</xref>) extracts features from time series, Category
  encoders
  (<xref alt="McGinnis et al., 2018" rid="ref-category_encoders" ref-type="bibr">McGinnis
  et al., 2018</xref>) supports a comprehensive list of methods to
  encode categorical variables, and Scikit-learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-sklearn" ref-type="bibr">Pedregosa
  et al., 2011</xref>) implements a number of data transformation
  techniques, with the caveat that the transformations are applied to
  the entire dataset, and the output are NumPy arrays. Feature-engine
  extends the capabilities of the current Python’s scientific computing
  stack by allowing the application of the transformations to subsets of
  variables in the dataset, returning dataframes for data exploration,
  and supporting transformations not currently available in other
  libraries, like those for outlier censoring or removal, besides
  additional techniques for discretization and feature selection that
  were developed by data scientist working in the industry or data
  science competitions.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>I would like to acknowledge all of the contributors and users of
  Feature-engine, who helped with valuable feedback, bug fixes, and
  additional functionality to further improve the library. A special
  thanks to Christopher Samiullah for continuous support on code quality
  and architecture. A list of Feature-engine contributors is available
  at
  https://github.com/feature-engine/feature_engine/graphs/contributors.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-sklearn">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-pandas">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>McKinney</surname></name>
        </person-group>
        <article-title>Data Structures for Statistical Computing in Python</article-title>
        <source>Proceedings of the 9th Python in Science Conference</source>
        <person-group person-group-type="editor">
          <name><surname>Walt</surname></name>
          <name><surname>Millman</surname></name>
        </person-group>
        <year iso-8601-date="2010">2010</year>
        <pub-id pub-id-type="doi"> 10.25080/Majora-92bf1922-00a </pub-id>
      </element-citation>
    </ref>
    <ref id="ref-niculescu09_kdd">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Niculescu-Mizil</surname><given-names>Alexandru</given-names></name>
          <name><surname>Perlich</surname><given-names>Claudia</given-names></name>
          <name><surname>Swirszcz</surname><given-names>Grzegorz</given-names></name>
          <name><surname>Sindhwani</surname><given-names>Vikas</given-names></name>
          <name><surname>Liu</surname><given-names>Yan</given-names></name>
          <name><surname>Melville</surname><given-names>Prem</given-names></name>
          <name><surname>Wang</surname><given-names>Dong</given-names></name>
          <name><surname>Xiao</surname><given-names>Jing</given-names></name>
          <name><surname>Hu</surname><given-names>Jianying</given-names></name>
          <name><surname>Singh</surname><given-names>Moninder</given-names></name>
          <name><surname>Shang</surname><given-names>Wei Xiong</given-names></name>
          <name><surname>Zhu</surname><given-names>Yan Feng</given-names></name>
        </person-group>
        <article-title>Winning the KDD cup orange challenge with ensemble selection</article-title>
        <source>Proceedings of KDD-cup 2009 competition</source>
        <person-group person-group-type="editor">
          <name><surname>Dror</surname><given-names>Gideon</given-names></name>
          <name><surname>Boullé</surname><given-names>Mar</given-names></name>
          <name><surname>Guyon</surname><given-names>Isabelle</given-names></name>
          <name><surname>Lemaire</surname><given-names>Vincent</given-names></name>
          <name><surname>Vogel</surname><given-names>David</given-names></name>
        </person-group>
        <publisher-name>PMLR</publisher-name>
        <publisher-loc>New York, New York, USA</publisher-loc>
        <year iso-8601-date="2009">2009</year>
        <volume>7</volume>
        <uri>http://proceedings.mlr.press/v7/niculescu09.html</uri>
      </element-citation>
    </ref>
    <ref id="ref-micci_mean_encoder">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Micci-Barreca</surname><given-names>Daniele</given-names></name>
        </person-group>
        <article-title>A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems</article-title>
        <source>SIGKDD Explor. Newsl.</source>
        <publisher-name>Association for Computing Machinery</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2001-07">2001</year><month>07</month>
        <volume>3</volume>
        <issue>1</issue>
        <issn>1931-0145</issn>
        <uri>https://doi.org/10.1145/507533.507538</uri>
        <pub-id pub-id-type="doi">10.1145/507533.507538</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-boxcox">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Box</surname><given-names>G. E. P.</given-names></name>
          <name><surname>Cox</surname><given-names>D. R.</given-names></name>
        </person-group>
        <article-title>An analysis of transformations</article-title>
        <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>
        <year iso-8601-date="1964">1964</year>
        <volume>26</volume>
        <issue>2</issue>
        <uri>https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1964.tb00553.x</uri>
        <pub-id pub-id-type="doi">10.1111/j.2517-6161.1964.tb00553.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-yeojohnson">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Yeo</surname><given-names>In‐Kwon</given-names></name>
          <name><surname>Johnson</surname><given-names>Richard A.</given-names></name>
        </person-group>
        <article-title>A new family of power transformations to improve normality or symmetry</article-title>
        <source>Biometrika</source>
        <year iso-8601-date="2000-12">2000</year><month>12</month>
        <volume>87</volume>
        <issue>4</issue>
        <issn>0006-3444</issn>
        <uri>https://doi.org/10.1093/biomet/87.4.954</uri>
        <pub-id pub-id-type="doi">10.1093/biomet/87.4.954</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-data_prep">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kotsiantis</surname><given-names>Sotiris</given-names></name>
          <name><surname>Kanellopoulos</surname><given-names>Dimitris</given-names></name>
          <name><surname>Pintelas</surname><given-names>P.</given-names></name>
        </person-group>
        <article-title>Data preprocessing for supervised learning</article-title>
        <source>International Journal of Computer Science</source>
        <year iso-8601-date="2006-01">2006</year><month>01</month>
        <volume>1</volume>
      </element-citation>
    </ref>
    <ref id="ref-beatingkaggle">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Dong</surname><given-names>Ying</given-names></name>
        </person-group>
        <article-title>Beating Kaggle the easy way</article-title>
        <source>Studienarbeit</source>
        <publisher-name>Technische Universität Darmstadt</publisher-name>
        <year iso-8601-date="2015">2015</year>
      </element-citation>
    </ref>
    <ref id="ref-domingos">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Domingos</surname><given-names>Pedro</given-names></name>
        </person-group>
        <article-title>A few useful things to know about machine learning</article-title>
        <source>Commun. ACM</source>
        <publisher-name>Association for Computing Machinery</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2012-10">2012</year><month>10</month>
        <volume>55</volume>
        <issue>10</issue>
        <issn>0001-0782</issn>
        <uri>https://doi.org/10.1145/2347736.2347755</uri>
        <pub-id pub-id-type="doi">10.1145/2347736.2347755</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kdd_2009_competition">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Dror</surname><given-names>G.</given-names></name>
          <name><surname>Boullé</surname><given-names>M.</given-names></name>
          <name><surname>Guyon</surname><given-names>I.</given-names></name>
        </person-group>
        <article-title>The 2009 knowledge discovery and data mining competition (KDD cup 2009): Challenges in machine learning</article-title>
        <publisher-name>Microtome Publishing</publisher-name>
        <year iso-8601-date="2011">2011</year>
      </element-citation>
    </ref>
    <ref id="ref-miller09_kdd">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Miller</surname><given-names>Hugh</given-names></name>
          <name><surname>Clarke</surname><given-names>Sandy</given-names></name>
          <name><surname>Lane</surname><given-names>Stephen</given-names></name>
          <name><surname>Lonie</surname><given-names>Andrew</given-names></name>
          <name><surname>Lazaridis</surname><given-names>David</given-names></name>
          <name><surname>Petrovski</surname><given-names>Slave</given-names></name>
          <name><surname>Jones</surname><given-names>Owen</given-names></name>
        </person-group>
        <article-title>Predicting customer behaviour: The university of melbourne’s KDD cup report</article-title>
        <source>Proceedings of KDD-cup 2009 competition</source>
        <person-group person-group-type="editor">
          <name><surname>Dror</surname><given-names>Gideon</given-names></name>
          <name><surname>Boullé</surname><given-names>Mar</given-names></name>
          <name><surname>Guyon</surname><given-names>Isabelle</given-names></name>
          <name><surname>Lemaire</surname><given-names>Vincent</given-names></name>
          <name><surname>Vogel</surname><given-names>David</given-names></name>
        </person-group>
        <publisher-name>PMLR</publisher-name>
        <publisher-loc>New York, New York, USA</publisher-loc>
        <year iso-8601-date="2009">2009</year>
        <volume>7</volume>
        <uri>http://proceedings.mlr.press/v7/miller09.html</uri>
      </element-citation>
    </ref>
    <ref id="ref-kanter2015deep">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kanter</surname><given-names>James Max</given-names></name>
          <name><surname>Veeramachaneni</surname><given-names>Kalyan</given-names></name>
        </person-group>
        <article-title>Deep feature synthesis: Towards automating data science endeavors</article-title>
        <source>2015 IEEE international conference on data science and advanced analytics, DSAA 2015, paris, france, october 19-21, 2015</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1109/DSAA.2015.7344858</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-christ_tsfresh">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Christ</surname><given-names>Maximilian</given-names></name>
          <name><surname>Braun</surname><given-names>Nils</given-names></name>
          <name><surname>Neuffer</surname><given-names>Julius</given-names></name>
          <name><surname>Kempa-Liehr</surname><given-names>Andreas W.</given-names></name>
        </person-group>
        <article-title>Time series FeatuRe extraction on basis of scalable hypothesis tests (tsfresh – a python package)</article-title>
        <source>Neurocomputing</source>
        <year iso-8601-date="2018">2018</year>
        <volume>307</volume>
        <issn>0925-2312</issn>
        <uri>https://www.sciencedirect.com/science/article/pii/S0925231218304843</uri>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2018.03.067</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-category_encoders">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>McGinnis</surname><given-names>William D.</given-names></name>
          <name><surname>Siu</surname><given-names>Chapman</given-names></name>
          <name><surname>S</surname><given-names>Andre</given-names></name>
          <name><surname>Huang</surname><given-names>Hanyu</given-names></name>
        </person-group>
        <article-title>Category encoders: A scikit-learn-contrib package of transformers for encoding categorical data</article-title>
        <source>Journal of Open Source Software</source>
        <publisher-name>The Open Journal</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>3</volume>
        <issue>21</issue>
        <uri>https://doi.org/10.21105/joss.00501</uri>
        <pub-id pub-id-type="doi">10.21105/joss.00501</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

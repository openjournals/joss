<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2232</article-id>
<article-id pub-id-type="doi">10.21105/joss.02232</article-id>
<title-group>
<article-title>policytree: Policy learning via doubly robust empirical
welfare maximization over trees</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6093-1390</contrib-id>
<string-name>Erik Sverdrup</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Ayush Kanodia</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Zhengyuan Zhou</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Susan Athey</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Stefan Wager</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Stanford Graduate School of Business</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>NYU Stern</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-01-20">
<day>20</day>
<month>1</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>50</issue>
<fpage>2232</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>causal inference</kwd>
<kwd>econometrics</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The problem of learning treatment assignment policies from
  randomized or observational data arises in many fields. For example,
  in personalized medicine, we seek to map patient observables (like
  age, gender, heart pressure, etc.) to a treatment choice using a
  data-driven rule.</p>
  <p>There has recently been a considerable amount of work on
  statistical methodology for policy learning, including Manski
  (<xref alt="2004" rid="ref-manski2004statistical" ref-type="bibr">2004</xref>),
  Zhao et al.
  (<xref alt="2012" rid="ref-zhao2012estimating" ref-type="bibr">2012</xref>),
  Swaminathan &amp; Joachims
  (<xref alt="2015" rid="ref-swaminathan2015batch" ref-type="bibr">2015</xref>),
  Kitagawa &amp; Tetenov
  (<xref alt="2018" rid="ref-kitagawa2018should" ref-type="bibr">2018</xref>),
  van der Laan &amp; Luedtke
  (<xref alt="2015" rid="ref-van2015targeted" ref-type="bibr">2015</xref>),
  Luedtke &amp; van der Laan
  (<xref alt="2016" rid="ref-luedtke2016super" ref-type="bibr">2016</xref>),
  Mbakop &amp; Tabord-Meehan
  (<xref alt="2016" rid="ref-mbakop2016model" ref-type="bibr">2016</xref>),
  Athey &amp; Wager
  (<xref alt="2017" rid="ref-athey2017efficient" ref-type="bibr">2017</xref>),
  Kallus &amp; Zhou
  (<xref alt="2018" rid="ref-kallus2018confounding" ref-type="bibr">2018</xref>),
  and Zhou et al.
  (<xref alt="2018" rid="ref-zhou2018offline" ref-type="bibr">2018</xref>).
  In particular, Kitagawa &amp; Tetenov
  (<xref alt="2018" rid="ref-kitagawa2018should" ref-type="bibr">2018</xref>)
  show that if we only consider policies <inline-formula><alternatives>
  <tex-math><![CDATA[\pi]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
  restricted to a class <inline-formula><alternatives>
  <tex-math><![CDATA[\Pi]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Π</mml:mi></mml:math></alternatives></inline-formula>
  with finite VC dimension and have access to data from a randomized
  trial with <inline-formula><alternatives>
  <tex-math><![CDATA[n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>n</mml:mi></mml:math></alternatives></inline-formula>
  samples, then an empirical welfare maximization algorithm achieves
  regret that scales as <inline-formula><alternatives>
  <tex-math><![CDATA[\sqrt{\operatorname{VC}(\Pi) / n}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msqrt><mml:mrow><mml:mo>VC</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Π</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>/</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msqrt></mml:math></alternatives></inline-formula>.
  Athey &amp; Wager
  (<xref alt="2017" rid="ref-athey2017efficient" ref-type="bibr">2017</xref>)
  extend this result to observational studies via doubly robust scoring,
  and Zhou et al.
  (<xref alt="2018" rid="ref-zhou2018offline" ref-type="bibr">2018</xref>)
  further consider the case with multiple treatment choices (in
  particular, the regret will depend on the tree depth, feature space,
  and number of actions).</p>
  <p>The package <monospace>policytree</monospace> for
  <monospace>R</monospace>
  (<xref alt="R Core Team, 2020" rid="ref-R" ref-type="bibr">R Core
  Team, 2020</xref>) implements the multi-action doubly robust approach
  of Zhou et al.
  (<xref alt="2018" rid="ref-zhou2018offline" ref-type="bibr">2018</xref>)
  in the case where we want to learn policies
  <inline-formula><alternatives>
  <tex-math><![CDATA[\pi]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>π</mml:mi></mml:math></alternatives></inline-formula>
  that belong to the class <inline-formula><alternatives>
  <tex-math><![CDATA[\Pi]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Π</mml:mi></mml:math></alternatives></inline-formula>
  of depth-<inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>
  decision trees. In order to use <monospace>policytree</monospace>, the
  user starts by specifying a set of doubly robust scores for policy
  evaluation; the software then carries out globally optimal weighted
  search over decision trees.</p>
  <p>It is well known that finding an optimal tree of arbitrary depth is
  NP-hard. However, if we restrict our attention to trees of depth
  <inline-formula><alternatives>
  <tex-math><![CDATA[k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>,
  then the problem can be solved in polynomial time. Here, we implement
  the global optimization via an exhaustive (unconstrained) tree search
  that runs in <inline-formula><alternatives>
  <tex-math><![CDATA[O(P^{k} N^{k} (\log N + D) + PN\log N)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mi>N</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  time, where <inline-formula><alternatives>
  <tex-math><![CDATA[N]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>N</mml:mi></mml:math></alternatives></inline-formula>
  is the number of individuals, <inline-formula><alternatives>
  <tex-math><![CDATA[P]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>P</mml:mi></mml:math></alternatives></inline-formula>
  the number of characteristics observed for each individual and
  <inline-formula><alternatives>
  <tex-math><![CDATA[D]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>D</mml:mi></mml:math></alternatives></inline-formula>
  is the number of available treatment choices (see details below). If
  an individual’s characteristics only takes on a few discrete values,
  the runtime can be reduced by a factor of
  <inline-formula><alternatives>
  <tex-math><![CDATA[N^k]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msup><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:math></alternatives></inline-formula>.
  Additionally, an optional approximation parameter lets the user
  control how many splits to consider.</p>
  <fig>
    <caption><p>A depth 2 tree fit on data from the National Job
    Training Partnership Act Study
    (<xref alt="Bloom et al., 1997" rid="ref-bloom1997benefits" ref-type="bibr">Bloom
    et al., 1997</xref>). The reward matrix contains two outcomes: not
    assigning treatment (action 1), and assigning treatment, a job
    training program (action 2). The covariate matrix contains two
    variables: a candidate’s previous annual earnings in $1,000 and
    years of education. Note: the optional package
    <monospace>DiagrammeR</monospace> is needed to plot
    trees.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="example.png" xlink:title="" />
  </fig>
  <p>Our package is integrated with the <monospace>R</monospace> package
  <monospace>grf</monospace> of Athey et al.
  (<xref alt="2019" rid="ref-athey2019generalized" ref-type="bibr">2019</xref>),
  allowing for a simple workflow that uses random forests to estimate
  the nuisance components required to automatically form the doubly
  robust scores. We also generalize the
  <monospace>causal_forest</monospace> function from
  <monospace>grf</monospace> to multiple treatment effects with a one vs
  all encoding described in Zhou et al.
  (<xref alt="2018" rid="ref-zhou2018offline" ref-type="bibr">2018</xref>).
  The following simulation example illustrates this workflow in a
  setting with <inline-formula><alternatives>
  <tex-math><![CDATA[D = 3]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  actions; here, we write covariates with <monospace>X</monospace>,
  outcomes as <monospace>Y</monospace>, and actions as
  <monospace>W</monospace>. Figure 1 shows a tree similarly grown on a
  dataset considered by Kitagawa &amp; Tetenov
  (<xref alt="2018" rid="ref-kitagawa2018should" ref-type="bibr">2018</xref>).</p>
  <code language="r script">library(policytree)
X &lt;- matrix(rnorm(2000 * 10), 2000, 10)
W &lt;- sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), 2000, replace = TRUE)
Y &lt;- X[,1] + X[,2] * (W == &quot;B&quot;) + X[,3] * (W == &quot;C&quot;) + runif(2000)
multi.forest &lt;- multi_causal_forest(X = X, Y = Y, W = W)
DR.scores &lt;- double_robust_scores(multi.forest)
tr &lt;- policy_tree(X, DR.scores, depth = 2)
plot(tr)</code>
  <p>The core tree search functionality is built in C++ using the
  <monospace>Rcpp</monospace> interface
  (<xref alt="Eddelbuettel et al., 2011" rid="ref-eddelbuettel2011rcpp" ref-type="bibr">Eddelbuettel
  et al., 2011</xref>). This approach to tree search is discussed
  further by Zhou et al.
  (<xref alt="2018" rid="ref-zhou2018offline" ref-type="bibr">2018</xref>),
  who find it to scale better to large sample size problems than an
  alternative based on mixed-integer programming. We also note the
  <monospace>R</monospace> package <monospace>evtree</monospace> by
  Grubinger et al.
  (<xref alt="2014" rid="ref-JSSv061i01" ref-type="bibr">2014</xref>),
  which can be used to heuristically optimize over decision trees via
  evolutionary search, and <monospace>tmle3mopttx</monospace> by
  Malenica et al.
  (<xref alt="2020" rid="ref-tmle3" ref-type="bibr">2020</xref>), for
  estimating optimal individual treatments.</p>
</sec>
<sec id="appendix">
  <title>Appendix:</title>
  <sec id="details-on-tree-search">
    <title>Details on tree search</title>
    <p>The pseudocode for the tree search is outlined in Algorithm 1 and
    Algorithm 2. At a high level, in the main recursive case for
    <inline-formula><alternatives>
    <tex-math><![CDATA[k >= 2]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    the algorithm maintains the data structure
    <inline-formula><alternatives>
    <tex-math><![CDATA[sorted\_sets]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>_</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    to quickly obtain the sort order of points along all dimensions
    <inline-formula><alternatives>
    <tex-math><![CDATA[P]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>P</mml:mi></mml:math></alternatives></inline-formula>
    for a given split. For each of the <inline-formula><alternatives>
    <tex-math><![CDATA[P \times (N - 1)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    possible splits, for each dimension j all points on the right side
    are stored in <inline-formula><alternatives>
    <tex-math><![CDATA[set_R(j)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    All points on the left side are stored in
    <inline-formula><alternatives>
    <tex-math><![CDATA[set_L(j)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    For each split candidate, the point is moved from the right set to
    the left set for all dimensions. This proceeds recursively to
    enumerate the reward in all possible splits.</p>
    <p>The <inline-formula><alternatives>
    <tex-math><![CDATA[O(PN\log N)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>P</mml:mi><mml:mi>N</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    term arises from the fixed amortized cost of creating the global
    sort order once for every sample along all P dimensions. The
    remaining <inline-formula><alternatives>
    <tex-math><![CDATA[O(P^{k} N^{k} (\log N + D))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    term is obtained by inductively calculating the runtime for
    increasing depths <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>.</p>
  </sec>
  <sec id="deriving-the-running-time">
    <title>Deriving the running time</title>
    <p>: k = 0 (no splits): In this case, all we need to do is calculate
    the sum of rewards over each of the available treatment choices D
    for the N users. Hence, the time complexity is
    <inline-formula><alternatives>
    <tex-math><![CDATA[O(ND)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p>: k = 1 (1 split): In this case, as we show in Algorithm 2, the
    time complexity is <inline-formula><alternatives>
    <tex-math><![CDATA[O(NPD + NP \log N)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    We first sort all N points along all P dimensions. This accounts for
    the <inline-formula><alternatives>
    <tex-math><![CDATA[NP \log N]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    term. Along each dimension, first we keep a cumulative sum of
    rewards for each treatment on both sides of every possible split.
    This takes time <inline-formula><alternatives>
    <tex-math><![CDATA[O(ND)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    given the sorted order on points along that dimension. We can then
    calculate the best split point given this sort order, along with the
    best policy in both splits in time <inline-formula><alternatives>
    <tex-math><![CDATA[O(ND)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
    as in the pseudocode. Doing this over all dimensions, we get
    <inline-formula><alternatives>
    <tex-math><![CDATA[O(NPD)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    Combining this with the initial sort, we get
    <inline-formula><alternatives>
    <tex-math><![CDATA[O(NPD + NP \log N) = O(NP(\log N + D))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p> We propose the time complexity for
    <inline-formula><alternatives>
    <tex-math><![CDATA[k >= 1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    (1 or more splits) to be <inline-formula><alternatives>
    <tex-math><![CDATA[O(P^{k} N^{k} (\log N + D))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    This is satisfied for base case 2 above. For the recursive case,
    there are <inline-formula><alternatives>
    <tex-math><![CDATA[PN]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    possible split points. For every single split along along every
    dimension we remove a sample from a Binary Search Tree and add to
    another; this takes <inline-formula><alternatives>
    <tex-math><![CDATA[O(\log N)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    time, and we do this for each of the <inline-formula><alternatives>
    <tex-math><![CDATA[P]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>P</mml:mi></mml:math></alternatives></inline-formula>
    dimensions, leading to time <inline-formula><alternatives>
    <tex-math><![CDATA[(P \log N)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>P</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
    Further, for each split, we recursively call
    <inline-formula><alternatives>
    <tex-math><![CDATA[tree\_search]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    for depth <inline-formula><alternatives>
    <tex-math><![CDATA[k - 1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
    in general there are <inline-formula><alternatives>
    <tex-math><![CDATA[m_1]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[m_2]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
    points in each split at the top level such that
    <inline-formula><alternatives>
    <tex-math><![CDATA[N = m_1 + m_2]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.
    Assuming the recursive expression, the amount of work done for each
    split is then</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[O(P \log N + m_1^{k-1} P^{k-1} (\log m_1 + D) + m_2^{k-1} P^{k-1} (\log m_2 + D))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>P</mml:mi><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
    <p>Note that,</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[m_1^{k-1} P^{k-1} (\log {m_1} + D) < m_1^{k-1} P^{k-1}(\log N + D)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    since <inline-formula><alternatives>
    <tex-math><![CDATA[m_1 < N]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p>Similarly,</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[m_2^{k-1}P^{k-1}(\log m_2 + D) < m_2^{k-1}P^{k-1}(\log N + D)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    since <inline-formula><alternatives>
    <tex-math><![CDATA[m_2 < N]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p>Further,</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[m_1^{k-1} P (\log N + D) + m_2^{k-1} P (\log N + D) < N^{k-1} P^{k-1} (\log N + D)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
    <p>since <inline-formula><alternatives>
    <tex-math><![CDATA[m_1 + m_2 = N, m_1, m_2, N > 0]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p>Combining, the amount of work in each split is upper bounded
    by</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[O(P^{k-1} N^{k-1} (\log N + d))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <p>Since we have <inline-formula><alternatives>
    <tex-math><![CDATA[P N]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    splits, this leads to a running time of</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[O(PN (P^{k-1} N^{k-1} (\log N + d)) = O(P^{k}N^{k} (\log N + d))]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>O</mml:mi><mml:mo stretchy="false" form="prefix">(</mml:mo><mml:mi>P</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>log</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-athey2017efficient">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Athey</surname><given-names>Susan</given-names></name>
          <name><surname>Wager</surname><given-names>Stefan</given-names></name>
        </person-group>
        <article-title>Efficient policy learning</article-title>
        <source>arXiv preprint arXiv:1702.02896</source>
        <year iso-8601-date="2017">2017</year>
      </element-citation>
    </ref>
    <ref id="ref-kitagawa2018should">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kitagawa</surname><given-names>Toru</given-names></name>
          <name><surname>Tetenov</surname><given-names>Aleksey</given-names></name>
        </person-group>
        <article-title>Who should be treated? Empirical welfare maximization methods for treatment choice</article-title>
        <source>Econometrica</source>
        <publisher-name>Wiley Online Library</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>86</volume>
        <issue>2</issue>
        <uri>https://doi.org/10.3982/ECTA13288</uri>
        <pub-id pub-id-type="doi">10.3982/ECTA13288</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-zhou2018offline">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zhou</surname><given-names>Zhengyuan</given-names></name>
          <name><surname>Athey</surname><given-names>Susan</given-names></name>
          <name><surname>Wager</surname><given-names>Stefan</given-names></name>
        </person-group>
        <article-title>Offline multi-action policy learning: Generalization and optimization</article-title>
        <source>arXiv preprint arXiv:1810.04778</source>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-mbakop2016model">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Mbakop</surname><given-names>Eric</given-names></name>
          <name><surname>Tabord-Meehan</surname><given-names>Max</given-names></name>
        </person-group>
        <article-title>Model selection for treatment choice: Penalized welfare maximization</article-title>
        <source>arXiv preprint arXiv:1609.03167</source>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-athey2019generalized">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Athey</surname><given-names>Susan</given-names></name>
          <name><surname>Tibshirani</surname><given-names>Julie</given-names></name>
          <name><surname>Wager</surname><given-names>Stefan</given-names></name>
        </person-group>
        <article-title>Generalized random forests</article-title>
        <source>The Annals of Statistics</source>
        <publisher-name>Institute of Mathematical Statistics</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>47</volume>
        <issue>2</issue>
      </element-citation>
    </ref>
    <ref id="ref-bloom1997benefits">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bloom</surname><given-names>Howard S</given-names></name>
          <name><surname>Orr</surname><given-names>Larry L</given-names></name>
          <name><surname>Bell</surname><given-names>Stephen H</given-names></name>
          <name><surname>Cave</surname><given-names>George</given-names></name>
          <name><surname>Doolittle</surname><given-names>Fred</given-names></name>
          <name><surname>Lin</surname><given-names>Winston</given-names></name>
          <name><surname>Bos</surname><given-names>Johannes M</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>The benefits and costs of JTPA title II-a programs: Key findings from the national job training partnership act study</article-title>
        <source>Journal of human resources</source>
        <publisher-name>University of Wisconsin Press</publisher-name>
        <year iso-8601-date="1997">1997</year>
        <volume>32</volume>
        <issue>3</issue>
        <uri>https://doi.org/10.2307/146183</uri>
        <pub-id pub-id-type="doi">10.2307/146183</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kallus2018confounding">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kallus</surname><given-names>Nathan</given-names></name>
          <name><surname>Zhou</surname><given-names>Angela</given-names></name>
        </person-group>
        <article-title>Confounding-robust policy improvement</article-title>
        <source>Advances in neural information processing systems</source>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-eddelbuettel2011rcpp">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
          <name><surname>François</surname><given-names>Romain</given-names></name>
          <name><surname>Allaire</surname><given-names>J</given-names></name>
          <name><surname>Ushey</surname><given-names>Kevin</given-names></name>
          <name><surname>Kou</surname><given-names>Qiang</given-names></name>
          <name><surname>Russel</surname><given-names>N</given-names></name>
          <name><surname>Chambers</surname><given-names>John</given-names></name>
          <name><surname>Bates</surname><given-names>D</given-names></name>
        </person-group>
        <article-title>Rcpp: Seamless r and c++ integration</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2011">2011</year>
        <volume>40</volume>
        <issue>8</issue>
      </element-citation>
    </ref>
    <ref id="ref-JSSv061i01">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Grubinger</surname><given-names>Thomas</given-names></name>
          <name><surname>Zeileis</surname><given-names>Achim</given-names></name>
          <name><surname>Pfeiffer</surname><given-names>Karl-Peter</given-names></name>
        </person-group>
        <article-title>Evtree: Evolutionary learning of globally optimal classification and regression trees in r</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2014">2014</year>
        <volume>61</volume>
        <issue>1</issue>
        <issn>1548-7660</issn>
        <uri>https://www.jstatsoft.org/v061/i01</uri>
        <pub-id pub-id-type="doi">10.18637/jss.v061.i01</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-manski2004statistical">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Manski</surname><given-names>Charles F</given-names></name>
        </person-group>
        <article-title>Statistical treatment rules for heterogeneous populations</article-title>
        <source>Econometrica</source>
        <publisher-name>Wiley Online Library</publisher-name>
        <year iso-8601-date="2004">2004</year>
        <volume>72</volume>
        <issue>4</issue>
        <uri>https://www.jstor.org/stable/3598783</uri>
        <pub-id pub-id-type="doi">10.1111/j.1468-0262.2004.00530.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-zhao2012estimating">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zhao</surname><given-names>Yingqi</given-names></name>
          <name><surname>Zeng</surname><given-names>Donglin</given-names></name>
          <name><surname>Rush</surname><given-names>A John</given-names></name>
          <name><surname>Kosorok</surname><given-names>Michael R</given-names></name>
        </person-group>
        <article-title>Estimating individualized treatment rules using outcome weighted learning</article-title>
        <source>Journal of the American Statistical Association</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2012">2012</year>
        <volume>107</volume>
        <issue>499</issue>
      </element-citation>
    </ref>
    <ref id="ref-swaminathan2015batch">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Swaminathan</surname><given-names>Adith</given-names></name>
          <name><surname>Joachims</surname><given-names>Thorsten</given-names></name>
        </person-group>
        <article-title>Batch learning from logged bandit feedback through counterfactual risk minimization</article-title>
        <source>The Journal of Machine Learning Research</source>
        <publisher-name>JMLR. org</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>16</volume>
        <issue>1</issue>
      </element-citation>
    </ref>
    <ref id="ref-R">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <source>R: A language and environment for statistical computing</source>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2020">2020</year>
        <uri>https://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-luedtke2016super">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Luedtke</surname><given-names>Alexander R</given-names></name>
          <name><surname>van der Laan</surname><given-names>Mark</given-names></name>
        </person-group>
        <article-title>Super-learning of an optimal dynamic treatment rule</article-title>
        <source>The international journal of biostatistics</source>
        <publisher-name>De Gruyter</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>12</volume>
        <issue>1</issue>
        <uri>https://doi.org/10.1515/ijb-2015-0052</uri>
        <pub-id pub-id-type="doi">10.1515/ijb-2015-0052</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-van2015targeted">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>van der Laan</surname><given-names>Mark</given-names></name>
          <name><surname>Luedtke</surname><given-names>Alexander R</given-names></name>
        </person-group>
        <article-title>Targeted learning of the mean outcome under an optimal dynamic treatment rule</article-title>
        <source>Journal of causal inference</source>
        <publisher-name>De Gruyter</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>3</volume>
        <issue>1</issue>
      </element-citation>
    </ref>
    <ref id="ref-tmle3">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Malenica</surname><given-names>Ivana</given-names></name>
          <name><surname>Coyle</surname><given-names>Jeremy</given-names></name>
          <name><surname>van der Laan</surname><given-names>Mark</given-names></name>
        </person-group>
        <source>tmle3mopttx: Targeted maximum likelihood estimation of the mean under optimal individualized treatment</source>
        <year iso-8601-date="2020">2020</year>
        <uri>https://tlverse.org/tmle3mopttx</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

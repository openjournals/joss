<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1959</article-id>
<article-id pub-id-type="doi">10.21105/joss.01959</article-id>
<title-group>
<article-title>Pyglmnet: Python implementation of elastic-net
regularized generalized linear models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3199-9027</contrib-id>
<string-name>Mainak Jas</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-2124-2979</contrib-id>
<string-name>Titipat Achakulvisut</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<string-name>Aid Idrizoviƒá</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<string-name>Daniel Acuna</string-name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<string-name>Matthew Antalek</string-name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<string-name>Vinicius Marques</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<string-name>Tommy Odland</string-name>
<xref ref-type="aff" rid="aff-7"/>
</contrib>
<contrib contrib-type="author">
<string-name>Ravi Prakash Garg</string-name>
<xref ref-type="aff" rid="aff-6"/>
</contrib>
<contrib contrib-type="author">
<string-name>Mayank Agrawal</string-name>
<xref ref-type="aff" rid="aff-8"/>
</contrib>
<contrib contrib-type="author">
<string-name>Yu Umegaki</string-name>
<xref ref-type="aff" rid="aff-9"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0304-7213</contrib-id>
<string-name>Peter Foley</string-name>
<xref ref-type="aff" rid="aff-10"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0168-4104</contrib-id>
<string-name>Hugo Fernandes</string-name>
<xref ref-type="aff" rid="aff-11"/>
</contrib>
<contrib contrib-type="author">
<string-name>Drew Harris</string-name>
<xref ref-type="aff" rid="aff-12"/>
</contrib>
<contrib contrib-type="author">
<string-name>Beibin Li</string-name>
<xref ref-type="aff" rid="aff-13"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-5473-4849</contrib-id>
<string-name>Olivier Pieters</string-name>
<xref ref-type="aff" rid="aff-14"/>
<xref ref-type="aff" rid="aff-20"/>
</contrib>
<contrib contrib-type="author">
<string-name>Scott Otterson</string-name>
<xref ref-type="aff" rid="aff-15"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-8387-9983</contrib-id>
<string-name>Giovanni De Toni</string-name>
<xref ref-type="aff" rid="aff-16"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-1762-3450</contrib-id>
<string-name>Chris Rodgers</string-name>
<xref ref-type="aff" rid="aff-17"/>
</contrib>
<contrib contrib-type="author">
<string-name>Eva Dyer</string-name>
<xref ref-type="aff" rid="aff-18"/>
</contrib>
<contrib contrib-type="author">
<string-name>Matti Hamalainen</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Konrad Kording</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7450-0727</contrib-id>
<string-name>Pavan Ramkumar</string-name>
<xref ref-type="aff" rid="aff-19"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Massachusetts General Hospital</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Harvard Medical School</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Loyola University</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>University of Syracuse</institution>
</institution-wrap>
</aff>
<aff id="aff-6">
<institution-wrap>
<institution>Northwestern University</institution>
</institution-wrap>
</aff>
<aff id="aff-7">
<institution-wrap>
<institution>Sonat Consulting</institution>
</institution-wrap>
</aff>
<aff id="aff-8">
<institution-wrap>
<institution>Princeton University</institution>
</institution-wrap>
</aff>
<aff id="aff-9">
<institution-wrap>
<institution>NTT DATA Mathematical Systems Inc</institution>
</institution-wrap>
</aff>
<aff id="aff-10">
<institution-wrap>
<institution>605</institution>
</institution-wrap>
</aff>
<aff id="aff-11">
<institution-wrap>
<institution>Rockets of Awesome</institution>
</institution-wrap>
</aff>
<aff id="aff-12">
<institution-wrap>
<institution>Epoch Capital</institution>
</institution-wrap>
</aff>
<aff id="aff-13">
<institution-wrap>
<institution>University of Washington</institution>
</institution-wrap>
</aff>
<aff id="aff-14">
<institution-wrap>
<institution>IDLab-AIRO ‚Äì Ghent University ‚Äì imec</institution>
</institution-wrap>
</aff>
<aff id="aff-15">
<institution-wrap>
<institution>Clean Power Research</institution>
</institution-wrap>
</aff>
<aff id="aff-16">
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
</aff>
<aff id="aff-17">
<institution-wrap>
<institution>Columbia University</institution>
</institution-wrap>
</aff>
<aff id="aff-18">
<institution-wrap>
<institution>Georgia Tech</institution>
</institution-wrap>
</aff>
<aff id="aff-19">
<institution-wrap>
<institution>System1 Biosciences Inc</institution>
</institution-wrap>
</aff>
<aff id="aff-20">
<institution-wrap>
<institution>Research Institute for Agriculture, Fisheries and
Food</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-09-06">
<day>6</day>
<month>9</month>
<year>2019</year>
</pub-date>
<volume>5</volume>
<issue>47</issue>
<fpage>1959</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>glm</kwd>
<kwd>machine-learning</kwd>
<kwd>lasso</kwd>
<kwd>elastic-net</kwd>
<kwd>group-lasso</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized
  linear models</ext-link> (GLMs) are well-established tools for
  regression and classification and are widely applied across the
  sciences, economics, business, and finance. Owing to their convex
  loss, they are easy and efficient to fit. Moreover, they are
  relatively easy to interpret because of their well-defined noise
  distributions and point-wise nonlinearities.</p>
  <p>Mathematically, a GLM is estimated as follows:</p>
  <p><disp-formula><alternatives>
  <tex-math><![CDATA[\min_{\beta_0, \beta} \frac{1}{N} \sum_{i = 1}^N \mathcal{L} (y_i, \beta_0 + \beta^T x_i)
  + \lambda \mathcal{P}(\beta)]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:munder><mml:mo>min</mml:mo><mml:mrow><mml:msub><mml:mi>Œ≤</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>Œ≤</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>‚àë</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mstyle mathvariant="script"><mml:mi>‚Ñí</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>Œ≤</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Œª</mml:mi><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Œ≤</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p>
  <p>where <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{L} (y_i, \beta_0 + \beta^T x_i)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>‚Ñí</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Œ≤</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>Œ≤</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is the negative log-likelihood of an observation
  (<inline-formula><alternatives>
  <tex-math><![CDATA[x_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
  <inline-formula><alternatives>
  <tex-math><![CDATA[y_i]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>),
  and <inline-formula><alternatives>
  <tex-math><![CDATA[\lambda \mathcal{P}(\cdot)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Œª</mml:mi><mml:mstyle mathvariant="script"><mml:mi>ùí´</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  is the penalty that regularizes the solution, with
  <inline-formula><alternatives>
  <tex-math><![CDATA[\lambda]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œª</mml:mi></mml:math></alternatives></inline-formula>
  being a hyperparameter that controls the amount of regularization.</p>
  <p>Modern datasets can contain a number of predictor variables, and
  data analysis is often exploratory. To avoid overfitting of the data
  under these circumstances, it is critically important to regularize
  the model. Regularization works by adding penalty terms that penalize
  the model parameters in a variety of ways. It can be used to
  incorporate our prior knowledge about the parameters‚Äô distribution in
  a structured form.</p>
  <p>Despite the attractiveness and importance of regularized GLMs, the
  available tools in the Python data science eco-system do not serve all
  common functionalities. Specifically:</p>
  <list list-type="bullet">
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="http://statsmodels.sourceforge.net/devel/glm.html">statsmodels</ext-link>
      provides a wide range of noise distributions but no
      regularization.</p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">scikit-learn</ext-link>
      provides elastic net regularization but only limited noise
      distribution options.</p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://github.com/scikit-learn-contrib/lightning">lightning</ext-link>
      provides elastic net and group lasso regularization, but only for
      linear (Gaussian) and logistic (binomial) regression.</p>
    </list-item>
  </list>
  <sec id="pyglmnet-is-a-response-to-a-fragmented-ecosystem">
    <title>Pyglmnet is a response to a fragmented ecosystem</title>
    <p>Pyglmnet offers the ability to combine different types of
    regularization with different GLM noise distributions. In
    particular, it implements a broader form of elastic net
    regularization that include generalized L2 and L1 penalties
    (Tikhonov regularization and Group Lasso, respectively) with
    Gaussian, Binomial, Poisson, Probit, and Gamma distributions. The
    table below compares pyglmnet with existing libraries as of release
    version 1.1.</p>
    <table-wrap>
      <table>
        <colgroup>
          <col width="17%" />
          <col width="10%" />
          <col width="13%" />
          <col width="12%" />
          <col width="14%" />
          <col width="12%" />
          <col width="7%" />
          <col width="14%" />
        </colgroup>
        <thead>
          <tr>
            <th></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="http://github.com/glm-tools/pyglmnet/">pyglmnet</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/stable/">scikit-learn</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="http://statsmodels.sourceforge.net/devel/glm.html">statsmodels</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="https://github.com/scikit-learn-contrib/lightning">lightning</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="https://github.com/madrury/py-glm/">py-glm</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/help/stats/glmfit.html">Matlab</ext-link></th>
            <th align="center"><ext-link ext-link-type="uri" xlink:href="https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html">glmnet</ext-link>
            in R</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><bold>Distributions</bold></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td>Gaussian</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
          </tr>
          <tr>
            <td>Binomial</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
          </tr>
          <tr>
            <td>Poisson</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center">x</td>
          </tr>
          <tr>
            <td>Poisson (softplus)</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td>Probit</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td>Gamma</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
          </tr>
          <tr>
            <td><bold>Regularization</bold></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td>L2</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td>L1 (Lasso)</td>
            <td align="center">x</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center">x</td>
          </tr>
          <tr>
            <td>Generalized L1 (Group Lasso)</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center">x</td>
          </tr>
          <tr>
            <td>Generalized L2 (Tikhonov)</td>
            <td align="center">x</td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
            <td align="center"></td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </sec>
  <sec id="pyglmnet-is-an-extensible-pure-python-implementation">
    <title>Pyglmnet is an extensible pure Python implementation</title>
    <p>Pyglmnet implements the algorithm described in
    <ext-link ext-link-type="uri" xlink:href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">Friedman,
    J., Hastie, T., &amp; Tibshirani, R. (2010)</ext-link> and its
    accompanying popular R package
    <ext-link ext-link-type="uri" xlink:href="https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html">glmnet</ext-link>.
    As opposed to
    <ext-link ext-link-type="uri" xlink:href="https://github.com/civisanalytics/python-glmnet">python-glmnet</ext-link>
    or
    <ext-link ext-link-type="uri" xlink:href="https://github.com/bbalasub1/glmnet_python">glmnet_python</ext-link>,
    which are wrappers around this R package, pyglmnet is written in
    pure Python for Python 3.5+. Therefore, it is easier to extend and
    more compatible with the existing data science ecosystem.</p>
  </sec>
  <sec id="pyglmnet-is-unit-tested-and-documented-with-examples">
    <title>Pyglmnet is unit-tested and documented with examples</title>
    <p>Pyglmnet has already been used in published work
    (<xref alt="Benjamin et al., 2017" rid="ref-benjamin2017modern" ref-type="bibr">Benjamin
    et al., 2017</xref>;
    <xref alt="Bertr√°n et al., 2018" rid="ref-bertran2018active" ref-type="bibr">Bertr√°n
    et al., 2018</xref>;
    <xref alt="H√∂fling et al., 2019" rid="ref-hofling2019probing" ref-type="bibr">H√∂fling
    et al., 2019</xref>;
    <xref alt="Rybakken et al., 2019" rid="ref-rybakken2019decoding" ref-type="bibr">Rybakken
    et al., 2019</xref>). It contains unit tests and includes
    <ext-link ext-link-type="uri" xlink:href="https://glm-tools.github.io/pyglmnet/">documentation</ext-link>
    in the form of tutorials, docstrings and examples that are run
    through continuous integration.</p>
  </sec>
</sec>
<sec id="example-usage">
  <title>Example Usage</title>
  <p>Here, we apply pyglmnet to predict incidence of violent crime from
  the Community and Crime dataset, one of 400+ datasets curated by the
  UC Irvine Machine Learning Repository
  (<xref alt="Dua &amp; Graff, 2019" rid="ref-DuaU003A2019" ref-type="bibr">Dua
  &amp; Graff, 2019</xref>) which provides a highly curated set of 128
  demographic attributes of US counties. The target variable (violent
  crime per capita) is normalized to the range of
  <inline-formula><alternatives>
  <tex-math><![CDATA[[0, 1]]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
  Below, we demonstrate the usage of a pyglmnet‚Äôs binomial-distributed
  GLM with elastic net regularization.</p>
  <code language="python">from sklearn.model_selection import train_test_split
from pyglmnet import GLMCV, simulate_glm, datasets

# Read dataset and split it into train/test
X, y = datasets.fetch_community_crime_data()
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33)

# Instantiate a binomial-distributed GLM with elastic net regularization
glm = GLMCV(distr='binomial', alpha=0.05, score_metric='pseudo_R2', cv=3,
            tol=1e-4)

# Fit the model and then predict
glm.fit(Xtrain, ytrain)
yhat = glm.predict_proba(Xtest)</code>
  <p>As illustrated above, pyglmnet‚Äôs API is designed to be compatible
  with <monospace>scikit-learn</monospace>
  (<xref alt="Buitinck et al., 2013" rid="ref-sklearn_api" ref-type="bibr">Buitinck
  et al., 2013</xref>). Thus, it is possible to use standard idioms such
  as:</p>
  <code language="python">           glm.fit(X, y)
           glm.predict(X)</code>
  <p>Owing to this compatibility, tools from the
  <monospace>scikit-learn</monospace> ecosystem for building pipelines,
  applying cross-validation, and performing grid search over
  hyperparameters can also be employed with pyglmnet‚Äôs estimators.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p><monospace>Pyglmnet</monospace> development is partly supported by
  NIH NINDS R01-NS104585 and the Special Research Fund (B.O.F.) of Ghent
  University.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-bertran2018active">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bertr√°n</surname><given-names>Martƒ±ÃÅn A</given-names></name>
          <name><surname>Martƒ±ÃÅnez</surname><given-names>Natalia L</given-names></name>
          <name><surname>Wang</surname><given-names>Ye</given-names></name>
          <name><surname>Dunson</surname><given-names>David</given-names></name>
          <name><surname>Sapiro</surname><given-names>Guillermo</given-names></name>
          <name><surname>Ringach</surname><given-names>Dario</given-names></name>
        </person-group>
        <article-title>Active learning of cortical connectivity from two-photon imaging data</article-title>
        <source>PloS one</source>
        <publisher-name>Public Library of Science</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>13</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0196527</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-rybakken2019decoding">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Rybakken</surname><given-names>Erik</given-names></name>
          <name><surname>Baas</surname><given-names>Nils</given-names></name>
          <name><surname>Dunn</surname><given-names>Benjamin</given-names></name>
        </person-group>
        <article-title>Decoding of neural data using cohomological feature extraction</article-title>
        <source>Neural computation</source>
        <publisher-name>MIT Press</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>31</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1162/neco_a_01150</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hofling2019probing">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>H√∂fling</surname><given-names>Larissa</given-names></name>
          <name><surname>Berens</surname><given-names>Philipp</given-names></name>
          <name><surname>Zeck</surname><given-names>G√ºnther</given-names></name>
        </person-group>
        <article-title>Probing and predicting ganglion cell responses to smooth electrical stimulation in healthy and blind mouse retina</article-title>
        <source>bioRxiv</source>
        <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <pub-id pub-id-type="doi">10.1101/609826</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-benjamin2017modern">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Benjamin</surname><given-names>Ari S</given-names></name>
          <name><surname>Fernandes</surname><given-names>Hugo L</given-names></name>
          <name><surname>Tomlinson</surname><given-names>Tucker</given-names></name>
          <name><surname>Ramkumar</surname><given-names>Pavan</given-names></name>
          <name><surname>VerSteeg</surname><given-names>Chris</given-names></name>
          <name><surname>Chowdhury</surname><given-names>Raeed</given-names></name>
          <name><surname>Miller</surname><given-names>Lee</given-names></name>
          <name><surname>Kording</surname><given-names>Konrad Paul</given-names></name>
        </person-group>
        <article-title>Modern machine learning outperforms GLMs at predicting spikes</article-title>
        <source>bioRxiv</source>
        <publisher-name>Cold Spring Harbor Laboratory</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <pub-id pub-id-type="doi">10.1101/111450</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-sklearn_api">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Buitinck</surname><given-names>Lars</given-names></name>
          <name><surname>Louppe</surname><given-names>Gilles</given-names></name>
          <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
          <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
          <name><surname>Mueller</surname><given-names>Andreas</given-names></name>
          <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
          <name><surname>Niculae</surname><given-names>Vlad</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
          <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
          <name><surname>Grobler</surname><given-names>Jaques</given-names></name>
          <name><surname>Layton</surname><given-names>Robert</given-names></name>
          <name><surname>VanderPlas</surname><given-names>Jake</given-names></name>
          <name><surname>Joly</surname><given-names>Arnaud</given-names></name>
          <name><surname>Holt</surname><given-names>Brian</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Ga√´l</given-names></name>
        </person-group>
        <article-title>API design for machine learning software: Experiences from the scikit-learn project</article-title>
        <source>ECML PKDD workshop: Languages for data mining and machine learning</source>
        <year iso-8601-date="2013">2013</year>
      </element-citation>
    </ref>
    <ref id="ref-DuaU003A2019">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Dua</surname><given-names>Dheeru</given-names></name>
          <name><surname>Graff</surname><given-names>Casey</given-names></name>
        </person-group>
        <article-title>UCI machine learning repository</article-title>
        <publisher-name>University of California, Irvine, School of Information; Computer Sciences</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <uri>http://archive.ics.uci.edu/ml</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

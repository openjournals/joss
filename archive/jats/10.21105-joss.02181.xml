<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2181</article-id>
<article-id pub-id-type="doi">10.21105/joss.02181</article-id>
<title-group>
<article-title>ldaPrototype: A method in R to get a Prototype of
multiple Latent Dirichlet Allocations</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0007-4478</contrib-id>
<string-name>Jonas Rieger</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>TU Dortmund University</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-03-10">
<day>10</day>
<month>3</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>51</issue>
<fpage>2181</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>topic modeling</kwd>
<kwd>natural language processing</kwd>
<kwd>text data</kwd>
<kwd>tuning</kwd>
<kwd>model selection</kwd>
<kwd>high performance computing</kwd>
<kwd>parallelization</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Topic Modeling
  (<xref alt="Blei, 2012" rid="ref-blei2012" ref-type="bibr">Blei,
  2012</xref>) is one of the biggest subjects in the field of text data
  analysis. Here, the Latent Dirichlet Allocation
  (<xref alt="Blei et al., 2003" rid="ref-blei2003" ref-type="bibr">Blei
  et al., 2003</xref>) takes a special position. A large part of
  scientific text data analyses are based on this model (LDA). The LDA
  method has a far-reaching disadvantage. Random initialization and
  conditional reassignments within the iterative process of the Gibbs
  sampler
  (<xref alt="Griffiths &amp; Steyvers, 2004" rid="ref-griffiths2004" ref-type="bibr">Griffiths
  &amp; Steyvers, 2004</xref>) can result in fundamentally different
  models when executed several times on the same data and with identical
  parameter sets. This fact greatly limits the scientific
  reproducibility.</p>
  <p>Up to now, the so-called eye-balling method has been used in
  practice to select suitable results. From a set of models, subjective
  decisions are made to select the model that seems to fit the data best
  or, in the worst case, the result that best supports one’s hypothesis
  is chosen. The latter contradicts basically good scientific practice.
  A different method of objective and automated selection has also
  become established. A model from a set of LDAs can be determined
  optimizing the log-likelihood using the perplexity on held-out data.
  The
  <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/"><monospace>R</monospace></ext-link>
  (<xref alt="R Core Team, 2020" rid="ref-R" ref-type="bibr">R Core
  Team, 2020</xref>) package
  <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=topicmodels"><monospace>topicmodels</monospace></ext-link>
  (<xref alt="Grün &amp; Hornik, 2011" rid="ref-topicmodels" ref-type="bibr">Grün
  &amp; Hornik, 2011</xref>) provides a workflow for this procedure. As
  an extension, Nguyen et al.
  (<xref alt="2014" rid="ref-nguyen2014" ref-type="bibr">2014</xref>)
  proposed to average different iterations of the Gibbs sampling
  procedure to achieve an increase of perplexity. The averaging
  technique has the weakness, that the user does not get token specific
  assignments to topics, but only averaged topic counts or proportions
  per text. In addition, Chang et al.
  (<xref alt="2009" rid="ref-chang2009" ref-type="bibr">2009</xref>)
  were able to show that selection mechanisms aiming for optimizing
  likelihood-based measures do not correspond to the human perception of
  a well-adapted model of text data. Instead, the authors propose a
  so-called intruder procedure based on human codings. The corresponding
  methodology is implemented in the package
  <ext-link ext-link-type="uri" xlink:href="https://github.com/Docma-TU/tosca"><monospace>tosca</monospace></ext-link>
  (<xref alt="Koppers et al., 2019" rid="ref-tosca" ref-type="bibr">Koppers
  et al., 2019</xref>).</p>
  <p>The
  <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/"><monospace>R</monospace></ext-link>
  package
  <ext-link ext-link-type="uri" xlink:href="https://github.com/JonasRieger/ldaPrototype"><monospace>ldaPrototype</monospace></ext-link>
  on the other hand determines a prototypical LDA by automated selection
  from a set of LDAs. The method improves reliability of findings drawn
  from LDA results
  (<xref alt="Rieger et al., 2020" rid="ref-rieger2020" ref-type="bibr">Rieger
  et al., 2020</xref>), which is achieved following a typical
  statistical approach. For a given combination of parameters, a number
  of models is calculated (usually about 100), from which that LDA is
  determined that is most similar to all other LDAs from a set of
  models. For this purpose pairwise model similarities are calculated
  using the S-CLOP measure (<bold>S</bold>imilarity of Multiple Sets by
  <bold>C</bold>lustering with <bold>Lo</bold>cal <bold>P</bold>runing),
  which can be determined by a clustering procedure of the individual
  topic units based on topic similarities of the two LDA results
  considered. The package offers visualization possibilities for
  comparisons of LDA models based on the clustering of the associated
  topics. Furthermore, the package supports the repetition of the
  modeling procedure of the LDA by a simple calculation of the repeated
  LDA runs.</p>
  <p>In addition to the possibility of local parallel computation by
  connecting to the package
  <ext-link ext-link-type="uri" xlink:href="https://github.com/berndbischl/parallelMap"><monospace>parallelMap</monospace></ext-link>
  (<xref alt="Bischl &amp; Lang, 2019" rid="ref-parallelMap" ref-type="bibr">Bischl
  &amp; Lang, 2019</xref>), there is the possibility to calculate using
  batch systems on high performance computing (HPC) clusters by
  integrating helpful functions from the package
  <ext-link ext-link-type="uri" xlink:href="https://github.com/mllg/batchtools"><monospace>batchtools</monospace></ext-link>
  (<xref alt="Lang et al., 2017" rid="ref-batchtools" ref-type="bibr">Lang
  et al., 2017</xref>). This is especially helpful if the text corpora
  contains several hundred of thousands articles and the sequential
  calculation of 100 or more LDA runs would extend over several days.
  The modeling of single LDA runs is done with the help of the
  computation time optimized
  <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/"><monospace>R</monospace></ext-link>
  package
  <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=lda"><monospace>lda</monospace></ext-link>
  (<xref alt="Chang, 2015" rid="ref-lda" ref-type="bibr">Chang,
  2015</xref>), which implements the calculation in
  <monospace>C++</monospace> code. In general, the package
  <ext-link ext-link-type="uri" xlink:href="https://github.com/JonasRieger/ldaPrototype"><monospace>ldaPrototype</monospace></ext-link>
  is based on <monospace>S3</monospace> objects and thus extends the
  packages
  <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=lda"><monospace>lda</monospace></ext-link>
  and
  <ext-link ext-link-type="uri" xlink:href="https://github.com/Docma-TU/tosca"><monospace>tosca</monospace></ext-link>
  by user-friendly display and processing options. Other
  <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/"><monospace>R</monospace></ext-link>
  packages for estimating LDA are
  <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=topicmodels"><monospace>topicmodels</monospace></ext-link>
  and
  <ext-link ext-link-type="uri" xlink:href="https://github.com/mimno/RMallet"><monospace>mallet</monospace></ext-link>
  (<xref alt="Mimno, 2013" rid="ref-mallet" ref-type="bibr">Mimno,
  2013</xref>), whereas
  <ext-link ext-link-type="uri" xlink:href="https://www.structuraltopicmodel.com/"><monospace>stm</monospace></ext-link>
  (<xref alt="Roberts et al., 2019" rid="ref-stm" ref-type="bibr">Roberts
  et al., 2019</xref>) offers a powerful framework for Structural Topic
  Models and
  <ext-link ext-link-type="uri" xlink:href="https://quanteda.io/"><monospace>quanteda</monospace></ext-link>
  (<xref alt="Benoit et al., 2018" rid="ref-quanteda" ref-type="bibr">Benoit
  et al., 2018</xref>) is a popular framework for preprocessing and
  quantitative analysis of text data.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-R">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <source>R: A Language and Environment for Statistical Computing</source>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2020">2020</year>
        <uri>https://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-tosca">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Koppers</surname><given-names>Lars</given-names></name>
          <name><surname>Rieger</surname><given-names>Jonas</given-names></name>
          <name><surname>Boczek</surname><given-names>Karin</given-names></name>
          <name><surname>von Nordheim</surname><given-names>Gerret</given-names></name>
        </person-group>
        <source>tosca: Tools for Statistical Content Analysis</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://github.com/Docma-TU/tosca</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.3591068</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-batchtools">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Lang</surname><given-names>Michel</given-names></name>
          <name><surname>Bischl</surname><given-names>Bernd</given-names></name>
          <name><surname>Surmann</surname><given-names>Dirk</given-names></name>
        </person-group>
        <article-title>batchtools: Tools for R to work on batch systems</article-title>
        <source>The Journal of Open Source Software</source>
        <year iso-8601-date="2017-02">2017</year><month>02</month>
        <issue>10</issue>
        <uri>https://doi.org/10.21105/joss.00135</uri>
        <pub-id pub-id-type="doi">10.21105/joss.00135</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-parallelMap">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Bischl</surname><given-names>Bernd</given-names></name>
          <name><surname>Lang</surname><given-names>Michel</given-names></name>
        </person-group>
        <source>parallelMap: Unified Interface to Parallelization Back-Ends</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://CRAN.R-project.org/package=parallelMap</uri>
      </element-citation>
    </ref>
    <ref id="ref-lda">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Jonathan</given-names></name>
        </person-group>
        <source>lda: Collapsed Gibbs Sampling Methods for Topic Models</source>
        <year iso-8601-date="2015">2015</year>
        <uri>https://CRAN.R-project.org/package=lda</uri>
      </element-citation>
    </ref>
    <ref id="ref-topicmodels">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Grün</surname><given-names>Bettina</given-names></name>
          <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
        </person-group>
        <article-title>topicmodels: An R Package for Fitting Topic Models</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2011">2011</year>
        <volume>40</volume>
        <issue>13</issue>
        <pub-id pub-id-type="doi">10.18637/jss.v040.i13</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-mallet">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Mimno</surname><given-names>David</given-names></name>
        </person-group>
        <source>mallet: A wrapper around the Java machine learning tool MALLET</source>
        <year iso-8601-date="2013">2013</year>
        <uri>https://CRAN.R-project.org/package=mallet</uri>
      </element-citation>
    </ref>
    <ref id="ref-quanteda">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
          <name><surname>Watanabe</surname><given-names>Kohei</given-names></name>
          <name><surname>Wang</surname><given-names>Haiyan</given-names></name>
          <name><surname>Nulty</surname><given-names>Paul</given-names></name>
          <name><surname>Obeng</surname><given-names>Adam</given-names></name>
          <name><surname>Müller</surname><given-names>Stefan</given-names></name>
          <name><surname>Matsuo</surname><given-names>Akitaka</given-names></name>
        </person-group>
        <article-title>quanteda: An R package for the quantitative analysis of textual data</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2018">2018</year>
        <volume>3</volume>
        <issue>30</issue>
        <uri>https://quanteda.io</uri>
        <pub-id pub-id-type="doi">10.21105/joss.00774</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-stm">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Roberts</surname><given-names>Margaret E.</given-names></name>
          <name><surname>Stewart</surname><given-names>Brandon M.</given-names></name>
          <name><surname>Tingley</surname><given-names>Dustin</given-names></name>
        </person-group>
        <article-title>stm: An R Package for Structural Topic Models</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2019">2019</year>
        <volume>91</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.18637/jss.v091.i02</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-nguyen2014">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Nguyen</surname><given-names>Viet-An</given-names></name>
          <name><surname>Boyd-Graber</surname><given-names>Jordan</given-names></name>
          <name><surname>Resnik</surname><given-names>Philip</given-names></name>
        </person-group>
        <article-title>Sometimes Average is Best: The Importance of Averaging for Prediction using MCMC Inference in Topic Modeling</article-title>
        <source>Proceedings of the 2014 EMNLP-Conference</source>
        <publisher-name>ACL</publisher-name>
        <year iso-8601-date="2014">2014</year>
        <pub-id pub-id-type="doi">10.3115/v1/D14-1182</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-rieger2020">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Rieger</surname><given-names>Jonas</given-names></name>
          <name><surname>Koppers</surname><given-names>Lars</given-names></name>
          <name><surname>Jentsch</surname><given-names>Carsten</given-names></name>
          <name><surname>Rahnenführer</surname><given-names>Jörg</given-names></name>
        </person-group>
        <article-title>Improving Reliability of Latent Dirichlet Allocation by Assessing Its Stability Using Clustering Techniques on Replicated Runs</article-title>
        <year iso-8601-date="2020">2020</year>
        <uri>https://arxiv.org/abs/2003.04980</uri>
      </element-citation>
    </ref>
    <ref id="ref-griffiths2004">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Griffiths</surname><given-names>Thomas L.</given-names></name>
          <name><surname>Steyvers</surname><given-names>Mark</given-names></name>
        </person-group>
        <article-title>Finding scientific topics</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <publisher-name>National Academy of Sciences</publisher-name>
        <year iso-8601-date="2004">2004</year>
        <volume>101</volume>
        <issue>suppl 1</issue>
        <issn>0027-8424</issn>
        <pub-id pub-id-type="doi">10.1073/pnas.0307752101</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-blei2003">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Blei</surname><given-names>David M.</given-names></name>
          <name><surname>Ng</surname><given-names>Andrew Y.</given-names></name>
          <name><surname>Jordan</surname><given-names>Michael I.</given-names></name>
        </person-group>
        <article-title>Latent Dirichlet Allocation</article-title>
        <source>Journal of Machine Learning Research</source>
        <publisher-name>JMLR.org</publisher-name>
        <year iso-8601-date="2003">2003</year>
        <volume>3</volume>
        <issn>1532-4435</issn>
        <pub-id pub-id-type="doi">10.1162/jmlr.2003.3.4-5.993</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-blei2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Blei</surname><given-names>David M.</given-names></name>
        </person-group>
        <article-title>Probabilistic Topic Models</article-title>
        <source>Communications of the ACM</source>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2012">2012</year>
        <volume>55</volume>
        <issue>4</issue>
        <issn>0001-0782</issn>
        <pub-id pub-id-type="doi">10.1145/2133806.2133826</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chang2009">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Jonathan</given-names></name>
          <name><surname>Boyd-Graber</surname><given-names>Jordan</given-names></name>
          <name><surname>Gerrish</surname><given-names>Sean</given-names></name>
          <name><surname>Wang</surname><given-names>Chong</given-names></name>
          <name><surname>Blei</surname><given-names>David M.</given-names></name>
        </person-group>
        <article-title>Reading Tea Leaves: How Humans Interpret Topic Models</article-title>
        <source>Proceedings of the 22nd international conference on neural information processing systems</source>
        <publisher-name>Curran Associates Inc.</publisher-name>
        <publisher-loc>Red Hook, NY, USA</publisher-loc>
        <year iso-8601-date="2009">2009</year>
        <isbn>9781615679119</isbn>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

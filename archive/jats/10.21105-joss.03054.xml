<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3054</article-id>
<article-id pub-id-type="doi">10.21105/joss.03054</article-id>
<title-group>
<article-title>gmr: Gaussian Mixture Regression</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2824-7956</contrib-id>
<string-name>Alexander Fabisch</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Robotics Innovation Center, DFKI GmbH, Bremen,
Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-01-29">
<day>29</day>
<month>1</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>62</issue>
<fpage>3054</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>machine learning</kwd>
<kwd>regression</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>gmr is a Python library for Gaussian mixture regression (GMR). GMR
  is a regression approach that models probability distributions rather
  than functions. Hence, it is possible to model multimodal
  mappings.</p>
  <p>In GMR we first learn a joint probability distribution
  <inline-formula><alternatives>
  <tex-math><![CDATA[p(\boldsymbol{x}, \boldsymbol{y})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  of input <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{x}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  and output <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  through expectation maximization
  (<xref alt="Dempster et al., 1977" rid="ref-Dempster1977" ref-type="bibr">Dempster
  et al., 1977</xref>) and then compute the conditional distribution
  <inline-formula><alternatives>
  <tex-math><![CDATA[p(\boldsymbol{y}|\boldsymbol{x})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  to make predictions. Thus, training is the same procedure as in a
  standard Gaussian mixture model (GMM).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>The library gmr is fully compatible with scikit-learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-Pedregosa2011" ref-type="bibr">Pedregosa
  et al., 2011</xref>). It has its own implementation of expectation
  maximization (EM), but it can also be initialized with a GMM from
  scikit-learn, which means that we can also initialize it from a
  Bayesian GMM of scikit-learn. The prediction process for regression is
  not available in scikit-learn and, thus, will be provided by gmr.</p>
  <p>Note that while scikit-learn has the function
  GaussianMixture.predict, it does not perform regression. This function
  computes the index of the Gaussian for which the inputs have the
  highest probability. Furthermore, multimodal regression often requires
  a more complicated interface to extract not just the mean but also
  individual Gaussians or sample from the predicted distribution.</p>
  <p>The library gmr provides a simple interface and several useful
  features to deal with multimodal regression, mixtures of Gaussians,
  and multivariate Gaussian distributions:</p>
  <list list-type="bullet">
    <list-item>
      <p>EM implementation that only requires numpy and scipy</p>
    </list-item>
    <list-item>
      <p>computation of conditional distributions</p>
    </list-item>
    <list-item>
      <p>sampling from confidence regions of multivariate Gaussians</p>
    </list-item>
    <list-item>
      <p>collapsing a GMM to a single Gaussian</p>
    </list-item>
    <list-item>
      <p>extraction of individual Gaussians from a (conditional) GMM</p>
    </list-item>
    <list-item>
      <p>plotting of covariance ellipses</p>
    </list-item>
    <list-item>
      <p>unscented transform
      (<xref alt="Uhlmann, 1995" rid="ref-Uhlmann1995" ref-type="bibr">Uhlmann,
      1995</xref>) to estimate the effect of a nonlinear function on a
      Gaussian distribution</p>
    </list-item>
  </list>
  <p>Multimodal regression and Gaussian mixture regression has been used
  mostly by the robotics community. For example, inverse problems such
  as inverse kinematics cannot be easily modeled with standard
  regression approaches. Furthermore, Gaussian mixture regression is the
  basis of many programming by demonstration approaches
  (<xref alt="Billard et al., 2008" rid="ref-Billard2008" ref-type="bibr">Billard
  et al., 2008</xref>).</p>
</sec>
<sec id="background">
  <title>Background</title>
  <p>Gaussian mixture regression via EM has been proposed first by
  Ghahramani &amp; Jordan
  (<xref alt="1994" rid="ref-Ghahramani1994" ref-type="bibr">1994</xref>).
  Calinon et al.
  (<xref alt="2007" rid="ref-Calinon2007" ref-type="bibr">2007</xref>)
  introduced the term Gaussian mixture regression in the context of
  imitation learning for trajectories of robots and many publications
  that use GMR in this domain followed. Stulp &amp; Sigaud
  (<xref alt="2015" rid="ref-Stulp2015" ref-type="bibr">2015</xref>)
  present Gaussian mixture regression in a more recent survey.</p>
  <sec id="training">
    <title>Training</title>
    <p>During the training phase we learn a Gaussian mixture model</p>
    <p><disp-formula><alternatives>
    <tex-math><![CDATA[p(\boldsymbol{x}, \boldsymbol{y}) =
        \sum_{k=1}^K \pi_k
        \mathcal{N}_k(\boldsymbol{x}, \boldsymbol{y}|
                      {\boldsymbol{\mu}_{\boldsymbol{x}\boldsymbol{y}}}_k,
                      {\boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}}_k)]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p>
    <p>through EM, where <inline-formula><alternatives>
    <tex-math><![CDATA[\mathcal{N}_k(\boldsymbol{x}, \boldsymbol{y}|{\boldsymbol{\mu}_{\boldsymbol{x}\boldsymbol{y}}}_k, {\boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}}_k)]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    are Gaussian distributions with mean <inline-formula><alternatives>
    <tex-math><![CDATA[{\boldsymbol{\mu}_{\boldsymbol{x}\boldsymbol{y}}}_k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
    and covariance <inline-formula><alternatives>
    <tex-math><![CDATA[{\boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}}_k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
    <inline-formula><alternatives>
    <tex-math><![CDATA[K]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>
    is the number of Gaussians, and <inline-formula><alternatives>
    <tex-math><![CDATA[\pi_k \in \left[0, 1\right]]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
    are priors that sum up to one.</p>
  </sec>
  <sec id="prediction">
    <title>Prediction</title>
    <p>Gaussian mixture regression can be used to predict distributions
    of variables <inline-formula><alternatives>
    <tex-math><![CDATA[\boldsymbol{y}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
    by computing the conditional distribution
    <inline-formula><alternatives>
    <tex-math><![CDATA[p(\boldsymbol{y} | \boldsymbol{x})]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
    The conditional distribution of each individual Gaussian
    <disp-formula><alternatives>
    <tex-math><![CDATA[\mathcal{N}(\boldsymbol{x}, \boldsymbol{y}|{\boldsymbol{\mu}_{\boldsymbol{x}\boldsymbol{y}}},
    {\boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}})]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
    <disp-formula><alternatives>
    <tex-math><![CDATA[\boldsymbol{\mu}_{\boldsymbol{x}\boldsymbol{y}}
        = \left(\begin{array}{c}\boldsymbol{\mu}_{\boldsymbol{x}}\\\boldsymbol{\mu}_{\boldsymbol{y}}\end{array}\right),
    \quad
    \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}
        = \left(\begin{array}{cc}
            \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{x}} & \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}\\
            \boldsymbol{\Sigma}_{\boldsymbol{y}\boldsymbol{x}} & \boldsymbol{\Sigma}_{\boldsymbol{y}\boldsymbol{y}}\end{array}\right)]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1.0em"></mml:mspace><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
    is defined by <disp-formula><alternatives>
    <tex-math><![CDATA[\boldsymbol{\mu}_{\boldsymbol{y}|\boldsymbol{x}}
        = \boldsymbol{\mu}_{\boldsymbol{y}} + \boldsymbol{\Sigma}_{\boldsymbol{y}\boldsymbol{x}} \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{x}}^{-1}(\boldsymbol{x} - \boldsymbol{\mu}_{\boldsymbol{x}})]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
    <disp-formula><alternatives>
    <tex-math><![CDATA[\boldsymbol{\Sigma}_{\boldsymbol{y} | \boldsymbol{x}}
        = \boldsymbol{\Sigma}_{\boldsymbol{y}\boldsymbol{y}} - \boldsymbol{\Sigma}_{\boldsymbol{y}\boldsymbol{x}} \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{x}}^{-1} \boldsymbol{\Sigma}_{\boldsymbol{x}\boldsymbol{y}}.]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:msubsup><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>
    In a Gaussian mixture model we compute the conditional distribution
    of each individual Gaussian and their priors
    <disp-formula><alternatives>
    <tex-math><![CDATA[{\pi_{\boldsymbol{y}|\boldsymbol{x}}}_k =
    \frac{
    \mathcal{N}_k(\boldsymbol{x}|{\boldsymbol{\mu}_{\boldsymbol{x}}}_k,
                                 {\boldsymbol{\Sigma}_{\boldsymbol{x}}}_k)
    }{
    \sum_{l=1}^{K}
    \mathcal{N}_{l}(\boldsymbol{x}|{\boldsymbol{\mu}_{\boldsymbol{x}}}_{l},
                                 {\boldsymbol{\Sigma}_{\boldsymbol{x}}}_{l})
    }]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:msub><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></disp-formula>
    to obtain the conditional distribution <disp-formula><alternatives>
    <tex-math><![CDATA[p(\boldsymbol{y}|\boldsymbol{x}) =
        \sum_{k=1}^K {\pi_{\boldsymbol{y}|\boldsymbol{x}}}_k
        \mathcal{N}_k(\boldsymbol{y}|
                      {\boldsymbol{\mu}_{\boldsymbol{y}|\boldsymbol{x}}}_k,
                      {\boldsymbol{\Sigma}_{\boldsymbol{y}|\boldsymbol{x}}}_k).]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝛍</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝚺</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula></p>
  </sec>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>Here is an example of a dataset where multiple outputs
  <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{y}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  are valid predictions for one input <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{x}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>.
  It was introduced by Bishop
  (<xref alt="1994" rid="ref-Bishop1994" ref-type="bibr">1994</xref>).</p>
  <fig>
    <caption><p>Multimodal
    regression.<styled-content id="figU003Amultimodal_regression"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="multimodal_regression.png" xlink:title="" />
  </fig>
  <p>On the left side of
  <xref alt="Figure 1" rid="figU003Amultimodal_regression">Figure 1</xref>
  we see the training data and the fitted GMM indicated by ellipses
  corresponding to its components. On the right side we see the
  predicted probability density <inline-formula><alternatives>
  <tex-math><![CDATA[p(\boldsymbol{y}|\boldsymbol{x}=0.5)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐲</mml:mi></mml:mstyle><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  There are three peaks that correspond to three different valid
  predictions. Each peak is represented by at least one of the Gaussians
  of the GMM.</p>
  <p>We can use GMR to represent demonstrated motions. Here is an
  example in 2D, in which we have a dataset that is a sequence of
  positions <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{x}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  and corresponding velocities <inline-formula><alternatives>
  <tex-math><![CDATA[\dot{\boldsymbol{x}}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo accent="true">̇</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.
  We train a GMM to represent <inline-formula><alternatives>
  <tex-math><![CDATA[p(\boldsymbol{x}, \dot{\boldsymbol{x}})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mover><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo accent="true">̇</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  Then we can generate a new trajectory by iteratively sampling
  <inline-formula><alternatives>
  <tex-math><![CDATA[\dot{\boldsymbol{x}}_t \sim p(\dot{\boldsymbol{x}}|\boldsymbol{x}=\boldsymbol{x}_t)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mover><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo accent="true">̇</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo accent="true">̇</mml:mo></mml:mover><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  and computing the next position as <inline-formula><alternatives>
  <tex-math><![CDATA[\boldsymbol{x}_{t+1} = \boldsymbol{x}_t + \Delta t \dot{\boldsymbol{x}}_t]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mover><mml:mstyle mathvariant="bold"><mml:mi>𝐱</mml:mi></mml:mstyle><mml:mo accent="true">̇</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
  <fig>
    <caption><p>Imitation
    learning.<styled-content id="figU003Aimitation_learning"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="imitation.png" xlink:title="" />
  </fig>
  <p>In
  <xref alt="Figure 2" rid="figU003Aimitation_learning">Figure 2</xref>
  we can see that in the middle of the eight we have multiple modes: one
  velocity vector would lead to the left and one to the right. Sampling
  from the conditional GMM is only one possible solution here. Another
  one would be to select the component that contributes the most to the
  probability density and take its mean. When we sample, we often want
  to ensure that we do not end up in a region of low probability. Hence,
  we can resample as long as we are not in an
  <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>-confidence
  region, where <inline-formula><alternatives>
  <tex-math><![CDATA[\alpha \in \left[0, 1\right]]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  This strategy is used here and is directly provided by the
  library.</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>This work was supported through a grant of the German Federal
  Ministry of Economic Affairs and Energy (BMWi, FKZ 50 RA 1701) and one
  grant from the European Commission (870142).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Uhlmann1995">
      <element-citation publication-type="thesis">
        <person-group person-group-type="author">
          <name><surname>Uhlmann</surname><given-names>Jeffrey</given-names></name>
        </person-group>
        <article-title>Dynamic map building and localization: New theoretical foundations</article-title>
        <publisher-name>University of Oxford</publisher-name>
        <year iso-8601-date="1995">1995</year>
      </element-citation>
    </ref>
    <ref id="ref-Dempster1977">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Dempster</surname><given-names>A. P.</given-names></name>
          <name><surname>Laird</surname><given-names>N. M.</given-names></name>
          <name><surname>Rubin</surname><given-names>D. B.</given-names></name>
        </person-group>
        <article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title>
        <source>Journal of the Royal Statistical Society. Series B (Methodological)</source>
        <publisher-name>Royal Statistical Society, Wiley</publisher-name>
        <year iso-8601-date="1977">1977</year>
        <volume>39</volume>
        <issue>1</issue>
        <issn>00359246</issn>
        <uri>http://www.jstor.org/stable/2984875</uri>
      </element-citation>
    </ref>
    <ref id="ref-Ghahramani1994">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
          <name><surname>Jordan</surname><given-names>Michael</given-names></name>
        </person-group>
        <article-title>Supervised learning from incomplete data via an EM approach</article-title>
        <source>Advances in neural information processing systems</source>
        <person-group person-group-type="editor">
          <name><surname>Cowan</surname><given-names>J.</given-names></name>
          <name><surname>Tesauro</surname><given-names>G.</given-names></name>
          <name><surname>Alspector</surname><given-names>J.</given-names></name>
        </person-group>
        <publisher-name>Morgan-Kaufmann</publisher-name>
        <year iso-8601-date="1994">1994</year>
        <volume>6</volume>
        <uri>https://proceedings.neurips.cc/paper/1993/file/f2201f5191c4e92cc5af043eebfd0946-Paper.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-Calinon2007">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Calinon</surname><given-names>Sylcain</given-names></name>
          <name><surname>Guenter</surname><given-names>Florent</given-names></name>
          <name><surname>Billard</surname><given-names>Aude</given-names></name>
        </person-group>
        <article-title>On learning, representing, and generalizing a task in a humanoid robot</article-title>
        <source>IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</source>
        <year iso-8601-date="2007">2007</year>
        <volume>37</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1109/TSMCB.2006.886952</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Stulp2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Stulp</surname><given-names>Freek</given-names></name>
          <name><surname>Sigaud</surname><given-names>Olivier</given-names></name>
        </person-group>
        <article-title>Many regression algorithms, one unified model: A review</article-title>
        <source>Neural Networks</source>
        <year iso-8601-date="2015">2015</year>
        <volume>69</volume>
        <issn>0893-6080</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S0893608015001185</uri>
        <pub-id pub-id-type="doi">10.1016/j.neunet.2015.05.005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Pedregosa2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-Billard2008">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Billard</surname><given-names>Aude</given-names></name>
          <name><surname>Calinon</surname><given-names>Sylvain</given-names></name>
          <name><surname>Dillmann</surname><given-names>Rüdiger</given-names></name>
          <name><surname>Schaal</surname><given-names>Stefan</given-names></name>
        </person-group>
        <article-title>Robot programming by demonstration</article-title>
        <source>Springer handbook of robotics</source>
        <person-group person-group-type="editor">
          <name><surname>Siciliano</surname><given-names>Bruno</given-names></name>
          <name><surname>Khatib</surname><given-names>Oussama</given-names></name>
        </person-group>
        <publisher-name>Springer Berlin Heidelberg</publisher-name>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <year iso-8601-date="2008">2008</year>
        <isbn>978-3-540-30301-5</isbn>
        <pub-id pub-id-type="doi">10.1007/978-3-540-30301-5_60</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Bishop1994">
      <element-citation publication-type="report">
        <person-group person-group-type="author">
          <name><surname>Bishop</surname><given-names>Christopher M.</given-names></name>
        </person-group>
        <article-title>Mixture density networks</article-title>
        <publisher-name>Aston University</publisher-name>
        <year iso-8601-date="1994">1994</year>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

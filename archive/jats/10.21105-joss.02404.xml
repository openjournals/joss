<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2404</article-id>
<article-id pub-id-type="doi">10.21105/joss.02404</article-id>
<title-group>
<article-title>seg1d: A Python package for Automated segmentation of
one-dimensional (1D) data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3662-7203</contrib-id>
<string-name>Mathew Schwartz</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-8292-7189</contrib-id>
<string-name>Todd C. Pataky</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Cyril J. Donnelly</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>New Jersey Institute of Technology</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Kyoto University, Department of Human Health
Sciences</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Nanyang Technological University, Rehabilitation Research
Institute of Singapore</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-03-25">
<day>25</day>
<month>3</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>52</issue>
<fpage>2404</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>biomechanics</kwd>
<kwd>data series</kwd>
<kwd>movement</kwd>
<kwd>motion capture</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>The term segmentation refers to the division of a data series into
  segments. In this paper, segments refer to a contiguous time series
  which is a subset of another time series
  (<xref alt="Bouchard, 2006" rid="ref-bouchard2006automated" ref-type="bibr">Bouchard,
  2006</xref>). Identifying these segments requires a reference series
  to be found in the larger series, which can be an exact copy or an
  approximation. When an approximation of the desired segment is used,
  the metric and method for identifying similarity of all subsets are
  essential to achieving the desired result. Additionally, multiple
  references may be desired to further describe the aspects of segment
  similarity, some of which may be more important than others.</p>
  <p>Segmenting human motion is a topic studied in various fields such
  as robotics (e.g., humanoids), biomechanics, and computer graphics
  (e.g., gaming and animation). In the human movement sciences,
  segmentation is often performed as the labeling of specific events,
  such as the components of a gait cycle, for analysis and
  interpretation of the data within these labeled bounds. Subjectively
  defining what a movement or a phase of a movement is can be
  particularly difficult due to variations in what one may define as a
  single movement. As such, the points at which the movement or phases
  of a movement starts and ends can be ambiguous. The averaging of
  multiple features (e.g., marker trajectories, joint angles, or other
  information derived from the data) of a movement or even multiple
  movements (e.g., multiple marker trajectories from multiple
  observation sets) allows for tolerance to some individual features
  failing to provide an expected characteristic (e.g., a signal above or
  below a threshold value from a force plate) that may normally be
  relied upon for identifying an event. Defining weights of individual
  features, with either algorithmic approaches or through expert
  knowledge, further facilitates segmentation of similar movements.</p>
  <p>With feature-rich data such as multiple marker trajectories from
  motion capture, the reduction of meaningful features is important for
  segmentation performance
  (<xref alt="Bouchard &amp; Badler, 2015" rid="ref-bouchard2015segmenting" ref-type="bibr">Bouchard
  &amp; Badler, 2015</xref>). The use of marker trajectory and ground
  reaction force, without computing kinematics, has been shown to be
  sufficient in movement segmentation tasks
  (<xref alt="Lin et al., 2016" rid="ref-lin2016comparison" ref-type="bibr">Lin
  et al., 2016</xref>). Unique feature creation, extraction, and storage
  can be used to additionally index databases for fast movement-based
  time-series data retrieval
  (<xref alt="Kapadia et al., 2013" rid="ref-kapadia2013efficient" ref-type="bibr">Kapadia
  et al., 2013</xref>). Subseries searching of databases has often been
  performed with similarity metrics, each with their own individual
  downfalls, e.g., Longest Common Subseries (LCSS), Euclidean Distance
  (ED), and Dynamic Time Warping (DTW)
  (<xref alt="Vlachos et al., 2003" rid="ref-vlachos2003indexing" ref-type="bibr">Vlachos
  et al., 2003</xref>). Discrete Fourier Transformation (DFT) has also
  been used as a method for improving the efficiency of windowed
  correlations
  (<xref alt="Zhu &amp; Shasha, 2002" rid="ref-zhu2002statstream" ref-type="bibr">Zhu
  &amp; Shasha, 2002</xref>). Data reduction techniques for optimization
  can also be used in windowed correlations of generic time-series data
  (<xref alt="Cole et al., 2005" rid="ref-cole2005fast" ref-type="bibr">Cole
  et al., 2005</xref>).</p>
  <p>Peak detection has been used to identify gait events through the
  inference of cyclic motion and reducing reliance on physical meanings
  of the signal by searching for the assumed cyclic pattern rather than
  a given threshold value or calculated joint angle
  (<xref alt="Jiang et al., 2017" rid="ref-jiang2017robust" ref-type="bibr">Jiang
  et al., 2017</xref>). Peak detection from cross-correlated data has
  been used for gait event detection in accelerometry data
  (<xref alt="Yoneyama et al., 2013" rid="ref-yoneyama2013accelerometry" ref-type="bibr">Yoneyama
  et al., 2013</xref>). Alternative methods for segmenting data have
  used physical devices to act as switches on foot contact
  (<xref alt="Agostini et al., 2013" rid="ref-agostini2013segmentation" ref-type="bibr">Agostini
  et al., 2013</xref>). Most recently, deep neural networks have been
  used to predict foot contact but require a large amount (i.e.,
  thousands of trials) of training data
  (<xref alt="Kidziński et al., 2019" rid="ref-kidzinski2019automatic" ref-type="bibr">Kidziński
  et al., 2019</xref>). Using DTW,
  (<xref alt="Sarsfield et al., 2019" rid="ref-sarsfield2019segmentation" ref-type="bibr">Sarsfield
  et al., 2019</xref>) was able to identify movements in realtime with a
  single reference segment. Allowing both single and multiple reference
  segments, as well as multiple features and optional weights, the
  segmentation of various data is more practical in a single
  package.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Subsequence identification and similarity between a reference(s)
  and target data items is a commonly desired task done both manually
  and automatically in a variety of fields. The ability to further
  automate and create reliable, consistent results, is of importance for
  many data processing related tasks. For example, in typical motion
  capture sessions of walking gait in a lab, embedded force plates
  provide high fidelity measurements for foot-strike and toe-off.
  However, the cycles before and after this event are often discarded.
  By using a collection of features from a known segment (i.e., the
  cycle over the force-plate), similar sequences within a trial can be
  found and used for the study. Furthermore, some movements are not so
  well defined with these external sensing tools, and rather a template
  movement selected by a human is the most reasonable way to identify
  the sequence of data describing a particular motion.</p>
  <p>seg1d is an open-source Python package for the automated
  segmentation and extraction of time series data using one or more
  reference sequences. The segmentation process allows users to apply
  various methods and parameters for the process through weighted
  reference features in a rolling correlation size-varying window of any
  scale below the length of the targeted data. Correlations can be
  averaged across the references, and a peak detection algorithm finds
  individual segments. Non-overlapping segments are identified, and a
  clustering algorithm groups the most similar subsequence movements
  within the target. The package was developed for movement sciences but
  can be useful to anyone interested in extracting correlated
  subsequences from a dataset.</p>
  <fig>
    <caption><p>Sample segments in a timeseries from a reference
    <styled-content id="figU003Aexample"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="api_basic-1.png" xlink:title="" />
  </fig>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported in part by the Agency for Science,
  Technology and Research (A*STAR), Nanyang Technological University
  (NTU) and the National Health Group (NHG) (RRG3: 2019/19002).</p>
  <p>Todd Pataky is supported through the Kiban B Grant 17H02151 (Japan
  Society for the Promotion of Science).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-kapadia2013efficient">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kapadia</surname><given-names>Mubbasir</given-names></name>
          <name><surname>Chiang</surname><given-names>I-kao</given-names></name>
          <name><surname>Thomas</surname><given-names>Tiju</given-names></name>
          <name><surname>Badler</surname><given-names>Norman I</given-names></name>
          <name><surname>Kider Jr</surname><given-names>Joseph T</given-names></name>
        </person-group>
        <article-title>Efficient motion retrieval in large motion databases</article-title>
        <source>Proceedings of the ACM SIGGRAPH symposium on interactive 3D graphics and games</source>
        <year iso-8601-date="2013">2013</year>
        <pub-id pub-id-type="doi">10.1145/2448196.2448199</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bouchard2015segmenting">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Bouchard</surname><given-names>Durell</given-names></name>
          <name><surname>Badler</surname><given-names>Norman I</given-names></name>
        </person-group>
        <article-title>Segmenting motion capture data using a qualitative analysis</article-title>
        <source>Proceedings of the 8th ACM SIGGRAPH conference on motion in games</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1145/2822013.2822039</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-agostini2013segmentation">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Agostini</surname><given-names>Valentina</given-names></name>
          <name><surname>Balestra</surname><given-names>Gabriella</given-names></name>
          <name><surname>Knaflitz</surname><given-names>Marco</given-names></name>
        </person-group>
        <article-title>Segmentation and classification of gait cycles</article-title>
        <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2013">2013</year>
        <volume>22</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1109/tnsre.2013.2291907</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-jiang2017robust">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Jiang</surname><given-names>Shuo</given-names></name>
          <name><surname>Wang</surname><given-names>Xingchen</given-names></name>
          <name><surname>Kyrarini</surname><given-names>Maria</given-names></name>
          <name><surname>Gräser</surname><given-names>Axel</given-names></name>
        </person-group>
        <article-title>A robust algorithm for gait cycle segmentation</article-title>
        <source>2017 25th european signal processing conference (EUSIPCO)</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <pub-id pub-id-type="doi">10.23919/eusipco.2017.8081163</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-sarsfield2019segmentation">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Sarsfield</surname><given-names>Joe</given-names></name>
          <name><surname>Brown</surname><given-names>David</given-names></name>
          <name><surname>Sherkat</surname><given-names>Nasser</given-names></name>
          <name><surname>Langensiepen</surname><given-names>Caroline</given-names></name>
          <name><surname>Lewis</surname><given-names>James</given-names></name>
          <name><surname>Taheri</surname><given-names>Mohammad</given-names></name>
          <name><surname>Selwood</surname><given-names>Louise</given-names></name>
          <name><surname>Standen</surname><given-names>Penny</given-names></name>
          <name><surname>Logan</surname><given-names>Pip</given-names></name>
        </person-group>
        <article-title>Segmentation of exercise repetitions enabling real-time patient analysis and feedback using a single exemplar</article-title>
        <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>27</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1109/tnsre.2019.2907483</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-vlachos2003indexing">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Vlachos</surname><given-names>Michail</given-names></name>
          <name><surname>Hadjieleftheriou</surname><given-names>Marios</given-names></name>
          <name><surname>Gunopulos</surname><given-names>Dimitrios</given-names></name>
          <name><surname>Keogh</surname><given-names>Eamonn</given-names></name>
        </person-group>
        <article-title>Indexing multi-dimensional time-series with support for multiple distance measures</article-title>
        <source>Proceedings of the ninth ACM SIGKDD international conference on knowledge discovery and data mining</source>
        <year iso-8601-date="2003">2003</year>
        <pub-id pub-id-type="doi">10.1145/956750.956777</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-zhu2002statstream">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Zhu</surname><given-names>Yunyue</given-names></name>
          <name><surname>Shasha</surname><given-names>Dennis</given-names></name>
        </person-group>
        <article-title>Statstream: Statistical monitoring of thousands of data streams in real time</article-title>
        <source>VLDB’02: Proceedings of the 28th international conference on very large databases</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2002">2002</year>
      </element-citation>
    </ref>
    <ref id="ref-cole2005fast">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Cole</surname><given-names>Richard</given-names></name>
          <name><surname>Shasha</surname><given-names>Dennis</given-names></name>
          <name><surname>Zhao</surname><given-names>Xiaojian</given-names></name>
        </person-group>
        <article-title>Fast window correlations over uncooperative time series</article-title>
        <source>Proceedings of the eleventh ACM SIGKDD international conference on knowledge discovery in data mining</source>
        <year iso-8601-date="2005">2005</year>
        <pub-id pub-id-type="doi">10.1145/1081870.1081966</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-yoneyama2013accelerometry">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Yoneyama</surname><given-names>Mitsuru</given-names></name>
          <name><surname>Kurihara</surname><given-names>Yosuke</given-names></name>
          <name><surname>Watanabe</surname><given-names>Kajiro</given-names></name>
          <name><surname>Mitoma</surname><given-names>Hiroshi</given-names></name>
        </person-group>
        <article-title>Accelerometry-based gait analysis and its application to parkinson’s disease assessment—part 1: Detection of stride event</article-title>
        <source>IEEE Transactions on neural systems and rehabilitation engineering</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2013">2013</year>
        <volume>22</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1109/tnsre.2013.2260561</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bouchard2006automated">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bouchard</surname><given-names>Durell</given-names></name>
        </person-group>
        <article-title>Automated time series segmentation for human motion analysis</article-title>
        <source>Center for Human Modeling and Simulation, University of Pennsylvania</source>
        <publisher-name>Citeseer</publisher-name>
        <year iso-8601-date="2006">2006</year>
      </element-citation>
    </ref>
    <ref id="ref-lin2016comparison">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Lin</surname><given-names>Jonathan Feng-Shun</given-names></name>
          <name><surname>Bonnet</surname><given-names>Vincent</given-names></name>
          <name><surname>Joukov</surname><given-names>Vladimir</given-names></name>
          <name><surname>Venture</surname><given-names>Gentiane</given-names></name>
          <name><surname>Kulic</surname><given-names>Dana</given-names></name>
        </person-group>
        <article-title>Comparison of kinematic and dynamic sensor modalities and derived features for human motion segmentation</article-title>
        <source>2016 IEEE healthcare innovation point-of-care technologies conference (HI-POCT)</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1109/hic.2016.7797709</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kidzinski2019automatic">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kidziński</surname><given-names>Łukasz</given-names></name>
          <name><surname>Delp</surname><given-names>Scott</given-names></name>
          <name><surname>Schwartz</surname><given-names>Michael</given-names></name>
        </person-group>
        <article-title>Automatic real-time gait event detection in children using deep neural networks</article-title>
        <source>PloS one</source>
        <publisher-name>Public Library of Science</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>14</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0211466</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1264</article-id>
<article-id pub-id-type="doi">10.21105/joss.01264</article-id>
<title-group>
<article-title>CluSim: a python package for calculating clustering
similarity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0099-7480</contrib-id>
<string-name>Alexander J. Gates</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-4352-4301</contrib-id>
<string-name>Yong-Yeol Ahn</string-name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Physics, Northeastern University, Boston,
02115, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Informatics, Indiana University, Bloomington,
47408, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Program in Cognitive Science, Indiana University,
Bloomington, 47408, USA</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-03-13">
<day>13</day>
<month>3</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>35</issue>
<fpage>1264</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>clustering</kwd>
<kwd>network communities</kwd>
<kwd>clustering similarity</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Clustering is a primary method to reveal the structure of data
  (<xref alt="Jain et al., 1999" rid="ref-Jain1999clustering" ref-type="bibr">Jain
  et al., 1999</xref>). To understand, evaluate, and leverage data
  clusterings, we need to quantitatively compare them. Clustering
  comparison is the basis for method evaluation, consensus clustering,
  and tracking the temporal evolution of clusters, among many other
  tasks. For instance, the evaluation of a clustering method is usually
  achieved by comparing the method’s result to a planted reference
  clustering, assuming that the more similar the method’s solution is to
  the reference clustering, the better the method. Despite the
  importance of clustering comparison, no consensus has been reached for
  a standardized assessment; each similarity measure rewards and
  penalizes different criteria, sometimes producing contradictory
  conclusions.</p>
  <p>Clustering similarity measures can be classified based on the
  cluster types: i) <italic>partitions</italic> that group elements into
  non-overlapping clusters, ii) <italic>hierarchical
  clusterings</italic> that group elements into a nested series of
  partitions (a.k.a. dendrogram), or iii) <italic>overlapping
  clusterings</italic> with elements belonging to multiple clusters. One
  approach to aid with the interpretation of the similarity score
  establishes a baseline in the context of a random ensemble of
  clusterings. Such a correction procedure requires two choices:
  <italic>a model for random clusterings</italic> and <italic>how
  clusterings are drawn from the random model</italic>. With few
  exceptions, similarity measures are only designed to compare
  clusterings of the same type, and the decisions required for the
  correction procedure are usually ignored or relegated to the status of
  technical trivialities
  (<xref alt="Gates &amp; Ahn, 2017" rid="ref-Gates2017impact" ref-type="bibr">Gates
  &amp; Ahn, 2017</xref>).</p>
  <p>Here, we introduce <italic>CluSim</italic>, a python package
  providing a unified library of over 20 clustering similarity measures
  for partitions, dendrograms, and overlapping clusterings. To our
  knowledge, this package constitutes the first collection of clustering
  similarity measures for all three clustering types and extended access
  to random models of clusterings
  (<xref alt="Gates et al., 2018" rid="ref-Gates2018element" ref-type="bibr">Gates
  et al., 2018</xref>). We illustrate the use of the package through two
  examples: an evaluation of measure behavior with variation in 3
  clustering properties (membership, cluster sizes, and number of
  clusters) and a clustering comparison of Gene Expression data in the
  context of different random models.</p>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>The basic class in the <italic>CluSim</italic> package is a
  <italic>Clustering</italic>, or an assignment of labeled elements
  (i.e. data points or network vertices) into clusters (the groups).
  <italic>Hierarchical Clusterings</italic> also contain a dendrogram,
  or more generally an acyclic graph, capturing the nested structure of
  the clusters. In <italic>CluSim</italic>, a
  <italic>Clustering</italic> can be instantiated from 7 different
  common formats, including full support for <italic>scipy</italic>,
  <italic>scikit-learn</italic>, and <italic>dendropy</italic>
  clustering formats
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikitlearn" ref-type="bibr">Pedregosa
  et al., 2011</xref>;
  <xref alt="Sukumaran &amp; Holder, 2010" rid="ref-Sukumaran2010dendropy" ref-type="bibr">Sukumaran
  &amp; Holder, 2010</xref>).</p>
  <p><italic>CluSim</italic> provides more than 20 clustering similarity
  and distance measures for the comparison between two
  <italic>Clusterings</italic>. All similarity measures produce a score
  in the range <inline-formula><alternatives>
  <tex-math><![CDATA[[0,1]]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
  where <inline-formula><alternatives>
  <tex-math><![CDATA[1]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>
  indicates identical clusterings and <inline-formula><alternatives>
  <tex-math><![CDATA[0]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>
  indicates maximally dissimilar clusterings. See the online
  documentation for a detailed list and mathematical definitions of
  these similarity measures.</p>
  <p>The clustering similarity measures presented here differ in how
  each evaluates the trade-offs between variation in three primary
  characteristics of clusterings: the grouping of elements into
  clusters, the number of clusters, and the size distribution of those
  clusters
  (<xref alt="Gates et al., 2018" rid="ref-Gates2018element" ref-type="bibr">Gates
  et al., 2018</xref>). To illustrate these trade-offs, we present three
  simple examples in Fig. 1. In the first example, 1,024 elements are
  grouped into 32 clusters of equal size and compared against a similar
  clustering with a fraction of the elements randomly exchanged between
  the clusters, keeping the same cluster sizes. As seen in Fig.
  1<bold>a</bold>), all similarity measures decrease as the fraction of
  shuffled elements increases, but the measures differ on whether they
  can differentiate between clusterings that are completely random, or
  if there is a discontinuous jump in the similarity value. In the
  second example, 1,024 elements are grouped into 32 clusters of equal
  size and compared against a similar clustering with increasing cluster
  size skew-ness. As seen in Fig. 1<bold>b</bold>), some similarity
  measures decrease as the fraction cluster size heterogeneity
  increases, while others increase. Finally, in the third example, 1,024
  elements are grouped into 8 clusters of equal size and compared
  against a similar clustering with an increasing number of equal-sized
  clusters. As seen in Fig. 1<bold>c</bold>), most similarity measures
  decrease as the number of clusters increases, but the normalized
  mutual information increases. For more details and an extended
  interpretation of these experiments, see the analysis in Gates et al
  (2019)
  (<xref alt="Gates et al., 2018" rid="ref-Gates2018element" ref-type="bibr">Gates
  et al., 2018</xref>). Ultimately, the practitioner should choose a
  clustering similarity measure that is sensitive to the relevant
  features of the clusterings for the problem at hand.</p>
  <fig>
    <caption><p><bold>Three clustering similarity scenarios illustrate
    the trade-offs for clustering comparisons.</bold> 1,024 elements are
    assigned to clusters according to the following scenarios
    (<bold>a-c</bold>) and compared using the Jaccard index, adjusted
    Rand index, the F measure, normalized mutual information,
    overlapping normalized mutual information, and the element-centric
    similarity. All results are averaged over 100 runs; error bars
    denote one standard deviation. <bold>a</bold>, A clustering with 32
    equal-sized clusters is compared to a randomized version of itself
    where elements are exchanged. <bold>b</bold>, A clustering with 32
    equal-sized clusters is compared against clusterings with increasing
    cluster size skew-ness. <bold>c</bold>, A clustering with 8
    equal-sized clusters is compared against a clustering with
    increasing number of clusters.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paperfigures/CluSimFig1.png" xlink:title="" />
  </fig>
  <p> </p>
  <p>To facilitate comparisons within a set of clusterings, it is often
  argued to consider clustering similarity in the context of a random
  baseline
  (<xref alt="Gates &amp; Ahn, 2017" rid="ref-Gates2017impact" ref-type="bibr">Gates
  &amp; Ahn, 2017</xref>;
  <xref alt="Hubert &amp; Arabie, 1985" rid="ref-Hubert1985adjrand" ref-type="bibr">Hubert
  &amp; Arabie, 1985</xref>;
  <xref alt="Vinh et al., 2009" rid="ref-Vinh2009nmicorrection" ref-type="bibr">Vinh
  et al., 2009</xref>). The <italic>CluSim</italic> package provides
  both analytic and statistical sampling methods for calculating such a
  correction for chance. Analytic solutions are available for the Rand
  index and Normalized Mutual Information using five random models: the
  permutation model, both one-sided and two-sided models for clusterings
  with a fixed number of clusters, and both one-sided and two-sided
  models for all random clusterings. See Gates &amp; Ahn (2017)
  (<xref alt="Gates &amp; Ahn, 2017" rid="ref-Gates2017impact" ref-type="bibr">Gates
  &amp; Ahn, 2017</xref>) for detailed derivations and explanations of
  the differences between clustering random models. For all other
  similarity measures, the correction for chance is estimated by
  randomly sampling the random ensemble of <italic>Clusterings</italic>
  using the provided random Clustering generators.</p>
  <p>A typical comparison using a correction for chance is illustrated
  in Fig. 2. Agglomerative Hierarchical Clustering was applied to gene
  expression data from
  (<xref alt="Souto et al., 2008" rid="ref-deSouto2008geneclustering" ref-type="bibr">Souto
  et al., 2008</xref>) and compared to the true classification of cancer
  types using the Rand Index (<inline-formula><alternatives>
  <tex-math><![CDATA[0.5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.5</mml:mn></mml:math></alternatives></inline-formula>,
  red). To determine if the Rand Index of <inline-formula><alternatives>
  <tex-math><![CDATA[0.5]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.5</mml:mn></mml:math></alternatives></inline-formula>
  is indeed a good score, it is assessed relative to the distribution of
  pairwise comparisons amongst a sample of 100 random
  <italic>Clusterings</italic> from the Permutation model (blue, see
  [Hubert1985adjrand]) with mean Rand index of
  <inline-formula><alternatives>
  <tex-math><![CDATA[0.44]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.44</mml:mn></mml:math></alternatives></inline-formula>
  (black). Thus, the naive assessment would conclude that Agglomerative
  Hierarchical Clustering has performed better than would be expected by
  chance. However, the more appropriate random model for this scenario
  is provided by the one-sided model with a Fixed Number of Clusters
  (see [Gates2017impact]), since Agglomerative Hierarchical Clustering
  fixes the number of clusters but not their sizes, and the comparison
  is made to a ground truth clustering. The distribution of pairwise
  comparisons amongst a sample of 100 random samples from this random
  model (blue) with a mean similarity of <inline-formula><alternatives>
  <tex-math><![CDATA[0.59]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.59</mml:mn></mml:math></alternatives></inline-formula>
  (black), demonstrates that Agglomerative Hierarchical Clustering
  actually performed worse than if we had drawn a random clustering!</p>
  <p> </p>
  <fig>
    <caption><p><bold>Evaluating clustering comparisons w.r.t. random
    models.</bold>. A comparison using the Rand Index between the
    classification of cancer types and clustering labels derived using
    Hierarchical Clustering on gene expression data
    (<inline-formula><alternatives>
    <tex-math><![CDATA[0.5]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.5</mml:mn></mml:math></alternatives></inline-formula>,
    red). above, Pairwise comparisons between samples from the
    Permutation model (blue, see [Hubert1985adjrand]) with mean
    <inline-formula><alternatives>
    <tex-math><![CDATA[0.44]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.44</mml:mn></mml:math></alternatives></inline-formula>
    (black). below, Pairwise comparisons between samples from the
    one-sided model with a Fixed Number of Clusters (blue, see
    [Gates2017impact]) with mean <inline-formula><alternatives>
    <tex-math><![CDATA[0.59]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mn>0.59</mml:mn></mml:math></alternatives></inline-formula>
    (black). The Permutation model suggests Hierarchical Clustering is
    more similar to the ground truth than a random clustering, while the
    one-sized fixed number of clusterings model, the more appropriate
    model for this scenario, reveals that the result is less similar
    than random clusterings.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paperfigures/CluSimFig2.png" xlink:title="" />
  </fig>
  <p> </p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The authors would like to thank Ian Wood for thoughtful
  discussions, and Andre David for suggestions which significantly
  improved the presentation of this work.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Hubert1985adjrand">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hubert</surname><given-names>Lawrence</given-names></name>
          <name><surname>Arabie</surname><given-names>Phipps</given-names></name>
        </person-group>
        <article-title>Comparing partitions</article-title>
        <source>Journal of Classification</source>
        <year iso-8601-date="1985-12">1985</year><month>12</month>
        <volume>2</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1007/BF01908075</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Jain1999clustering">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jain</surname><given-names>Anil K.</given-names></name>
          <name><surname>Murty</surname><given-names>M. Narasimha</given-names></name>
          <name><surname>Flynn</surname><given-names>Patrick J.</given-names></name>
        </person-group>
        <article-title>Data clustering: A review</article-title>
        <source>ACM Computing Surveys (CSUR)</source>
        <publisher-name>Acm</publisher-name>
        <year iso-8601-date="1999">1999</year>
        <volume>31</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1145/331499.331504</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-deSouto2008geneclustering">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Souto</surname><given-names>Marcilio CP de</given-names></name>
          <name><surname>Costa</surname><given-names>Ivan G.</given-names></name>
          <name><surname>Araujo</surname><given-names>Daniel SA de</given-names></name>
          <name><surname>Ludermir</surname><given-names>Teresa B.</given-names></name>
          <name><surname>Schliep</surname><given-names>Alexander</given-names></name>
        </person-group>
        <article-title>Clustering cancer gene expression data: A comparative study</article-title>
        <source>BMC Bioinformatics</source>
        <year iso-8601-date="2008">2008</year>
        <volume>9</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-497</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Vinh2009nmicorrection">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Vinh</surname><given-names>Nguyen Xuan</given-names></name>
          <name><surname>Epps</surname><given-names>Julien</given-names></name>
          <name><surname>Bailey</surname><given-names>James</given-names></name>
        </person-group>
        <article-title>Information theoretic measures for clusterings comparison: Is a correction for chance necessary?</article-title>
        <source>Proceedings of the 26th annual international conference on machine learning</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2009">2009</year>
        <pub-id pub-id-type="doi">10.1145/1553374.1553511</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Gates2017impact">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Gates</surname><given-names>Alexander J.</given-names></name>
          <name><surname>Ahn</surname><given-names>Yong-Yeol</given-names></name>
        </person-group>
        <article-title>The impact of random models on clustering similarity</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2017">2017</year>
        <volume>18</volume>
        <issue>87</issue>
        <pub-id pub-id-type="doi">10.1101/196840</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Gates2018element">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Gates</surname><given-names>Alexander J.</given-names></name>
          <name><surname>Wood</surname><given-names>Ian B.</given-names></name>
          <name><surname>Hetrick</surname><given-names>William P.</given-names></name>
          <name><surname>Ahn</surname><given-names>Yong-Yeol</given-names></name>
        </person-group>
        <article-title>On comparing clusterings: An element-centric framework unifies overlaps and hierarchy</article-title>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-scikitlearn">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-Sukumaran2010dendropy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Sukumaran</surname><given-names>J.</given-names></name>
          <name><surname>Holder</surname><given-names>Mark T.</given-names></name>
        </person-group>
        <article-title>DendroPy: A python library for phylogenetic computing</article-title>
        <source>Bioinformatics</source>
        <year iso-8601-date="2010">2010</year>
        <volume>26</volume>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq228</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1252</article-id>
<article-id pub-id-type="doi">10.21105/joss.01252</article-id>
<title-group>
<article-title>LightTwinSVM: A Simple and Fast Implementation of
Standard Twin Support Vector Machine Classifier</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9818-7752</contrib-id>
<string-name>Amir M. Mir</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-1821-5037</contrib-id>
<string-name>Jalal A. Nasiri</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Iranian Research Institute for Information Science and
Technology (IranDoc), Tehran, Iran</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>4</volume>
<issue>35</issue>
<fpage>1252</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>TwinSVM</kwd>
<kwd>classification</kwd>
<kwd>machine learning</kwd>
<kwd>Implementation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="abstract">
  <title>Abstract</title>
  <p>This paper presents the <monospace>LightTwinSVM</monospace> program
  and its features. It is a simple and fast implementation of twin
  support vector machine algorithm (TwinSVM). Numerical experiments on
  benchmark datasets show the effectiveness of the
  <monospace>LightTwinSVM</monospace> program in terms of accuracy. This
  program can be used by researchers, students, and practitioners to
  solve classifications tasks.</p>
</sec>
<sec id="introduction">
  <title>Introduction</title>
  <p>Classification is a widely-used learning method in machine
  learning. The task of classification consists of training samples for
  which the class labels are available. On the basis of such training
  samples, a classifier learns a rule for predicting an unseen sample
  (<xref alt="Shalev-Shwartz &amp; Ben-David, 2014" rid="ref-shalev2014" ref-type="bibr">Shalev-Shwartz
  &amp; Ben-David, 2014</xref>). To do a classification task, many
  algorithms have been proposed in machine learning literature such as
  Artificial Neural Network (ANN), Support Vector Machine (SVM),
  K-nearest neighbors (KNN), and Decision Trees. Among these
  classification algorithms, SVM classifier has relatively better
  prediction accuracy and generalization
  (<xref alt="Kotsiantis et al., 2007" rid="ref-kotsiantis2007" ref-type="bibr">Kotsiantis
  et al., 2007</xref>). The main idea of SVM is to find the optimal
  separating hyperplane with the largest margin between the two classes.
  Figure <xref alt="1" rid="figU003A1">1</xref> shows the geometric
  illustration of SVM classifier.</p>
  <fig>
    <caption><p>Geometric illustration of SVM
    classifier.<styled-content id="figU003A1"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figs/SVM.png" xlink:title="" />
  </fig>
  <p>Over the past decade, researchers have proposed new classifiers
  based on the SVM
  (<xref alt="Nayak et al., 2015" rid="ref-nayak2015" ref-type="bibr">Nayak
  et al., 2015</xref>). Of these extensions of SVM, the twin support
  vector machine (TwinSVM)
  (<xref alt="Jayadeva et al., 2007" rid="ref-jayadeva2007" ref-type="bibr">Jayadeva
  et al., 2007</xref>) has received more attention from scholars in the
  field of SVM research. This may be due to the novel idea of TwinSVM
  which is doing classification using two non-parallel hyperplanes. Each
  of which is as close as possible to samples of its own class and far
  from samples of the other class. To show the central idea of TwinSVM
  graphically, Figure <xref alt="2" rid="figU003A2">2</xref> shows the
  geometric illustration of TwinSVM classifier.</p>
  <fig>
    <caption><p>Geometric illustration of TwinSVM
    classifier.<styled-content id="figU003A2"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figs/TwinSVM.png" xlink:title="" />
  </fig>
  <p>For SVMs, there exist several stable software packages and
  implementations such as <monospace>LIBSVM</monospace>
  (<xref alt="Chang &amp; Lin, 2011" rid="ref-chang2011libsvm" ref-type="bibr">Chang
  &amp; Lin, 2011</xref>) and <monospace>LIBLINEAR</monospace>
  (<xref alt="Fan et al., 2008" rid="ref-fan2008liblinear" ref-type="bibr">Fan
  et al., 2008</xref>). These packages were used to implement SVM in
  <monospace>scikit-learn</monospace>
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa2011scikit" ref-type="bibr">Pedregosa
  et al., 2011</xref>) which is a widely-used machine learning package
  for Python programming language. To solve a classification problem
  with the SVM algorithm, one can use
  <monospace>scikit-learn</monospace> with only a few lines of code in
  Python.</p>
  <p>Even though TwinSVM is a popular classification algorithm in the
  field of SVM research, to the best of our knowledge, there exists no
  free and reliable implementation with a user guide on the internet.
  This motivated us to develop <monospace>LightTwinSVM</monospace>
  program to help researchers, practitioners, and students build their
  own classifier on the basis of <monospace>LightTwinSVM</monospace>.
  Moreover, this program can be used to solve classification problems.
  In the next section, we present <monospace>LightTwinSVM</monospace>,
  its features, and compare it with
  <monospace>scikit-learn</monospace>’s SVM.</p>
</sec>
<sec id="lighttwinsvm">
  <title>LightTwinSVM</title>
  <p>The <monospace>LightTwinSVM</monospace> program is a simple and
  fast implementation of the TwinSVM classifier. It is mostly written in
  Python and its main design goals are simplicity and speed. Also, this
  program is free, open source, and licensed under the terms of GNU GPL
  v3<xref ref-type="fn" rid="fn1">1</xref>.
  <monospace>LightTwinSVM</monospace> is built on top of
  <monospace>NumPy</monospace>
  (<xref alt="Walt et al., 2011" rid="ref-walt2011" ref-type="bibr">Walt
  et al., 2011</xref>), <monospace>scikit-learn</monospace>
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa2011scikit" ref-type="bibr">Pedregosa
  et al., 2011</xref>), and <monospace>pandas</monospace>
  (<xref alt="McKinney, 2011" rid="ref-mckinney2011pandas" ref-type="bibr">McKinney,
  2011</xref>).</p>
  <p><monospace>LightTwinSVM</monospace> program can be used by both
  researchers in the field of SVM research and by students in courses on
  pattern recognition and machine learning. Moreover, this software can
  be applied to a wide variety of research applications such as text
  classification, image or video recognition, medical diagnosis, and
  bioinformatics. For example, <monospace>LightTwinSVM</monospace> was
  used for the numerical experiments in our previous research paper
  (<xref alt="Mir &amp; Nasiri, 2018" rid="ref-mir2018" ref-type="bibr">Mir
  &amp; Nasiri, 2018</xref>).</p>
  <p>The main features of the <monospace>LightTwinSVM</monospace>
  program are the following:</p>
  <list list-type="bullet">
    <list-item>
      <p>To make its usage simple, a <bold>command-line
      application</bold> was created to help users solve classification
      tasks step-by-step.</p>
    </list-item>
    <list-item>
      <p>Since speed is one of the design goals, the <bold>clipDCD
      optimization algorithm</bold>
      (<xref alt="Peng et al., 2014" rid="ref-peng2014" ref-type="bibr">Peng
      et al., 2014</xref>) is employed which is a simple and fast
      external optimizer. It was improved and implemented in C++.</p>
    </list-item>
    <list-item>
      <p>In order to solve linear or non-linear classification problems,
      both <bold>linear</bold> and <bold>RBF kernels</bold> are
      supported.</p>
    </list-item>
    <list-item>
      <p>Multi-class classification problems can be solved using either
      <bold>One-vs-One</bold> or <bold>One-vs-All</bold> scheme.</p>
    </list-item>
    <list-item>
      <p>The One-vs-One classifier is <bold>scikit-learn
      compatible</bold>. Therefore, <monospace>scikit-learn</monospace>
      tools such as GridSearchCV and cross_val_score can be
      employed.</p>
    </list-item>
    <list-item>
      <p>To evaluate the performance of the classifier, <bold>K-fold
      cross-validation</bold> and <bold>train/test split</bold> are
      supported.</p>
    </list-item>
    <list-item>
      <p>The optimal values of hyper-parameters can be found with
      <bold>grid search</bold>.</p>
    </list-item>
    <list-item>
      <p><bold>CSV</bold> and <bold>LIBSVM</bold> formats are supported
      for importing datasets.</p>
    </list-item>
    <list-item>
      <p>Detailed classification results are saved in a spreadsheet file
      so that results can be analyzed and interpreted.</p>
    </list-item>
  </list>
  <p>The source code of <monospace>LightTwinSVM</monospace>, its
  installation guide and usage example can be found at
  <ext-link ext-link-type="uri" xlink:href="https://github.com/mir-am/LightTwinSVM">https://github.com/mir-am/LightTwinSVM</ext-link>.</p>
</sec>
<sec id="numerical-experiments">
  <title>Numerical Experiments</title>
  <p>In this section, we conducted experiments to show the efficiency of
  <monospace>LightTwinSVM</monospace> program, and compared it with the
  implementation of SVM in <monospace>scikit-learn</monospace> on the
  UCI<xref ref-type="fn" rid="fn2">2</xref> benchmark datasets. To
  evaluate the classifiers’ performance, 5-fold cross-validation is
  used. For both standard SVM and TwinSVM, the penalty parameter
  <inline-formula><alternatives>
  <tex-math><![CDATA[C]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>C</mml:mi></mml:math></alternatives></inline-formula>
  was selected from the set <inline-formula><alternatives>
  <tex-math><![CDATA[\{2^{i} \mid i=-10,-9,\dots,5 \}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msup><mml:mo>∣</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>9</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false" form="postfix">}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
  Moreover, the RBF kernel was used and its parameter
  <inline-formula><alternatives>
  <tex-math><![CDATA[\gamma]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>γ</mml:mi></mml:math></alternatives></inline-formula>
  was chosen over the range <inline-formula><alternatives>
  <tex-math><![CDATA[\{2^{i} \mid i=-15,-14,\dots,5\}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msup><mml:mo>∣</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>14</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false" form="postfix">}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.
  Since the classification performance of standard SVM and TwinSVM
  depends heavily on the optimal choice of hyper-parameters, grid search
  is used to find the optimal values of hyper-parameters.</p>
  <p>To analyze the classification performance of
  <monospace>LightTwinSVM</monospace> and
  <monospace>scikit-learn</monospace>’s SVM, the results on benchmark
  datasets are summarized in Table
  <xref alt="1" rid="tabU003A1">1</xref>.</p>
  <table-wrap>
    <caption>
      <p>The accuracy comparison between
      <monospace>LightTwinSVM</monospace> and
      <monospace>scikit-learn</monospace>’s
      SVM<styled-content id="tabU003A1"></styled-content></p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="center">Datasets</th>
          <th align="center">LightTwinSVM</th>
          <th align="center">scikit-learn’s SVM</th>
          <th align="center">Difference in Accuracy</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center">Pima-Indian</td>
          <td align="center"><bold>78.91</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>3.73</bold></td>
          <td align="center">78.26<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>2.62</td>
          <td align="center">0.65</td>
        </tr>
        <tr>
          <td align="center">Australian</td>
          <td align="center"><bold>87.25</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>2.27</bold></td>
          <td align="center">86.81<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>3.22</td>
          <td align="center">0.44</td>
        </tr>
        <tr>
          <td align="center">Haberman</td>
          <td align="center">76.12<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>4.79</td>
          <td align="center"><bold>76.80</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>2.68</bold></td>
          <td align="center">-0.68</td>
        </tr>
        <tr>
          <td align="center">Cleveland</td>
          <td align="center"><bold>85.14</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>5.45</bold></td>
          <td align="center">84.82<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>4.04</td>
          <td align="center">0.32</td>
        </tr>
        <tr>
          <td align="center">Sonar</td>
          <td align="center"><bold>84.62</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>4.89</bold></td>
          <td align="center">64.42<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>6.81</td>
          <td align="center">20.2</td>
        </tr>
        <tr>
          <td align="center">Heart-Statlog</td>
          <td align="center"><bold>85.56</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>2.96</bold></td>
          <td align="center">85.19<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>2.62</td>
          <td align="center">0.37</td>
        </tr>
        <tr>
          <td align="center">Hepatitis</td>
          <td align="center"><bold>86.45</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>5.16</bold></td>
          <td align="center">83.23<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>3.55</td>
          <td align="center">3.22</td>
        </tr>
        <tr>
          <td align="center">WDBC</td>
          <td align="center"><bold>98.24</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>1.36</bold></td>
          <td align="center">98.07<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>0.85</td>
          <td align="center">0.17</td>
        </tr>
        <tr>
          <td align="center">Spectf</td>
          <td align="center"><bold>81.68</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>5.35</bold></td>
          <td align="center">79.78<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>0.19</td>
          <td align="center">1.9</td>
        </tr>
        <tr>
          <td align="center">Titanic</td>
          <td align="center">81.93<disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula>2.59</td>
          <td align="center"><bold>82.27</bold><disp-formula><alternatives>
          <tex-math><![CDATA[\pm]]></tex-math>
          <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mo>±</mml:mo></mml:math></alternatives></disp-formula><bold>1.83</bold></td>
          <td align="center">-0.34</td>
        </tr>
        <tr>
          <td align="center">Mean Accuracy</td>
          <td align="center"><bold>84.59</bold></td>
          <td align="center">81.94</td>
          <td align="center">2.65</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>From the Table <xref alt="1" rid="tabU003A1">1</xref>, it can be
  seen that <monospace>LightTwinSVM</monospace> outperforms
  <monospace>scikit-learn</monospace>’s SVM on most datasets. For
  instance, the accuracy difference in Sonar dataset is as high as 20.2%
  which is a significant result. However, in consideration of the mean
  accuracy, one may notice that the difference in accuracy between the
  two classifiers is not very large. To show whether a significant
  difference exists, statistical tests are often used in research papers
  on classification
  (<xref alt="Demšar, 2006" rid="ref-demsar2006" ref-type="bibr">Demšar,
  2006</xref>). Due to the limited space, comprehensive experiments with
  statistical tests are skipped in this paper. In summary, the
  experiment indicates that the <monospace>LightTwinSVM</monospace>
  program can be used for classification tasks and it may produce a
  better prediction accuracy.</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>This research work was carried out at the machine learning lab of
  IranDoc Institution. We would like to thank the director of IranDoc
  Institution for providing us with research facilities.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-shalev2014">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Shalev-Shwartz</surname><given-names>Shai</given-names></name>
          <name><surname>Ben-David</surname><given-names>Shai</given-names></name>
        </person-group>
        <source>Understanding machine learning: From theory to algorithms</source>
        <publisher-name>Cambridge university press</publisher-name>
        <year iso-8601-date="2014">2014</year>
        <pub-id pub-id-type="doi">10.1017/CBO9781107298019</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kotsiantis2007">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kotsiantis</surname><given-names>Sotiris B</given-names></name>
          <name><surname>Zaharakis</surname><given-names>I</given-names></name>
          <name><surname>Pintelas</surname><given-names>P</given-names></name>
        </person-group>
        <article-title>Supervised machine learning: A review of classification techniques</article-title>
        <source>Emerging artificial intelligence applications in computer engineering</source>
        <year iso-8601-date="2007">2007</year>
        <volume>160</volume>
      </element-citation>
    </ref>
    <ref id="ref-jayadeva2007">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jayadeva</surname></name>
          <name><surname>Khemchandani</surname><given-names>R</given-names></name>
          <name><surname>Chandra</surname><given-names>Suresh</given-names></name>
        </person-group>
        <article-title>Twin support vector machines for pattern classification</article-title>
        <source>IEEE Transactions on pattern analysis and machine intelligence</source>
        <year iso-8601-date="2007">2007</year>
        <volume>29</volume>
        <issue>5</issue>
        <issn>0162-8828</issn>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2007.1068</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chang2011libsvm">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Chih-Chung</given-names></name>
          <name><surname>Lin</surname><given-names>Chih-Jen</given-names></name>
        </person-group>
        <article-title>LIBSVM: A library for support vector machines</article-title>
        <source>ACM transactions on intelligent systems and technology (TIST)</source>
        <publisher-name>Acm</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>2</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-pedregosa2011scikit">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Gaël</given-names></name>
          <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
          <name><surname>Michel</surname><given-names>Vincent</given-names></name>
          <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
          <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
          <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
          <name><surname>Weiss</surname><given-names>Ron</given-names></name>
          <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in python</article-title>
        <source>Journal of machine learning research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
        <issue>Oct</issue>
      </element-citation>
    </ref>
    <ref id="ref-peng2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Peng</surname><given-names>Xinjun</given-names></name>
          <name><surname>Chen</surname><given-names>Dongjing</given-names></name>
          <name><surname>Kong</surname><given-names>Lingyan</given-names></name>
        </person-group>
        <article-title>A clipping dual coordinate descent algorithm for solving support vector machines</article-title>
        <source>Knowledge-Based Systems</source>
        <year iso-8601-date="2014">2014</year>
        <volume>71</volume>
        <issn>0950-7051</issn>
        <pub-id pub-id-type="doi">10.1016/j.knosys.2014.08.005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-mir2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Mir</surname><given-names>A.</given-names></name>
          <name><surname>Nasiri</surname><given-names>Jalal A.</given-names></name>
        </person-group>
        <article-title>KNN-based least squares twin support vector machine for pattern classification</article-title>
        <source>Applied Intelligence</source>
        <year iso-8601-date="2018-12-01">2018</year><month>12</month><day>01</day>
        <volume>48</volume>
        <issue>12</issue>
        <issn>1573-7497</issn>
        <pub-id pub-id-type="doi">10.1007/s10489-018-1225-z</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-walt2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Walt</surname><given-names>Stéfan van der</given-names></name>
          <name><surname>Colbert</surname><given-names>S Chris</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Gael</given-names></name>
        </person-group>
        <article-title>The NumPy array: A structure for efficient numerical computation</article-title>
        <source>Computing in Science and Engineering</source>
        <year iso-8601-date="2011">2011</year>
        <volume>13</volume>
        <issue>2</issue>
        <issn>1521-9615</issn>
        <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-mckinney2011pandas">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>McKinney</surname><given-names>Wes</given-names></name>
        </person-group>
        <article-title>Pandas: A foundational python library for data analysis and statistics</article-title>
        <source>Python for High Performance and Scientific Computing</source>
        <year iso-8601-date="2011">2011</year>
      </element-citation>
    </ref>
    <ref id="ref-demsar2006">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Demšar</surname><given-names>Janez</given-names></name>
        </person-group>
        <article-title>Statistical comparisons of classifiers over multiple data sets</article-title>
        <source>Journal of Machine learning research</source>
        <year iso-8601-date="2006">2006</year>
        <volume>7</volume>
        <issue>Jan</issue>
      </element-citation>
    </ref>
    <ref id="ref-nayak2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Nayak</surname><given-names>Janmenjoy</given-names></name>
          <name><surname>Naik</surname><given-names>Bighnaraj</given-names></name>
          <name><surname>Behera</surname><given-names>H</given-names></name>
        </person-group>
        <article-title>A comprehensive survey on support vector machine in data mining tasks: Applications and challenges</article-title>
        <source>International Journal of Database Theory and Application</source>
        <year iso-8601-date="2015">2015</year>
        <volume>8</volume>
        <issue>1</issue>
        <issn>2005-4270</issn>
      </element-citation>
    </ref>
    <ref id="ref-fan2008liblinear">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fan</surname><given-names>Rong-En</given-names></name>
          <name><surname>Chang</surname><given-names>Kai-Wei</given-names></name>
          <name><surname>Hsieh</surname><given-names>Cho-Jui</given-names></name>
          <name><surname>Wang</surname><given-names>Xiang-Rui</given-names></name>
          <name><surname>Lin</surname><given-names>Chih-Jen</given-names></name>
        </person-group>
        <article-title>LIBLINEAR: A library for large linear classification</article-title>
        <source>Journal of machine learning research</source>
        <year iso-8601-date="2008">2008</year>
        <volume>9</volume>
        <issue>Aug</issue>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>https://opensource.org/licenses/GPL-3.0</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>http://archive.ics.uci.edu/ml/datasets.html</p>
  </fn>
</fn-group>
</back>
</article>

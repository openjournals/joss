<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
</journal-title-group>
<issn></issn>
<publisher>
<publisher-name></publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2461</article-id>
<article-id pub-id-type="doi">10.21105/joss.02461</article-id>
<title-group>
<article-title>oolong: An R package for validating automated content
analysis tools</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6232-7530</contrib-id>
<string-name>Chung-hong Chan</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-8604-4666</contrib-id>
<string-name>Marius Sältzer</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Mannheimer Zentrum für Europäische Sozialforschung,
Universität Mannheim</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-10-15">
<day>15</day>
<month>10</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>55</issue>
<fpage>2461</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>text analysis</kwd>
<kwd>topic model</kwd>
<kwd>sentiment analysis</kwd>
<kwd>validation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Oolong is an R package providing functions for semantic validation
  of topic modeling and dictionary-based methods, two main tools for
  doing automated content analysis
  (<xref alt="Boumans &amp; Trilling, 2016" rid="ref-boumans2016taking" ref-type="bibr">Boumans
  &amp; Trilling, 2016</xref>;
  <xref alt="Günther &amp; Quandt, 2016" rid="ref-gunther2016word" ref-type="bibr">Günther
  &amp; Quandt, 2016</xref>).</p>
  <p>While the validation of statistical properties of topics models is
  well established, the substantive meaning of categories uncovered is
  often less clear and their interpretation reliant on “intuition” or
  “eyeballing”. As Chang et al.
  (<xref alt="2009, p. 1" rid="ref-chang2009reading" ref-type="bibr">2009,
  p. 1</xref>) put it: “qualitative evaluation of the latent space” or
  figuratively, reading tea leaves.</p>
  <p>The story for dictionary-based methods is not better. Researchers
  usually assume these dictionaries have built-in validity and use them
  directly in their research. However, multiple validation studies
  (<xref alt="Boukes et al., 2020" rid="ref-boukes2020whatsthetone" ref-type="bibr">Boukes
  et al., 2020</xref>;
  <xref alt="González-Bailón &amp; Paltoglou, 2015" rid="ref-gonzalez2015signals" ref-type="bibr">González-Bailón
  &amp; Paltoglou, 2015</xref>;
  <xref alt="Ribeiro et al., 2016" rid="ref-ribeiro2016sentibench" ref-type="bibr">Ribeiro
  et al., 2016</xref>) demonstrate these dictionaries have very limited
  criterion validity.</p>
  <p>Oolong provides a set of tools to objectively judge substantive
  interpretability to applied users in disciplines such as political
  science and communication science. It allows standardized content
  based testing of topic models as well as dictionary-based methods with
  clear numeric indicators of semantic validity. Oolong makes it easy to
  generate standard validation tests suggested by Chang et al.
  (<xref alt="2009" rid="ref-chang2009reading" ref-type="bibr">2009</xref>)
  and Song et al.
  (<xref alt="2020" rid="ref-song2020validations" ref-type="bibr">2020</xref>).</p>
</sec>
<sec id="validation-of-automated-content-analysis">
  <title>Validation of automated content analysis</title>
  <p>Validity is a requirement of content analysis
  (<xref alt="Krippendorff, 2018" rid="ref-krippendorff2018content" ref-type="bibr">Krippendorff,
  2018</xref>;
  <xref alt="Neuendorf, 2016" rid="ref-neuendorf2016content" ref-type="bibr">Neuendorf,
  2016</xref>). Validation of automated methods has been called for by
  many scholars, e.g. Grimmer &amp; Stewart
  (<xref alt="2013" rid="ref-grimmer2013text" ref-type="bibr">2013</xref>);
  Ribeiro et al.
  (<xref alt="2016" rid="ref-ribeiro2016sentibench" ref-type="bibr">2016</xref>);
  Van Atteveldt &amp; Peng
  (<xref alt="2018" rid="ref-van2018communication" ref-type="bibr">2018</xref>).
  But how to validate these methods? The paper by DiMaggio et al.
  (<xref alt="2013" rid="ref-dimaggio2013exploiting" ref-type="bibr">2013</xref>)
  conceptualizes validation of automated methods as three different
  operations and the three operations supplement each other. These three
  operations are: 1) <italic>statistical</italic> validation –to see if
  the model results agree with the assumptions of the model. Examples of
  statistical validation are calculation of pointwise mutual
  information, perplexity or semantic coherence of a topic model; 2)
  <italic>semantic</italic> validation –to see if the model results are
  semantically making sense. This procedure involves comparing model
  results with human judgment
  (<xref alt="Grimmer &amp; King, 2011" rid="ref-grimmer2011general" ref-type="bibr">Grimmer
  &amp; King, 2011</xref>); 3) <italic>predictive</italic> validation
  –to see if the model results can predict external events
  (<xref alt="Quinn et al., 2010" rid="ref-quinn2010analyze" ref-type="bibr">Quinn
  et al., 2010</xref>). For example, one can study whether external
  events can explain surges in attention to a topic extracted by a topic
  model.</p>
  <p>This package focuses on semantic validation for three reasons:
  First, there is existing architecture for conducting statistical
  validation and predictive validation. Topic modeling packages such as
  <monospace>text2vec</monospace>
  (<xref alt="Selivanov et al., 2020" rid="ref-selivanov2020tex2vec" ref-type="bibr">Selivanov
  et al., 2020</xref>), <monospace>topicmodels</monospace>
  (<xref alt="Grün &amp; Hornik, 2011" rid="ref-bettina2011topicmodels" ref-type="bibr">Grün
  &amp; Hornik, 2011</xref>), and <monospace>textmineR</monospace>
  (<xref alt="Jones, 2019" rid="ref-jones2019textminer" ref-type="bibr">Jones,
  2019</xref>) provide functions to calculate metrics such as perplexity
  and semantic coherence. Packages such as
  <monospace>stminsights</monospace>
  (<xref alt="Schwemmer, 2018" rid="ref-schwemmer2018stminsights" ref-type="bibr">Schwemmer,
  2018</xref>) and <monospace>LDAvis</monospace>
  (<xref alt="Sievert &amp; Shirley, 2015" rid="ref-sievert2015ldavis" ref-type="bibr">Sievert
  &amp; Shirley, 2015</xref>) offer additional qualitative methods for
  predictive validation. As of writing, <monospace>tosca</monospace>
  (<xref alt="Koppers et al., 2020" rid="ref-koppers2020tosca" ref-type="bibr">Koppers
  et al., 2020</xref>) is the only package dealing with semantic
  validation. But the text-based interface might pose challenges to
  human annotators and it can only support topic models from the
  <monospace>lda</monospace> package
  (<xref alt="Chang, 2015" rid="ref-change2015lda" ref-type="bibr">Chang,
  2015</xref>).</p>
  <p>Second, results from statistical validation do not always agree
  with those from semantic validation. For example, a topic model with a
  lower perplexity does not have a better interpretability
  (<xref alt="Chang et al., 2009" rid="ref-chang2009reading" ref-type="bibr">Chang
  et al., 2009</xref>). Of course, there are also metrics from
  statistical validation that are shown to be correlated with semantic
  validity, e.g. semantic coherence
  (<xref alt="Mimno et al., 2011" rid="ref-mimno2011optimizing" ref-type="bibr">Mimno
  et al., 2011</xref>). But this correlation is also dependent on the
  text material. For example, Fan et al.
  (<xref alt="2019" rid="ref-fan2019assessing" ref-type="bibr">2019</xref>)
  show that semantic coherence is weakly correlated at best with human
  assessment, when the text material used for training a topic model has
  some frequent terms. But still, calculation of semantic coherence is
  recommended in the best practice paper by Maier et al.
  (<xref alt="2018" rid="ref-maier2018applying" ref-type="bibr">2018</xref>).
  Nonetheless, conducting only statistical validation is not adequate
  because these three validation operations supplement each other.</p>
  <p>Finally, predictive validation is dependent on research questions
  and thus it is difficult to be generalized as a reusable software
  framework. Additionally, the relationship between external
  (sociopolitical) events and the results from automated content
  analysis tools is usually what social scientists are eager to study,
  cf. using topic models for information retrieval
  (<xref alt="Yi &amp; Allan, 2008" rid="ref-yi2008evaluating" ref-type="bibr">Yi
  &amp; Allan, 2008</xref>). We do not believe social scientists would
  ignore conducting any form of predictive validation.</p>
  <p>Oolong focuses on semantic validation. The package provides the
  “human-in-the-loop” semantic validation procedures suggested by Chang
  et al.
  (<xref alt="2009" rid="ref-chang2009reading" ref-type="bibr">2009</xref>)
  and Song et al.
  (<xref alt="2020" rid="ref-song2020validations" ref-type="bibr">2020</xref>).
  The procedure proposed by Chang et al.
  (<xref alt="2009" rid="ref-chang2009reading" ref-type="bibr">2009</xref>)
  has been adopted in subsequent social science studies as the gold
  standard to validate topic models, e.g. Bohr
  (<xref alt="2020" rid="ref-bohr2020reporting" ref-type="bibr">2020</xref>),
  Chuang et al.
  (<xref alt="2015" rid="ref-chuang2015topiccheck" ref-type="bibr">2015</xref>),
  and Miller
  (<xref alt="2017" rid="ref-miller2017australia" ref-type="bibr">2017</xref>).
  The procedure proposed by Song et al.
  (<xref alt="2020" rid="ref-song2020validations" ref-type="bibr">2020</xref>)
  emphasizes both criterion validity and interrater reliability.</p>
</sec>
<sec id="semantic-validation-of-topic-models">
  <title>Semantic validation of topic models</title>
  <p>Topic models can be validated by word intrusion test and topic
  intrusion test
  (<xref alt="Chang et al., 2009" rid="ref-chang2009reading" ref-type="bibr">Chang
  et al., 2009</xref>). In these tests, a human rater is asked to pick
  an odd word from a bunch of words (word intrusion test) or pick an odd
  topic from a bunch of topics for a document (topic intrusion test).
  Oolong provides an easy-to-use Shiny interface for these tests (Figure
  1).</p>
  <p>Currently, oolong supports a variety of topic models,
  e.g. structural topic models / correlated topic models from
  <monospace>stm</monospace>
  (<xref alt="Roberts et al., 2019" rid="ref-roberts2019stm" ref-type="bibr">Roberts
  et al., 2019</xref>), warp-LDA models from
  <monospace>text2vec</monospace>
  (<xref alt="Selivanov et al., 2020" rid="ref-selivanov2020tex2vec" ref-type="bibr">Selivanov
  et al., 2020</xref>), latent dirichlet allocation / correlated-topic
  models from <monospace>topicmodels</monospace>
  (<xref alt="Grün &amp; Hornik, 2011" rid="ref-bettina2011topicmodels" ref-type="bibr">Grün
  &amp; Hornik, 2011</xref>), biterm topic models from
  <monospace>BTM</monospace>
  (<xref alt="Wijffels, 2020" rid="ref-wijffels2020btm" ref-type="bibr">Wijffels,
  2020</xref>) and keyword-assisted topic models from
  <monospace>keyATM</monospace>
  (<xref alt="Eshima et al., 2020" rid="ref-eshima2020keyatm" ref-type="bibr">Eshima
  et al., 2020</xref>).</p>
  <p>For instance, <monospace>abstracts_stm</monospace> is a structural
  topic model trained with the text data from
  <monospace>abstracts$text</monospace>
  (<xref alt="Chan &amp; Grill, 2020" rid="ref-chan2020high" ref-type="bibr">Chan
  &amp; Grill, 2020</xref>).</p>
  <code language="r script">library(stm)
library(tibble)
library(dplyr)
library(quanteda)
library(oolong)</code>
  <code language="r script">abstracts_stm</code>
  <preformat>## A topic model with 20 topics, 2500 documents and a 3998 word dictionary.</preformat>
  <p>The function <monospace>create_oolong</monospace> creates a test
  object with both word intrusion test and topic intrusion test.</p>
  <code language="r script">oolong_test &lt;- create_oolong(input_model = abstracts_stm,
                             input_corpus = abstracts$text)
oolong_test</code>
  <preformat>## An oolong test object with k = 20, 0 coded.
## Use the method $do_word_intrusion_test() to do word intrusion test.
## With 25 cases of topic intrusion test. 0 coded.
## Use the method $do_topic_intrusion_test() to do topic intrusion test.
## Use the method $lock() to finalize this object and see the results.</preformat>
  <p>The tests can be administered with methods
  <monospace>do_word_intrusion_test</monospace> and
  <monospace>do_topic_intrusion_test</monospace>.</p>
  <code language="r script">oolong_test$do_word_intrusion_test()
oolong_test$do_topic_intrusion_test()</code>
  <p>After both tests has been done by a human rater, the test object
  must be locked and then accuracy metrics such as model precision (MP)
  and TLO (topic log odd) are displayed.</p>
  <code language="r script">oolong_test$lock()
oolong_test</code>
  <preformat>## An oolong test object with k = 20, 20 coded.
## 95%  precision
## With 25 cases of topic intrusion test. 25 coded.
## TLO: -0.235</preformat>
  <p>The suggested workflow is to have at least two human raters to do
  the same set of tests. Test object can be cloned to allow multiple
  raters to do the test. More than one test object can be studied
  together using the function
  <monospace>summarize_oolong()</monospace>.</p>
  <code language="r script">oolong_test_rater1 &lt;- create_oolong(abstracts_stm, abstracts$text)
oolong_test_rater2 &lt;- clone_oolong(oolong_test_rater1)</code>
  <code language="r script">## Let rater 1 do the test.
oolong_test_rater1$do_word_intrusion_test()
oolong_test_rater1$do_topic_intrusion_test()
oolong_test_rater1$lock()

## Let rater 2 do the test.
oolong_test_rater2$do_word_intrusion_test()
oolong_test_rater2$do_topic_intrusion_test()
oolong_test_rater2$lock()</code>
  <p>Get a summary of the two objects.</p>
  <code language="r script">summarize_oolong(oolong_test_rater1, oolong_test_rater2)</code>
  <preformat>## Mean model precision: 0.35
## Quantiles of model precision: 0.3, 0.325, 0.35, 0.375, 0.4
## P-value of the model precision
##  (H0: Model precision is not better than random guess): 0.0089
## Krippendorff's alpha: 0.143
## K Precision:
## 0.5, 0, 0, 0.5, 0, 0.5, 0, 0, 1, 0, 0, 1, 0, 1, 0.5, 0, 0.5, 0.5, 0.5, 0.5
## Mean TLO: -1.58
## Median TLO: -0.08
## Quantiles of TLO: -6.64, -2.9, -0.08, 0, 0
## P-Value of the median TLO 
## (H0: Median TLO is not better than random guess): 0</preformat>
  <p>Two key indicators of semantic validity are mean model precision
  and median TLO. Please interpret the magnitude of the two values (see
  <xref alt="Chang et al., 2009" rid="ref-chang2009reading" ref-type="bibr">Chang
  et al., 2009</xref>) rather than the two statisical tests. The two
  statistical tests are testing whether the raters did better than
  random guess. Therefore, rejection of the null hypothesis is just the
  bare minimum of topic interpretability, <italic>not</italic> an
  indicator of adquate semantic validity of the topic model. Besides,
  please a very conservative significant level, e.g. alpha &lt;
  0.001.</p>
</sec>
<sec id="semantic-validation-of-dictionary-based-methods">
  <title>Semantic validation of dictionary-based methods</title>
  <p>Dictionary-based methods such as AFINN
  (<xref alt="Nielsen, 2011" rid="ref-nielsen2011new" ref-type="bibr">Nielsen,
  2011</xref>) can be validated by creating a gold standard dataset
  (<xref alt="Song et al., 2020" rid="ref-song2020validations" ref-type="bibr">Song
  et al., 2020</xref>). Oolong provides a workflow for generating such
  gold standard dataset.</p>
  <p>For example, you are interested in studying the sentiment of tweets
  from Donald Trump. <monospace>trump2k</monospace> is a random subset
  of 2,000 tweets from Donald Trump. And you would like to use AFINN to
  extract sentiment from these tweets. In this analysis, AFINN sentiment
  score is the <italic>target value</italic>.</p>
  <p>A test object can be generated also with
  <monospace>create_oolong</monospace>. The argument
  <monospace>construct</monospace> should be an adjective,
  e.g. “positive” or “liberal”.</p>
  <code language="r script">trump &lt;- create_oolong(input_corpus = trump2k,
                       construct = &quot;positive&quot;,
                       exact_n = 20)
trump</code>
  <preformat>## An oolong test object (gold standard generation) with 20 cases, 0 coded.
## Use the method $do_gold_standard_test() to generate gold standard.
## Use the method $lock() to finalize this object and see the results.</preformat>
  <p>Similarly, we suggest to have at least two human coders to do the
  same set of tests.</p>
  <code language="r script">trump2 &lt;- clone_oolong(trump)</code>
  <p>Instruct two coders to code the tweets and lock the objects.</p>
  <code language="r script">trump$do_gold_standard_test()
trump2$do_gold_standard_test()
trump$lock()
trump2$lock()</code>
  <p>The method <monospace>turn_gold</monospace> converts a test object
  into a quanteda corpus
  (<xref alt="Benoit et al., 2018" rid="ref-benoit2018quanteda" ref-type="bibr">Benoit
  et al., 2018</xref>).</p>
  <code language="r script">gold_standard &lt;- trump$turn_gold()
gold_standard</code>
  <preformat>## Corpus consisting of 20 documents and 1 docvar.
## text1 :
## &quot;Thank you Eau Claire, Wisconsin.  #VoteTrump on Tuesday, Apr...&quot;
## 
## text2 :
## &quot;&quot;@bobby990r_1: @realDonaldTrump would lead polls the second ...&quot;
## 
## text3 :
## &quot;&quot;@KdanielsK: @misstcassidy @AllAboutTheTea_ @realDonaldTrump...&quot;
## 
## text4 :
## &quot;Thank you for a great afternoon Birmingham, Alabama! #Trump2...&quot;
## 
## text5 :
## &quot;&quot;@THETAINTEDT: @foxandfriends @realDonaldTrump Trump 2016 ht...&quot;
## 
## text6 :
## &quot;People believe CNN these days almost as little as they belie...&quot;
## 
## [ reached max_ndoc ... 14 more documents ]
## Access the answer from the coding with quanteda::docvars(obj, 'answer')</preformat>
  <p>This corpus can be used to calculate the target value,
  e.g. AFINN.</p>
  <code language="r script">dfm(gold_standard, remove_punct = TRUE) %&gt;% dfm_lookup(afinn) %&gt;%
    quanteda::convert(to = &quot;data.frame&quot;) %&gt;%
    mutate(matching_word_valence = (neg5 * -5) + (neg4 * -4) +
               (neg3 * -3) + (neg2 * -2) + (neg1 * -1) +
               (zero * 0) + (pos1 * 1) + (pos2 * 2) + (pos3 * 3) +
               (pos4 * 4) + (pos5 * 5),
           base = ntoken(gold_standard, remove_punct = TRUE),
           afinn_score = matching_word_valence / base) %&gt;% 
           pull(afinn_score) -&gt; afinn_score</code>
  <p>Summarize all oolong objects with the target value.</p>
  <code language="r script">res &lt;- summarize_oolong(trump, trump2, target_value = afinn_score)</code>
  <p>Printing the summary shows Krippendorff’s Alpha, an indicator of
  interrater reliability. The validity metrics of a text analytic method
  can be tinted by poor interrater reliability of manual annotations
  (<xref alt="Song et al., 2020" rid="ref-song2020validations" ref-type="bibr">Song
  et al., 2020</xref>). It is important to ensure high interrater
  reliability first.</p>
  <code language="r script">res</code>
  <preformat>## Krippendorff's Alpha: 0.931
## Correlation: 0.744 (p = 2e-04)
## Effect of content length: -0.323 (p = 0.1643)</preformat>
  <p>Additional diagnostic plots can also be displayed (Figure 2).</p>
  <code language="r script">plot(res)</code>
  <fig>
    <caption><p>Diagnostic plots generated by oolong</p></caption>
    <graphic mimetype="application" mime-subtype="pdf" xlink:href="paper_files/figure-latex/diagplot-1.pdf" xlink:title="" />
  </fig>
  <p>The 4 subplots from left to right, top to bottom are:</p>
  <list list-type="order">
    <list-item>
      <p>Correlation between human judgement and target value - A strong
      correlation between the two is an indicator of criterion validity
      of the target value.</p>
    </list-item>
    <list-item>
      <p>Bland-Altman plot - If the dots are randomly scattering around
      the mean value (solid line), it is an indicator of good agreement
      between human judgement and the target value.</p>
    </list-item>
    <list-item>
      <p>Correlation between target value and content length - If there
      is no strong correlation between the target value and content
      length, it is an indicator of robustness against the influence of
      content length (see
      <xref alt="Chan et al., 2020" rid="ref-chan_4b" ref-type="bibr">Chan
      et al., 2020</xref>).</p>
    </list-item>
    <list-item>
      <p>Cook’s distance of all data points - if there are only a few
      dots above the threshold (dotted line), it is an indicator of
      robustness against the influence of outliers.</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The development of oolong is partially supported by SAGE Concept
  Grant.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-chan_4b">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chan</surname><given-names>Chung-hong</given-names></name>
          <name><surname>Bajjalieh</surname><given-names>Joseph</given-names></name>
          <name><surname>Auvil</surname><given-names>Loretta</given-names></name>
          <name><surname>Wessler</surname><given-names>Hartmut</given-names></name>
          <name><surname>Althaus</surname><given-names>Scott</given-names></name>
          <name><surname>Welbers</surname><given-names>Kasper</given-names></name>
          <name><surname>Van Atteveldt</surname><given-names>Wouter</given-names></name>
          <name><surname>Jungblut</surname><given-names>Marc</given-names></name>
        </person-group>
        <article-title>Four best practices for measuring news sentiment using off-the-shelf dictionaries: A large-scale p-hacking experiment</article-title>
        <source>Computational Communication Research</source>
        <year iso-8601-date="2020">2020</year>
        <uri>osf.io/preprints/socarxiv/np5wa</uri>
        <pub-id pub-id-type="doi">10.31235/osf.io/np5wa</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-eshima2020keyatm">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Eshima</surname><given-names>Shusei</given-names></name>
          <name><surname>Imai</surname><given-names>Kosuke</given-names></name>
          <name><surname>Sasaki</surname><given-names>Tomoya</given-names></name>
        </person-group>
        <article-title>Keyword assisted topic models</article-title>
        <source>arXiv preprint arXiv:2004.05964</source>
        <year iso-8601-date="2020">2020</year>
      </element-citation>
    </ref>
    <ref id="ref-wijffels2020btm">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Wijffels</surname><given-names>Jan</given-names></name>
        </person-group>
        <source>BTM: Biterm topic models for short text</source>
        <year iso-8601-date="2020">2020</year>
        <uri>https://CRAN.R-project.org/package=BTM</uri>
      </element-citation>
    </ref>
    <ref id="ref-bettina2011topicmodels">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Grün</surname><given-names>Bettina</given-names></name>
          <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
        </person-group>
        <article-title>topicmodels: An R package for fitting topic models</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2011">2011</year>
        <volume>40</volume>
        <issue>13</issue>
        <pub-id pub-id-type="doi">10.18637/jss.v040.i13</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-selivanov2020tex2vec">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Selivanov</surname><given-names>Dmitriy</given-names></name>
          <name><surname>Bickel</surname><given-names>Manuel</given-names></name>
          <name><surname>Wang</surname><given-names>Qing</given-names></name>
        </person-group>
        <source>text2vec: Modern text mining framework for R</source>
        <year iso-8601-date="2020">2020</year>
        <uri>https://CRAN.R-project.org/package=text2vec</uri>
      </element-citation>
    </ref>
    <ref id="ref-benoit2018quanteda">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
          <name><surname>Watanabe</surname><given-names>Kohei</given-names></name>
          <name><surname>Wang</surname><given-names>Haiyan</given-names></name>
          <name><surname>Nulty</surname><given-names>Paul</given-names></name>
          <name><surname>Obeng</surname><given-names>Adam</given-names></name>
          <name><surname>Müller</surname><given-names>Stefan</given-names></name>
          <name><surname>Matsuo</surname><given-names>Akitaka</given-names></name>
        </person-group>
        <article-title>quanteda: An R package for the quantitative analysis of textual data</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2018">2018</year>
        <volume>3</volume>
        <issue>30</issue>
        <pub-id pub-id-type="doi">10.21105/joss.00774</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-nielsen2011new">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Nielsen</surname><given-names>Finn Årup</given-names></name>
        </person-group>
        <article-title>A new ANEW: Evaluation of a word list for sentiment analysis in microblogs</article-title>
        <source>arXiv preprint arXiv:1103.2903</source>
        <year iso-8601-date="2011">2011</year>
      </element-citation>
    </ref>
    <ref id="ref-chan2020high">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chan</surname><given-names>Chung-hong</given-names></name>
          <name><surname>Grill</surname><given-names>Christiane</given-names></name>
        </person-group>
        <article-title>The highs in communication research: Research topics with high supply, high popularity and high prestige in high-impact journals</article-title>
        <source>Communication Research</source>
        <year iso-8601-date="2020">2020</year>
        <pub-id pub-id-type="doi">10.1177/0093650220944790</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-song2020validations">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Song</surname><given-names>Hyunjin</given-names></name>
          <name><surname>Tolochko</surname><given-names>Petro</given-names></name>
          <name><surname>Eberl</surname><given-names>Jakob-Moritz</given-names></name>
          <name><surname>Eisele</surname><given-names>Olga</given-names></name>
          <name><surname>Greussing</surname><given-names>Esther</given-names></name>
          <name><surname>Heidenreich</surname><given-names>Tobias</given-names></name>
          <name><surname>Lind</surname><given-names>Fabienne</given-names></name>
          <name><surname>Galyga</surname><given-names>Sebastian</given-names></name>
          <name><surname>Boomgaarden</surname><given-names>Hajo G</given-names></name>
        </person-group>
        <article-title>In validations we trust? The impact of imperfect human annotations as a gold standard on the quality of validation of automated content analysis</article-title>
        <source>Political Communication</source>
        <year iso-8601-date="2020">2020</year>
        <pub-id pub-id-type="doi">10.1080/10584609.2020.1723752</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-krippendorff2018content">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Krippendorff</surname><given-names>Klaus</given-names></name>
        </person-group>
        <source>Content analysis: An introduction to its methodology</source>
        <publisher-name>SAGE</publisher-name>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-chang2009reading">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Jonathan</given-names></name>
          <name><surname>Gerrish</surname><given-names>Sean</given-names></name>
          <name><surname>Wang</surname><given-names>Chong</given-names></name>
          <name><surname>Boyd-Graber</surname><given-names>Jordan L</given-names></name>
          <name><surname>Blei</surname><given-names>David M</given-names></name>
        </person-group>
        <article-title>Reading tea leaves: How humans interpret topic models</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <year iso-8601-date="2009">2009</year>
        <uri>https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models</uri>
      </element-citation>
    </ref>
    <ref id="ref-van2018communication">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Van Atteveldt</surname><given-names>Wouter</given-names></name>
          <name><surname>Peng</surname><given-names>Tai-Quan</given-names></name>
        </person-group>
        <article-title>When communication meets computation: Opportunities, challenges, and pitfalls in computational communication science</article-title>
        <source>Communication Methods and Measures</source>
        <year iso-8601-date="2018">2018</year>
        <volume>12</volume>
        <issue>2-3</issue>
        <pub-id pub-id-type="doi">10.1080/19312458.2018.1458084</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-grimmer2013text">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Grimmer</surname><given-names>Justin</given-names></name>
          <name><surname>Stewart</surname><given-names>Brandon M</given-names></name>
        </person-group>
        <article-title>Text as data: The promise and pitfalls of automatic content analysis methods for political texts</article-title>
        <source>Political analysis</source>
        <year iso-8601-date="2013">2013</year>
        <volume>21</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1093/pan/mps028</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-neuendorf2016content">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Neuendorf</surname><given-names>Kimberly A</given-names></name>
        </person-group>
        <source>The content analysis guidebook</source>
        <publisher-name>SAGE</publisher-name>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-ribeiro2016sentibench">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Ribeiro</surname><given-names>Filipe N</given-names></name>
          <name><surname>Araújo</surname><given-names>Matheus</given-names></name>
          <name><surname>Gonçalves</surname><given-names>Pollyanna</given-names></name>
          <name><surname>Gonçalves</surname><given-names>Marcos André</given-names></name>
          <name><surname>Benevenuto</surname><given-names>Fabrı́cio</given-names></name>
        </person-group>
        <article-title>Sentibench-a benchmark comparison of state-of-the-practice sentiment analysis methods</article-title>
        <source>EPJ Data Science</source>
        <year iso-8601-date="2016">2016</year>
        <volume>5</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1140/epjds/s13688-016-0085-1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-roberts2019stm">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Roberts</surname><given-names>Margaret E.</given-names></name>
          <name><surname>Stewart</surname><given-names>Brandon M.</given-names></name>
          <name><surname>Tingley</surname><given-names>Dustin</given-names></name>
        </person-group>
        <article-title>stm: An R package for structural topic models</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2019">2019</year>
        <volume>91</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.18637/jss.v091.i02</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-dimaggio2013exploiting">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>DiMaggio</surname><given-names>Paul</given-names></name>
          <name><surname>Nag</surname><given-names>Manish</given-names></name>
          <name><surname>Blei</surname><given-names>David</given-names></name>
        </person-group>
        <article-title>Exploiting affinities between topic modeling and the sociological perspective on culture: Application to newspaper coverage of US government arts funding</article-title>
        <source>Poetics</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2013">2013</year>
        <volume>41</volume>
        <issue>6</issue>
        <pub-id pub-id-type="doi">10.1016/j.poetic.2013.08.004</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-grimmer2011general">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Grimmer</surname><given-names>Justin</given-names></name>
          <name><surname>King</surname><given-names>Gary</given-names></name>
        </person-group>
        <article-title>General purpose computer-assisted clustering and conceptualization</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <publisher-name>National Acad Sciences</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>108</volume>
        <issue>7</issue>
        <pub-id pub-id-type="doi">10.1073/pnas.1018067108</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-quinn2010analyze">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Quinn</surname><given-names>Kevin M</given-names></name>
          <name><surname>Monroe</surname><given-names>Burt L</given-names></name>
          <name><surname>Colaresi</surname><given-names>Michael</given-names></name>
          <name><surname>Crespin</surname><given-names>Michael H</given-names></name>
          <name><surname>Radev</surname><given-names>Dragomir R</given-names></name>
        </person-group>
        <article-title>How to analyze political attention with minimal assumptions and costs</article-title>
        <source>American Journal of Political Science</source>
        <publisher-name>Wiley Online Library</publisher-name>
        <year iso-8601-date="2010">2010</year>
        <volume>54</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1111/j.1540-5907.2009.00427.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-jones2019textminer">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Jones</surname><given-names>Tommy</given-names></name>
        </person-group>
        <source>textmineR: Functions for text mining and topic modeling</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://CRAN.R-project.org/package=textmineR</uri>
      </element-citation>
    </ref>
    <ref id="ref-schwemmer2018stminsights">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Schwemmer</surname><given-names>Carsten</given-names></name>
        </person-group>
        <source>stminsights: A ’Shiny’ application for inspecting structural topic models</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=stminsights</uri>
      </element-citation>
    </ref>
    <ref id="ref-sievert2015ldavis">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Sievert</surname><given-names>Carson</given-names></name>
          <name><surname>Shirley</surname><given-names>Kenny</given-names></name>
        </person-group>
        <source>LDAvis: Interactive visualization of topic models</source>
        <year iso-8601-date="2015">2015</year>
        <uri>https://CRAN.R-project.org/package=LDAvis</uri>
      </element-citation>
    </ref>
    <ref id="ref-koppers2020tosca">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Koppers</surname><given-names>Lars</given-names></name>
          <name><surname>Rieger</surname><given-names>Jonas</given-names></name>
          <name><surname>Boczek</surname><given-names>Karin</given-names></name>
          <name><surname>von Nordheim</surname><given-names>Gerret</given-names></name>
        </person-group>
        <source>tosca: Tools for statistical content analysis</source>
        <year iso-8601-date="2020">2020</year>
        <uri>https://github.com/Docma-TU/tosca</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.3591068</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-mimno2011optimizing">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Mimno</surname><given-names>David</given-names></name>
          <name><surname>Wallach</surname><given-names>Hanna</given-names></name>
          <name><surname>Talley</surname><given-names>Edmund</given-names></name>
          <name><surname>Leenders</surname><given-names>Miriam</given-names></name>
          <name><surname>McCallum</surname><given-names>Andrew</given-names></name>
        </person-group>
        <article-title>Optimizing semantic coherence in topic models</article-title>
        <source>Proceedings of the 2011 conference on empirical methods in natural language processing</source>
        <year iso-8601-date="2011">2011</year>
      </element-citation>
    </ref>
    <ref id="ref-maier2018applying">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Maier</surname><given-names>Daniel</given-names></name>
          <name><surname>Waldherr</surname><given-names>Annie</given-names></name>
          <name><surname>Miltner</surname><given-names>Peter</given-names></name>
          <name><surname>Wiedemann</surname><given-names>Gregor</given-names></name>
          <name><surname>Niekler</surname><given-names>Andreas</given-names></name>
          <name><surname>Keinert</surname><given-names>Alexa</given-names></name>
          <name><surname>Pfetsch</surname><given-names>Barbara</given-names></name>
          <name><surname>Heyer</surname><given-names>Gerhard</given-names></name>
          <name><surname>Reber</surname><given-names>Ueli</given-names></name>
          <name><surname>Häussler</surname><given-names>Thomas</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Applying LDA topic modeling in communication research: Toward a valid and reliable methodology</article-title>
        <source>Communication Methods and Measures</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>12</volume>
        <issue>2-3</issue>
        <pub-id pub-id-type="doi">10.1080/19312458.2018.1430754</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-yi2008evaluating">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Yi</surname><given-names>Xing</given-names></name>
          <name><surname>Allan</surname><given-names>James</given-names></name>
        </person-group>
        <article-title>Evaluating topic models for information retrieval</article-title>
        <source>Proceedings of the 17th ACM conference on Information and knowledge management</source>
        <year iso-8601-date="2008">2008</year>
        <pub-id pub-id-type="doi">10.1145/1458082.1458317</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chuang2015topiccheck">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Chuang</surname><given-names>Jason</given-names></name>
          <name><surname>Roberts</surname><given-names>Margaret E</given-names></name>
          <name><surname>Stewart</surname><given-names>Brandon M</given-names></name>
          <name><surname>Weiss</surname><given-names>Rebecca</given-names></name>
          <name><surname>Tingley</surname><given-names>Dustin</given-names></name>
          <name><surname>Grimmer</surname><given-names>Justin</given-names></name>
          <name><surname>Heer</surname><given-names>Jeffrey</given-names></name>
        </person-group>
        <article-title>TopicCheck: Interactive alignment for assessing topic model stability</article-title>
        <source>Proceedings of the 2015 conference of the north american chapter of the Association for Computational Linguistics: Human Language Technologies</source>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.3115/v1/N15-1018</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-miller2017australia">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Miller</surname><given-names>Charles</given-names></name>
        </person-group>
        <article-title>Australia’s anti-islam right in their own words. Text as data analysis of social media content</article-title>
        <source>Australian Journal of Political Science</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <volume>52</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1080/10361146.2017.1324561</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bohr2020reporting">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bohr</surname><given-names>Jeremiah</given-names></name>
        </person-group>
        <article-title>Reporting on climate change: A computational analysis of US newspapers and sources of bias, 1997–2017</article-title>
        <source>Global Environmental Change</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>61</volume>
        <pub-id pub-id-type="doi">10.1016/j.gloenvcha.2020.102038</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-change2015lda">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Jonathan</given-names></name>
        </person-group>
        <source>lda: Collapsed Gibbs sampling methods for topic models</source>
        <year iso-8601-date="2015">2015</year>
        <uri>https://CRAN.R-project.org/package=lda</uri>
      </element-citation>
    </ref>
    <ref id="ref-gonzalez2015signals">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>González-Bailón</surname><given-names>Sandra</given-names></name>
          <name><surname>Paltoglou</surname><given-names>Georgios</given-names></name>
        </person-group>
        <article-title>Signals of public opinion in online communication: A comparison of methods and data sources</article-title>
        <source>The ANNALS of the American Academy of Political and Social Science</source>
        <publisher-name>SAGE Publications Sage CA: Los Angeles, CA</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>659</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1177/0002716215569192</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-boukes2020whatsthetone">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Boukes</surname><given-names>Mark</given-names></name>
          <name><surname>Velde</surname><given-names>Bob van de</given-names></name>
          <name><surname>Araujo</surname><given-names>Theo</given-names></name>
          <name><surname>Vliegenthart</surname><given-names>Rens</given-names></name>
        </person-group>
        <article-title>What’s the tone? Easy doesn’t do it: Analyzing performance and agreement between off-the-shelf sentiment analysis tools</article-title>
        <source>Communication Methods and Measures</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>14</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1080/19312458.2019.1671966</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-boumans2016taking">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Boumans</surname><given-names>Jelle W</given-names></name>
          <name><surname>Trilling</surname><given-names>Damian</given-names></name>
        </person-group>
        <article-title>Taking stock of the toolkit: An overview of relevant automated content analysis approaches and techniques for digital journalism scholars</article-title>
        <source>Digital Journalism</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>4</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1080/21670811.2015.1096598</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gunther2016word">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Günther</surname><given-names>Elisabeth</given-names></name>
          <name><surname>Quandt</surname><given-names>Thorsten</given-names></name>
        </person-group>
        <article-title>Word counts and topic models: Automated text analysis methods for digital journalism research</article-title>
        <source>Digital Journalism</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>4</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1080/21670811.2015.1093270</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-fan2019assessing">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fan</surname><given-names>Angela</given-names></name>
          <name><surname>Doshi-Velez</surname><given-names>Finale</given-names></name>
          <name><surname>Miratrix</surname><given-names>Luke</given-names></name>
        </person-group>
        <article-title>Assessing topic model relevance: Evaluation and informative priors</article-title>
        <source>Statistical Analysis and Data Mining: The ASA Data Science Journal</source>
        <publisher-name>Wiley Online Library</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>12</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1002/sam.11415</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

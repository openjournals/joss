<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2016</article-id>
<article-id pub-id-type="doi">10.21105/joss.02016</article-id>
<title-group>
<article-title>Audiometry: A model-view-viewmodel (MVVM) application
framework for hearing impairment diagnosis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-4647-4565</contrib-id>
<string-name>Waseem Sheikh</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Nadeem Sheikh</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Associate Professor, Electrical and Computer Engineering,
Utah Valley University, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Assistant Professor of ENT, CMH, Quetta,
Pakistan</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>5</volume>
<issue>51</issue>
<fpage>2016</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>WPF</kwd>
<kwd>audiometry</kwd>
<kwd>hearing loss</kwd>
<kwd>model-view-viewmodel</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Around 466 million people worldwide (over 5% of the world’s
  population) have disabling hearing loss, and out of these 34 million
  are children
  (<xref alt="Deafness and Hearing Loss, n.d." rid="ref-WhoU003A2019" ref-type="bibr"><italic>Deafness
  and Hearing Loss</italic>, n.d.</xref>). Estimates suggest that by
  2050, over 900 million people worldwide will have disabling hearing
  loss. The annual global cost of unaddressed hearing loss amounts to
  US$ 750 billion
  (<xref alt="Deafness and Hearing Loss, n.d." rid="ref-WhoU003A2019" ref-type="bibr"><italic>Deafness
  and Hearing Loss</italic>, n.d.</xref>). Early detection of hearing
  loss can reduce its impact on an individual’s life in addition to
  saving a huge cost. The existing hearing test applications are
  closed-source, not extensible, test for a limited number of hearing
  tests such as pure-tone air conduction audiometry, the audiograms
  generated are either incomplete or do not fully conform to the
  American National Standards Institute (ANSI) ANSI S3.6-1996
  Specification for Audiometers
  (<xref alt="Institute, 1996" rid="ref-ANSIS3.6-1996U003A1996" ref-type="bibr">Institute,
  1996</xref>), are tightly coupled with a specific vendor hardware, and
  do not provide an ability to implement various data analytics
  algorithms to draw important conclusions from the hearing test data
  (<xref alt="Abu-Ghanem et al., 2016" rid="ref-AbuSmartphoneU003A2016" ref-type="bibr">Abu-Ghanem
  et al., 2016</xref>;
  <xref alt="Barczik &amp; Serpanos, 2018" rid="ref-BarczikAccuracyU003A2018" ref-type="bibr">Barczik
  &amp; Serpanos, 2018</xref>;
  <xref alt="Chen et al., 2018" rid="ref-ChenSmartphoneU003A2018" ref-type="bibr">Chen
  et al., 2018</xref>;
  <xref alt="Livshitz et al., 2017" rid="ref-LivshitzApplicationU003A2017" ref-type="bibr">Livshitz
  et al., 2017</xref>;
  <xref alt="Samelli et al., 2018" rid="ref-SamelliTabletU003A2018" ref-type="bibr">Samelli
  et al., 2018</xref>;
  <xref alt="Yao et al., 2015" rid="ref-YaoBrowserU003A2015" ref-type="bibr">Yao
  et al., 2015</xref>). In addition, the price of proprietary hearing
  test software applications makes these prohibitive for underdeveloped
  countries which tend to have a higher prevalence of people with
  hearing loss. In most underdeveloped countries, hearing test data is
  still stored on paper and graphs such as audiograms are drawn by hand.
  Such a primitive system of managing hearing test data is error-prone
  and makes it very difficult to save, track, analyze, and reproduce
  hearing test data. In addition, a lack of open-source software in this
  domain stifles innovation.</p>
  <p><monospace>Audiometry</monospace> is an open-source application
  framework written in C# and based on WPF and .NET to create hearing
  test applications. <monospace>Audiometry</monospace> enables accurate
  digital recording, search, analysis, graphical visualization, and
  reproduction of human audio-vestibular impairment test data to assist
  in hearing loss or disability diagnosis. The framework is built using
  the Model-View-ViewModel (MVVM)
  (<xref alt="Model-View-Viewmodel, n.d." rid="ref-MvvmWikipediaU003A2019" ref-type="bibr"><italic>Model-View-Viewmodel</italic>,
  n.d.</xref>;
  <xref alt="The Model-View-Viewmodel Pattern, n.d." rid="ref-MvvmMicrosoftU003A2019" ref-type="bibr"><italic>The
  Model-View-Viewmodel Pattern</italic>, n.d.</xref>) software
  architectural pattern which separates the development of graphical
  user interface (GUI) from the development of business and back-end
  logic. Some of the benefits of the MVVM pattern include reusable
  components, independent development of GUI and business or back-end
  logic, flexibility to modify GUI without having to change business or
  back-end logic, ease of comprehensive unit testing, faster application
  development time, and reduced maintenance overhead. The proposed
  framework makes it possible to easily extend the application
  functionality thus enabling other researchers and practitioners to
  develop their own hearing impairment diagnosis applications.</p>
  <p><monospace>Audiometry</monospace> can store, search, analyze,
  print, and visualize data corresponding to tuning fork tests including
  Weber, Rinne, Schwabach, absolute bone conduction, Teal, and Gelle;
  speech audiometry; pure-tone audiometry (PTA); impedance audiometry;
  bithermal caloric test; and advanced tests including alternate
  binaural loudness balance (ABLB), short increment sensitivity index
  (SISI), tone decay, and Stenger
  (<xref alt="Bess &amp; Humes, 2008" rid="ref-BessAudiologyU003A2003" ref-type="bibr">Bess
  &amp; Humes, 2008</xref>;
  <xref alt="Dhingra &amp; Dhingra, 2018" rid="ref-DhingraDiseasesU003A2014" ref-type="bibr">Dhingra
  &amp; Dhingra, 2018</xref>;
  <xref alt="Gelfand, 2016" rid="ref-GelfandEssentialsU003A2016" ref-type="bibr">Gelfand,
  2016</xref>;
  <xref alt="Katz et al., 2015" rid="ref-KatzHandbookU003A2015" ref-type="bibr">Katz
  et al., 2015</xref>;
  <xref alt="Kramer &amp; Brown, 2019" rid="ref-KramerAudiologyU003A2019" ref-type="bibr">Kramer
  &amp; Brown, 2019</xref>). The application framework can also be used
  to develop new hearing test applications by extending its current
  functionality. <monospace>Audiometry</monospace> is independent of
  specific hearing test hardware thus making it possible to be used with
  a wide variety of hearing test hardware. In addition,
  <monospace>Audiometry</monospace> provides a unified and uniform
  interface for storing, analyzing, and visualizing data from a wide
  range of hearing tests which traditionally rely on different hardware
  and software. The software was evaluated by an otolaryngologist who
  found it to be very beneficial in reaching a hearing impairment
  diagnosis conclusion more methodically, swiftly, and accurately.</p>
  <p>Following are examples of some of the research questions that can
  be investigated by the use of <monospace>Audiometry</monospace>:</p>
  <list list-type="order">
    <list-item>
      <p>The software can be used to compare the sensitivity
      (true-positive rate) and specificity (true-negative rate) of
      various hearing test equipment and methods. For example, questions
      like how reliable is a pure-tone audiometry test performed by a
      smartphone or a tablet when compared to a benchmark calibrated
      audiometer can be easily answered by using this software.</p>
    </list-item>
    <list-item>
      <p>The software can be used to determine important correlations
      between lifestyle, work conditions, and demographics; and the
      types of hearing loss.</p>
    </list-item>
    <list-item>
      <p>The software can be used to measure the efficacy of a certain
      treatment, intervention, or equipment on the progression of a
      hearing loss.</p>
    </list-item>
  </list>
  <p>The current functionality of the application can be extended and
  enhanced in various ways. Some important future research directions
  include adding additional hearing impairment diagnostic intelligence
  into the application, using machine learning and artificial
  intelligence techniques to increase the accuracy of diagnosis, and a
  client-server based architecture of the application.</p>
</sec>
<sec id="figures">
  <title>Figures</title>
  <fig>
    <caption><p>Pure-tone audiogram interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="puretone1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Speech audiometry interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="speech1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Impedance audiometry interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="impedance1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Bithermal caloric interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="calorigram1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Search interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="search1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>Patient interface.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="patient1.png" xlink:title="" />
  </fig>
</sec>
<sec id="documentation">
  <title>Documentation</title>
  <p>The Doxygen generated API documentation for
  <monospace>Audiometry</monospace> can be found under the docs folder.
  The full-length paper on <monospace>Audiometry</monospace> which
  explains its design, architecture, and implementation in detail is
  located in the paper folder.</p>
</sec>
<sec id="installation">
  <title>Installation</title>
  <p><monospace>Audiometry</monospace> can be installed on a Windows 7
  or Windows 10 machine. To install the application, run the
  AudiometryInstaller.msi in the installer folder of the repository. To
  test the application, please follow the steps listed in the test.md
  file under the test folder.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-WhoU003A2019">
      <element-citation>
        <article-title>Deafness and hearing loss</article-title>
        <uri>https://www.who.int/news-room/fact-sheets/detail/deafness-and-hearing-loss</uri>
      </element-citation>
    </ref>
    <ref id="ref-MvvmWikipediaU003A2019">
      <element-citation>
        <article-title>Model-view-viewmodel</article-title>
        <uri>https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel</uri>
      </element-citation>
    </ref>
    <ref id="ref-MvvmMicrosoftU003A2019">
      <element-citation>
        <article-title>The model-view-viewmodel pattern</article-title>
        <uri>https://docs.microsoft.com/en-us/xamarin/xamarin-forms/enterprise-application-patterns/mvvm</uri>
      </element-citation>
    </ref>
    <ref id="ref-KramerAudiologyU003A2019">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Kramer</surname><given-names>Steven</given-names></name>
          <name><surname>Brown</surname><given-names>David K</given-names></name>
        </person-group>
        <source>Audiology: Science to practice</source>
        <publisher-name>Plural Publishing</publisher-name>
        <year iso-8601-date="2019">2019</year>
      </element-citation>
    </ref>
    <ref id="ref-GelfandEssentialsU003A2016">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Gelfand</surname><given-names>Stanley A</given-names></name>
        </person-group>
        <source>Essentials of audiology</source>
        <publisher-name>Thieme Medical Publishers</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1055/b-006-161125</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-KatzHandbookU003A2015">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Katz</surname><given-names>Jack</given-names></name>
          <name><surname>Chasin</surname><given-names>Marshall</given-names></name>
          <name><surname>English</surname><given-names>Kristina M</given-names></name>
          <name><surname>Hood</surname><given-names>Linda J</given-names></name>
          <name><surname>Tillery</surname><given-names>Kim L</given-names></name>
        </person-group>
        <source>Handbook of clinical audiology</source>
        <publisher-name>Wolters Kluwer Health</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1097/00003446-198608000-00010</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-BessAudiologyU003A2003">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Bess</surname><given-names>Fred H</given-names></name>
          <name><surname>Humes</surname><given-names>Larry E</given-names></name>
        </person-group>
        <source>Audiology: The fundamentals</source>
        <publisher-name>Lippincott Williams &amp; Wilkins</publisher-name>
        <year iso-8601-date="2008">2008</year>
      </element-citation>
    </ref>
    <ref id="ref-DhingraDiseasesU003A2014">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Dhingra</surname><given-names>PL</given-names></name>
          <name><surname>Dhingra</surname><given-names>Shruti</given-names></name>
        </person-group>
        <source>Diseases of ear, nose and throat &amp; head and neck surgery</source>
        <publisher-name>RELX India Pvt. Ltd.</publisher-name>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-ChenSmartphoneU003A2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chen</surname><given-names>Fei</given-names></name>
          <name><surname>Wang</surname><given-names>Shuai</given-names></name>
          <name><surname>Li</surname><given-names>Juanjuan</given-names></name>
          <name><surname>Tan</surname><given-names>Huajun</given-names></name>
          <name><surname>Jia</surname><given-names>Wen</given-names></name>
          <name><surname>Wang</surname><given-names>Zhihua</given-names></name>
        </person-group>
        <article-title>Smartphone-based hearing self-assessment system using hearing aids with fast audiometry method</article-title>
        <source>IEEE transactions on biomedical circuits and systems</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>13</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1109/tbcas.2018.2878341</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-YaoBrowserU003A2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Yao</surname><given-names>Jianchu</given-names></name>
          <name><surname>Yao</surname><given-names>Daoyuan</given-names></name>
          <name><surname>Givens</surname><given-names>Gregg</given-names></name>
        </person-group>
        <article-title>A browser-server-based tele-audiology system that supports multiple hearing test modalities</article-title>
        <source>Telemedicine and e-Health</source>
        <publisher-name>Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>21</volume>
        <issue>9</issue>
        <pub-id pub-id-type="doi">10.1089/tmj.2014.0171</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-SamelliTabletU003A2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Samelli</surname><given-names>Alessandra G</given-names></name>
          <name><surname>Rabelo</surname><given-names>Camila M</given-names></name>
          <name><surname>Sanches</surname><given-names>Seisse G Gandolfi</given-names></name>
          <name><surname>Martinho</surname><given-names>Ana C</given-names></name>
          <name><surname>Matas</surname><given-names>Carla G</given-names></name>
        </person-group>
        <article-title>Tablet-based tele-audiometry: Automated hearing screening for schoolchildren</article-title>
        <source>Journal of telemedicine and telecare</source>
        <publisher-name>SAGE Publications Sage UK: London, England</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1177/1357633x18800856</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-BarczikAccuracyU003A2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Barczik</surname><given-names>Jessica</given-names></name>
          <name><surname>Serpanos</surname><given-names>Yula C</given-names></name>
        </person-group>
        <article-title>Accuracy of smartphone self-hearing test applications across frequencies and earphone styles in adults</article-title>
        <source>American journal of audiology</source>
        <publisher-name>ASHA</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>27</volume>
        <issue>4</issue>
        <pub-id pub-id-type="doi">10.1044/2018_aja-17-0070</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-AbuSmartphoneU003A2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Abu-Ghanem</surname><given-names>Sara</given-names></name>
          <name><surname>Handzel</surname><given-names>Ophir</given-names></name>
          <name><surname>Ness</surname><given-names>Lior</given-names></name>
          <name><surname>Ben-Artzi-Blima</surname><given-names>Miri</given-names></name>
          <name><surname>Fait-Ghelbendorf</surname><given-names>Karin</given-names></name>
          <name><surname>Himmelfarb</surname><given-names>Mordechai</given-names></name>
        </person-group>
        <article-title>Smartphone-based audiometric test for screening hearing loss in the elderly</article-title>
        <source>European archives of oto-rhino-laryngology</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>273</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1007/s00405-015-3533-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-LivshitzApplicationU003A2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Livshitz</surname><given-names>Leonid</given-names></name>
          <name><surname>Ghanayim</surname><given-names>Reem</given-names></name>
          <name><surname>Kraus</surname><given-names>Carmi</given-names></name>
          <name><surname>Farah</surname><given-names>Raymond</given-names></name>
          <name><surname>Even-Tov</surname><given-names>Ella</given-names></name>
          <name><surname>Avraham</surname><given-names>Yaniv</given-names></name>
          <name><surname>Sharabi-Nov</surname><given-names>Adi</given-names></name>
          <name><surname>Gilbey</surname><given-names>Peter</given-names></name>
        </person-group>
        <article-title>Application-based hearing screening in the elderly population</article-title>
        <source>Annals of Otology, Rhinology &amp; Laryngology</source>
        <publisher-name>SAGE Publications Sage CA: Los Angeles, CA</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <volume>126</volume>
        <issue>1</issue>
      </element-citation>
    </ref>
    <ref id="ref-ANSIS3.6-1996U003A1996">
      <element-citation publication-type="report">
        <person-group person-group-type="author">
          <name><surname>Institute</surname><given-names>American National Standards</given-names></name>
        </person-group>
        <article-title>American national standards institute specifications for audiometers (ANSI S3.6-1996)</article-title>
        <publisher-name>American National Standards Institute</publisher-name>
        <publisher-loc>New York, NY</publisher-loc>
        <year iso-8601-date="1996">1996</year>
        <volume></volume>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

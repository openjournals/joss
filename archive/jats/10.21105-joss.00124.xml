<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">124</article-id>
<article-id pub-id-type="doi">10.21105/joss.00124</article-id>
<title-group>
<article-title>Confidence Intervals for Random Forests in
Python</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3498-0479</contrib-id>
<string-name>Kivan Polimis</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0679-1985</contrib-id>
<string-name>Ariel Rokem</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7532-645X</contrib-id>
<string-name>Bryna Hazelton</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>eScience Institute, University of Washington</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2017-07-07">
<day>7</day>
<month>7</month>
<year>2017</year>
</pub-date>
<volume>2</volume>
<issue>19</issue>
<fpage>124</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>scikit-learn</kwd>
<kwd>random forest</kwd>
<kwd>confidence intervals</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Random forests are a method for predicting numerous ensemble
  learning tasks. Prediction variability can illustrate how influential
  the training set is for producing the observed random forest
  predictions and provides additional information about prediction
  accuracy. <monospace>forest-confidence-interval</monospace> is a
  Python module for calculating variance and adding confidence intervals
  to <monospace>scikit-learn</monospace> random forest regression or
  classification objects. The core functions calculate an in-bag and
  error bars for random forest objects. Our software is designed for
  individuals using <monospace>scikit-learn</monospace> random forest
  objects that want to add estimates of uncertainty to random forest
  predictors. This module is an implementation of an algorithm developed
  by Wager et al.
  (<xref alt="2014" rid="ref-wager_confidence_2014" ref-type="bibr">2014</xref>)
  and previously implemented in R
  (<xref alt="Wager, 2016" rid="ref-wager_randomforestci_2016" ref-type="bibr">Wager,
  2016</xref>).</p>
</sec>
<sec id="usage">
  <title>Usage</title>
  <p>Our package’s <monospace>random_forest_error</monospace> and
  <monospace>calc_inbag</monospace> functions use the random forest
  object (including training and test data) to create variance estimates
  that can be plotted (e.g. as confidence intervals or standard
  deviations). The in-bag matrix that fit the data is set to
  <monospace>None</monospace> by default, and the in-bag will be
  inferred from the forest. However, this only works for trees for which
  bootstrapping was set to <monospace>True</monospace>. That is, if
  sampling was done with replacement. Otherwise, users need to provide
  their own in-bag matrix.</p>
</sec>
<sec id="examples-gallery">
  <title>Examples gallery</title>
  <p>The regression example uses a slightly modified data-set from the
  Carnegie Mellon University’s StatLib library (available from the
  <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Auto+MPG">UC
  Irvine Machine Learning Repository</ext-link>) with features of
  different cars and their MPG
  (<xref alt="Quinlan, 1993" rid="ref-quinlan_combining_1993" ref-type="bibr">Quinlan,
  1993</xref>). The classification example generates synthetic data to
  simulate a task like that of a spam filter: classifying items into one
  of two categories (e.g., spam/non-spam) based on a number of features.
  This module will work for matrices or <monospace>pandas</monospace>
  data frames. Then, <monospace>scikit-learn</monospace> functions split
  the example data into training and test data and generate a random
  forest object (regression or classifier). The examples calculate
  variance from random forest objects that use the highest mean
  probability estimate across the trees. The focus on means for
  estimates and unit comparability between sample mean and dispersion
  measures is the basis for plotting with the square root of the
  variance (standard deviation). As the plots with variance estimated
  show, some predictions have more error than others. For instance, in
  the regression (MPG) example, predictions of higher mileage MPG are
  associated with greater variance than lower mileage predictions.</p>
  <sec id="regression-example">
    <title>Regression example</title>
    <sec id="no-variance-estimated">
      <title>No variance estimated</title>
      <p>-<inline-graphic mimetype="image" mime-subtype="png" xlink:href="plot_mpg_no_variance.png" /></p>
    </sec>
    <sec id="plot-with-variance">
      <title>Plot with variance</title>
      <p>-<inline-graphic mimetype="image" mime-subtype="png" xlink:href="plot_mpg.png" /></p>
    </sec>
  </sec>
  <sec id="classification-example">
    <title>Classification example</title>
    <sec id="no-variance-estimated-1">
      <title>No variance estimated</title>
      <p>-<inline-graphic mimetype="image" mime-subtype="png" xlink:href="plot_spam_no_variance.png" /></p>
    </sec>
    <sec id="plot-with-variance-1">
      <title>Plot with variance</title>
      <p>-<inline-graphic mimetype="image" mime-subtype="png" xlink:href="plot_spam.png" /></p>
    </sec>
  </sec>
  <sec id="community-guidelines">
    <title>Community guidelines</title>
    <p>Contributions are very welcome, but we ask that contributors
    abide by the
    <ext-link ext-link-type="uri" xlink:href="http://contributor-covenant.org/version/1/4/">contributor
    covenant</ext-link>.</p>
    <p>To report issues with the software, please post to the
    <ext-link ext-link-type="uri" xlink:href="https://github.com/scikit-learn-contrib/forest-confidence-interval/issues">issue
    log</ext-link> Bug reports are also appreciated, please add them to
    the issue log after verifying that the issue does not already exist.
    Comments on existing issues are also welcome.</p>
    <p>Please submit improvements as pull requests against the repo
    after verifying that the existing tests pass and any new code is
    well covered by unit tests. Please write code that complies with the
    Python style guide,
    <ext-link ext-link-type="uri" xlink:href="https://www.python.org/dev/peps/pep-0008/">PEP8</ext-link></p>
    <p>Please e-mail
    <ext-link ext-link-type="uri" xlink:href="mailto:arokem@gmail.com">Ariel
    Rokem</ext-link>,
    <ext-link ext-link-type="uri" xlink:href="mailto:kivan.polimis@gmail.com">Kivan
    Polimis</ext-link>, or
    <ext-link ext-link-type="uri" xlink:href="mailto:brynah@phys.washington.edu">Bryna
    Hazelton</ext-link> if you have any questions, suggestions or
    feedback.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-wager_confidence_2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wager</surname><given-names>Stefan</given-names></name>
          <name><surname>Hastie</surname><given-names>Trevor</given-names></name>
          <name><surname>Efron</surname><given-names>Bradley</given-names></name>
        </person-group>
        <article-title>Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2014-01">2014</year><month>01</month>
        <volume>15</volume>
        <issue>1</issue>
        <issn>1532-4435</issn>
        <uri>http://dl.acm.org/citation.cfm?id=2627435.2638587</uri>
      </element-citation>
    </ref>
    <ref id="ref-wager_randomforestci_2016">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Wager</surname><given-names>Stefan</given-names></name>
        </person-group>
        <article-title>randomForestCI</article-title>
        <year iso-8601-date="2016-09">2016</year><month>09</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2016-09-23">2016</year><month>09</month><day>23</day></date-in-citation>
        <uri>https://github.com/swager/randomForestCI</uri>
      </element-citation>
    </ref>
    <ref id="ref-quinlan_combining_1993">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Quinlan</surname><given-names>J. Ross</given-names></name>
        </person-group>
        <article-title>Combining Instance-based and Model-based Learning</article-title>
        <source>Proceedings of the Tenth International Conference on International Conference on Machine Learning</source>
        <publisher-name>Morgan Kaufmann Publishers Inc.</publisher-name>
        <publisher-loc>San Francisco, CA, USA</publisher-loc>
        <year iso-8601-date="1993">1993</year>
        <isbn>1-55860-307-7</isbn>
        <uri>http://dl.acm.org/citation.cfm?id=3091529.3091560</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

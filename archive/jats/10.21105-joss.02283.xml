<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2283</article-id>
<article-id pub-id-type="doi">10.21105/joss.02283</article-id>
<title-group>
<article-title>datafold: data-driven models for point clouds and time
series on manifolds</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-4012-5014</contrib-id>
<string-name>Daniel Lehmberg</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-2906-1769</contrib-id>
<string-name>Felix Dietrich</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3369-6206</contrib-id>
<string-name>Gerta Köster</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Hans-Joachim Bungartz</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Munich University of Applied Sciences, Lothstr. 64, 80333
Munich, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Technical University of Munich, Boltzmannstr. 3, 85747
Garching, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-05-18">
<day>18</day>
<month>5</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>51</issue>
<fpage>2283</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>data-driven models</kwd>
<kwd>manifold learning</kwd>
<kwd>point cloud</kwd>
<kwd>time series</kwd>
<kwd>dynamic mode decomposition</kwd>
<kwd>dynamical system</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Ever increasing data availability has changed the way how data is
  analyzed and interpreted in many scientific fields. While the
  underlying complex systems remain the same, data measurements increase
  in both quantity and dimension. The main drivers are larger computer
  simulation capabilities and increasingly versatile sensors. In
  contrast to an equation-driven workflow, a scientist can use
  data-driven models to analyze a wider range of systems, including
  those with unknown or intractable equations. The models can be applied
  to a variety of data-driven scenarios, such as enriching the analysis
  of unknown systems or merely serve as an equation-free surrogate by
  providing fast, albeit approximate, responses to unseen data.</p>
  <p>However, expanding datasets create challenges throughout the
  analysis workflow from extracting and processing to interpreting the
  data. This includes the fact that new data does not always provide
  completely new and uncorrelated information to existing data. One way
  to extract the essential information is to understand and parametrize
  the intrinsic data geometry. An intrinsic geometry is what most
  data-driven models assume implicitly or explicitly in the available
  data, and successful machine learning algorithms adapt to this
  underlying structure for tasks like regression or classification
  (e.g.,
  <xref alt="Bishop, 2006" rid="ref-bishop16" ref-type="bibr">Bishop,
  2006</xref>). This geometry is often of much lower dimension than the
  ambient data space, and finding a suitable set of coordinates can
  reduce the complexity of the dataset. We refer to this geometric
  structure encoded in the data as a “manifold”. In mathematical terms,
  a manifold is a topological space that is locally homeomorphic to
  Euclidean space. Typically, manifold learning attempts to construct a
  global parametrization (embedding) of this manifold, in a space of
  much lower dimension than the original ambient space. The well-known
  manifold hypothesis states that such manifolds underlie many
  observations and processes, including time-dependent systems.</p>
  <p><italic>datafold</italic> is a Python package that provides
  <bold>data</bold>-driven models for point clouds to find an
  <italic>explicit</italic> mani-<bold>fold</bold> parametrization and
  to identify non-linear dynamical systems on these manifolds. The
  explicit data manifold treatment allows prior knowledge of a system
  and its problem-specific domain to be included. This can be the
  proximity between points in the dataset
  (<xref alt="Coifman &amp; Lafon, 2006a" rid="ref-coifman8" ref-type="bibr">Coifman
  &amp; Lafon, 2006a</xref>) or functions defined on the phase space
  manifold of a dynamical system, such as (partially) known governing
  equation terms
  (<xref alt="Brunton et al., 2016" rid="ref-brunton18" ref-type="bibr">Brunton
  et al., 2016</xref>;
  <xref alt="Williams et al., 2015" rid="ref-williams4" ref-type="bibr">Williams
  et al., 2015</xref>).</p>
  <p><italic>datafold</italic> is open-source software with a design
  that reflects a workflow hierarchy: from low-level data structures and
  algorithms to high-level meta-models intended to solve complex machine
  learning tasks. The key benefit of <italic>datafold</italic> is that
  it accommodates and integrates models on the different workflow
  levels. Each model has been investigated and tested individually and
  found to be useful by the scientific community. In
  <italic>datafold</italic> these models can be used in a single
  processing pipeline. Our integrated workflow facilitates the
  application of data-driven analysis and thus has the potential to
  boost widespread utilization. The implemented models are integrated
  into a software architecture with a clear modularization and an API
  that is templated from the <monospace>scikit-learn</monospace>
  project, which can be used as part of its processing pipeline
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa17" ref-type="bibr">Pedregosa
  et al., 2011</xref>). The data structures are subclasses from common
  objects of the Python scientific computing stack, allowing models to
  generalize for both static point clouds and temporally ordered time
  series collection data. The software design and modularity in
  <italic>datafold</italic> reflects two requirements: high flexibility
  to test model configurations, and openness to new model
  implementations with clear and well-defined scope. We want to support
  active research in data-driven analysis with manifold context and thus
  target students, researchers and experienced practitioners from
  different fields of dataset analysis.</p>
  <fig>
    <caption><p>(Left) Point cloud of embedded handwritten digits
    between 0 and 5 with the “Diffusion Map” model. Each point
    originally has 64 dimensions where each dimension represents a pixel
    of an 8 x 8 image. (Right) Conceptual illustration of a
    three-dimensional time series forming a phase space with geometrical
    structure. The time series start on the <monospace>(x,y)</monospace>
    plane and end on the <monospace>z</monospace>-axis.
    <styled-content id="figU003Amanifold"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="manifold_figure.png" xlink:title="" />
  </fig>
  <sec id="point-cloud-data">
    <title>1. Point cloud data</title>
    <p>High-dimensional and unordered point clouds are often directly
    connected to the “manifold assumption”, i.e. that the data lies
    close to a lower-dimensional manifold. Our software aims to find a
    low-dimensional parametrization (embedding) of this manifold. In a
    machine learning context, this is also referred to as “non-linear
    unsupervised learning” or shorter “manifold learning”. Often the
    models are endowed with a kernel which encodes the proximity between
    data to preserve local structures. Examples are the general “Kernel
    Principal Component Analysis”
    (<xref alt="Bengio et al., 2004" rid="ref-bengio9" ref-type="bibr">Bengio
    et al., 2004</xref>), “Local Linear Embedding”
    (<xref alt="Belkin &amp; Niyogi, 2003" rid="ref-belkin14" ref-type="bibr">Belkin
    &amp; Niyogi, 2003</xref>), or “Hessian Eigenmaps”
    (<xref alt="Donoho &amp; Grimes, 2003" rid="ref-donoho15" ref-type="bibr">Donoho
    &amp; Grimes, 2003</xref>). A variety of manifold learning models
    already exist in the <monospace>scikit-learn</monospace> Python
    package. In addition to these, <italic>datafold</italic> provides an
    efficient implementation of the “Diffusion Maps” model
    (<xref alt="Coifman &amp; Lafon, 2006a" rid="ref-coifman8" ref-type="bibr">Coifman
    &amp; Lafon, 2006a</xref>). The model includes an optional sparse
    kernel matrix representation with which the model can scale to
    larger datasets. In addition to non-linear dimension reduction,
    “Diffusion Maps” allow the user to approximate mathematically
    meaningful objects on manifold data, such as the Laplace-Beltrami
    operator
    (<xref alt="Coifman &amp; Lafon, 2006a" rid="ref-coifman8" ref-type="bibr">Coifman
    &amp; Lafon, 2006a</xref>). <italic>datafold</italic> also supplies
    functionality for follow-up aspects of non-linear manifold learning,
    such as estimating the kernel scale parameters to describe the
    locality of points in a dataset and extending the embedding to
    unseen data. The latter refers to the image and pre-image mapping
    between the original and latent space (e.g., see analysis in
    <xref alt="Chiavazzo et al., 2014" rid="ref-chiavazzo19" ref-type="bibr">Chiavazzo
    et al., 2014</xref>). This so-called “out-of-sample” extension
    interpolates general function values on manifold point clouds and,
    therefore, has to handle large input data dimensions
    (<xref alt="Coifman &amp; Lafon, 2006b" rid="ref-coifman7" ref-type="bibr">Coifman
    &amp; Lafon, 2006b</xref>;
    <xref alt="Fernández et al., 2020" rid="ref-fernandez10" ref-type="bibr">Fernández
    et al., 2020</xref>;
    <xref alt="Rabin &amp; Coifman, 2012" rid="ref-rabin6" ref-type="bibr">Rabin
    &amp; Coifman, 2012</xref>). In <italic>datafold</italic>,
    out-of-sample extensions are implemented efficiently, so that
    interpolated function values for millions of points can be computed
    in seconds on a standard desktop computer.</p>
  </sec>
  <sec id="time-series-data">
    <title>2. Time series data</title>
    <p>A special kind of point cloud type targeted by
    <italic>datafold</italic> are time series and collections thereof.
    In this case, a data-driven model can fit and generalize the
    underlying dynamics to perform prediction or regression. Usually,
    the phase space of the dynamical system, underlying the time series
    observations, is assumed to be a manifold (see a conceptual
    illustration in
    <xref alt="Figure 1" rid="figU003Amanifold">Figure 1</xref>).
    <italic>datafold</italic> focuses on the algorithms “Dynamic Mode
    Decomposition” (DMD)
    (<xref alt="Kutz et al., 2016" rid="ref-kutz12" ref-type="bibr">Kutz
    et al., 2016</xref>;
    <xref alt="Schmid, 2010" rid="ref-schmid13" ref-type="bibr">Schmid,
    2010</xref>;
    <xref alt="Tu et al., 2014" rid="ref-tu3" ref-type="bibr">Tu et al.,
    2014</xref>) and “Extended Dynamic Mode Decomposition” (E-DMD,
    <xref alt="Williams et al., 2015" rid="ref-williams4" ref-type="bibr">Williams
    et al., 2015</xref>). DMD linearly decomposes the available time
    series data into spatio-temporal components, which then define a
    linear dynamical system. Many DMD based variants address even more
    general, non-linear underlying dynamical systems. This is usually
    done by changing the time series coordinates in a step before DMD is
    applied
    (<xref alt="Champion et al., 2019" rid="ref-champion2" ref-type="bibr">Champion
    et al., 2019</xref>;
    <xref alt="Giannakis, 2019" rid="ref-giannakis1" ref-type="bibr">Giannakis,
    2019</xref>;
    <xref alt="Le Clainche et al., 2017" rid="ref-le0" ref-type="bibr">Le
    Clainche et al., 2017</xref>;
    <xref alt="Williams et al., 2015" rid="ref-williams4" ref-type="bibr">Williams
    et al., 2015</xref>). The justification of this workflow is covered
    by operator theory and functional analysis, specifically the Koopman
    operator. In practice, the E-DMD algorithm approximates the Koopman
    operator with a matrix, based on a finite set of functions evaluated
    on the available data, the so-called “dictionary”. Finding a good
    choice for the dictionary is comparable to the machine learning task
    of “model selection” and requires great flexibility in setting up
    the data processing pipeline. The flexibility of setting an
    arbitrary dictionary combined with a selection of the provided DMD
    variants is a core feature of <italic>datafold’s</italic>
    implementation of E-DMD.</p>
  </sec>
  <sec id="comparison-to-other-software-projects">
    <title>Comparison to other software projects</title>
    <p>The Python package <italic>statsmodels</italic>
    (<xref alt="Seabold &amp; Perktold, 2010" rid="ref-seabold22" ref-type="bibr">Seabold
    &amp; Perktold, 2010</xref>) includes statistical models for time
    series analysis, such as the <italic>AutoRegressive Integrated
    Moving Average</italic> (ARIMA) and variations thereof. These models
    usually assume an underlying stochastical process and aim to
    approximate autocorrelations in time series data. Another type of
    popular data-driven models are deep neural networks; widely adopted
    packages are the frameworks <italic>tensorflow</italic>
    (<xref alt="Martı́n Abadi et al., 2016" rid="ref-abadi26" ref-type="bibr">Martı́n
    Abadi et al., 2016</xref>;
    <xref alt="Martın Abadi et al., 2015" rid="ref-abadi24" ref-type="bibr">Martın
    Abadi et al., 2015</xref>) and <italic>PyTorch</italic>
    (<xref alt="Paszke et al., 2019" rid="ref-paszke21" ref-type="bibr">Paszke
    et al., 2019</xref>). Deep learning models generalize well in
    several problem domains, but common drawbacks are a
    non-deterministic construction process, the requirement of large
    datasets, and only limited options to include prior knowledge about
    the underlying system. For manifold learning, one can use
    (variational) autoencoders, while recurrent architectures (e.g.,
    LSTM networks
    <xref alt="Hochreiter &amp; Schmidhuber, 1997" rid="ref-hochreiter25" ref-type="bibr">Hochreiter
    &amp; Schmidhuber, 1997</xref>) are often used for system
    identification. Other packages in <italic>datafold</italic>’s scope
    are the Python packages <italic>PyDMD</italic>
    (<xref alt="Demo et al., 2018" rid="ref-demo23" ref-type="bibr">Demo
    et al., 2018</xref>) and <italic>PySINDy</italic>
    (<xref alt="Silva et al., 2020" rid="ref-desilva20" ref-type="bibr">Silva
    et al., 2020</xref>). The <italic>PyDMD</italic> project includes
    numerous variations of DMD, such as the “Higher Order DMD”
    (<xref alt="Le Clainche et al., 2017" rid="ref-le0" ref-type="bibr">Le
    Clainche et al., 2017</xref>). The <italic>PySINDy</italic> software
    focuses on “Sparse Identification of Non-linear Dynamics” (SINDy)
    (<xref alt="Brunton et al., 2016" rid="ref-brunton18" ref-type="bibr">Brunton
    et al., 2016</xref>). <italic>datafold</italic>’s EDMD
    implementation allows an arbitrary DMD variant to be used in a
    processing pipeline to regress the dynamics, which means the models
    from both <italic>PyDMD</italic> and <italic>PySINDy</italic> could
    be used in combination with <italic>datafold</italic>.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>DL is supported by the German Research Foundation (DFG), grant no.
  KO 5257/3-1 and thanks the research office (FORWIN) of Munich
  University of Applied Sciences and CeDoSIA of TUM Graduate School at
  the Technical University of Munich for their support. DL and FD thank
  Yannis Kevrekidis from the Johns Hopkins University, Baltimore, USA,
  for his support during a research stay of DL in 2018, which paved the
  way for the <italic>datafold</italic> software project.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-le0">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Le Clainche</surname><given-names>Soledad</given-names></name>
          <name><surname>Vega</surname><given-names>José M.</given-names></name>
          <name><surname>Soria</surname><given-names>Julio</given-names></name>
        </person-group>
        <article-title>Higher order dynamic mode decomposition of noisy experimental data: The flow structure of a zero-net-mass-flux jet</article-title>
        <source>Experimental Thermal and Fluid Science</source>
        <year iso-8601-date="2017-11">2017</year><month>11</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-03-06">2019</year><month>03</month><day>06</day></date-in-citation>
        <volume>88</volume>
        <issn>08941777</issn>
        <uri>https://linkinghub.elsevier.com/retrieve/pii/S089417771730184X</uri>
        <pub-id pub-id-type="doi">10.1016/j.expthermflusci.2017.06.011</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-giannakis1">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Giannakis</surname><given-names>Dimitrios</given-names></name>
        </person-group>
        <article-title>Data-driven spectral decomposition and forecasting of ergodic dynamical systems</article-title>
        <source>Applied and Computational Harmonic Analysis</source>
        <year iso-8601-date="2019-09">2019</year><month>09</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-14">2019</year><month>12</month><day>14</day></date-in-citation>
        <volume>47</volume>
        <issue>2</issue>
        <issn>10635203</issn>
        <uri>https://linkinghub.elsevier.com/retrieve/pii/S1063520317300982</uri>
        <pub-id pub-id-type="doi">10.1016/j.acha.2017.09.001</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-champion2">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Champion</surname><given-names>Kathleen P.</given-names></name>
          <name><surname>Brunton</surname><given-names>Steven L.</given-names></name>
          <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
        </person-group>
        <article-title>Discovery of Nonlinear Multiscale Systems: Sampling Strategies and Embeddings</article-title>
        <source>SIAM Journal on Applied Dynamical Systems</source>
        <year iso-8601-date="2019-01">2019</year><month>01</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-03-06">2019</year><month>03</month><day>06</day></date-in-citation>
        <volume>18</volume>
        <issue>1</issue>
        <issn>1536-0040</issn>
        <uri>https://epubs.siam.org/doi/10.1137/18M1188227</uri>
        <pub-id pub-id-type="doi">10.1137/18M1188227</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-tu3">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Tu</surname><given-names>Jonathan H.</given-names></name>
          <name><surname>Rowley</surname><given-names>Clarence W.</given-names></name>
          <name><surname>Luchtenburg</surname><given-names>Dirk M.</given-names></name>
          <name><surname>Brunton</surname><given-names>Steven L.</given-names></name>
          <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
        </person-group>
        <article-title>On Dynamic Mode Decomposition: Theory and Applications</article-title>
        <source>Journal of Computational Dynamics</source>
        <year iso-8601-date="2014-12">2014</year><month>12</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-03-06">2019</year><month>03</month><day>06</day></date-in-citation>
        <volume>1</volume>
        <issue>2</issue>
        <issn>2158-2491</issn>
        <uri>http://arxiv.org/abs/1312.0041</uri>
        <pub-id pub-id-type="doi">10.3934/jcd.2014.1.391</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-williams4">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Williams</surname><given-names>Matthew O.</given-names></name>
          <name><surname>Kevrekidis</surname><given-names>Ioannis G.</given-names></name>
          <name><surname>Rowley</surname><given-names>Clarence W.</given-names></name>
        </person-group>
        <article-title>A DataDriven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition</article-title>
        <source>Journal of Nonlinear Science</source>
        <year iso-8601-date="2015-12">2015</year><month>12</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-03-13">2019</year><month>03</month><day>13</day></date-in-citation>
        <volume>25</volume>
        <issue>6</issue>
        <issn>0938-8974, 1432-1467</issn>
        <uri>http://link.springer.com/10.1007/s00332-015-9258-5</uri>
        <pub-id pub-id-type="doi">10.1007/s00332-015-9258-5</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-rabin6">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Rabin</surname><given-names>Neta</given-names></name>
          <name><surname>Coifman</surname><given-names>Ronald R.</given-names></name>
        </person-group>
        <article-title>Heterogeneous datasets representation and learning using diffusion maps and Laplacian pyramids</article-title>
        <source>Proceedings of the 2012 SIAM International Conference on Data Mining</source>
        <publisher-name>Society for Industrial; Applied Mathematics</publisher-name>
        <year iso-8601-date="2012-04">2012</year><month>04</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-14">2019</year><month>12</month><day>14</day></date-in-citation>
        <isbn>978-1-61197-232-0 978-1-61197-282-5</isbn>
        <uri>https://epubs.siam.org/doi/10.1137/1.9781611972825.17</uri>
        <pub-id pub-id-type="doi">10.1137/1.9781611972825.17</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-coifman7">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Coifman</surname><given-names>Ronald R.</given-names></name>
          <name><surname>Lafon</surname><given-names>Stéphane</given-names></name>
        </person-group>
        <article-title>Geometric harmonics: A novel tool for multiscale out-of-sample extension of empirical functions</article-title>
        <source>Applied and Computational Harmonic Analysis</source>
        <year iso-8601-date="2006-07">2006</year><month>07</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-15">2019</year><month>12</month><day>15</day></date-in-citation>
        <volume>21</volume>
        <issue>1</issue>
        <issn>10635203</issn>
        <uri>https://linkinghub.elsevier.com/retrieve/pii/S1063520306000522</uri>
        <pub-id pub-id-type="doi">10.1016/j.acha.2005.07.005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-coifman8">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Coifman</surname><given-names>Ronald R.</given-names></name>
          <name><surname>Lafon</surname><given-names>Stéphane</given-names></name>
        </person-group>
        <article-title>Diffusion maps</article-title>
        <source>Applied and Computational Harmonic Analysis</source>
        <year iso-8601-date="2006-07">2006</year><month>07</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-15">2019</year><month>12</month><day>15</day></date-in-citation>
        <volume>21</volume>
        <issue>1</issue>
        <issn>10635203</issn>
        <uri>https://linkinghub.elsevier.com/retrieve/pii/S1063520306000546</uri>
        <pub-id pub-id-type="doi">10.1016/j.acha.2006.04.006</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bengio9">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>
          <name><surname>Delalleau</surname><given-names>Olivier</given-names></name>
          <name><surname>Roux</surname><given-names>Nicolas Le</given-names></name>
          <name><surname>Paiement</surname><given-names>Jean-François</given-names></name>
          <name><surname>Vincent</surname><given-names>Pascal</given-names></name>
          <name><surname>Ouimet</surname><given-names>Marie</given-names></name>
        </person-group>
        <article-title>Learning Eigenfunctions Links Spectral Embedding and Kernel PCA</article-title>
        <source>Neural Computation</source>
        <year iso-8601-date="2004-10">2004</year><month>10</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-15">2019</year><month>12</month><day>15</day></date-in-citation>
        <volume>16</volume>
        <issue>10</issue>
        <issn>0899-7667, 1530-888X</issn>
        <uri>http://www.mitpressjournals.org/doi/10.1162/0899766041732396</uri>
        <pub-id pub-id-type="doi">10.1162/0899766041732396</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-fernandez10">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fernández</surname><given-names>Ángela</given-names></name>
          <name><surname>Rabin</surname><given-names>Neta</given-names></name>
          <name><surname>Fishelov</surname><given-names>Dalia</given-names></name>
          <name><surname>Dorronsoro</surname><given-names>José R.</given-names></name>
        </person-group>
        <article-title>Auto-adaptive multi-scale Laplacian Pyramids for modeling non-uniform data</article-title>
        <source>Engineering Applications of Artificial Intelligence</source>
        <year iso-8601-date="2020-08">2020</year><month>08</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-07-13">2020</year><month>07</month><day>13</day></date-in-citation>
        <volume>93</volume>
        <issn>09521976</issn>
        <uri>https://linkinghub.elsevier.com/retrieve/pii/S0952197620301202</uri>
        <pub-id pub-id-type="doi">10.1016/j.engappai.2020.103682</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kutz12">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
          <name><surname>Brunton</surname><given-names>Steven L.</given-names></name>
          <name><surname>Brunton</surname><given-names>Bingni W.</given-names></name>
          <name><surname>Proctor</surname><given-names>Joshua L.</given-names></name>
        </person-group>
        <source>Dynamic mode decomposition. Data-Driven modelling of complex systems</source>
        <publisher-name>Society for Industrial; Applied Mathematics</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <isbn>978-1-61197-450-8</isbn>
      </element-citation>
    </ref>
    <ref id="ref-schmid13">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Schmid</surname><given-names>Peter J.</given-names></name>
        </person-group>
        <article-title>Dynamic mode decomposition of numerical and experimental data</article-title>
        <source>Journal of Fluid Mechanics</source>
        <year iso-8601-date="2010-08">2010</year><month>08</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-04-09">2020</year><month>04</month><day>09</day></date-in-citation>
        <volume>656</volume>
        <issn>0022-1120, 1469-7645</issn>
        <uri>https://www.cambridge.org/core/product/identifier/S0022112010001217/type/journal_article</uri>
        <pub-id pub-id-type="doi">10.1017/S0022112010001217</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-belkin14">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Belkin</surname><given-names>Mikhail</given-names></name>
          <name><surname>Niyogi</surname><given-names>Partha</given-names></name>
        </person-group>
        <article-title>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation</article-title>
        <source>Neural Computation</source>
        <year iso-8601-date="2003-06">2003</year><month>06</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-04-29">2020</year><month>04</month><day>29</day></date-in-citation>
        <volume>15</volume>
        <issue>6</issue>
        <issn>0899-7667, 1530-888X</issn>
        <uri>http://www.mitpressjournals.org/doi/10.1162/089976603321780317</uri>
        <pub-id pub-id-type="doi">10.1162/089976603321780317</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-donoho15">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Donoho</surname><given-names>D. L.</given-names></name>
          <name><surname>Grimes</surname><given-names>C.</given-names></name>
        </person-group>
        <article-title>Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year iso-8601-date="2003-05">2003</year><month>05</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-04-29">2020</year><month>04</month><day>29</day></date-in-citation>
        <volume>100</volume>
        <issue>10</issue>
        <issn>0027-8424, 1091-6490</issn>
        <uri>http://www.pnas.org/cgi/doi/10.1073/pnas.1031596100</uri>
        <pub-id pub-id-type="doi">10.1073/pnas.1031596100</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bishop16">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Bishop</surname><given-names>Christopher M.</given-names></name>
        </person-group>
        <source>Pattern recognition and machine learning</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <year iso-8601-date="2006">2006</year>
        <isbn>978-0-387-31073-2</isbn>
      </element-citation>
    </ref>
    <ref id="ref-pedregosa17">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Gael</given-names></name>
          <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
          <name><surname>Michel</surname><given-names>Vincent</given-names></name>
          <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
          <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
          <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
          <name><surname>Weiss</surname><given-names>Ron</given-names></name>
          <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
          <name><surname>Vanderplas</surname><given-names>Jake</given-names></name>
          <name><surname>Passos</surname><given-names>Alexandre</given-names></name>
          <name><surname>Cournapeau</surname><given-names>David</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine Learning in Python</article-title>
        <source>Machine Learning in Python</source>
        <year iso-8601-date="2011">2011</year>
      </element-citation>
    </ref>
    <ref id="ref-brunton18">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Brunton</surname><given-names>Steven L.</given-names></name>
          <name><surname>Proctor</surname><given-names>Joshua L.</given-names></name>
          <name><surname>Kutz</surname><given-names>J. Nathan</given-names></name>
        </person-group>
        <article-title>Discovering governing equations from data by sparse identification of nonlinear dynamical systems</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year iso-8601-date="2016-04">2016</year><month>04</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-04-29">2020</year><month>04</month><day>29</day></date-in-citation>
        <volume>113</volume>
        <issue>15</issue>
        <issn>0027-8424, 1091-6490</issn>
        <uri>http://www.pnas.org/lookup/doi/10.1073/pnas.1517384113</uri>
        <pub-id pub-id-type="doi">10.1073/pnas.1517384113</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chiavazzo19">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chiavazzo</surname><given-names>Eliodoro</given-names></name>
          <name><surname>Gear</surname><given-names>Charles</given-names></name>
          <name><surname>Dsilva</surname><given-names>Carmeline</given-names></name>
          <name><surname>Rabin</surname><given-names>Neta</given-names></name>
          <name><surname>Kevrekidis</surname><given-names>Ioannis</given-names></name>
        </person-group>
        <article-title>Reduced Models in Chemical Kinetics via Nonlinear Data-Mining</article-title>
        <source>Processes</source>
        <year iso-8601-date="2014-01">2014</year><month>01</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2019-12-14">2019</year><month>12</month><day>14</day></date-in-citation>
        <volume>2</volume>
        <issue>1</issue>
        <issn>2227-9717</issn>
        <uri>http://www.mdpi.com/2227-9717/2/1/112</uri>
        <pub-id pub-id-type="doi">10.3390/pr2010112</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-desilva20">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Silva</surname><given-names>Brian de</given-names></name>
          <name><surname>Champion</surname><given-names>Kathleen</given-names></name>
          <name><surname>Quade</surname><given-names>Markus</given-names></name>
          <name><surname>Loiseau</surname><given-names>Jean-Christophe</given-names></name>
          <name><surname>Kutz</surname><given-names>J.</given-names></name>
          <name><surname>Brunton</surname><given-names>Steven</given-names></name>
        </person-group>
        <article-title>PySINDy: A Python package for the sparse identification of nonlinear dynamical systems from data</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2020-05">2020</year><month>05</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-06-15">2020</year><month>06</month><day>15</day></date-in-citation>
        <volume>5</volume>
        <issue>49</issue>
        <issn>2475-9066</issn>
        <uri>https://joss.theoj.org/papers/10.21105/joss.02104</uri>
        <pub-id pub-id-type="doi">10.21105/joss.02104</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-paszke21">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Paszke</surname><given-names>Adam</given-names></name>
          <name><surname>Gross</surname><given-names>Sam</given-names></name>
          <name><surname>Massa</surname><given-names>Francisco</given-names></name>
          <name><surname>Lerer</surname><given-names>Adam</given-names></name>
          <name><surname>Bradbury</surname><given-names>James</given-names></name>
          <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
          <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
          <name><surname>Lin</surname><given-names>Zeming</given-names></name>
          <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
          <name><surname>Antiga</surname><given-names>Luca</given-names></name>
          <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
          <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
          <name><surname>Yang</surname><given-names>Edward</given-names></name>
          <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
          <name><surname>Raison</surname><given-names>Martin</given-names></name>
          <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
          <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Fang</surname><given-names>Lu</given-names></name>
          <name><surname>Bai</surname><given-names>Junjie</given-names></name>
          <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
        </person-group>
        <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
        <source>Advances in neural information processing systems 32</source>
        <person-group person-group-type="editor">
          <name><surname>Wallach</surname><given-names>H.</given-names></name>
          <name><surname>Larochelle</surname><given-names>H.</given-names></name>
          <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
          <name><surname>dAlché-Buc</surname><given-names>F.</given-names></name>
          <name><surname>Fox</surname><given-names>E.</given-names></name>
          <name><surname>Garnett</surname><given-names>R.</given-names></name>
        </person-group>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <uri>http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-seabold22">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Seabold</surname><given-names>Skipper</given-names></name>
          <name><surname>Perktold</surname><given-names>Josef</given-names></name>
        </person-group>
        <article-title>Statsmodels: Econometric and Statistical Modeling with Python</article-title>
        <publisher-loc>Austin, Texas</publisher-loc>
        <year iso-8601-date="2010">2010</year>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-06-15">2020</year><month>06</month><day>15</day></date-in-citation>
        <uri>https://conference.scipy.org/proceedings/scipy2010/seabold.html</uri>
        <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-011</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-demo23">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Demo</surname><given-names>Nicola</given-names></name>
          <name><surname>Tezzele</surname><given-names>Marco</given-names></name>
          <name><surname>Rozza</surname><given-names>Gianluigi</given-names></name>
        </person-group>
        <article-title>PyDMD: Python Dynamic Mode Decomposition</article-title>
        <source>The Journal of Open Source Software</source>
        <year iso-8601-date="2018-02">2018</year><month>02</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-06-15">2020</year><month>06</month><day>15</day></date-in-citation>
        <volume>3</volume>
        <issue>22</issue>
        <issn>2475-9066</issn>
        <uri>http://joss.theoj.org/papers/10.21105/joss.00530</uri>
        <pub-id pub-id-type="doi">10.21105/joss.00530</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-abadi24">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Abadi</surname><given-names>Martın</given-names></name>
          <name><surname>Agarwal</surname><given-names>Ashish</given-names></name>
          <name><surname>Barham</surname><given-names>Paul</given-names></name>
          <name><surname>Brevdo</surname><given-names>Eugene</given-names></name>
          <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>
          <name><surname>Citro</surname><given-names>Craig</given-names></name>
          <name><surname>Corrado</surname><given-names>Greg S</given-names></name>
          <name><surname>Davis</surname><given-names>Andy</given-names></name>
          <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
          <name><surname>Devin</surname><given-names>Matthieu</given-names></name>
          <name><surname>Ghemawat</surname><given-names>Sanjay</given-names></name>
          <name><surname>Goodfellow</surname><given-names>Ian</given-names></name>
          <name><surname>Harp</surname><given-names>Andrew</given-names></name>
          <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
          <name><surname>Isard</surname><given-names>Michael</given-names></name>
          <name><surname>Jia</surname><given-names>Yangqing</given-names></name>
          <name><surname>Jozefowicz</surname><given-names>Rafal</given-names></name>
          <name><surname>Kaiser</surname><given-names>Lukasz</given-names></name>
          <name><surname>Kudlur</surname><given-names>Manjunath</given-names></name>
          <name><surname>Levenberg</surname><given-names>Josh</given-names></name>
          <name><surname>Mane</surname><given-names>Dan</given-names></name>
          <name><surname>Monga</surname><given-names>Rajat</given-names></name>
          <name><surname>Moore</surname><given-names>Sherry</given-names></name>
          <name><surname>Murray</surname><given-names>Derek</given-names></name>
          <name><surname>Olah</surname><given-names>Chris</given-names></name>
          <name><surname>Schuster</surname><given-names>Mike</given-names></name>
          <name><surname>Shlens</surname><given-names>Jonathon</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>
          <name><surname>Talwar</surname><given-names>Kunal</given-names></name>
          <name><surname>Tucker</surname><given-names>Paul</given-names></name>
          <name><surname>Vanhoucke</surname><given-names>Vincent</given-names></name>
          <name><surname>Vasudevan</surname><given-names>Vijay</given-names></name>
          <name><surname>Viegas</surname><given-names>Fernanda</given-names></name>
          <name><surname>Vinyals</surname><given-names>Oriol</given-names></name>
          <name><surname>Warden</surname><given-names>Pete</given-names></name>
          <name><surname>Wattenberg</surname><given-names>Martin</given-names></name>
          <name><surname>Wicke</surname><given-names>Martin</given-names></name>
          <name><surname>Yu</surname><given-names>Yuan</given-names></name>
          <name><surname>Zheng</surname><given-names>Xiaoqiang</given-names></name>
        </person-group>
        <article-title>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</article-title>
        <year iso-8601-date="2015">2015</year>
        <uri>https://www.tensorflow.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-abadi26">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Abadi</surname><given-names>Martı́n</given-names></name>
          <name><surname>Barham</surname><given-names>Paul</given-names></name>
          <name><surname>Chen</surname><given-names>Jianmin</given-names></name>
          <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>
          <name><surname>Davis</surname><given-names>Andy</given-names></name>
          <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
          <name><surname>Devin</surname><given-names>Matthieu</given-names></name>
          <name><surname>Ghemawat</surname><given-names>Sanjay</given-names></name>
          <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
          <name><surname>Isard</surname><given-names>Michael</given-names></name>
          <name><surname>Kudlur</surname><given-names>Manjunath</given-names></name>
          <name><surname>Levenberg</surname><given-names>Josh</given-names></name>
          <name><surname>Monga</surname><given-names>Rajat</given-names></name>
          <name><surname>Moore</surname><given-names>Sherry</given-names></name>
          <name><surname>Murray</surname><given-names>Derek G.</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Tucker</surname><given-names>Paul</given-names></name>
          <name><surname>Vasudevan</surname><given-names>Vijay</given-names></name>
          <name><surname>Warden</surname><given-names>Pete</given-names></name>
          <name><surname>Wicke</surname><given-names>Martin</given-names></name>
          <name><surname>Yu</surname><given-names>Yuan</given-names></name>
          <name><surname>Zheng</surname><given-names>Xiaoqiang</given-names></name>
        </person-group>
        <article-title>TensorFlow: A System for Large-Scale Machine Learning</article-title>
        <source>Proceedings of the 12th USENIX conference on operating systems design and implementation</source>
        <publisher-name>USENIX Association</publisher-name>
        <publisher-loc>USA</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <isbn>9781931971331</isbn>
      </element-citation>
    </ref>
    <ref id="ref-hochreiter25">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hochreiter</surname><given-names>Sepp</given-names></name>
          <name><surname>Schmidhuber</surname><given-names>Jürgen</given-names></name>
        </person-group>
        <article-title>Long Short-Term Memory</article-title>
        <source>Neural Computation</source>
        <year iso-8601-date="1997-11">1997</year><month>11</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2020-06-17">2020</year><month>06</month><day>17</day></date-in-citation>
        <volume>9</volume>
        <issue>8</issue>
        <issn>0899-7667, 1530-888X</issn>
        <uri>http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735</uri>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3453</article-id>
<article-id pub-id-type="doi">10.21105/joss.03453</article-id>
<title-group>
<article-title>mcboost: Multi-Calibration Boosting for R</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8867-762X</contrib-id>
<string-name>Florian Pfisterer</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-7363-4299</contrib-id>
<string-name>Christoph Kern</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-4324-4163</contrib-id>
<string-name>Susanne Dandl</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Matthew Sun</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<string-name>Michael P. Kim</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6002-6980</contrib-id>
<string-name>Bernd Bischl</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Ludwig Maximilian University of Munich</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>University of Mannheim</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Princeton University</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>UC Berkeley</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-06-01">
<day>1</day>
<month>6</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>64</issue>
<fpage>3453</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Multi-Calibration</kwd>
<kwd>Multi-Accuracy</kwd>
<kwd>Boosting</kwd>
<kwd>Post-Processing</kwd>
<kwd>Fair ML</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Given the increasing usage of automated prediction systems in the
  context of high-stakes decisions, a growing body of research focuses
  on methods for detecting and mitigating biases in algorithmic
  decision-making. One important framework to audit for and mitigate
  biases in predictions is that of Multi-Calibration, introduced by
  Hebert-Johnson et al.
  (<xref alt="2018" rid="ref-hebert-johnson2018" ref-type="bibr">2018</xref>).
  The underlying fairness notion, Multi-Calibration, promotes the idea
  of multi-group fairness and requires calibrated predictions not only
  for marginal populations, but also for subpopulations that may be
  defined by complex intersections of many attributes. A simpler variant
  of Multi-Calibration, referred to as Multi-Accuracy, requires unbiased
  predictions for large collections of subpopulations. Hebert-Johnson et
  al.
  (<xref alt="2018" rid="ref-hebert-johnson2018" ref-type="bibr">2018</xref>)
  proposed a boosting-style algorithm for learning multi-calibrated
  predictors. Kim et al.
  (<xref alt="2019" rid="ref-kim2019" ref-type="bibr">2019</xref>)
  demonstrated how to turn this algorithm into a post-processing
  strategy to achieve multi-accuracy, demonstrating empirical
  effectiveness across various domains. This package provides a stable
  implementation of the multi-calibration algorithm, called MCBoost. In
  contrast to other Fair ML approaches, MCBoost does not harm the
  overall utility of a prediction model, but rather aims at improving
  calibration and accuracy for large sets of subpopulations
  post-training. MCBoost comes with strong theoretical guarantees, which
  have been explored formally in Hebert-Johnson et al.
  (<xref alt="2018" rid="ref-hebert-johnson2018" ref-type="bibr">2018</xref>),
  Kim et al.
  (<xref alt="2019" rid="ref-kim2019" ref-type="bibr">2019</xref>),
  Dwork et al.
  (<xref alt="2019" rid="ref-dwork-rankings" ref-type="bibr">2019</xref>),
  Dwork et al.
  (<xref alt="2020" rid="ref-dwork-oi" ref-type="bibr">2020</xref>) and
  Kim et al.
  (<xref alt="2021" rid="ref-kimkern2021" ref-type="bibr">2021</xref>).</p>
  <p><monospace>mcboost</monospace> implements Multi-Calibration
  Boosting for R. <monospace>mcboost</monospace> is model agnostic and
  allows the user to post-process any supervised machine learning model.
  It accepts initial models that fit binary outcomes or continuous
  outcomes with predictions that are in (or scaled to) the range [0, 1].
  For convenience and ease of use, <monospace>mcboost</monospace>
  tightly integrates with the <bold>mlr3</bold>
  (<xref alt="Lang et al., 2019" rid="ref-mlr3" ref-type="bibr">Lang et
  al., 2019</xref>) machine learning eco-system in R by allowing to
  calibrate regression or classification models fitted either within or
  outside of mlr3. Post-processing with <monospace>mcboost</monospace>
  starts with an initial prediction model that is passed on to an
  auditing algorithm that runs Multi-Calibration-Boosting on a labeled
  auditing dataset (Fig. 1). The resulting model can be used for
  obtaining multi-calibrated predictions. <monospace>mcboost</monospace>
  includes two pre-defined learners for auditing (ridge regression and
  decision trees), and allows to easily adjust the learner and its
  parameters for Multi-Calibration Boosting. Users may also specify a
  fixed set of subgroups, instead of a learner, on which predictions
  should be audited. Furthermore, <monospace>mcboost</monospace>
  includes utilities to guard against overfitting to the auditing
  dataset during post-processing.</p>
  <fig>
    <caption><p>Fig 1. Conceptual illustration of Multi-Calibration
    Boosting with
    <monospace>mcboost</monospace>.<styled-content id="figU003Aoverview"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="MCBoost.png" xlink:title="" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Given the ubiquitous use of machine learning models in crucial
  areas and growing concerns of biased predictions for minority
  subpopulations, Multi-Calibration Boosting should be widely accessible
  in the form of a free and open-source software package. Prior to the
  development of <monospace>mcboost</monospace>, Multi-Calibration
  Boosting has not been released as a software package for R.</p>
  <p>The results in Kim et al.
  (<xref alt="2019" rid="ref-kim2019" ref-type="bibr">2019</xref>)
  highlight that MCBoost can improve classification accuracy for
  subpopulations in various settings, including gender detection with
  image data, income classification with survey data and disease
  prediction using biomedical data. Barda, Yona, et al.
  (<xref alt="2020" rid="ref-Barda2020bias" ref-type="bibr">2020</xref>)
  show that post-processing for Multi-Calibration can greatly improve
  calibration metrics of two medical risk assessment models when
  evaluated in subpopulations defined by intersections of age, sex,
  ethnicity, socioeconomic status and immigration history. Barda,
  Riesel, et al.
  (<xref alt="2020" rid="ref-Barda2020covid" ref-type="bibr">2020</xref>)
  demonstrate that Multi-Calibration can also be used to adjust an
  initial classifier for a new task. They re-calibrate a baseline model
  for predicting the risk of severe respiratory infection with data on
  COVID-19 fatality rates in subpopulations, resulting in an accurate
  and calibrated COVID-19 mortality prediction model.</p>
  <p>We hope that <monospace>mcboost</monospace> lets Multi-Calibration
  Boosting be utilized by a wide community of developers and data
  scientists to audit and post-process prediction models, and helps to
  promote fairness in machine learning and statistical estimation
  applications.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank Matthew Sun for developing an initial Python
  implementation of MCBoost. This work has been partially supported by
  the German Federal Ministry of Education and Research (BMBF) under
  Grant No.Â 01IS18036A. The authors of this work take full
  responsibilities for its content.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Barda2020covid">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Barda</surname><given-names>Noam</given-names></name>
          <name><surname>Riesel</surname><given-names>Dan</given-names></name>
          <name><surname>Akriv</surname><given-names>Amichay</given-names></name>
          <name><surname>Levy</surname><given-names>Joseph</given-names></name>
          <name><surname>Finkel</surname><given-names>Uriah</given-names></name>
          <name><surname>Yona</surname><given-names>Gal</given-names></name>
          <name><surname>Greenfeld</surname><given-names>Daniel</given-names></name>
          <name><surname>Sheiba</surname><given-names>Shimon</given-names></name>
          <name><surname>Somer</surname><given-names>Jonathan</given-names></name>
          <name><surname>Bachmat</surname><given-names>Eitan</given-names></name>
          <name><surname>Rothblum</surname><given-names>Guy</given-names></name>
          <name><surname>Shalit</surname><given-names>Uri</given-names></name>
          <name><surname>Netzer</surname><given-names>Doron</given-names></name>
          <name><surname>Balicer</surname><given-names>Ran</given-names></name>
          <name><surname>Dagan</surname><given-names>Noa</given-names></name>
        </person-group>
        <article-title>Developing a COVID-19 mortality risk prediction model when individual-level data are not available</article-title>
        <source>Nature communications</source>
        <year iso-8601-date="2020-09">2020</year><month>09</month>
        <volume>11</volume>
        <pub-id pub-id-type="doi">10.1038/s41467-020-18297-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Barda2020bias">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Barda</surname><given-names>Noam</given-names></name>
          <name><surname>Yona</surname><given-names>Gal</given-names></name>
          <name><surname>Rothblum</surname><given-names>Guy N</given-names></name>
          <name><surname>Greenland</surname><given-names>Philip</given-names></name>
          <name><surname>Leibowitz</surname><given-names>Morton</given-names></name>
          <name><surname>Balicer</surname><given-names>Ran</given-names></name>
          <name><surname>Bachmat</surname><given-names>Eitan</given-names></name>
          <name><surname>Dagan</surname><given-names>Noa</given-names></name>
        </person-group>
        <article-title>Addressing bias in prediction models by improving subpopulation calibration</article-title>
        <source>Journal of the American Medical Informatics Association</source>
        <year iso-8601-date="2020-11">2020</year><month>11</month>
        <volume>28</volume>
        <issue>3</issue>
        <issn>1527-974X</issn>
        <uri>https://doi.org/10.1093/jamia/ocaa283</uri>
        <pub-id pub-id-type="doi">10.1093/jamia/ocaa283</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-dwork-oi">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Dwork</surname><given-names>Cynthia</given-names></name>
          <name><surname>Kim</surname><given-names>Michael P.</given-names></name>
          <name><surname>Reingold</surname><given-names>Omer</given-names></name>
          <name><surname>Rothblum</surname><given-names>Guy N.</given-names></name>
          <name><surname>Yona</surname><given-names>Gal</given-names></name>
        </person-group>
        <article-title>Outcome indistinguishability</article-title>
        <year iso-8601-date="2020">2020</year>
        <uri>https://arxiv.org/abs/2011.13426</uri>
      </element-citation>
    </ref>
    <ref id="ref-dwork-rankings">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Dwork</surname><given-names>Cynthia</given-names></name>
          <name><surname>Kim</surname><given-names>Michael P.</given-names></name>
          <name><surname>Reingold</surname><given-names>Omer</given-names></name>
          <name><surname>Rothblum</surname><given-names>Guy N.</given-names></name>
          <name><surname>Yona</surname><given-names>Gal</given-names></name>
        </person-group>
        <article-title>Learning from outcomes: Evidence-based rankings</article-title>
        <source>2019 IEEE 60th annual symposium on foundations of computer science (FOCS)</source>
        <year iso-8601-date="2019">2019</year>
        <pub-id pub-id-type="doi">10.1109/FOCS.2019.00016</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hebert-johnson2018">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Hebert-Johnson</surname><given-names>Ursula</given-names></name>
          <name><surname>Kim</surname><given-names>Michael</given-names></name>
          <name><surname>Reingold</surname><given-names>Omer</given-names></name>
          <name><surname>Rothblum</surname><given-names>Guy</given-names></name>
        </person-group>
        <article-title>Multicalibration: Calibration for the (Computationally-identifiable) masses</article-title>
        <source>Proceedings of the 35th international conference on machine learning</source>
        <person-group person-group-type="editor">
          <name><surname>Dy</surname><given-names>Jennifer</given-names></name>
          <name><surname>Krause</surname><given-names>Andreas</given-names></name>
        </person-group>
        <publisher-name>PMLR</publisher-name>
        <publisher-loc>StockholmsmÃ¤ssan, Stockholm Sweden</publisher-loc>
        <year iso-8601-date="2018">2018</year>
        <volume>80</volume>
      </element-citation>
    </ref>
    <ref id="ref-kim2019">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kim</surname><given-names>Michael P.</given-names></name>
          <name><surname>Ghorbani</surname><given-names>Amirata</given-names></name>
          <name><surname>Zou</surname><given-names>James</given-names></name>
        </person-group>
        <article-title>Multiaccuracy: Black-box post-processing for fairness in classification</article-title>
        <source>Proceedings of the 2019 AAAI/ACM conference on AI, ethics, and society</source>
        <publisher-name>Association for Computing Machinery</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2019">2019</year>
        <isbn>9781450363242</isbn>
        <uri>https://doi.org/10.1145/3306618.3314287</uri>
        <pub-id pub-id-type="doi">10.1145/3306618.3314287</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kimkern2021">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Kim</surname><given-names>Michael P.</given-names></name>
          <name><surname>Kern</surname><given-names>Christoph</given-names></name>
          <name><surname>Goldwasser</surname><given-names>Shafi</given-names></name>
          <name><surname>Kreuter</surname><given-names>Frauke</given-names></name>
          <name><surname>Reingold</surname><given-names>Omer</given-names></name>
        </person-group>
        <article-title>Universal generalization versus propensity scoring</article-title>
        <publisher-name>Manuscript submitted for publication</publisher-name>
        <year iso-8601-date="2021">2021</year>
      </element-citation>
    </ref>
    <ref id="ref-mlr3">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Lang</surname><given-names>Michel</given-names></name>
          <name><surname>Binder</surname><given-names>Martin</given-names></name>
          <name><surname>Richter</surname><given-names>Jakob</given-names></name>
          <name><surname>Schratz</surname><given-names>Patrick</given-names></name>
          <name><surname>Pfisterer</surname><given-names>Florian</given-names></name>
          <name><surname>Coors</surname><given-names>Stefan</given-names></name>
          <name><surname>Au</surname><given-names>Quay</given-names></name>
          <name><surname>Casalicchio</surname><given-names>Giuseppe</given-names></name>
          <name><surname>Kotthoff</surname><given-names>Lars</given-names></name>
          <name><surname>Bischl</surname><given-names>Bernd</given-names></name>
        </person-group>
        <article-title>mlr3: A modern object-oriented machine learning framework in R</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2019-12">2019</year><month>12</month>
        <uri>https://joss.theoj.org/papers/10.21105/joss.01903</uri>
        <pub-id pub-id-type="doi">10.21105/joss.01903</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

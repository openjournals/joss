<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1389</article-id>
<article-id pub-id-type="doi">10.21105/joss.01389</article-id>
<title-group>
<article-title>pyCeterisParibus: explaining Machine Learning models with
Ceteris Paribus Profiles in Python</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9181-0126</contrib-id>
<string-name>Michał Kuźba</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-2278-4219</contrib-id>
<string-name>Ewa Baranowska</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8423-1823</contrib-id>
<string-name>Przemysław Biecek</string-name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Faculty of Mathematics and Information Science, Warsaw
University of Technology</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Faculty of Mathematics, Informatics, and Mechanics,
University of Warsaw</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-03-18">
<day>18</day>
<month>3</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>37</issue>
<fpage>1389</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>xAI</kwd>
<kwd>Machine Learning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>Machine learning is needed and used everywhere. It has
  fundamentally changed all data-driven disciplines, like health-care,
  biology, finance, legal, military, security, transportation, and many
  others. The increasing availability of large annotated data sources
  combined with recent developments in Machine Learning revolutionizes
  many disciplines. However, predictive models become more and more
  complex. It is not uncommon to have ensembles of predictive models
  with thousands or millions of parameters. Such models act as
  blackboxes. It is almost impossible for a human to understand reasons
  for model decisions.</p>
  <p>This lack of interpretability often leads to harmful situations.
  Models are not working properly or are hard to debug, results are
  biased in a systematic way, data drift leads to the deterioration in
  models performance, the model is wrong but no-one can explain what
  caused a wrong prediction. Many examples for these problems are listed
  in the <italic>Weapons of Math Destruction</italic>, a bestseller with
  an expressive subtitle <italic>How Big Data Increases Inequality and
  Threatens Democracy</italic>
  (<xref alt="O’Neil, 2016" rid="ref-ONeil" ref-type="bibr">O’Neil,
  2016</xref>). Reactions for some of these problems are new legal
  regulations, like the <italic>General Data Protection Regulation and
  the Right to Explanation</italic>
  (<xref alt="Ruiz, 2018" rid="ref-RightToExpl3" ref-type="bibr">Ruiz,
  2018</xref>).</p>
  <p>New tools are being created to support model interpretability. The
  most known methods are Local Interpretable Model-agnostic Explanations
  (LIME)
  (<xref alt="Ribeiro et al., 2016" rid="ref-LIME" ref-type="bibr">Ribeiro
  et al., 2016</xref>), SHapley Additive exPlanations (SHAP)
  (<xref alt="Lundberg &amp; Lee, 2017" rid="ref-SHAP" ref-type="bibr">Lundberg
  &amp; Lee, 2017</xref>) and Descriptive mAchine Learning EXplanations
  (DALEX)
  (<xref alt="Biecek, 2018" rid="ref-DALEX" ref-type="bibr">Biecek,
  2018</xref>). General purpose libraries for interpretable Machine
  Learning in Python are skater
  (<xref alt="Choudhary et al., 2018" rid="ref-pramit_choudhary_2018_1198885" ref-type="bibr">Choudhary
  et al., 2018</xref>) and
  <ext-link ext-link-type="uri" xlink:href="https://eli5.readthedocs.io/en/latest/">ELI5</ext-link>.</p>
  <p>An interesting alternative to these tools is the methodology of
  <italic>Ceteris Paribus Profiles</italic> and their averages called
  <italic>Partial Dependency Plots</italic>. They enable to understand
  how the model response would change if a selected variable is changed.
  It’s a perfect tool for What-If scenarios. <italic>Ceteris
  Paribus</italic> is a Latin phrase meaning <italic>all else
  unchanged</italic>. These plots present the change in model response
  as the values of one feature change with all others being fixed.
  Ceteris Paribus method is model-agnostic - it works for any Machine
  Learning model. The idea is an extension of <italic>PDP</italic>
  (Partial Dependency Plots)
  (<xref alt="Friedman, 2000" rid="ref-Friedman00greedyfunction" ref-type="bibr">Friedman,
  2000</xref>) and <italic>ICE</italic> (Individual Conditional
  Expectations) plots
  (<xref alt="Goldstein et al., 2015" rid="ref-GoldsteinICE" ref-type="bibr">Goldstein
  et al., 2015</xref>). It allows explaining single observations for
  multiple variables at the same time.</p>
  <p>In this paper, we introduce a
  <monospace>pyCeterisParibus</monospace> library for Python that
  supports a wide range of tools built on Ceteris Paribus Profiles.
  There might be several motivations behind utilizing this idea. Imagine
  a person gets a low credit score. The client wants to understand how
  to increase the score and the scoring institution (e.g., a bank)
  should be able to answer such questions. Moreover, this method is
  useful for researchers and developers to analyze, debug, explain and
  improve Machine Learning models, assisting the entire process of the
  model design. The more detailed demonstration is available in the
  <italic>Examples</italic> section.</p>
</sec>
<sec id="pyceterisparibus-library">
  <title>pyCeterisParibus library</title>
  <p><monospace>pyCeterisParibus</monospace> is a Python
  <ext-link ext-link-type="uri" xlink:href="https://github.com/ModelOriented/pyCeterisParibus">library</ext-link>
  based on an <italic>R</italic> package <italic>CeterisParibus</italic>
  (<xref alt="Biecek, 2019" rid="ref-CeterisParibus" ref-type="bibr">Biecek,
  2019</xref>). It is an open source software released on the Apache
  license.</p>
  <p>The workflow consists of three steps:</p>
  <list list-type="bullet">
    <list-item>
      <p>wrapping models into a unified representation</p>
    </list-item>
    <list-item>
      <p>calculating profiles for given observations, variables and
      models</p>
    </list-item>
    <list-item>
      <p>plotting the profiles</p>
    </list-item>
  </list>
  <p>Plots are drawn using a separate <italic>D3.js</italic>
  <ext-link ext-link-type="uri" xlink:href="https://github.com/ModelOriented/ceterisParibusD3">library</ext-link>
  which produces interactive Ceteris Paribus plots for both
  <italic>Python</italic> (this package) and
  <ext-link ext-link-type="uri" xlink:href="https://github.com/flaminka/ceterisParibusD3"><italic>R</italic></ext-link>
  implementations. This package allows explaining multiple observations
  and observing local behaviours of the model. For this purpose, methods
  for sampling and selecting neighbouring observations are implemented
  along with the <italic>Gower’s distance
  (<xref alt="Gower, 1971" rid="ref-gower" ref-type="bibr">Gower,
  1971</xref>)</italic> function. A more detailed description might be
  found in the package
  <ext-link ext-link-type="uri" xlink:href="https://pyceterisparibus.readthedocs.io/">documentation</ext-link>.</p>
</sec>
<sec id="examples">
  <title>Examples</title>
  <p>We demonstrate Ceteris Paribus Plots using the well-known Titanic
  dataset. In this problem, we examine the chance of survival for
  Titanic passengers. We start with preprocessing the data and creating
  an XGBoost model.</p>
  <code language="python">import pandas as pd
df = pd.read_csv('titanic_train.csv')

y = df['Survived']
x = df.drop(['Survived', 'PassengerId', 'Name', 'Cabin', 'Ticket'],
    inplace=False, axis=1)
    
valid = x['Age'].isnull() | x['Embarked'].isnull()
x = x[-valid]
y = y[-valid]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y,
    test_size=0.2, random_state=42)</code>
  <code language="python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# We create the preprocessing pipelines for both numeric and categorical data.
numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())])

categorical_features = ['Embarked', 'Sex']
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])</code>
  <code language="python">from xgboost import XGBClassifier
xgb_clf = Pipeline(steps=[('preprocessor', preprocessor),
('classifier', XGBClassifier())])
xgb_clf.fit(X_train, y_train)</code>
  <p>Here the pyCeterisParibus starts. Since this library works in a
  model agnostic fashion, first we need to create a wrapper around the
  model with uniform predict interface.</p>
  <code language="python">from ceteris_paribus.explainer import explain
explainer_xgb = explain(xgb_clf, data=x, y=y, label='XGBoost',
    predict_function=lambda X: xgb_clf.predict_proba(X)[::, 1])</code>
  <sec id="single-variable-profile">
    <title>Single variable profile</title>
    <p>Let’s look at Mr Ernest James Crease, the 19-year-old man,
    travelling on the 3rd class from Southampton with an 8 pounds ticket
    in his pocket. He died on the Titanic. Most likely, this would not
    have been the case had Ernest been a few years younger. Figure 1
    presents the chance of survival for a person like Ernest at
    different ages. We can see things were tough for people like him
    unless they were a child.</p>
    <code language="python">ernest = X_test.iloc[10]
label_ernest = y_test.iloc[10]
from ceteris_paribus.profiles import individual_variable_profile
cp_xgb = individual_variable_profile(explainer_xgb, ernest, label_ernest)</code>
    <p>Having calculated the profile we can plot it. Note, that
    <monospace>plot_notebook</monospace> might be used instead of
    <monospace>plot</monospace> when used in Jupyter notebooks.</p>
    <code language="python">from ceteris_paribus.plots.plots import plot
plot(cp_xgb, selected_variables=[&quot;Age&quot;])</code>
    <fig>
      <caption><p>Chance of survival depending on age</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="./img/figure1.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="many-models">
    <title>Many models</title>
    <p>The above picture explains the prediction of XGBoost model. What
    if we compare various models?</p>
    <code language="python">from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
rf_clf = Pipeline(steps=[('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier())])
linear_clf = Pipeline(steps=[('preprocessor', preprocessor),
    ('classifier', LogisticRegression())])
    
rf_clf.fit(X_train, y_train)
linear_clf.fit(X_train, y_train)

explainer_rf = explain(rf_clf, data=x, y=y, label='RandomForest',
    predict_function=lambda X: rf_clf.predict_proba(X)[::, 1])
explainer_linear = explain(linear_clf, data=x, y=y, label='LogisticRegression', 
    predict_function=lambda X: linear_clf.predict_proba(X)[::, 1])
    
plot(cp_xgb, cp_rf, cp_linear, selected_variables=[&quot;Age&quot;])</code>
    <fig>
      <caption><p>The probability of survival estimated with various
      models.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="./img/figure2.png" xlink:title="" />
    </fig>
    <p>Clearly, XGBoost offers a better fit than Logistic Regression
    (Figure 2). Also, it predicts a higher chance of survival at child’s
    age than the Random Forest model does.</p>
  </sec>
  <sec id="profiles-for-many-variables">
    <title>Profiles for many variables</title>
    <p>This time we have a look at Miss. Elizabeth Mussey Eustis. She is
    54 years old, travels at 1st class with her sister Marta, as they
    return to the US from their tour of southern Europe. They both
    survived the disaster.</p>
    <code language="python">elizabeth = X_test.iloc[1]
label_elizabeth = y_test.iloc[1]
cp_xgb_2 = individual_variable_profile(explainer_xgb, elizabeth, label_elizabeth)</code>
    <code language="python">plot(cp_xgb_2, selected_variables=[&quot;Pclass&quot;, &quot;Sex&quot;, &quot;Age&quot;, &quot;Embarked&quot;])</code>
    <fig>
      <caption><p>Profiles for many variables.</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="./img/figure3.png" xlink:title="" />
    </fig>
    <p>Would she have returned home if she had travelled at 3rd class or
    if she had been a man? As we can observe (Figure 3) this is less
    likely. On the other hand, for a first class, female passenger
    chances of survival were high regardless of age. Note, this was
    different in the case of Ernest. Place of embarkment (Cherbourg) has
    no influence, which is expected behaviour.</p>
  </sec>
  <sec id="feature-interactions-and-average-response">
    <title>Feature interactions and average response</title>
    <p>Now, what if we look at passengers most similar to Miss. Eustis
    (middle-aged, upper class)?</p>
    <code language="python">from ceteris_paribus.select_data import select_neighbours
neighbours = select_neighbours(X_train, elizabeth, 
    selected_variables=['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], 
    n=15)
cp_xgb_ns = individual_variable_profile(explainer_xgb, neighbours)</code>
    <code language="python">plot(cp_xgb_ns, color=&quot;Sex&quot;, selected_variables=[&quot;Pclass&quot;, &quot;Age&quot;], 
    aggregate_profiles='mean', size_pdps=6, alpha_pdps=1, size=2)</code>
    <fig>
      <caption><p>Interaction with gender. Apart from charts with
      Ceteris Paribus Profiles (top of the visualisation), we can plot a
      table with observations used to calculate these profiles (bottom
      of the visualisation).</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="./img/figure4.png" xlink:title="" />
    </fig>
    <p>There are two distinct clusters of passengers determined with
    their gender (Figure 4), therefore a <italic>PDP</italic> average
    plot (on grey) does not show the whole picture. Children of both
    genders were likely to survive, but then we see a large gap. Also,
    being female increased the chance of survival mostly for second and
    first class passengers.</p>
    <p>Plot function comes with extensive customization options. List of
    all parameters might be found in the documentation. Additionally,
    one can interact with the plot by hovering over a point of interest
    to see more details. Similarly, there is an interactive table with
    options for highlighting relevant elements as well as filtering and
    sorting rows.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Michał Kuźba was financially supported by NCN Opus grant
  2016/21/B/ST6/0217 , Ewa Baranowska was financially supported by NCN
  Opus grant 2017/27/B/ST6/01307.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-ONeil">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>O’Neil</surname><given-names>Cathy</given-names></name>
        </person-group>
        <source>Weapons of math destruction: How big data increases inequality and threatens democracy</source>
        <publisher-name>Crown Publishing Group</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <isbn>0553418815, 9780553418811</isbn>
      </element-citation>
    </ref>
    <ref id="ref-RightToExpl3">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Ruiz</surname><given-names>Javier</given-names></name>
        </person-group>
        <article-title>Machine learning and the right to explanation in GDPR</article-title>
        <publisher-name>https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr</publisher-name>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-DALEX">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemysław</given-names></name>
        </person-group>
        <article-title>DALEX: Explainers for complex predictive models in r</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2018">2018</year>
        <volume>19</volume>
      </element-citation>
    </ref>
    <ref id="ref-CeterisParibus">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemysław</given-names></name>
        </person-group>
        <article-title>Ceteris paribus plots (what-if plots) for explanations of a single observation</article-title>
        <source>GitHub repository</source>
        <publisher-name>https://github.com/pbiecek/ceterisParibus; GitHub</publisher-name>
        <year iso-8601-date="2019">2019</year>
      </element-citation>
    </ref>
    <ref id="ref-SHAP">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Lundberg</surname><given-names>Scott M</given-names></name>
          <name><surname>Lee</surname><given-names>Su-In</given-names></name>
        </person-group>
        <article-title>A unified approach to interpreting model predictions</article-title>
        <source>Advances in neural information processing systems 30</source>
        <person-group person-group-type="editor">
          <name><surname>Guyon</surname><given-names>I.</given-names></name>
          <name><surname>Luxburg</surname><given-names>U. V.</given-names></name>
          <name><surname>Bengio</surname><given-names>S.</given-names></name>
          <name><surname>Wallach</surname><given-names>H.</given-names></name>
          <name><surname>Fergus</surname><given-names>R.</given-names></name>
          <name><surname>Vishwanathan</surname><given-names>S.</given-names></name>
          <name><surname>Garnett</surname><given-names>R.</given-names></name>
        </person-group>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <uri>http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-LIME">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Ribeiro</surname><given-names>Marco Tulio</given-names></name>
          <name><surname>Singh</surname><given-names>Sameer</given-names></name>
          <name><surname>Guestrin</surname><given-names>Carlos</given-names></name>
        </person-group>
        <article-title>Why should i trust you?: Explaining the predictions of any classifier</article-title>
        <publisher-name>ACM Press</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <isbn>978-1-4503-4232-2</isbn>
        <uri>http://dl.acm.org/citation.cfm?doid=2939672.2939778</uri>
        <pub-id pub-id-type="doi">10.1145/2939672.2939778</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-GoldsteinICE">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Goldstein</surname><given-names>Alex</given-names></name>
          <name><surname>Kapelner</surname><given-names>Adam</given-names></name>
          <name><surname>Bleich</surname><given-names>Justin</given-names></name>
          <name><surname>Pitkin</surname><given-names>Emil</given-names></name>
        </person-group>
        <article-title>Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year iso-8601-date="2015">2015</year>
        <volume>24</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1080/10618600.2014.907095</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Friedman00greedyfunction">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>Jerome H.</given-names></name>
        </person-group>
        <article-title>Greedy function approximation: A gradient boosting machine</article-title>
        <source>Annals of Statistics</source>
        <year iso-8601-date="2000">2000</year>
        <volume>29</volume>
      </element-citation>
    </ref>
    <ref id="ref-pramit_choudhary_2018_1198885">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Choudhary</surname><given-names>Pramit</given-names></name>
          <name><surname>Kramer</surname><given-names>Aaron</given-names></name>
          <name><surname>team</surname><given-names>contributors datascience.com</given-names></name>
        </person-group>
        <article-title>Skater: Model Interpretation Library</article-title>
        <year iso-8601-date="2018-03">2018</year><month>03</month>
        <uri>https://doi.org/10.5281/zenodo.1198885</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1198885</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gower">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Gower</surname><given-names>John</given-names></name>
        </person-group>
        <article-title>A general coefficient of similarity and some of its properties</article-title>
        <source>Biometrics</source>
        <year iso-8601-date="1971-12">1971</year><month>12</month>
        <volume>27</volume>
        <pub-id pub-id-type="doi">10.2307/2528823</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3455</article-id>
<article-id pub-id-type="doi">10.21105/joss.03455</article-id>
<title-group>
<article-title>Biosensor Framework: A C# Library for Affective
Computing</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0819-0710</contrib-id>
<string-name>Walker Arce</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3457-2288</contrib-id>
<string-name>James Gehringer, PhD</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Virtual Reality Laboratory in the Munroe Meyer Institute at
the University of Nebraska Medical Center</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-05-15">
<day>15</day>
<month>5</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>64</issue>
<fpage>3455</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Affective Computing</kwd>
<kwd>Biometrics</kwd>
<kwd>Machine Learning</kwd>
<kwd>Unity</kwd>
<kwd>Microsoft.ML</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Developed in the Virtual Reality Laboratory at the Munroe Meyer
  Institute, the Biosensor Framework library provides an interface for
  interacting with biosensors and performing affective computing tasks
  on their output data streams. Currently, it natively supports the
  Empatica E4 biosensor and communicates through a TCP connection with
  their provided server.</p>
  <p>This library provides the following capabilities: - Connection to
  the
  <ext-link ext-link-type="uri" xlink:href="https://github.com/empatica/ble-client-windows">TCP
  client</ext-link> that Empatica provides for connecting their devices
  to a user’s PC - Parsing and packing of commands to communicate
  bidirectionally with the TCP client - Collection and delivery of
  biometric readings to an end user’s software application - Extraction
  of literature supported feature vectors to allow characterization of
  the biological signal features - Microsoft.ML support for inferencing
  on the feature vectors natively in C# in both multi-class and binary
  classification tasks - Support for simulating a data stream for
  debugging and testing applications without an Empatica E4 device -
  Support for parsing open source Empatica E4 datasets and training
  machine learning models on them (i.e., WESAD
  (<xref alt="Schmidt et al., 2018" rid="ref-schmidt2018introducing" ref-type="bibr">Schmidt
  et al., 2018</xref>)) - Support for interfacing new sensors into the
  same pipeline - Contains models trained on WESAD dataset in the
  Microsoft.ML framework.</p>
</sec>
<sec id="background">
  <title>Background</title>
  <p>Biosensor Framework is a C# library that handles the full process
  of gathering biometric data from a body-worn sensor, transforming it
  into handcrafted feature vectors, and delivering an inferencing result
  in thirty-five lines of code. Purpose built to handle the Empatica E4
  biosensor, the Empatica provided TCP client is wrapped in a static C#
  class to provide convenient function calls and error handling to
  simplify code structure. With the introduction of Microsoft.ML, the
  entire pipeline is handled in C# managed code and is fully compatible
  with the Unity game engine, allowing for affective computing to be
  easily introduced into existing virtual reality therapy tools. The
  decoupled structure of the library also allows for new biosensors to
  be introduced into the pipeline, requiring only a single code file to
  be added to retrieve data in a list of doubles.</p>
  <p>Generally, affective computing is concerned with the physiological
  changes of the subject and how that relates to their internal state.
  Most implementations of affective computing look at electrodermal
  activity (EDA), like a lie detector test, to measure the onset of
  stress before the subject may even be aware of it
  (<xref alt="Gjoreski et al., 2016" rid="ref-gjoreski2016continuous" ref-type="bibr">Gjoreski
  et al., 2016</xref>;
  <xref alt="Healey, 2000" rid="ref-healey2000wearable" ref-type="bibr">Healey,
  2000</xref>;
  <xref alt="Healey &amp; Picard, 2005" rid="ref-healey2005detecting" ref-type="bibr">Healey
  &amp; Picard, 2005</xref>;
  <xref alt="Kutt et al., 2018" rid="ref-kutt2018towards" ref-type="bibr">Kutt
  et al., 2018</xref>). There is a growing body of literature that
  incorporates the use of multiple body sensors, primarily worn on the
  wrist, such as photoplethysmography (PPG), three axis acceleration
  (ACC), and skin temperature (TMP)
  (<xref alt="Choi et al., 2011" rid="ref-choi2011development" ref-type="bibr">Choi
  et al., 2011</xref>;
  <xref alt="Gent et al., 2019" rid="ref-van2019heartpy" ref-type="bibr">Gent
  et al., 2019</xref>;
  <xref alt="Gjoreski et al., 2016" rid="ref-gjoreski2016continuous" ref-type="bibr">Gjoreski
  et al., 2016</xref>;
  <xref alt="Kaczor et al., 2020" rid="ref-kaczor2020objective" ref-type="bibr">Kaczor
  et al., 2020</xref>;
  <xref alt="Kleiman et al., 2019" rid="ref-kleiman2019using" ref-type="bibr">Kleiman
  et al., 2019</xref>;
  <xref alt="Kutt et al., 2018" rid="ref-kutt2018towards" ref-type="bibr">Kutt
  et al., 2018</xref>;
  <xref alt="Zhou et al., 2017" rid="ref-zhou2017indexing" ref-type="bibr">Zhou
  et al., 2017</xref>). As these sensors are miniaturized, they can be
  easily incorporated into wrist-worn packages and can be fused with
  other sensor modalities, such as respiratory sensors, eye trackers, or
  body trackers, to estimate a subject’s emotional state more
  accurately.</p>
  <p>Biosensor Framework incorporates the algorithms used in the WESAD
  dataset for computing feature vectors for all sensors on the Empatica
  E4: EDA, PPG, ACC, and TMP
  (<xref alt="Schmidt et al., 2018" rid="ref-schmidt2018introducing" ref-type="bibr">Schmidt
  et al., 2018</xref>). Additionally, the E4 provides estimations on the
  heart rate and inter-beat interval, as well as a button for manually
  tagging the data stream, which has been implemented in a function to
  mark relevant events. To detrend the EDA signal, a time-varying,
  finite-impulse-response, high-pass filter is used
  (<xref alt="Tarvainen et al., 2002" rid="ref-tarvainen2002advanced" ref-type="bibr">Tarvainen
  et al., 2002</xref>). For detecting major responses in the EDA, the
  method proposed by Healey is used
  (<xref alt="Healey, 2000" rid="ref-healey2000wearable" ref-type="bibr">Healey,
  2000</xref>). To perform the Fast Fourier Transform, the
  <ext-link ext-link-type="uri" xlink:href="https://www.codeproject.com/Articles/1107480/DSPLib-FFT-DFT-Fourier-Transform-Library-for-NET-6">DSPLib</ext-link>
  project was incorporated to allow real-time computation of the signal
  spectra. Finally, a stillness metric was added to compute a unitless
  measure of movement from the accelerometer signals
  (<xref alt="Chang et al., 2012" rid="ref-chang2012wireless" ref-type="bibr">Chang
  et al., 2012</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>In the application of virtual reality therapy tools for patients
  with autism spectrum disorder, the continual management of stress is
  of utmost importance
  (<xref alt="Bishop-Fitzpatrick et al., 2015" rid="ref-bishop2015relationship" ref-type="bibr">Bishop-Fitzpatrick
  et al., 2015</xref>;
  <xref alt="Kildahl et al., 2019" rid="ref-kildahl2019identification" ref-type="bibr">Kildahl
  et al., 2019</xref>). These tools can introduce stressful situations
  such as navigating an airport, handling an airplane ride, or crossing
  a busy intersection, which can be difficult or impossible to simulate
  in a controlled clinical environment
  (<xref alt="Miller et al., 2020" rid="ref-miller2020virtual" ref-type="bibr">Miller
  et al., 2020</xref>;
  <xref alt="Poyade et al., 2017" rid="ref-poyade2017using" ref-type="bibr">Poyade
  et al., 2017</xref>;
  <xref alt="Saiano et al., 2015" rid="ref-saiano2015natural" ref-type="bibr">Saiano
  et al., 2015</xref>). This stress can be monitored using biosensors
  and literature supported machine learning models, which gives the
  clinician an additional layer of information for tuning the
  environment for its intended therapeutic effect. Additionally, the
  library can be used in applications for monitoring and managing
  ambulatory stress for at-risk patients, allowing another layer of
  information for medical personnel to assess the state of their
  patients
  (<xref alt="Kleiman et al., 2019" rid="ref-kleiman2019using" ref-type="bibr">Kleiman
  et al., 2019</xref>).</p>
  <p>The most common tool to implement virtual reality therapy tools is
  the Unity game engine, which runs a C# interpreter based on the Mono
  compiler. To reasonably use common open-source machine learning tools,
  such as Python, MATLAB, or R, would require the use of additional TCP
  servers to act as the intermediary between the virtual environment and
  the biosensor readings. This adds an additional layer to the
  technology stack and, for Unity developers, requires the compilation
  and management of multiple projects. The Biosensor Framework library
  removes this additional layer and simplifies the machine learning down
  to simple function calls.</p>
</sec>
<sec id="affect-classification-model-performance">
  <title>Affect Classification Model Performance</title>
  <p>We split the WESAD dataset into the binary classification and
  multi-class organization as specified in
  (<xref alt="Schmidt et al., 2018" rid="ref-schmidt2018introducing" ref-type="bibr">Schmidt
  et al., 2018</xref>) and calculated the feature vectors accordingly.
  We used a train-test split of 0.3 and trained using the standard Fit
  method built into the Microsoft.ML models. The binary classification
  task was split into <italic>stress vs. non-stress</italic> and the
  multi-class classification task was split into <italic>baseline
  vs. stress vs. amusement</italic>. The regression tasks also used the
  latter dataset. The metrics were calculated from the test fit and were
  automatically generated by Microsoft.ML.</p>
  <p>Regression Model Metrics</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th></th>
          <th>Fast Forest</th>
          <th>Fast Tree</th>
          <th>Fast Tree Tweedie</th>
          <th>LBFGS</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Loss Function</td>
          <td>19.54</td>
          <td>11.34</td>
          <td>12.27</td>
          <td>37.11</td>
        </tr>
        <tr>
          <td>Mean Absolute Error</td>
          <td>28.33</td>
          <td>16.64</td>
          <td>16.63</td>
          <td>45.89</td>
        </tr>
        <tr>
          <td>Mean Squared Error</td>
          <td>19.54</td>
          <td>11.14</td>
          <td>12.27</td>
          <td>37.11</td>
        </tr>
        <tr>
          <td>RMS Error</td>
          <td>44.20</td>
          <td>33.67</td>
          <td>35.03</td>
          <td>60.92</td>
        </tr>
        <tr>
          <td>R Squared</td>
          <td>65.17</td>
          <td><bold>79.79</bold></td>
          <td>78.12</td>
          <td>26.11</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>Multi-Class Classification Metrics</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th></th>
          <th>Fast Forest</th>
          <th>Fast Tree</th>
          <th>LBFGS Regression</th>
          <th>LBFGS Max Entropy</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Log Loss</td>
          <td>31.30</td>
          <td>22.27</td>
          <td>45.11</td>
          <td>41.51</td>
        </tr>
        <tr>
          <td>LL Reduction</td>
          <td>68.51</td>
          <td>77.59</td>
          <td>51.82</td>
          <td>55.67</td>
        </tr>
        <tr>
          <td>Macro Acc</td>
          <td>84.59</td>
          <td><bold>93.78</bold></td>
          <td>68.80</td>
          <td>71.97</td>
        </tr>
        <tr>
          <td>Micro Acc</td>
          <td>89.06</td>
          <td><bold>95.40</bold></td>
          <td>84.76</td>
          <td>85.40</td>
        </tr>
        <tr>
          <td>Class 0 Precision</td>
          <td>93.72</td>
          <td>95.90</td>
          <td>83.09</td>
          <td>84.69</td>
        </tr>
        <tr>
          <td>Class 0 Recall</td>
          <td>93.36</td>
          <td>97.82</td>
          <td>95.85</td>
          <td>94.54</td>
        </tr>
        <tr>
          <td>Class 0 Loss</td>
          <td>22.03</td>
          <td>9.92</td>
          <td>23.13</td>
          <td>23.59</td>
        </tr>
        <tr>
          <td>Class 1 Precision</td>
          <td>83.98</td>
          <td>98.34</td>
          <td>91.46</td>
          <td>90.56</td>
        </tr>
        <tr>
          <td>Class 1 Recall</td>
          <td>92.97</td>
          <td>94.73</td>
          <td>91.09</td>
          <td>91.30</td>
        </tr>
        <tr>
          <td>Class 1 Loss</td>
          <td>25.96</td>
          <td>27.68</td>
          <td>42.37</td>
          <td>34.16</td>
        </tr>
        <tr>
          <td>Class 2 Precision</td>
          <td>83.21</td>
          <td>88.53</td>
          <td>63.64</td>
          <td>85.40</td>
        </tr>
        <tr>
          <td>Class 2 Recall</td>
          <td>67.26</td>
          <td>88.79</td>
          <td>19.44</td>
          <td>30.09</td>
        </tr>
        <tr>
          <td>Class 2 Loss</td>
          <td>71.23</td>
          <td>52.41</td>
          <td>152.03</td>
          <td>140.35</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>Binary Classification Metrics</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th></th>
          <th>Fast Forest</th>
          <th>Fast Tree</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Accuracy</td>
          <td>92.35</td>
          <td><bold>96.85</bold></td>
        </tr>
        <tr>
          <td>AUPRC</td>
          <td>97.95</td>
          <td>99.05</td>
        </tr>
        <tr>
          <td>AURC</td>
          <td>97.39</td>
          <td>98.88</td>
        </tr>
        <tr>
          <td>F1 Score</td>
          <td>92.86</td>
          <td>97.06</td>
        </tr>
        <tr>
          <td>Negative Precision</td>
          <td>92.34</td>
          <td>97.07</td>
        </tr>
        <tr>
          <td>Negative Recall</td>
          <td>91.19</td>
          <td>96.17</td>
        </tr>
        <tr>
          <td>Positive Precision</td>
          <td>92.36</td>
          <td>96.67</td>
        </tr>
        <tr>
          <td>Positive Recall</td>
          <td>93.37</td>
          <td>97.46</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>For our evaluation of the machine learning framework, we focused on
  the binary classification task of <italic>stress v.
  non-stress</italic>. Microsoft.ML has built in models that allow for
  quick training, evaluation, and deployment of machine learning
  applications. The ones that we evaluated were the Fast Forest and Fast
  Tree models. The models evaluated performed very well in the binary
  classification task and the Fast Tree outperformed the Fast Forest.
  For all three classification tasks the Fast Tree outperformed all
  other models.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We would like to thank the Integrated Center for Autism Spectrum
  Disorder and the Munroe Meyer Guild at the Munroe Meyer Institute at
  the University of Nebraska Medical Center for supporting our work.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-schmidt2018introducing">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Schmidt</surname><given-names>Philip</given-names></name>
          <name><surname>Reiss</surname><given-names>Attila</given-names></name>
          <name><surname>Duerichen</surname><given-names>Robert</given-names></name>
          <name><surname>Marberger</surname><given-names>Claus</given-names></name>
          <name><surname>Van Laerhoven</surname><given-names>Kristof</given-names></name>
        </person-group>
        <article-title>Introducing WESAD, a multimodal dataset for wearable stress and affect detection</article-title>
        <source>Proceedings of the 20th ACM international conference on multimodal interaction</source>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1145/3242969.3242985</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-healey2000wearable">
      <element-citation publication-type="thesis">
        <person-group person-group-type="author">
          <name><surname>Healey</surname><given-names>Jennifer A</given-names></name>
        </person-group>
        <article-title>Wearable and automotive systems for affect recognition from physiology</article-title>
        <publisher-name>Massachusetts Institute of Technology</publisher-name>
        <year iso-8601-date="2000">2000</year>
      </element-citation>
    </ref>
    <ref id="ref-healey2005detecting">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Healey</surname><given-names>Jennifer A</given-names></name>
          <name><surname>Picard</surname><given-names>Rosalind W</given-names></name>
        </person-group>
        <article-title>Detecting stress during real-world driving tasks using physiological sensors</article-title>
        <source>IEEE Transactions on intelligent transportation systems</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2005">2005</year>
        <volume>6</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1109/tits.2005.848368</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kutt2018towards">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kutt</surname><given-names>Krzysztof</given-names></name>
          <name><surname>Binek</surname><given-names>Wojciech</given-names></name>
          <name><surname>Misiak</surname><given-names>Piotr</given-names></name>
          <name><surname>Nalepa</surname><given-names>Grzegorz J</given-names></name>
          <name><surname>Bobek</surname><given-names>Szymon</given-names></name>
        </person-group>
        <article-title>Towards the development of sensor platform for processing physiological data from wearable sensors</article-title>
        <source>International conference on artificial intelligence and soft computing</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1007/978-3-319-91262-2_16</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gjoreski2016continuous">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Gjoreski</surname><given-names>Martin</given-names></name>
          <name><surname>Gjoreski</surname><given-names>Hristijan</given-names></name>
          <name><surname>Luštrek</surname><given-names>Mitja</given-names></name>
          <name><surname>Gams</surname><given-names>Matjaž</given-names></name>
        </person-group>
        <article-title>Continuous stress detection using a wrist device: In laboratory and real life</article-title>
        <source>Proceedings of the 2016 ACM international joint conference on pervasive and ubiquitous computing: adjunct</source>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1145/2968219.2968306</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-zhou2017indexing">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Zhou</surname><given-names>Jianlong</given-names></name>
          <name><surname>Arshad</surname><given-names>Syed Z</given-names></name>
          <name><surname>Luo</surname><given-names>Simon</given-names></name>
          <name><surname>Yu</surname><given-names>Kun</given-names></name>
          <name><surname>Berkovsky</surname><given-names>Shlomo</given-names></name>
          <name><surname>Chen</surname><given-names>Fang</given-names></name>
        </person-group>
        <article-title>Indexing cognitive load using blood volume pulse features</article-title>
        <source>Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems</source>
        <year iso-8601-date="2017">2017</year>
        <pub-id pub-id-type="doi">10.1145/3027063.3053140</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-van2019heartpy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Gent</surname><given-names>Paul van</given-names></name>
          <name><surname>Farah</surname><given-names>Haneen</given-names></name>
          <name><surname>Nes</surname><given-names>Nicole van</given-names></name>
          <name><surname>Arem</surname><given-names>Bart van</given-names></name>
        </person-group>
        <article-title>HeartPy: A novel heart rate algorithm for the analysis of noisy signals</article-title>
        <source>Transportation research part F: traffic psychology and behaviour</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>66</volume>
        <pub-id pub-id-type="doi">10.1016/j.trf.2019.09.015</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kleiman2019using">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kleiman</surname><given-names>Evan</given-names></name>
          <name><surname>Millner</surname><given-names>Alexander J</given-names></name>
          <name><surname>Joyce</surname><given-names>Victoria W</given-names></name>
          <name><surname>Nash</surname><given-names>Carol C</given-names></name>
          <name><surname>Buonopane</surname><given-names>Ralph J</given-names></name>
          <name><surname>Nock</surname><given-names>Matthew K</given-names></name>
        </person-group>
        <article-title>Using wearable physiological monitors with suicidal adolescent inpatients: Feasibility and acceptability study</article-title>
        <source>JMIR mHealth and uHealth</source>
        <publisher-name>JMIR Publications Inc., Toronto, Canada</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>7</volume>
        <issue>9</issue>
        <pub-id pub-id-type="doi">10.2196/13725</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kaczor2020objective">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kaczor</surname><given-names>Eric</given-names></name>
          <name><surname>Carreiro</surname><given-names>Stephanie</given-names></name>
          <name><surname>Stapp</surname><given-names>Joshua</given-names></name>
          <name><surname>Chapman</surname><given-names>Brittany</given-names></name>
          <name><surname>Indic</surname><given-names>Premananda</given-names></name>
        </person-group>
        <article-title>Objective measurement of physician stress in the emergency department using a wearable sensor</article-title>
        <source>Proceedings of the... Annual hawaii international conference on system sciences. Annual hawaii international conference on system sciences</source>
        <publisher-name>NIH Public Access</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>2020</volume>
        <pub-id pub-id-type="doi">10.24251/hicss.2020.456</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-choi2011development">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Choi</surname><given-names>Jongyoon</given-names></name>
          <name><surname>Ahmed</surname><given-names>Beena</given-names></name>
          <name><surname>Gutierrez-Osuna</surname><given-names>Ricardo</given-names></name>
        </person-group>
        <article-title>Development and evaluation of an ambulatory stress monitor based on wearable sensors</article-title>
        <source>IEEE transactions on information technology in biomedicine</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>16</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.37896/jxu15.3/018</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-tarvainen2002advanced">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Tarvainen</surname><given-names>Mika P</given-names></name>
          <name><surname>Ranta-Aho</surname><given-names>Perttu O</given-names></name>
          <name><surname>Karjalainen</surname><given-names>Pasi A</given-names></name>
        </person-group>
        <article-title>An advanced detrending method with application to HRV analysis</article-title>
        <source>IEEE Transactions on Biomedical Engineering</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2002">2002</year>
        <volume>49</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1109/10.979357</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chang2012wireless">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chang</surname><given-names>Kang-Ming</given-names></name>
          <name><surname>Chen</surname><given-names>Sih-Huei</given-names></name>
          <name><surname>Lee</surname><given-names>Hsin-Yi</given-names></name>
          <name><surname>Ching</surname><given-names>Congo Tak-Shing</given-names></name>
          <name><surname>Huang</surname><given-names>Chun-Lung</given-names></name>
        </person-group>
        <article-title>A wireless accelerometer-based body posture stability detection system and its application for meditation practitioners</article-title>
        <source>Sensors</source>
        <publisher-name>Multidisciplinary Digital Publishing Institute</publisher-name>
        <year iso-8601-date="2012">2012</year>
        <volume>12</volume>
        <issue>12</issue>
        <pub-id pub-id-type="doi">10.3390/s121217620</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kildahl2019identification">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kildahl</surname><given-names>Arvid Nikolai</given-names></name>
          <name><surname>Bakken</surname><given-names>Trine Lise</given-names></name>
          <name><surname>Iversen</surname><given-names>Trine Elisabeth</given-names></name>
          <name><surname>Helverschou</surname><given-names>Sissel Berge</given-names></name>
        </person-group>
        <article-title>Identification of post-traumatic stress disorder in individuals with autism spectrum disorder and intellectual disability: A systematic review</article-title>
        <source>Journal of Mental Health Research in Intellectual Disabilities</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <volume>12</volume>
        <issue>1-2</issue>
        <pub-id pub-id-type="doi">10.1080/19315864.2019.1595233</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-bishop2015relationship">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bishop-Fitzpatrick</surname><given-names>Lauren</given-names></name>
          <name><surname>Mazefsky</surname><given-names>Carla A</given-names></name>
          <name><surname>Minshew</surname><given-names>Nancy J</given-names></name>
          <name><surname>Eack</surname><given-names>Shaun M</given-names></name>
        </person-group>
        <article-title>The relationship between stress and social functioning in adults with autism spectrum disorder and without intellectual disability</article-title>
        <source>Autism Research</source>
        <publisher-name>Wiley Online Library</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>8</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1002/aur.1433</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-poyade2017using">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Poyade</surname><given-names>Matthieu</given-names></name>
          <name><surname>Morris</surname><given-names>Glyn</given-names></name>
          <name><surname>Taylor</surname><given-names>Ian</given-names></name>
          <name><surname>Portela</surname><given-names>Victor</given-names></name>
        </person-group>
        <article-title>Using mobile virtual reality to empower people with hidden disabilities to overcome their barriers</article-title>
        <source>Proceedings of the 19th ACM international conference on multimodal interaction</source>
        <year iso-8601-date="2017">2017</year>
        <pub-id pub-id-type="doi">10.1145/3136755.3143025</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-miller2020virtual">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Miller</surname><given-names>Ian T</given-names></name>
          <name><surname>Wiederhold</surname><given-names>Brenda K</given-names></name>
          <name><surname>Miller</surname><given-names>Catherine S</given-names></name>
          <name><surname>Wiederhold</surname><given-names>Mark D</given-names></name>
        </person-group>
        <article-title>Virtual reality air travel training with children on the autism spectrum: A preliminary report</article-title>
        <source>Cyberpsychology, Behavior, and Social Networking</source>
        <publisher-name>Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New …</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>23</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1089/cyber.2019.0093</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-saiano2015natural">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Saiano</surname><given-names>Mario</given-names></name>
          <name><surname>Pellegrino</surname><given-names>Laura</given-names></name>
          <name><surname>Casadio</surname><given-names>Maura</given-names></name>
          <name><surname>Summa</surname><given-names>Susanna</given-names></name>
          <name><surname>Garbarino</surname><given-names>Eleonora</given-names></name>
          <name><surname>Rossi</surname><given-names>Valentina</given-names></name>
          <name><surname>Dall’Agata</surname><given-names>Daniela</given-names></name>
          <name><surname>Sanguineti</surname><given-names>Vittorio</given-names></name>
        </person-group>
        <article-title>Natural interfaces and virtual environments for the acquisition of street crossing and path following skills in adults with autism spectrum disorders: A feasibility study</article-title>
        <source>Journal of neuroengineering and rehabilitation</source>
        <publisher-name>BioMed Central</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>12</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1186/s12984-015-0010-z</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

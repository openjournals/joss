<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1970</article-id>
<article-id pub-id-type="doi">10.21105/joss.01970</article-id>
<title-group>
<article-title>MOAFS: A Massive Online Analysis library for feature
selection in data streams</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9485-0334</contrib-id>
<string-name>Matheus Bernardelli de Moraes</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6520-9740</contrib-id>
<string-name>André Leon Sampaio Gradvohl</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Faculty of Technology, University of Campinas</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-10-08">
<day>8</day>
<month>10</month>
<year>2019</year>
</pub-date>
<volume>5</volume>
<issue>45</issue>
<fpage>1970</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>feature selection</kwd>
<kwd>data streams</kwd>
<kwd>concept drift</kwd>
<kwd>moa</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Each feature selection algorithm performs efficiently depending on
  different circumstances, such as data dimensionality (low, medium,
  high or ultra), speed rate, attribute type (nominal or numerical),
  number of classes, among others. Therefore, to perform different
  experiments on some of the most relevant feature selection algorithms
  proposed for data streams classification problems, the Massive Online
  Analysis Feature Selection (<monospace>MOAFS</monospace>) was created.
  <monospace>MOAFS</monospace> is a library for the Massive Online
  Analysis (MOA)
  (<xref alt="Bifet et al., 2010" rid="ref-BifetU003A2010" ref-type="bibr">Bifet
  et al., 2010</xref>) framework, and it is based on the MOAReduction
  (<xref alt="Ramírez-Gallego et al., 2017" rid="ref-Ramirez-GallegoU003A2017" ref-type="bibr">Ramírez-Gallego
  et al., 2017</xref>) extension. It contains seven feature selection
  algorithms to be used as dimensionality reduction techniques in data
  streams classification problems, especially in the text-domain field,
  since they are not directly available on MOA.
  <monospace>MOAFS</monospace> includes incremental versions of
  information-based filter algorithms such as Information Gain and Gain
  Ratio
  (<xref alt="Quinlan, 1986" rid="ref-QuinlanU003A1986" ref-type="bibr">Quinlan,
  1986</xref>), Symmetrical Uncertainty used by the Fast
  Correlation-Based Filter
  (<xref alt="Yu &amp; Liu, 2003" rid="ref-YuU003A2003" ref-type="bibr">Yu
  &amp; Liu, 2003</xref>), Chi-squared
  (<xref alt="Pearson, 1992" rid="ref-PearsonU003A1990" ref-type="bibr">Pearson,
  1992</xref>) and Cramers V-Test
  (<xref alt="Cramer, 1946" rid="ref-CramerU003A1946" ref-type="bibr">Cramer,
  1946</xref>), as well as wrapper algorithms such as Online Feature
  Selection
  (<xref alt="Wang et al., 2014" rid="ref-WangU003A2014" ref-type="bibr">Wang
  et al., 2014</xref>) and Extremal Feature Selection
  (<xref alt="Carvalho &amp; Cohen, 2006" rid="ref-CarvalhoU003A2006" ref-type="bibr">Carvalho
  &amp; Cohen, 2006</xref>). Therefore, <monospace>MOAFS</monospace> is
  a package for MOA to perform feature selection in data streams
  classification problems.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Data streams are continuous, potentially unbounded, high volume and
  high dimensional data, which turns impracticable its storage in
  traditional database mechanisms
  (<xref alt="Ramírez-Gallego et al., 2017" rid="ref-Ramirez-GallegoU003A2017" ref-type="bibr">Ramírez-Gallego
  et al., 2017</xref>). For its properties, data streams have to be
  processed and analyzed online. However, as it is potentially
  unbounded, data streams probabilistic distribution changes over time,
  the so-called Concept Drift phenomenon. This phenomenon turns the
  online data process and analysis completely dynamic. Using
  classification algorithms is one approach to learn from data streams,
  as it classifies data into different classes for future decisions.
  Nevertheless, data streams high dimensionality imposes a challenge on
  the classification process, since it increases both computational cost
  and time, as well as aggravate the concept drift impacts. To solve
  this problem, online feature selection algorithms have been proposed
  to reduce data streams dimensionality by removing irrelevant and
  redundant attributes from data streams. As shown in the figure below,
  feature selection methods affect the classification process in
  multiple forms. Using the appropriate method is an important step in
  the learning process, especially when handling the concept drift
  phenomenon.</p>
  <fig>
    <caption><p>Accuracy over time.</p></caption>
    <graphic mimetype="application" mime-subtype="eps" xlink:href="acc_usenet1.eps" xlink:title="" />
  </fig>
</sec>
<sec id="library-design">
  <title>Library design</title>
  <p>Using a feature selection method is optional in
  <monospace>MOAFS</monospace>. If no method is defined, the base
  classifier (Naïve Bayes) performs classification in a standard
  approach, using all available features. On the other hand, if a
  feature selection algorithm is selected, it determines the most
  relevant features before the classification step. Then, the method
  transfers the selected subset of features to the base classifier which
  then performs classification using only the given subset of features.
  The figure below presents a flowchart example of this process.
  Therefore, with <monospace>MOAFS</monospace>, it is possible to verify
  which feature selection method is more suitable under a specific
  scenario.</p>
  <fig>
    <caption><p>MOAFS flowchart example.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="ilustration.png" xlink:title="" />
  </fig>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was supported by the Brazilian Coordination for the
  Improvement of Higher Education Personnel (CAPES).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Ramirez-GallegoU003A2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Ramírez-Gallego</surname><given-names>Sergio</given-names></name>
          <name><surname>Krawczyk</surname><given-names>Bartosz</given-names></name>
          <name><surname>García</surname><given-names>Salvador</given-names></name>
          <name><surname>Woźniak</surname><given-names>Michał</given-names></name>
          <name><surname>Herrera</surname><given-names>Francisco</given-names></name>
        </person-group>
        <article-title>A survey on data preprocessing for data stream mining: Current status and future directions</article-title>
        <source>Neurocomputing</source>
        <year iso-8601-date="2017">2017</year>
        <volume>239</volume>
        <issn>0925-2312</issn>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2017.01.078</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-PearsonU003A1990">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Pearson</surname><given-names>Karl</given-names></name>
        </person-group>
        <article-title>On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling</article-title>
        <source>Breakthroughs in statistics: Methodology and distribution</source>
        <person-group person-group-type="editor">
          <name><surname>Kotz</surname><given-names>Samuel</given-names></name>
          <name><surname>Johnson</surname><given-names>Norman L.</given-names></name>
        </person-group>
        <publisher-name>Springer New York</publisher-name>
        <publisher-loc>New York, NY</publisher-loc>
        <year iso-8601-date="1992">1992</year>
        <isbn>978-1-4612-4380-9</isbn>
        <pub-id pub-id-type="doi">10.1007/978-1-4612-4380-9_2</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-CramerU003A1946">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Cramer</surname><given-names>Harald</given-names></name>
        </person-group>
        <source>Mathematical methods of statistics</source>
        <publisher-name>Princeton University Press</publisher-name>
        <publisher-loc>Princeton, NJ</publisher-loc>
        <year iso-8601-date="1946">1946</year>
      </element-citation>
    </ref>
    <ref id="ref-CarvalhoU003A2006">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Carvalho</surname><given-names>Vitor R.</given-names></name>
          <name><surname>Cohen</surname><given-names>William W.</given-names></name>
        </person-group>
        <article-title>Single-pass online learning: Performance, voting schemes and online feature selection</article-title>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2006">2006</year>
        <isbn>1-59593-339-5</isbn>
        <pub-id pub-id-type="doi">10.1145/1150402.1150466</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-WangU003A2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wang</surname><given-names>Jialei</given-names></name>
          <name><surname>Zhao</surname><given-names>Peilin</given-names></name>
          <name><surname>Hoi</surname><given-names>Steven C. H.</given-names></name>
          <name><surname>Jin</surname><given-names>Rong</given-names></name>
        </person-group>
        <article-title>Online feature selection and its applications</article-title>
        <source>IEEE Transactions on Knowledge and Data Engineering</source>
        <year iso-8601-date="2014">2014</year>
        <volume>26</volume>
        <issue>3</issue>
        <issn>1041--4347</issn>
        <pub-id pub-id-type="doi">10.1109/TKDE.2013.32</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-QuinlanU003A1986">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Quinlan</surname><given-names>J. R.</given-names></name>
        </person-group>
        <article-title>Induction of Decision Trees</article-title>
        <source>Machine Learning</source>
        <year iso-8601-date="1986">1986</year>
        <volume>1</volume>
        <issue>1</issue>
        <issn>1573-0565</issn>
        <pub-id pub-id-type="doi">10.1023/A:1022643204877</pub-id>
        <pub-id pub-id-type="pmid">17050186</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-YuU003A2003">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Yu</surname><given-names>Lei</given-names></name>
          <name><surname>Liu</surname><given-names>Huan</given-names></name>
        </person-group>
        <article-title>Feature selection for high-dimensional data: A fast correlation-based filter solution</article-title>
        <person-group person-group-type="editor">
          <name><surname>Fawcett</surname><given-names>T.</given-names></name>
          <name><surname>Mishra</surname><given-names>N.</given-names></name>
        </person-group>
        <publisher-name>Scopus</publisher-name>
        <publisher-loc>Washington</publisher-loc>
        <year iso-8601-date="2003">2003</year>
        <volume>2</volume>
        <isbn>1577351894</isbn>
      </element-citation>
    </ref>
    <ref id="ref-BifetU003A2010">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bifet</surname><given-names>Albert</given-names></name>
          <name><surname>Holmes</surname><given-names>Geoff</given-names></name>
          <name><surname>Kirkby</surname><given-names>Richard</given-names></name>
          <name><surname>Pfahringer</surname><given-names>Bernhard</given-names></name>
        </person-group>
        <article-title>MOA: Massive online analysis</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2010">2010</year>
        <volume>11</volume>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

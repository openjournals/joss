<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1166</article-id>
<article-id pub-id-type="doi">10.21105/joss.01166</article-id>
<title-group>
<article-title>MIDI.jl: Simple and intuitive handling of MIDI
data.</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6427-2385</contrib-id>
<string-name>George Datseris</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Joel Hobson</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Max Planck Institute for Dynamics and
Self-Organization</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Physics, Georg-August-Universität
Göttingen</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Roadmunk Inc.</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-12-21">
<day>21</day>
<month>12</month>
<year>2018</year>
</pub-date>
<volume>4</volume>
<issue>35</issue>
<fpage>1166</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>music</kwd>
<kwd>MIDI</kwd>
<kwd>midi</kwd>
<kwd>note</kwd>
<kwd>notes</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="introduction">
  <title>Introduction</title>
  <p><bold>MIDI.jl</bold> is a Julia Bezanson et al.
  (<xref alt="2017" rid="ref-Julia" ref-type="bibr">2017</xref>) package
  for reading, writing and analyzing
  <ext-link ext-link-type="uri" xlink:href="https://www.midi.org/specifications">MIDI</ext-link>
  data. In this paper, we are briefly overviewing versions
  <monospace>1.1.0</monospace> or later for <bold>MIDI.jl</bold>.</p>
  <p>MIDI (Music Instrument Digital Interface) is a data format created
  to transmit music data across devices and computers. The
  <ext-link ext-link-type="uri" xlink:href="https://www.midi.org/specifications">actual
  MIDI interface</ext-link> is low-level, directly translating all music
  information to and from byte chunks. <bold>MIDI.jl</bold> exposes all
  this low-level interface, but it also builds a useable high-level
  interface on top of that. This makes reading MIDI data intuitive and
  convenient, as we demonstrate in the following examples.</p>
  <p>All functionality of <bold>MIDI.jl</bold> is well documented and
  hosted online:
  https://juliamusic.github.io/JuliaMusic_documentation.jl/latest/.
  Besides documentation of functions there are plenty of useful real
  world examples.</p>
</sec>
<sec id="intuitive-and-simple-interface">
  <title>Intuitive and Simple Interface</title>
  <p>The biggest strength of <bold>MIDI.jl</bold> is the ability to
  transform the raw MIDI data in a format that is human-readable,
  intuitive and simple to use and manipulate. In addition, the
  high-level interface does not require knowledge of which exact MIDI
  code corresponds to which exact MIDI command.</p>
  <p>What makes this possible is the data structures we have designed in
  order to provide easier handling of MIDI files. The most important
  data structure is the
  <monospace>Note</monospace>/<monospace>Notes</monospace>. A music note
  can be (in its most basic level) deconstructed into just four numbers:
  the temporal position the note is played in, the duration, the pitch,
  and the intensity (strength with which the note is played, also called
  velocity). A <monospace>Note</monospace> is a data structure that has
  these four “quantities” as its “fields”. All of these are accessible
  immediately with e.g., <monospace>Note.position</monospace> and their
  values can be mutated in place.</p>
  <p>These aspects can be deduced from the raw MIDI format with a lot of
  analyzing of bytes. However, in <bold>MIDI.jl</bold> we provide a
  simple function:</p>
  <code language="julia">getnotes(midi, args...)</code>
  <p>which obtains all note-specific information and stores it as a
  vector of notes, which we call <monospace>Notes</monospace>. This is
  very convenient, as to “identify” a note in the MIDI format, one needs
  to first identify two different streams of bytes; one denotes the
  start and the other the end of the note. This quickly becomes tedious,
  but <monospace>getnotes</monospace> does not expose all these details
  to the user.</p>
</sec>
<sec id="extensions">
  <title>Extensions</title>
  <p>The easy-to-use high-level interface allows <bold>MIDI.jl</bold> to
  be extendable. For instance, in another software package
  <bold>MusicManipulations.jl</bold> we provide general functions for
  manipulating (and further analyzing) music data. For example, the
  function <monospace>quantize</monospace> from the package
  <bold>MusicManipulations.jl</bold> allows the user to quantize any
  <monospace>Notes</monospace> instance to any grid.</p>
  <p>This functionality is offered by Digital Audio Workstations, like
  the software Cubase, but we offer ways to do it programmatically
  instead. Many other helpful functions are contained in
  <bold>MusicManipulations.jl</bold>, and for further reading we point
  to the official documentation of the
  <ext-link ext-link-type="uri" xlink:href="https://juliamusic.github.io/JuliaMusic_documentation.jl/latest/">JuliaMusic</ext-link>
  GitHub organization, which hosts both <bold>MIDI.jl</bold> and
  <bold>MusicManipulations.jl</bold>, as well as other useful
  packages.</p>
</sec>
<sec id="scientific-application">
  <title>Scientific Application</title>
  <p>Microtiming deviations are defined as temporal deviations below the
  phrase level, typically in the millisecond range. These have been
  studied extensively in the literature and their importance and
  influence are debated strongly, see Madison et al.
  (<xref alt="2011" rid="ref-Madison2011" ref-type="bibr">2011</xref>),
  Butterfield
  (<xref alt="2010" rid="ref-Butterfield2010" ref-type="bibr">2010</xref>),
  Frühauf et al.
  (<xref alt="2013" rid="ref-Fruehauf2013" ref-type="bibr">2013</xref>),
  Davies et al.
  (<xref alt="2013" rid="ref-Davies2013" ref-type="bibr">2013</xref>),
  Senn et al.
  (<xref alt="2016" rid="ref-Senn2016" ref-type="bibr">2016</xref>),
  Hofmann et al.
  (<xref alt="2017" rid="ref-Hofmann2017" ref-type="bibr">2017</xref>)
  and references therein.</p>
  <p>Qualitative studies of these microtiming deviations have been done
  extensively by Geisel and coworkers Holger Hennig et al.
  (<xref alt="2011" rid="ref-Hennig2011" ref-type="bibr">2011</xref>),
  H. Hennig
  (<xref alt="2014" rid="ref-Hennig2014" ref-type="bibr">2014</xref>),
  Räsänen et al.
  (<xref alt="2015" rid="ref-Raesaenen2015" ref-type="bibr">2015</xref>),
  Sogorski et al.
  (<xref alt="2018" rid="ref-Sogorski2018" ref-type="bibr">2018</xref>).
  A crucial finding is that the sequence of such deviations is not
  random but power-law correlated. In addition, there is strong evidence
  that their distribution is normal (Gaussian).</p>
  <p>In the following, we will compute the distribution of the
  microtiming deviations of a piano track (played by a professional
  pianist) and show that indeed it approximates a normal
  distribution.</p>
  <p>We first load the notes of the piano track:</p>
  <code language="julia">using MusicManipulations # Re-exports MIDI
midi = readMIDIFile(testmidi()) # test midi file

# Track number 4 is the piano track
piano = midi.tracks[4]
notes = getnotes(piano, midi.tpq)</code>
  <preformat>533 Notes with tpq=960
 Note F4  | vel = 69  | pos = 7427, dur = 181
 Note A♯4 | vel = 85  | pos = 7760, dur = 450
 Note D5  | vel = 91  | pos = 8319, dur = 356
 Note D4  | vel = 88  | pos = 8323, dur = 314
 Note G♯3 | vel = 88  | pos = 8327, dur = 358
 Note A♯4 | vel = 76  | pos = 8694, dur = 575
 Note G4  | vel = 66  | pos = 9281, dur = 273
 Note A♯4 | vel = 94  | pos = 9594, dur = 666
 Note F♯3 | vel = 98  | pos = 10189, dur = 307
 Note C4  | vel = 87  | pos = 10206, dur = 285
  ⋮</preformat>
  <p>We then compute their microtiming deviations. For the purpose of
  this article, we define the microtiming deviations of a note as the
  distance of the position of a note from its position when quantized on
  a 8th-note triplet grid (the pianist was playing triplets in the above
  midi file).</p>
  <p>We now compute those microtiming deviations, using the function
  <monospace>quantize</monospace> from
  <bold>MusicManipulations.jl</bold></p>
  <code language="julia">grid = 0:(1//3):1 # grid to quantize on, see documentation
qnotes = quantize(notes, grid)
mtds = positions(notes) .- positions(qnotes)
mtds_ms = mtds .* ms_per_tick(midi)</code>
  <preformat>533-element Array{Float64,1}:
  32.21150624999999
  38.461499999999994
   ⋮
  12.499987499999998
  13.461524999999998</preformat>
  <p>A plot of the histogram of these is presented in Figure 1. Even if
  produced with an extremely small pool of data, the plot follows the
  existing evidence that the distribution of the microtiming deviations
  follows a normal distribution.</p>
  <fig>
    <caption><p>Histogram of the microtiming deviations of a simple
    piano recording.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="mtd_hist.png" xlink:title="" />
  </fig>
</sec>
<sec id="conclusions">
  <title>Conclusions</title>
  <p>In conclusion, <bold>MIDI.jl</bold> is a useful package with
  intuitive usage, as we have demonstrated by our simple application. In
  addition, it has plenty more use for scientific applications. We
  currently have a manuscript titled <italic>Does it Swing? Microtiming
  Deviations and Swing Feeling in Jazz</italic> under review, where we
  have used <bold>MIDI.jl</bold> and its extensions to not only read but
  also manipulate microtiming deviations of human recordings in order to
  inquire about the impact of microtiming deviations in the listening
  experience.</p>
</sec>
<sec id="related-software">
  <title>Related Software</title>
  <p>There is existing software that offers functionality similar, but
  not identical, to <bold>MIDI.jl</bold>. Some of these software
  are:</p>
  <list list-type="bullet">
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://github.com/mido/mido">mido</ext-link></p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://github.com/vishnubob/python-midi">python-midi</ext-link></p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="https://github.com/craffel/pretty-midi">pretty-midi</ext-link>
      (<xref alt="Raffel &amp; Ellis, 2014" rid="ref-Raffel" ref-type="bibr">Raffel
      &amp; Ellis, 2014</xref>).</p>
    </list-item>
  </list>
  <p>Notable differences between <bold>MIDI.jl</bold> and these
  libraries include (but are not limited to):</p>
  <list list-type="order">
    <list-item>
      <p>The <monospace>Notes</monospace> data structure and
      <monospace>getnotes</monospace> functionality that exists in
      <bold>MIDI.jl</bold>. Although the package
      <monospace>pretty-midi</monospace> contains similar functionality,
      it lacks the channel property.</p>
    </list-item>
    <list-item>
      <p><bold>MIDI.jl</bold> is extended further into higher level
      applications like the ones offered by
      <bold>MusicManipulations.jl</bold> or the module
      <monospace>MotifSequenceGenerator</monospace> that can create
      specially random sequences of notes.</p>
    </list-item>
    <list-item>
      <p>The fact that <bold>MIDI.jl</bold> is written for the Julia
      programming language.</p>
    </list-item>
    <list-item>
      <p>The fact that <bold>MIDI.jl</bold> is the only package for
      handling MIDI data for the Julia programming language.</p>
    </list-item>
    <list-item>
      <p><bold>MIDI.jl</bold> has proper, multi-page and multi-example
      documentation that is hosted online and is automatically updated
      with every commit to the repository.</p>
    </list-item>
    <list-item>
      <p><bold>MIDI.jl</bold> does not currently have the so-called
      “piano roll” functionality, which plots notes as in a Digital
      Audio Workstation.</p>
    </list-item>
    <list-item>
      <p>Sequencer functionality, which has been implemented in the
      <monospace>python-midi</monospace> package, is currently lacking
      in <bold>MIDI.jl</bold>.</p>
    </list-item>
    <list-item>
      <p>Basic tempo estimation, which has been implemented in
      <monospace>pretty-midi</monospace>, is also absent in
      <bold>MIDI.jl</bold>.</p>
    </list-item>
  </list>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Julia">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bezanson</surname><given-names>Jeff</given-names></name>
          <name><surname>Edelman</surname><given-names>Alan</given-names></name>
          <name><surname>Karpinski</surname><given-names>Stefan</given-names></name>
          <name><surname>Shah</surname><given-names>Viral B.</given-names></name>
        </person-group>
        <article-title>Julia: A fresh approach to numerical computing</article-title>
        <source>SIAM Review</source>
        <year iso-8601-date="2017">2017</year>
        <volume>59</volume>
        <issue>1</issue>
        <uri>
                https://doi.org/10.1137/141000671

        </uri>
        <pub-id pub-id-type="doi">10.1137/141000671</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Madison2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Madison</surname><given-names>Guy</given-names></name>
          <name><surname>Gouyon</surname><given-names>Fabien</given-names></name>
          <name><surname>Ullén</surname><given-names>Fredrik</given-names></name>
          <name><surname>Hörnström</surname><given-names>Kalle</given-names></name>
        </person-group>
        <article-title>Modeling the tendency for music to induce movement in humans: First correlations with low-level audio descriptors across music genres.</article-title>
        <source>J. Exp. Psychol. Hum. Percept. Perform.</source>
        <publisher-name>American Psychological Association</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>37</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1037/a0024323</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Butterfield2010">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Butterfield</surname><given-names>Matthew</given-names></name>
        </person-group>
        <article-title>Participatory discrepancies and the perception of beats in jazz</article-title>
        <source>Music Perception: An Interdisciplinary Journal</source>
        <publisher-name>University of California Press Journals</publisher-name>
        <year iso-8601-date="2010">2010</year>
        <volume>27</volume>
        <issue>3</issue>
        <issn>0730-7829</issn>
        <pub-id pub-id-type="doi">10.1525/mp.2010.27.3.157</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Fruehauf2013">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Frühauf</surname><given-names>Jan</given-names></name>
          <name><surname>Kopiez</surname><given-names>Reinhard</given-names></name>
          <name><surname>Platz</surname><given-names>Friedrich</given-names></name>
        </person-group>
        <article-title>Music on the timing grid: The influence of microtiming on the perceived groove quality of a simple drum pattern performance</article-title>
        <source>Musicae Scientiae</source>
        <year iso-8601-date="2013">2013</year>
        <volume>17</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1177/1029864913486793</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Davies2013">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Davies</surname><given-names>Matthew</given-names></name>
          <name><surname>Madison</surname><given-names>Guy</given-names></name>
          <name><surname>Silva</surname><given-names>Pedro</given-names></name>
          <name><surname>Gouyon</surname><given-names>Fabien</given-names></name>
        </person-group>
        <article-title>The effect of microtiming deviations on the perception of groove in short rhythms</article-title>
        <source>Music Perception: An Interdisciplinary Journal</source>
        <publisher-name>University of California Press Journals</publisher-name>
        <year iso-8601-date="2013">2013</year>
        <volume>30</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1525/mp.2013.30.5.497</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Senn2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Senn</surname><given-names>Olivier</given-names></name>
          <name><surname>Kilchenmann</surname><given-names>Lorenz</given-names></name>
          <name><surname>Von Georgi</surname><given-names>Richard</given-names></name>
          <name><surname>Bullerjahn</surname><given-names>Claudia</given-names></name>
        </person-group>
        <article-title>The effect of expert performance microtiming on listeners’ experience of groove in swing or funk music</article-title>
        <source>Front. Psychol.</source>
        <publisher-name>Frontiers Media SA</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>7</volume>
        <issn>1664-1078</issn>
        <pub-id pub-id-type="doi">10.3389/fpsyg.2016.01487</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Hofmann2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hofmann</surname><given-names>Alex</given-names></name>
          <name><surname>Wesolowski</surname><given-names>Brian C</given-names></name>
          <name><surname>Goebl</surname><given-names>Werner</given-names></name>
        </person-group>
        <article-title>The tight-interlocked rhythm section: Production and perception of synchronisation in jazz trio performance</article-title>
        <source>Journal of new music research</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <volume>46</volume>
        <issue>4</issue>
        <pub-id pub-id-type="doi">10.1080/09298215.2017.1355394</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Hennig2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hennig</surname><given-names>Holger</given-names></name>
          <name><surname>Fleischmann</surname><given-names>Ragnar</given-names></name>
          <name><surname>Fredebohm</surname><given-names>Anneke</given-names></name>
          <name><surname>Hagmayer</surname><given-names>York</given-names></name>
          <name><surname>Nagler</surname><given-names>Jan</given-names></name>
          <name><surname>Witt</surname><given-names>Annette</given-names></name>
          <name><surname>Theis</surname><given-names>Fabian J</given-names></name>
          <name><surname>Geisel</surname><given-names>Theo</given-names></name>
        </person-group>
        <article-title>The nature and perception of fluctuations in human musical rhythms</article-title>
        <source>PLoS One</source>
        <publisher-name>Public Library of Science</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>6</volume>
        <issue>10</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0026457</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Raesaenen2015">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Räsänen</surname><given-names>Esa</given-names></name>
          <name><surname>Pulkkinen</surname><given-names>Otto</given-names></name>
          <name><surname>Virtanen</surname><given-names>Tuomas</given-names></name>
          <name><surname>Zollner</surname><given-names>Manfred</given-names></name>
          <name><surname>Hennig</surname><given-names>Holger</given-names></name>
        </person-group>
        <article-title>Fluctuations of hi-hat timing and dynamics in a virtuoso drum track of a popular music recording</article-title>
        <source>PLoS One</source>
        <publisher-name>Public Library of Science</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>10</volume>
        <issue>6</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0127902</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Sogorski2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Sogorski</surname><given-names>Mathias</given-names></name>
          <name><surname>Geisel</surname><given-names>Theo</given-names></name>
          <name><surname>Priesemann</surname><given-names>Viola</given-names></name>
        </person-group>
        <article-title>Correlated microtiming deviations in jazz and rock music</article-title>
        <source>PLoS One</source>
        <person-group person-group-type="editor">
          <name><surname>Hernandez-Lemus</surname><given-names>Enrique</given-names></name>
        </person-group>
        <year iso-8601-date="2018-01">2018</year><month>01</month>
        <volume>13</volume>
        <issue>1</issue>
        <isbn>1111111111</isbn>
        <issn>1932-6203</issn>
        <uri>http://arxiv.org/abs/1710.05608 http://dx.plos.org/10.1371/journal.pone.0186361</uri>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0186361</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Hennig2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hennig</surname><given-names>H.</given-names></name>
        </person-group>
        <article-title>Synchronization in human musical rhythms and mutually interacting complex systems</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year iso-8601-date="2014">2014</year>
        <volume>111</volume>
        <issue>36</issue>
        <isbn>1324142111</isbn>
        <issn>0027-8424</issn>
        <uri>http://www.pnas.org/cgi/doi/10.1073/pnas.1324142111</uri>
        <pub-id pub-id-type="doi">10.1073/pnas.1324142111</pub-id>
        <pub-id pub-id-type="pmid">25114228</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Raffel">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Raffel</surname><given-names>Colin</given-names></name>
          <name><surname>Ellis</surname><given-names>Daniel PW</given-names></name>
        </person-group>
        <article-title>Intuitive analysis, creation and manipulation of MIDI data with pretty_midi</article-title>
        <source>15th international society for music information retrieval conference late breaking and demo papers</source>
        <year iso-8601-date="2014">2014</year>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3635</article-id>
<article-id pub-id-type="doi">10.21105/joss.03635</article-id>
<title-group>
<article-title>AstronomicAL: an interactive dashboard for visualisation,
integration and classification of data with Active
Learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-8885-4443</contrib-id>
<string-name>Grant Stevens</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9686-254X</contrib-id>
<string-name>Sotiria Fotopoulou</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Malcolm N. Bremer</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Oliver Ray</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Computer Science, Merchant Venturers
Building, University of Bristol, Woodland Road, Bristol, BS8
1UB</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>School of Physics, HH Wills Physics Laboratory, University
of Bristol, Tyndall Avenue, Bristol, BS8 1TL</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-08-05">
<day>5</day>
<month>8</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>65</issue>
<fpage>3635</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>astronomy</kwd>
<kwd>machine learning</kwd>
<kwd>active learning</kwd>
<kwd>labelling</kwd>
<kwd>classification</kwd>
<kwd>software</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>AstronomicAL is a human-in-the-loop interactive labelling and
  training dashboard that allows users to create reliable datasets and
  robust classifiers using active learning. This technique prioritises
  data that offer high information gain, leading to improved performance
  using substantially less data. The system allows users to visualise
  and integrate data from different sources and deal with incorrect or
  missing labels and imbalanced class sizes. AstronomicAL enables
  experts to visualise domain-specific plots and key information
  relating both to broader context and details of a point of interest
  drawn from a variety of data sources, ensuring reliable labels. In
  addition, AstronomicAL provides functionality to explore all aspects
  of the training process, including custom models and query strategies.
  This makes the software a tool for experimenting with both
  domain-specific classifications and more general-purpose machine
  learning strategies. We illustrate using the system with an
  astronomical dataset due to the field’s immediate need; however,
  AstronomicAL has been designed for datasets from any discipline.
  Finally, by exporting a simple configuration file, entire layouts,
  models, and assigned labels can be shared with the community. This
  allows for complete transparency and ensures that the process of
  reproducing results is effortless.</p>
  <fig>
    <caption><p>AstronomicAL workflow from the perspective of an
    astronomy user. Each part of the workflow improves the reliability
    of labels, leading to enhanced performance of any classifiers
    produced. AstronomicAL allows the user to tailor this workflow
    specifically to their domain with its modular and extensible design.
    <styled-content id="figU003Aworkflow"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paper/astronomicAL_diagram_portrait.png" xlink:title="" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Active learning has proven to be an effective method in machine
  learning over the last few decades
  (<xref alt="Baldridge &amp; Palmer, 2009" rid="ref-baldridge2009well" ref-type="bibr">Baldridge
  &amp; Palmer, 2009</xref>;
  <xref alt="Gal et al., 2017" rid="ref-gal2017deep" ref-type="bibr">Gal
  et al., 2017</xref>;
  <xref alt="Settles &amp; Craven, 2008" rid="ref-settles2008analysis" ref-type="bibr">Settles
  &amp; Craven, 2008</xref>). In more recent years, there has been a
  growing adoption in all domains of scientific research
  (<xref alt="Eisenstein, 2020" rid="ref-eisenstein2020active" ref-type="bibr">Eisenstein,
  2020</xref>;
  <xref alt="Walmsley et al., 2020" rid="ref-walmsley2020galaxy" ref-type="bibr">Walmsley
  et al., 2020</xref>). This is evident by the increasing popularity of
  machine learning frameworks offering an active learning
  element<xref ref-type="fn" rid="fn1">1</xref>. However, the purpose of
  these frameworks is to allow users to integrate active learning into
  their machine learning workflows. Any additional functionality such as
  data exploration and interactive labelling is left to the user to
  implement. Due to each domain’s varying requirements, researchers will
  often need multiple specialised but disjoint tools that hinder
  effective and efficient interactive labelling. When data from multiple
  sources is required, presenting all the information in one system is
  essential. Without a tool that combines these key features, a
  significant barrier exists to the adoption and effectiveness of active
  learning in research. AstronomicAL’s goal is to remove this barrier to
  allow more researchers to access the benefits of active learning.</p>
  <p>Active learning
  (<xref alt="Settles, 2012" rid="ref-settles2012active" ref-type="bibr">Settles,
  2012</xref>) removes the requirement for large amounts of labelled
  training data whilst still producing high accuracy models. This is
  extremely important as with ever-growing datasets; it is becoming
  impossible to manually inspect and verify ground truth used to train
  machine learning systems. The reliability of the training data limits
  the performance of any supervised learning model, so consistent
  classifications become more problematic as data sizes increase. The
  problem is exacerbated when a dataset does not contain any labelled
  data, preventing supervised learning techniques entirely. AstronomicAL
  has been developed to tackle these issues head-on and provide a
  solution for any large scientific dataset.</p>
  <p>It is common for active learning to query areas of high
  uncertainty; these are often in the boundaries between classes where
  the expert’s knowledge is required. To facilitate this
  human-in-the-loop process, AstronomicAL provides users with the
  functionality to fully explore each data point chosen. This allows
  them to inject their domain expertise directly into the training
  process, ensuring that assigned labels are both accurate and
  reliable.</p>
  <p>AstronomicAL has been extensively validated on astronomy datasets.
  These are highly representative of the issues that we anticipate will
  be found in other domains for which the tool is designed to be easily
  customisable. Such issues include the volume of data (millions of
  sources per survey), vastly imbalanced classes and ambiguous class
  definitions leading to inconsistent labelling. AstronomicAL has been
  developed to be sufficiently general for any tabular data and can be
  customised for any domain. For example, we provide the functionality
  for data fusion of catalogued data and online cutout services for
  astronomical datasets.</p>
  <p>Using its modular and extensible design, researchers can quickly
  adapt AstronomicAL for their research to allow for domain-specific
  plots, novel query strategies, and improved models. Furthermore, there
  is no requirement to be well-versed in the underlying libraries that
  the software uses. This is due to large parts of the complexity being
  abstracted whilst allowing more experienced users to access full
  customisability.</p>
  <p>As the software runs entirely locally on the user’s system,
  AstronomicAL provides a private space to experiment whilst providing a
  public mechanism to share results. By sharing only the configuration
  file, users remain in charge of distributing their potentially
  sensitive data, enabling collaboration whilst respecting privacy. The
  full workflow for AstronomicAL is shown in
  <xref alt="Figure 1" rid="figU003Aworkflow">Figure 1</xref>.</p>
  <fig>
    <caption><p>The dashboard is set up in 3 main areas. A) Active
    learning and labelling panel which controls the machine learning
    functionality. Users can train separate models for each class and
    see how each performs as additional points are added to the model.
    B) User-defined information shown for the currently active data
    point, such as specific columns, local images and online cutout
    services. C) Customisable domain-specific plots that can render
    millions of data points.
    <styled-content id="figU003Afull_layout"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paper/full_layout_browser_box.png" xlink:title="" />
  </fig>
</sec>
<sec id="active-learning-and-classification">
  <title>Active Learning and Classification</title>
  <p>Active learning utilises methods for predicting which part of the
  search space of unseen examples would be most likely to improve
  classification accuracy. By querying these key examples and presenting
  them directly to the user for inspection and labelling, active
  learning removes the reliance on non-verified data. In the optimal
  case, it provides users with simple classifications that have a high
  impact on model performance, leading to a dramatic reduction in the
  number of data points required for training a classifier.</p>
  <p>By making use of the modAL
  (<xref alt="Danka &amp; Horvath, 2018" rid="ref-modAL2018" ref-type="bibr">Danka
  &amp; Horvath, 2018</xref>) active learning framework, AstronomicAL
  allows users to take full advantage of active learning techniques,
  leading to improved classifiers. Scikit-Learn
  (<xref alt="Pedregosa et al., 2011" rid="ref-scikit-learn" ref-type="bibr">Pedregosa
  et al., 2011</xref>) models are fully supported in AstronomicAL, and
  the software will be extended to support Pytorch
  (<xref alt="Paszke et al., 2019" rid="ref-pytorch" ref-type="bibr">Paszke
  et al., 2019</xref>) and Tensorflow
  (<xref alt="Abadi et al., 2015" rid="ref-tensorflow2015-whitepaper" ref-type="bibr">Abadi
  et al., 2015</xref>) in the future.</p>
  <p>Astronomy datasets are frequently the result of the fusion of
  multiple heterogeneous data sources. Often in machine learning, only
  information that is available across all data points is usable during
  training. However, in astronomy, where <italic>any</italic> available
  information could be critical in determining an object’s true class,
  it must be used whenever this information is available. With the
  flexibility to choose which information is essential for
  classification, AstronomicAL ensures that users are presented with
  this critical information whenever available - directly leading to
  improved confidence and justifiability for any assigned labels.
  Although this extra information remains unseen by the model, by using
  AstronomicAL, we inject this information into the training process by
  labelling the data based on all the available information rather than
  just the features the model sees.</p>
  <p>In <xref alt="Figure 2" rid="figU003Afull_layout">Figure 2</xref>
  we show an example of a classification task using an extract of the
  astronomical dataset used in Fotopoulou &amp; Paltani
  (<xref alt="2018" rid="ref-Fotopoulou2018CPz" ref-type="bibr">2018</xref>).
  <xref alt="Figure 2" rid="figU003Afull_layout">Figure 2</xref> (A)
  shows the benefits of active learning where with only 30 data points
  given as training data to the model, we can classify Stars with 97.5%
  accuracy.
  <xref alt="Figure 2" rid="figU003Afull_layout">Figure 2</xref> (B)
  shows the extra information chosen by the user to improve confidence
  in the assigned labels. This information can be retrieved from web
  services or local files. In this example, we are showing the
  SDSS<xref ref-type="fn" rid="fn2">2</xref>
  (<xref alt="Ahumada et al., 2020" rid="ref-Ahumada2020DR16" ref-type="bibr">Ahumada
  et al., 2020</xref>) and FIRST<xref ref-type="fn" rid="fn3">3</xref>
  (<xref alt="Becker et al., 1995" rid="ref-Becker1995Radio" ref-type="bibr">Becker
  et al., 1995</xref>) cutout services.
  <xref alt="Figure 2" rid="figU003Afull_layout">Figure 2</xref> (C)
  shows how domain-specific plots can be created and visualised to gain
  extra insight into the data, aiding the researcher in their ability
  and confidence in labelling data points.
  <xref alt="Figure 3" rid="figU003Aactive_learning">Figure 3</xref>
  shows the model performance plots available to the user for each
  classifier being trained. These include training and validation
  correctness plots, tracking of performance scores as new data points
  are added, and a visualisation of the model’s confidence of each data
  point.</p>
  <fig>
    <caption><p>AstronomicAL allows users to view all key information
    during training. Top Left: Training set showing points that have
    been trained on, current queried point and correct and incorrect
    predictions. Top Right: Visualisation of the model’s confidence of
    each data point. Bottom Left: Validation set showing correct and
    incorrect predictions of the model. Bottom Right: The performance
    scores of the model as new points are added to the training set.
    <styled-content id="figU003Aactive_learning"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paper/active_learning_1.png" xlink:title="" />
  </fig>
</sec>
<sec id="interactivity">
  <title>Interactivity</title>
  <p>Using the Panel dashboard library
  (<xref alt="Rudiger, Artusi, et al., 2021" rid="ref-philipp_rudiger_panel_2021_4573728" ref-type="bibr">Rudiger,
  Artusi, et al., 2021</xref>), paired with Holoviews
  (<xref alt="Rudiger, Stevens, et al., 2021" rid="ref-philipp_rudiger_holoviews_2021_4581995" ref-type="bibr">Rudiger,
  Stevens, et al., 2021</xref>), Bokeh
  (<xref alt="Bokeh Development Team, 2018" rid="ref-Bokeh2018" ref-type="bibr">Bokeh
  Development Team, 2018</xref>) and Datashader
  (<xref alt="Bednar et al., 2020" rid="ref-james_a_bednar_datashader_2020_3987379" ref-type="bibr">Bednar
  et al., 2020</xref>) visualisation libraries, AstronomicAL provides
  users with interactive plots, enabling zooming and panning of millions
  of data points in real-time whilst also giving the ability to
  rearrange and resize plots dynamically to optimise screen layout.</p>
  <p>Plots are also interconnected, with any updates projected to all
  panels simultaneously, allowing analysis of how the properties of a
  particular point fit in the context of the whole dataset. This enables
  researchers to gain insight and identify trends - crucial for reliable
  labelling.</p>
  <fig>
    <caption><p>AstronomicAL enables the creation of curated test sets.
    The sample is selected according to user-defined criteria and
    verified visually. This test set can then be used during the active
    learning training process to ensure that the model will be
    sufficiently generalisable to future data.
    <styled-content id="figU003Alabelling_mode"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="paper/labelling_mode.png" xlink:title="" />
  </fig>
  <p>The interactive labelling functionality is not limited to only the
  training stage; as shown in
  <xref alt="Figure 4" rid="figU003Alabelling_mode">Figure 4</xref>,
  users can curate a labelled test set to sufficiently demonstrate the
  validity and generalisability of their model. Furthermore, to
  facilitate and encourage only assigning labels that the user trusts,
  AstronomicAL allows users to mark any example as
  <italic>unsure</italic>. Such examples are excluded from the training
  set, ensuring that all training data are of high quality.</p>
  <p>In summary, all design decisions have been in response to user
  feedback and were explicitly tailored to improve the visualisation of
  data, irrespective of the data’s specific nature, to ensure that
  AstronomicAL is a tool for any discipline.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>Grant Stevens acknowledges financial support from the UKRI for a
  Centre for Doctoral Training studentship in Interactive Artificial
  Intelligence at the University of Bristol. (EP/S022937/1)</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Bokeh2018">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>Bokeh Development Team</string-name>
        </person-group>
        <source>Bokeh: Python library for interactive visualization</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://bokeh.pydata.org/en/latest/</uri>
      </element-citation>
    </ref>
    <ref id="ref-philipp_rudiger_holoviews_2021_4581995">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Rudiger</surname><given-names>Philipp</given-names></name>
          <name><surname>Stevens</surname><given-names>Jean-Luc</given-names></name>
          <name><surname>Bednar</surname><given-names>James A.</given-names></name>
          <name><surname>Nijholt</surname><given-names>Bas</given-names></name>
          <name><surname>Mease</surname><given-names>Jon</given-names></name>
          <name><surname>Andrew</surname></name>
          <name><surname>B</surname><given-names>Chris</given-names></name>
          <name><surname>Randelhoff</surname><given-names>Achim</given-names></name>
          <name><surname>Tenner</surname><given-names>Vasco</given-names></name>
          <name><surname>maxalbert</surname></name>
          <name><surname>Kaiser</surname><given-names>Markus</given-names></name>
          <name><surname>ea42gh</surname></name>
          <name><surname>Samuels</surname><given-names>Jordan</given-names></name>
          <name><surname>stonebig</surname></name>
          <name><surname>Pevey</surname><given-names>Kim</given-names></name>
          <name><surname>LB</surname><given-names>Florian</given-names></name>
          <name><surname>Tolmie</surname><given-names>Andrew</given-names></name>
          <name><surname>Stephan</surname><given-names>Daniel</given-names></name>
          <name><surname>Hoxbro</surname></name>
          <name><surname>Bois</surname><given-names>Justin</given-names></name>
          <name><surname>Lowe</surname><given-names>Scott</given-names></name>
          <name><surname>Bampton</surname><given-names>John</given-names></name>
          <name><surname>henriqueribeiro</surname></name>
          <name><surname>ruoyu0088</surname></name>
          <name><surname>Lustig</surname><given-names>Irv</given-names></name>
          <name><surname>Klein</surname><given-names>Almar</given-names></name>
          <name><surname>Ven</surname><given-names>Bryan Van de</given-names></name>
          <name><surname>Signell</surname><given-names>Julia</given-names></name>
          <name><surname>Talirz</surname><given-names>Leopold</given-names></name>
          <name><surname>Barth</surname><given-names>Lukas</given-names></name>
        </person-group>
        <source>Holoviz/holoviews: Version 1.14.2</source>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2021-03">2021</year><month>03</month>
        <uri>https://doi.org/10.5281/zenodo.4581995</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.4581995</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-james_a_bednar_datashader_2020_3987379">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Bednar</surname><given-names>James A.</given-names></name>
          <name><surname>Crail</surname><given-names>Joseph</given-names></name>
          <name><surname>Crist-Harif</surname><given-names>Jim</given-names></name>
          <name><surname>Rudiger</surname><given-names>Philipp</given-names></name>
          <name><surname>Brener</surname><given-names>Greg</given-names></name>
          <name><surname>B</surname><given-names>Chris</given-names></name>
          <name><surname>Mease</surname><given-names>Jon</given-names></name>
          <name><surname>Signell</surname><given-names>Julia</given-names></name>
          <name><surname>Collins</surname><given-names>Brendan</given-names></name>
          <name><surname>Stevens</surname><given-names>Jean-Luc</given-names></name>
          <name><surname>Bird</surname><given-names>Sarah</given-names></name>
          <name><surname>kbowen</surname></name>
          <name><surname>maihde</surname></name>
          <name><surname>Thorve</surname><given-names>Ajay</given-names></name>
          <name><surname>Ahmadia</surname><given-names>Aron</given-names></name>
          <name><surname>Jr</surname><given-names>Barry A Bragg</given-names></name>
          <name><surname>Brandt</surname><given-names>Carlos H</given-names></name>
          <name><surname>Tolboom</surname><given-names>Clemens</given-names></name>
          <name><surname>G.</surname><given-names>Enno</given-names></name>
          <name><surname>Bourbeau</surname><given-names>James</given-names></name>
          <name><surname>Schmidt</surname><given-names>Johannes Jörg</given-names></name>
          <name><surname>Delicious.</surname><given-names>Making GitHub</given-names></name>
          <name><surname>Raifer</surname><given-names>Martin</given-names></name>
          <name><surname>Paprocki</surname><given-names>Mateusz</given-names></name>
          <name><surname>Hoffman</surname><given-names>Sam</given-names></name>
          <name><surname>Lane</surname><given-names>Sean</given-names></name>
          <name><surname>Haenel</surname><given-names>Valentin</given-names></name>
          <name><surname>Vinay</surname></name>
          <name><surname>lancelot1969</surname></name>
          <name><surname>narendramukherjee</surname></name>
        </person-group>
        <source>Holoviz/datashader: Version 0.11.1</source>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2020-08">2020</year><month>08</month>
        <uri>https://doi.org/10.5281/zenodo.3987379</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.3987379</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-philipp_rudiger_panel_2021_4573728">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Rudiger</surname><given-names>Philipp</given-names></name>
          <name><surname>Artusi</surname><given-names>Xavier</given-names></name>
          <name><surname>Bednar</surname><given-names>James A.</given-names></name>
          <name><surname>Madsen</surname><given-names>Marc Skov</given-names></name>
          <name><surname>B</surname><given-names>Chris</given-names></name>
          <name><surname>Signell</surname><given-names>Julia</given-names></name>
          <name><surname>Stevens</surname><given-names>Jean-Luc</given-names></name>
          <name><surname>Liquet</surname><given-names>Maxime</given-names></name>
          <name><surname>Hoxbro</surname></name>
          <name><surname>Mease</surname><given-names>Jon</given-names></name>
          <name><surname>Andrew</surname></name>
          <name><surname>Arne</surname></name>
          <name><surname>Paprocki</surname><given-names>Mateusz</given-names></name>
          <name><surname>kbowen</surname></name>
          <name><surname>Jung</surname><given-names>Ed</given-names></name>
          <name><surname>Amanieu</surname><given-names>Hugues-Yanis</given-names></name>
          <name><surname>Winkelmann</surname><given-names>Julius</given-names></name>
          <name><surname>Talirz</surname><given-names>Leopold</given-names></name>
          <name><surname>A</surname><given-names>Pav</given-names></name>
          <name><surname>Randelhoff</surname><given-names>Achim</given-names></name>
          <name><surname>Sullivan</surname><given-names>Bane</given-names></name>
          <name><surname>Barhak</surname><given-names>Jacob</given-names></name>
          <name><surname>Ghenzi</surname><given-names>Nestor</given-names></name>
          <name><surname>hoseppan</surname></name>
          <name><surname>kleavor</surname></name>
          <name><surname>miliante</surname></name>
          <name><surname>Mulpuri</surname><given-names>Ravi</given-names></name>
          <name><surname>Bischof</surname><given-names>Garrett</given-names></name>
          <name><surname>Thorve</surname><given-names>Ajay</given-names></name>
        </person-group>
        <source>Holoviz/panel: Version 0.11.0</source>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2021-03">2021</year><month>03</month>
        <uri>https://doi.org/10.5281/zenodo.4573728</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.4573728</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-modAL2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Danka</surname><given-names>Tivadar</given-names></name>
          <name><surname>Horvath</surname><given-names>Peter</given-names></name>
        </person-group>
        <article-title>ModAL: A modular active learning framework for Python</article-title>
        <year iso-8601-date="2018">2018</year>
        <uri>https://github.com/modAL-python/modAL</uri>
      </element-citation>
    </ref>
    <ref id="ref-scikit-learn">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-settles2012active">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Settles</surname><given-names>Burr</given-names></name>
        </person-group>
        <article-title>Active learning</article-title>
        <source>Synthesis lectures on artificial intelligence and machine learning</source>
        <publisher-name>Morgan &amp; Claypool Publishers</publisher-name>
        <year iso-8601-date="2012">2012</year>
        <volume>6</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.2200/S00429ED1V01Y201207AIM018</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Fotopoulou2018CPz">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fotopoulou</surname><given-names>S.</given-names></name>
          <name><surname>Paltani</surname><given-names>S.</given-names></name>
        </person-group>
        <article-title>CPz: Classification-aided photometric-redshift estimation</article-title>
        <source></source>
        <year iso-8601-date="2018-10">2018</year><month>10</month>
        <volume>619</volume>
        <uri>https://arxiv.org/abs/1808.04977</uri>
        <pub-id pub-id-type="doi">10.1051/0004-6361/201730763</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Becker1995Radio">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Becker</surname><given-names>Robert H.</given-names></name>
          <name><surname>White</surname><given-names>Richard L.</given-names></name>
          <name><surname>Helfand</surname><given-names>David J.</given-names></name>
        </person-group>
        <article-title>The FIRST Survey: Faint Images of the Radio Sky at Twenty Centimeters</article-title>
        <source></source>
        <year iso-8601-date="1995-09">1995</year><month>09</month>
        <volume>450</volume>
        <pub-id pub-id-type="doi">10.1086/176166</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Ahumada2020DR16">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Ahumada</surname><given-names>Romina</given-names></name>
          <name><surname>Prieto</surname><given-names>Carlos Allende</given-names></name>
          <name><surname>Almeida</surname><given-names>Andrés</given-names></name>
          <name><surname>Anders</surname><given-names>Friedrich</given-names></name>
          <name><surname>Anderson</surname><given-names>Scott F.</given-names></name>
          <name><surname>Andrews</surname><given-names>Brett H.</given-names></name>
          <name><surname>Anguiano</surname><given-names>Borja</given-names></name>
          <name><surname>Arcodia</surname><given-names>Riccardo</given-names></name>
          <name><surname>Armengaud</surname><given-names>Eric</given-names></name>
          <name><surname>Aubert</surname><given-names>Marie</given-names></name>
        </person-group>
        <article-title>The 16th Data Release of the Sloan Digital Sky Surveys: First Release from the APOGEE-2 Southern Survey and Full Release of eBOSS Spectra</article-title>
        <source></source>
        <year iso-8601-date="2020-07">2020</year><month>07</month>
        <volume>249</volume>
        <issue>1</issue>
        <uri>https://arxiv.org/abs/1912.02905</uri>
        <pub-id pub-id-type="doi">10.3847/1538-4365/ab929e</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-pytorch">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Paszke</surname><given-names>Adam</given-names></name>
          <name><surname>Gross</surname><given-names>Sam</given-names></name>
          <name><surname>Massa</surname><given-names>Francisco</given-names></name>
          <name><surname>Lerer</surname><given-names>Adam</given-names></name>
          <name><surname>Bradbury</surname><given-names>James</given-names></name>
          <name><surname>Chanan</surname><given-names>Gregory</given-names></name>
          <name><surname>Killeen</surname><given-names>Trevor</given-names></name>
          <name><surname>Lin</surname><given-names>Zeming</given-names></name>
          <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>
          <name><surname>Antiga</surname><given-names>Luca</given-names></name>
          <name><surname>Desmaison</surname><given-names>Alban</given-names></name>
          <name><surname>Kopf</surname><given-names>Andreas</given-names></name>
          <name><surname>Yang</surname><given-names>Edward</given-names></name>
          <name><surname>DeVito</surname><given-names>Zachary</given-names></name>
          <name><surname>Raison</surname><given-names>Martin</given-names></name>
          <name><surname>Tejani</surname><given-names>Alykhan</given-names></name>
          <name><surname>Chilamkurthy</surname><given-names>Sasank</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Fang</surname><given-names>Lu</given-names></name>
          <name><surname>Bai</surname><given-names>Junjie</given-names></name>
          <name><surname>Chintala</surname><given-names>Soumith</given-names></name>
        </person-group>
        <article-title>PyTorch: An imperative style, high-performance deep learning library</article-title>
        <source>Advances in neural information processing systems 32</source>
        <person-group person-group-type="editor">
          <name><surname>Wallach</surname><given-names>H.</given-names></name>
          <name><surname>Larochelle</surname><given-names>H.</given-names></name>
          <name><surname>Beygelzimer</surname><given-names>A.</given-names></name>
          <name><surname>dAlché-Buc</surname><given-names>F.</given-names></name>
          <name><surname>Fox</surname><given-names>E.</given-names></name>
          <name><surname>Garnett</surname><given-names>R.</given-names></name>
        </person-group>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <uri>http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-tensorflow2015-whitepaper">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Abadi</surname><given-names>Martı́n</given-names></name>
          <name><surname>Agarwal</surname><given-names>Ashish</given-names></name>
          <name><surname>Barham</surname><given-names>Paul</given-names></name>
          <name><surname>Brevdo</surname><given-names>Eugene</given-names></name>
          <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>
          <name><surname>Citro</surname><given-names>Craig</given-names></name>
          <name><surname>Corrado</surname><given-names>Greg S.</given-names></name>
          <name><surname>Davis</surname><given-names>Andy</given-names></name>
          <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>
          <name><surname>Devin</surname><given-names>Matthieu</given-names></name>
          <name><surname>Ghemawat</surname><given-names>Sanjay</given-names></name>
          <name><surname>Goodfellow</surname><given-names>Ian</given-names></name>
          <name><surname>Harp</surname><given-names>Andrew</given-names></name>
          <name><surname>Irving</surname><given-names>Geoffrey</given-names></name>
          <name><surname>Isard</surname><given-names>Michael</given-names></name>
          <name><surname>Jia</surname><given-names>Yangqing</given-names></name>
          <name><surname>Jozefowicz</surname><given-names>Rafal</given-names></name>
          <name><surname>Kaiser</surname><given-names>Lukasz</given-names></name>
          <name><surname>Kudlur</surname><given-names>Manjunath</given-names></name>
          <name><surname>Levenberg</surname><given-names>Josh</given-names></name>
          <name><surname>Mané</surname><given-names>Dandelion</given-names></name>
          <name><surname>Monga</surname><given-names>Rajat</given-names></name>
          <name><surname>Moore</surname><given-names>Sherry</given-names></name>
          <name><surname>Murray</surname><given-names>Derek</given-names></name>
          <name><surname>Olah</surname><given-names>Chris</given-names></name>
          <name><surname>Schuster</surname><given-names>Mike</given-names></name>
          <name><surname>Shlens</surname><given-names>Jonathon</given-names></name>
          <name><surname>Steiner</surname><given-names>Benoit</given-names></name>
          <name><surname>Sutskever</surname><given-names>Ilya</given-names></name>
          <name><surname>Talwar</surname><given-names>Kunal</given-names></name>
          <name><surname>Tucker</surname><given-names>Paul</given-names></name>
          <name><surname>Vanhoucke</surname><given-names>Vincent</given-names></name>
          <name><surname>Vasudevan</surname><given-names>Vijay</given-names></name>
          <name><surname>Viégas</surname><given-names>Fernanda</given-names></name>
          <name><surname>Vinyals</surname><given-names>Oriol</given-names></name>
          <name><surname>Warden</surname><given-names>Pete</given-names></name>
          <name><surname>Wattenberg</surname><given-names>Martin</given-names></name>
          <name><surname>Wicke</surname><given-names>Martin</given-names></name>
          <name><surname>Yu</surname><given-names>Yuan</given-names></name>
          <name><surname>Zheng</surname><given-names>Xiaoqiang</given-names></name>
        </person-group>
        <article-title>TensorFlow: Large-scale machine learning on heterogeneous systems</article-title>
        <year iso-8601-date="2015">2015</year>
        <uri>https://www.tensorflow.org/</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.4724125</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-baldridge2009well">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Baldridge</surname><given-names>Jason</given-names></name>
          <name><surname>Palmer</surname><given-names>Alexis</given-names></name>
        </person-group>
        <article-title>How well does active learning actually work? Time-based evaluation of cost-reduction strategies for language documentation.</article-title>
        <source>Proceedings of the 2009 conference on empirical methods in natural language processing</source>
        <year iso-8601-date="2009">2009</year>
      </element-citation>
    </ref>
    <ref id="ref-settles2008analysis">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Settles</surname><given-names>Burr</given-names></name>
          <name><surname>Craven</surname><given-names>Mark</given-names></name>
        </person-group>
        <article-title>An analysis of active learning strategies for sequence labeling tasks</article-title>
        <source>Proceedings of the 2008 conference on empirical methods in natural language processing</source>
        <year iso-8601-date="2008">2008</year>
        <pub-id pub-id-type="doi">10.3115/1613715.1613855</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gal2017deep">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Gal</surname><given-names>Yarin</given-names></name>
          <name><surname>Islam</surname><given-names>Riashat</given-names></name>
          <name><surname>Ghahramani</surname><given-names>Zoubin</given-names></name>
        </person-group>
        <article-title>Deep bayesian active learning with image data</article-title>
        <source>International conference on machine learning</source>
        <publisher-name>PMLR</publisher-name>
        <year iso-8601-date="2017">2017</year>
      </element-citation>
    </ref>
    <ref id="ref-walmsley2020galaxy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Walmsley</surname><given-names>Mike</given-names></name>
          <name><surname>Smith</surname><given-names>Lewis</given-names></name>
          <name><surname>Lintott</surname><given-names>Chris</given-names></name>
          <name><surname>Gal</surname><given-names>Yarin</given-names></name>
          <name><surname>Bamford</surname><given-names>Steven</given-names></name>
          <name><surname>Dickinson</surname><given-names>Hugh</given-names></name>
          <name><surname>Fortson</surname><given-names>Lucy</given-names></name>
          <name><surname>Kruk</surname><given-names>Sandor</given-names></name>
          <name><surname>Masters</surname><given-names>Karen</given-names></name>
          <name><surname>Scarlata</surname><given-names>Claudia</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Galaxy zoo: Probabilistic morphology through bayesian CNNs and active learning</article-title>
        <source>Monthly Notices of the Royal Astronomical Society</source>
        <publisher-name>Oxford University Press</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>491</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1093/mnras/stz2816</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-eisenstein2020active">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Eisenstein</surname><given-names>Michael</given-names></name>
        </person-group>
        <article-title>Active machine learning helps drug hunters tackle biology.</article-title>
        <source>Nature biotechnology</source>
        <publisher-name>Nature Publishing Group</publisher-name>
        <year iso-8601-date="2020">2020</year>
        <volume>38</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1038/s41587-020-0521-4</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
<fn-group>
  <fn id="fn1">
    <label>1</label><p>https://github.com/topics/active-learning</p>
  </fn>
  <fn id="fn2">
    <label>2</label><p>http://skyserver.sdss.org/dr16/en/help/docs/api.aspx#imgcutout</p>
  </fn>
  <fn id="fn3">
    <label>3</label><p>https://third.ucllnl.org/cgi-bin/firstcutout</p>
  </fn>
</fn-group>
</back>
</article>

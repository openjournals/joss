<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">655</article-id>
<article-id pub-id-type="doi">10.21105/joss.00655</article-id>
<title-group>
<article-title>Fast, Consistent Tokenization of Natural Language
Text</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-5103-6917</contrib-id>
<string-name>Lincoln A. Mullen</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0797-564X</contrib-id>
<string-name>Kenneth Benoit</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-5196-609X</contrib-id>
<string-name>Os Keyes</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<string-name>Dmitry Selivanov</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-9953-3904</contrib-id>
<string-name>Jeffrey Arnold</string-name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of History and Art History, George Mason
University</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Methodology, London School of Economics and
Political Science</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Human Centered Design and Engineering,
University of Washington</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Open Data Science</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Department of Political Science, University of
Washington</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-03-12">
<day>12</day>
<month>3</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>23</issue>
<fpage>655</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>text mining</kwd>
<kwd>tokenization</kwd>
<kwd>natural language processing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<p>Computational text analysis usually proceeds according to a series of
well-defined steps. After importing texts, the usual next step is to
turn the human-readable text into machine-readable tokens. Tokens are
defined as segments of a text identified as meaningful units for the
purpose of analyzing the text. They may consist of individual words or
of larger or smaller segments, such as word sequences, word
subsequences, paragraphs, sentences, or lines
(<xref alt="Manning et al., 2008, p. 22" rid="ref-Manningetal2008" ref-type="bibr">Manning
et al., 2008, p. 22</xref>). Tokenization is the process of splitting
the text into these smaller pieces, and it often involves preprocessing
the text to remove punctuation and transform all tokens into lowercase
(<xref alt="Welbers et al., 2017, pp. 250–251" rid="ref-welbers_text_2017" ref-type="bibr">Welbers
et al., 2017, pp. 250–251</xref>). Decisions made during tokenization
have a significant effect on subsequent analysis
(<xref alt="Denny &amp; Spirling, 2018" rid="ref-denny_text_forthcoming" ref-type="bibr">Denny
&amp; Spirling, 2018</xref>;
<xref alt="Guthrie et al., 2006" rid="ref-guthrie_closer_2006" ref-type="bibr">Guthrie
et al., 2006</xref>). Especially for large corpora, tokenization can be
computationally expensive, and tokenization is highly language
dependent. Efficiency and correctness are therefore paramount concerns
for tokenization.</p>
<p>The
<ext-link ext-link-type="uri" xlink:href="http://lincolnmullen.com/software/tokenizers/">tokenizers</ext-link>
package for R provides fast, consistent tokenization for natural
language text
(<xref alt="Mullen, 2018" rid="ref-tokenizers" ref-type="bibr">Mullen,
2018</xref>;
<xref alt="R Core Team, 2017" rid="ref-rbase" ref-type="bibr">R Core
Team, 2017</xref>). (The package is available on
<ext-link ext-link-type="uri" xlink:href="https://github.com/ropensci/tokenizers">GitHub</ext-link>
and archived on
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1205017">Zenodo</ext-link>.)
Each of the tokenizers expects a consistent input and returns a
consistent output, so that the tokenizers can be used interchangeably
with one another or relied on in other packages. To ensure the
correctness of output, the package depends on the stringi package, which
implements Unicode support for R
(<xref alt="Gagolewski, 2018" rid="ref-gagolewski_2018" ref-type="bibr">Gagolewski,
2018</xref>). To ensure the speed of tokenization, key components such
as the <italic>n</italic>-gram and skip <italic>n</italic>-gram
tokenizers are written using the Rcpp package
(<xref alt="Eddelbuettel, 2013" rid="ref-eddelbuettel_2013" ref-type="bibr">Eddelbuettel,
2013</xref>;
<xref alt="Eddelbuettel &amp; Balamuta, 2017" rid="ref-eddelbuettel_2017" ref-type="bibr">Eddelbuettel
&amp; Balamuta, 2017</xref>). The tokenizers package is part of the
<ext-link ext-link-type="uri" xlink:href="https://ropensci.org/">rOpenSci
project</ext-link>.</p>
<p>The most important tokenizers in the current version of the package
can be grouped as follows:</p>
<list list-type="bullet">
  <list-item>
    <p>tokenizers for characters and shingled characters</p>
  </list-item>
  <list-item>
    <p>tokenizers for words and word stems, as well as for Penn Treebank
    tokens</p>
  </list-item>
  <list-item>
    <p>tokenizers <italic>n</italic>-grams and skip
    <italic>n</italic>-grams</p>
  </list-item>
  <list-item>
    <p>tokenizers for tweets, which preserve formatting of usernames and
    hashtags</p>
  </list-item>
</list>
<p>In addition the package provides functions for splitting longer
documents into sentences and paragraphs, or for splitting a long text
into smaller chunks each with the same number of words. This allows
users to treat parts of very long texts as documents in their own right.
The package also provides functions for counting words, characters, and
sentences.</p>
<p>The tokenizers in this package can be used on their own, or they can
be wrapped by higher-level R packages. For instance, the tokenizers
package is a dependency for the tidytext
(<xref alt="Silge &amp; Robinson, 2016" rid="ref-silge_2016" ref-type="bibr">Silge
&amp; Robinson, 2016</xref>), text2vec
(<xref alt="Selivanov &amp; Wang, 2018" rid="ref-selivanov_2018" ref-type="bibr">Selivanov
&amp; Wang, 2018</xref>), and textreuse
(<xref alt="Mullen, 2016" rid="ref-mullen_2016" ref-type="bibr">Mullen,
2016</xref>) packages. More broadly, the output of the tokenization
functions follows the guidelines set by the text-interchange format
defined at an rOpenSci Text Workshop in 2017
(<xref alt="rOpenSci Text Workshop, 2017" rid="ref-tif_2017" ref-type="bibr">rOpenSci
Text Workshop, 2017</xref>). Other packages which buy into the
text-interchange format can thus use the tokenizers package
interchangeably.</p>
<p>The tokenizers package has research applications in any discipline
which uses computational text analysis. The package was originally
created for
historical research into the use of the Bible in American newspapers
(<xref alt="Mullen, forthcoming" rid="ref-mullen_americas" ref-type="bibr">Mullen,
forthcoming</xref>) and into the borrowing of legal codes of civil
procedure in the nineteenth-century United States Funk &amp; Mullen
(<xref alt="2016" rid="ref-funkmullen_servile_2016" ref-type="bibr">2016</xref>).
The tokenizers package underlies the tidytext package
(<xref alt="Silge &amp; Robinson, 2017" rid="ref-silge_text_2017" ref-type="bibr">Silge
&amp; Robinson, 2017</xref>), and via that package tokenizers has been
used in disciplines such as political science
(<xref alt="Sanger &amp; Warin, n.d." rid="ref-sanger_2015_" ref-type="bibr">Sanger
&amp; Warin, n.d.</xref>), social science
(<xref alt="Warin et al., n.d." rid="ref-warin_mapping" ref-type="bibr">Warin
et al., n.d.</xref>), communication studies
(<xref alt="Xu &amp; Guo, 2018" rid="ref-xu_using_2018" ref-type="bibr">Xu
&amp; Guo, 2018</xref>), English
(<xref alt="Ballier &amp; Lissón, 2017" rid="ref-ballier_rbased_2017" ref-type="bibr">Ballier
&amp; Lissón, 2017</xref>), and the digital humanities more
generally.</p>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-silge_text_2017">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Silge</surname><given-names>Julia</given-names></name>
          <name><surname>Robinson</surname><given-names>David</given-names></name>
        </person-group>
        <source>Text Mining with R: A Tidy Approach</source>
        <publisher-name>O’Reilly</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <uri>http://tidytextmining.com/</uri>
      </element-citation>
    </ref>
    <ref id="ref-mullen_americas">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Mullen</surname><given-names>Lincoln A.</given-names></name>
        </person-group>
        <source>America’s public bible: Biblical quotations in U.S. newspapers</source>
        <publisher-name>Stanford University Press</publisher-name>
        <uri>http://americaspublicbible.org</uri>
      </element-citation>
    </ref>
    <ref id="ref-funkmullen_spine_2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Funk</surname><given-names>Kellen</given-names></name>
          <name><surname>Mullen</surname><given-names>Lincoln A.</given-names></name>
        </person-group>
        <article-title>The spine of american law: Digital text analysis and U.S. Legal practice</article-title>
        <source>American Historical Review</source>
        <year iso-8601-date="2018-02-01">2018</year><month>02</month><day>01</day>
        <volume>123</volume>
        <issue>1</issue>
        <issn>0002-8762</issn>
        <pub-id pub-id-type="doi">10.1093/ahr/123.1.132</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-welbers_text_2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Welbers</surname><given-names>Kasper</given-names></name>
          <name><surname>Van Atteveldt</surname><given-names>Wouter</given-names></name>
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
        </person-group>
        <article-title>Text analysis in r</article-title>
        <source>Communication Methods and Measures</source>
        <year iso-8601-date="2017-10-02">2017</year><month>10</month><day>02</day>
        <volume>11</volume>
        <issue>4</issue>
        <issn>1931-2458</issn>
        <uri>https:doi.org/10.1080/19312458.2017.1387238</uri>
        <pub-id pub-id-type="doi">10.1080/19312458.2017.1387238</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-funkmullen_servile_2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Funk</surname><given-names>Kellen</given-names></name>
          <name><surname>Mullen</surname><given-names>Lincoln A.</given-names></name>
        </person-group>
        <article-title>A servile copy: Text reuse and medium data in american civil procedure</article-title>
        <source>Rechtsgeschichte [Legal History]</source>
        <year iso-8601-date="2016">2016</year>
        <issue>24</issue>
        <uri>http://rg.rg.mpg.de/en/article_id/1040</uri>
        <pub-id pub-id-type="doi">10.12946/rg24/341-343</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-sanger_2015_">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Sanger</surname><given-names>William</given-names></name>
          <name><surname>Warin</surname><given-names>Thierry</given-names></name>
        </person-group>
        <article-title>The 2015 canadian election on twitter: A tidy algorithmic analysis</article-title>
      </element-citation>
    </ref>
    <ref id="ref-ballier_rbased_2017">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Ballier</surname><given-names>Nicolas</given-names></name>
          <name><surname>Lissón</surname><given-names>Paula</given-names></name>
        </person-group>
        <article-title>R-based strategies for DH in english linguistics: A case study</article-title>
        <source>Teaching NLP for Digital Humanities</source>
        <publisher-name>Peggy Bockwinkel</publisher-name>
        <publisher-loc>Berlin, Germany</publisher-loc>
        <year iso-8601-date="2017-09">2017</year><month>09</month>
        <volume>1918</volume>
        <uri>https://hal.archives-ouvertes.fr/hal-01587126</uri>
      </element-citation>
    </ref>
    <ref id="ref-warin_mapping">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Warin</surname><given-names>Thierry</given-names></name>
          <name><surname>Le Duc</surname><given-names>Romain</given-names></name>
          <name><surname>Sanger</surname><given-names>William</given-names></name>
        </person-group>
        <article-title>Mapping Innovations in Artificial Intelligence Through Patents: A Social Data Science Perspective</article-title>
      </element-citation>
    </ref>
    <ref id="ref-xu_using_2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Xu</surname><given-names>Zhan</given-names></name>
          <name><surname>Guo</surname><given-names>Hao</given-names></name>
        </person-group>
        <article-title>Using Text Mining to Compare Online Pro- and Anti-Vaccine Headlines: Word Usage, Sentiments, and Online Popularity</article-title>
        <source>Communication Studies</source>
        <year iso-8601-date="2018-01-01">2018</year><month>01</month><day>01</day>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-03-13">2018</year><month>03</month><day>13</day></date-in-citation>
        <volume>69</volume>
        <issue>1</issue>
        <issn>1051-0974</issn>
        <uri>https://doi.org/10.1080/10510974.2017.1414068</uri>
        <pub-id pub-id-type="doi">10.1080/10510974.2017.1414068</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-rbase">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <source>R: A language and environment for statistical computing</source>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2017">2017</year>
        <uri>https://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-gagolewski_2018">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Gagolewski</surname><given-names>Marek</given-names></name>
        </person-group>
        <source>R package stringi: Character string processing facilities</source>
        <year iso-8601-date="2018">2018</year>
        <uri>http://www.gagolewski.com/software/stringi/</uri>
      </element-citation>
    </ref>
    <ref id="ref-eddelbuettel_2013">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
        </person-group>
        <source>Seamless R and C++ integration with Rcpp</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2013">2013</year>
        <pub-id pub-id-type="doi">10.1007/978-1-4614-6868-4</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-eddelbuettel_2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Eddelbuettel</surname><given-names>Dirk</given-names></name>
          <name><surname>Balamuta</surname><given-names>James Joseph</given-names></name>
        </person-group>
        <article-title>Extending R with C++: A Brief Introduction to Rcpp</article-title>
        <source>PeerJ Preprints</source>
        <year iso-8601-date="2017-08">2017</year><month>08</month>
        <volume>5</volume>
        <issn>2167-9843</issn>
        <uri>https://doi.org/10.7287/peerj.preprints.3188v1</uri>
        <pub-id pub-id-type="doi">10.7287/peerj.preprints.3188v1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-silge_2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Silge</surname><given-names>Julia</given-names></name>
          <name><surname>Robinson</surname><given-names>David</given-names></name>
        </person-group>
        <article-title>tidytext: Text mining and analysis using tidy data principles in r</article-title>
        <source>JOSS</source>
        <publisher-name>Journal of Open Source Software</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <volume>1</volume>
        <issue>3</issue>
        <uri>https://doi.org/10.21105/joss.00037</uri>
        <pub-id pub-id-type="doi">10.21105/joss.00037</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-selivanov_2018">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Selivanov</surname><given-names>Dmitriy</given-names></name>
          <name><surname>Wang</surname><given-names>Qing</given-names></name>
        </person-group>
        <source>text2vec: Modern text mining framework for r</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=text2vec</uri>
      </element-citation>
    </ref>
    <ref id="ref-mullen_2016">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Mullen</surname><given-names>Lincoln A.</given-names></name>
        </person-group>
        <source>textreuse: Detect text reuse and document similarity</source>
        <year iso-8601-date="2016">2016</year>
        <uri>https://github.com/ropensci/textreuse</uri>
      </element-citation>
    </ref>
    <ref id="ref-tif_2017">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>rOpenSci Text Workshop</string-name>
        </person-group>
        <source>tif: Text interchange format</source>
        <year iso-8601-date="2017">2017</year>
        <uri>https://github.com/ropensci/tif</uri>
      </element-citation>
    </ref>
    <ref id="ref-denny_text_forthcoming">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Denny</surname><given-names>Matthew J.</given-names></name>
          <name><surname>Spirling</surname><given-names>Arthur</given-names></name>
        </person-group>
        <article-title>Text preprocessing for unsupervised learning: Why it matters, when it misleads, and what to do about it</article-title>
        <source>Political Analysis</source>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.1017/pan.2017.44</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Manningetal2008">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Manning</surname><given-names>C. D.</given-names></name>
          <name><surname>Raghavan</surname><given-names>P.</given-names></name>
          <name><surname>Schütze</surname><given-names>H.</given-names></name>
        </person-group>
        <source>Introduction to information retrieval</source>
        <publisher-name>Cambridge University Press</publisher-name>
        <year iso-8601-date="2008">2008</year>
      </element-citation>
    </ref>
    <ref id="ref-guthrie_closer_2006">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Guthrie</surname><given-names>David</given-names></name>
          <name><surname>Allison</surname><given-names>Ben</given-names></name>
          <name><surname>Liu</surname><given-names>Wei</given-names></name>
          <name><surname>Guthrie</surname><given-names>Louise</given-names></name>
          <name><surname>Wilks</surname><given-names>Yorick</given-names></name>
        </person-group>
        <article-title>A Closer Look at Skip-Gram Modelling</article-title>
        <source>Proceedings of the 5th International Conference on Language Resources and Evaluation</source>
        <year iso-8601-date="2006">2006</year>
        <uri>http://www.lrec-conf.org/proceedings/lrec2006/pdf/357_pdf.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-tokenizers">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Mullen</surname><given-names>Lincoln A.</given-names></name>
        </person-group>
        <source>tokenizers: Fast, consistent tokenization of natural language text</source>
        <year iso-8601-date="2018">2018</year>
        <uri>http://lincolnmullen.com/software/tokenizers/</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2812</article-id>
<article-id pub-id-type="doi">10.21105/joss.02812</article-id>
<title-group>
<article-title>Minimalist And Customisable Optimisation
Package</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6071-744X</contrib-id>
<string-name>J√©r√¥me Buisine</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Samuel Delepoulle</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Christophe Renaud</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Univ. Littoral C√¥te d‚ÄôOpale, LISIC Calais, France,
F-62100</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-10-11">
<day>11</day>
<month>10</month>
<year>2020</year>
</pub-date>
<volume>6</volume>
<issue>59</issue>
<fpage>2812</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Operations Research</kwd>
<kwd>Mono-objective</kwd>
<kwd>Multi-objective</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Optimisation problems are frequently encountered in science and
  industry. Given a real-valued function <inline-formula><alternatives>
  <tex-math><![CDATA[f]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
  defined on a set called the search space
  <inline-formula><alternatives>
  <tex-math><![CDATA[X]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>,
  optimising the function <inline-formula><alternatives>
  <tex-math><![CDATA[f]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
  consists of finding a point <inline-formula><alternatives>
  <tex-math><![CDATA[x \in X]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>x</mml:mi><mml:mo>‚àà</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
  that has the optimal value <inline-formula><alternatives>
  <tex-math><![CDATA[f(x)]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>,
  or at least constructing a sequence <inline-formula><alternatives>
  <tex-math><![CDATA[(x_t)_{t \in \mathbf{N}} \in X^\mathbb{N}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>‚àà</mml:mo><mml:mstyle mathvariant="bold"><mml:mi>ùêç</mml:mi></mml:mstyle></mml:mrow></mml:msub><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mstyle mathvariant="double-struck"><mml:mi>‚Ñï</mml:mi></mml:mstyle></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>
  that is close to the optimum. Depending on the search space
  <inline-formula><alternatives>
  <tex-math><![CDATA[X]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>,
  optimisation problems can be globally classified as discrete problems
  (e.g.¬†<inline-formula><alternatives>
  <tex-math><![CDATA[X=\{0,1\}^n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false" form="postfix">}</mml:mo><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>)
  or as continuous problems (e.g.¬†<inline-formula><alternatives>
  <tex-math><![CDATA[X=\mathbb{R}^n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mstyle mathvariant="double-struck"><mml:mi>‚Ñù</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>).
  Tools for modelling and solving discrete
  (<xref alt="Soni, 2017" rid="ref-solid-solver" ref-type="bibr">Soni,
  2017</xref>) and continuous
  (<xref alt="Agarwal et al., 2020" rid="ref-ceres-solver" ref-type="bibr">Agarwal
  et al., 2020</xref>) problems are proposed in the literature.</p>
  <p>In this paper, <monospace>Macop</monospace> for
  <monospace>Minimalist And Customisable Optimisation Package</monospace>,
  is proposed as a discrete optimisation Python package which doesn‚Äôt
  implement every algorithm in the literature, but provides the ability
  to quickly develop and test your own algorithm and strategies. The
  main objective of this package is to provide maximum flexibility,
  which allows easy implementation when experimenting new
  algorithms.</p>
  <p>Based on a common interaction loop (see
  <xref alt="Figure¬†1" rid="figU003Amacop-behaviour">Figure¬†1</xref>) of
  all the algorithms, <monospace>Macop</monospace> wants to allow users
  to quickly focus on one of the main parts of this loop.</p>
  <fig>
    <caption><p>Macop common interation
    loop.<styled-content id="figU003Amacop-behaviour"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="docs/source/_static/documentation/macop_behaviour_reduced.png" xlink:title="" />
  </fig>
</sec>
<sec id="statement-of-need">
  <title>Statement of Need</title>
  <p>Most of the operational research libraries developed in Python
  offer users either problems and algorithms where it is possible to
  choose parameters to obtain optimal (or near optimal) results such as
  proposed in
  (<xref alt="Maher et al., 2016" rid="ref-10.1007U002F978-3-319-42432-3_37" ref-type="bibr">Maher
  et al., 2016</xref>), or, libraries targeted to a specific problem or
  algorithm such as
  (<xref alt="Perry, 2019" rid="ref-simanneal-solver" ref-type="bibr">Perry,
  2019</xref>). Another package is proposed in
  (<xref alt="Soni, 2017" rid="ref-solid-solver" ref-type="bibr">Soni,
  2017</xref>) which is a comprehensive gradient-free optimization
  framework written in Python. It seems very similar to
  <monospace>Macop</monospace>. However, hiearchic dependencies between
  algorithms, the notion of callbacks and adaptive operator selection
  are proposed within <monospace>Macop</monospace>.</p>
  <p>On the other hand, available libraries
  (<xref alt="Hart et al., 2017" rid="ref-hart2017pyomo" ref-type="bibr">Hart
  et al., 2017</xref>;
  <xref alt="Perez et al., 2012" rid="ref-pyopt-paper" ref-type="bibr">Perez
  et al., 2012</xref>) in the literature did not allow to attach custom
  evaluation function to each algorithm used in this hierarchy of
  algorithms. Indeed, it is sometimes possible that the main algorithm
  manages local searches. Each local search may evaluate the solution
  differently using a different evaluation function of the parent
  algorithm (the main algorithm). Such as example, using a surrogate
  mathematical model
  (<xref alt="Lepr√™tre et al., 2019" rid="ref-10.1145U002F3321707.3321800" ref-type="bibr">Lepr√™tre
  et al., 2019</xref>) with a quick-to-evaluate function if the real
  evaluation function is very expensive in time. This is why in
  <monospace>Macop</monospace>, each algorithm can have its own
  mechanism (or partially), i.e.¬†its evaluation function, its operators
  for obtaining new solution, as well as its solution update policy.
  This is independent of the parent algorithm to which it is linked.
  This means that only the results (solutions found) are exchanged.</p>
  <p>Hence, motivation behind <bold>Macop</bold> is a flexible discrete
  optimisation package allowing a quick implementation of problems. In
  particular it meets the following needs:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Common basis:</bold> the interaction loop during the
      solution finding process proposed within the package is common to
      all heuristics. This allows the user to modify only a part of this
      interaction loop if necessary without rendering the process
      non-functional;</p>
    </list-item>
    <list-item>
      <p><bold>Hierarchy:</bold> a hierarchical algorithm management
      system is available, especially when an algorithm needs to manage
      local searches. This hierarchy remains transparent to the user.
      The main algorithm will be able to manage and control the process
      of searching for solutions;</p>
    </list-item>
    <list-item>
      <p><bold>Flexibility:</bold> although the algorithms are dependent
      on each other, it is possible that their internal management
      (search mechanism) is different. This means that the ways in which
      solutions are evaluated and updated, for example, may be
      different;</p>
    </list-item>
    <list-item>
      <p><bold>Abstraction:</bold> thanks to the modular separability of
      the package, it is quickly possible to implement new problems,
      solutions representation, way to evaluate, update solutions within
      the package;</p>
    </list-item>
    <list-item>
      <p><bold>Extensible:</bold> the package is open to extension,
      i.e.¬†it does not partition the user in these developer choices. It
      can just as well implement continuous optimization problems if
      needed while making use of the main interaction loop proposed by
      the package;</p>
    </list-item>
    <list-item>
      <p><bold>Easy Setup:</bold> as a pure Python package distributed
      is <monospace>pip</monospace> installable and easy to use.</p>
    </list-item>
  </list>
</sec>
<sec id="target-audience">
  <title>Target Audience</title>
  <p>This package would meet the expectations of people wishing to:</p>
  <list list-type="bullet">
    <list-item>
      <p>Solve a problem using an evolutionary algorithm but without
      developing their own frawmework. They can rely on what the package
      already proposes but also on its generic and flexible contribution
      in order to adapt their own content;</p>
    </list-item>
    <list-item>
      <p>Conduct research work leading to the rapid modification of
      meta-heuristics and the interaction of different algorithms. More
      precisely:</p>
      <list list-type="bullet">
        <list-item>
          <p>test new combinations of algorithms. Changing algorithms
          during evaluations, e.g.¬†different local searches;</p>
        </list-item>
        <list-item>
          <p>provide reinforcement learning during searches
          (e.g.¬†adaptive operator choice strategy).</p>
        </list-item>
        <list-item>
          <p>test new multi-objective methods quickly thanks to the
          proposed algorithmic hierarchy allowing to easily decompose
          the multi-objective problem into single-objective
          sub-problems.</p>
        </list-item>
      </list>
    </list-item>
    <list-item>
      <p>Take advantage of a system for launching calculations from a
      backup in order to avoid any loss in case of unwanted program
      interruption;</p>
    </list-item>
    <list-item>
      <p>Quickly model a problem that is still unknown, i.e.¬†the type of
      solution and the evaluation function, while taking advantage of
      the interaction loop proposed by the package.</p>
    </list-item>
  </list>
</sec>
<sec id="description">
  <title>Description</title>
  <p>At the beginning of the development of this library, the idea of
  making it as modular as possible was topical. The library divide into
  sub-module forms considered to be the most important to build and
  solve an optimisation problem.</p>
  <p>The package consists of main several modules:</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>solutions:</bold> representation of the solution;</p>
    </list-item>
    <list-item>
      <p><bold>validator:</bold> such as constraint programming, a
      <monospace>validator</monospace> is a function which is used to
      validate or not a solution data state;</p>
    </list-item>
    <list-item>
      <p><bold>evaluator:</bold> stores problem instance data and
      implements a <monospace>compute</monospace> method in order to
      evaluate a solution;</p>
    </list-item>
    <list-item>
      <p><bold>operators:</bold> mutators, crossovers operators to
      update and obtain new solution;</p>
    </list-item>
    <list-item>
      <p><bold>policies:</bold> the way you choose the available
      operators (might be using reinforcement learning);</p>
    </list-item>
    <list-item>
      <p><bold>algorithms:</bold> generic and implemented optimisation
      research algorithms;</p>
    </list-item>
    <list-item>
      <p><bold>callbacks:</bold> callbacks to automatically keep track
      of the search space advancement and restart from previous state if
      nedded.</p>
    </list-item>
  </list>
  <p>The primary advantage of using Python is that it allows you to
  dynamically add new members within the new implemented solution or
  algorithm classes. This of course does not close the possibilities of
  extension and storage of information within solutions and algorithms.
  It all depends on the current need.</p>
  <sec id="in-macop.algorithms-module">
    <title>In <monospace>macop.algorithms</monospace> module:</title>
    <p>Both single and multi-objective algorithms have been implemented
    for demonstration purposes.</p>
    <p>A hierarchy between dependent algorithms is also available, based
    on a parent/child link, allowing quick access to global information
    when looking for solutions, such as the best solution found, the
    number of global evaluations.</p>
    <p>The mono-objective Iterated Local Search
    (<xref alt="Louren√ßo et al., 2003" rid="ref-Louren√ßo2003" ref-type="bibr">Louren√ßo
    et al., 2003</xref>) algorithm has been implemented. This algorithm
    aims to perform local searches (child algorithms linked to the main
    algorithm) and then to explore again (explorations vs.¬†exploitation
    trade-off). On the multi-objective side, the MOEA/D algorithm
    (<xref alt="Zhang &amp; Li, 2007" rid="ref-DBLPU003AjournalsU002FtecU002FZhangL07" ref-type="bibr">Zhang
    &amp; Li, 2007</xref>) has been implemented by using the
    weighted-sum of objectives to change multi-objectives problem into a
    set of mono-objective problems (Tchebycheff approach can also be
    used
    (<xref alt="Alves &amp; Almeida, 2007" rid="ref-DBLPU003AjournalsU002FcorU002FAlvesA07" ref-type="bibr">Alves
    &amp; Almeida, 2007</xref>)). Hence, this algorithm aims at
    decomposing the multi-objective problem into
    <inline-formula><alternatives>
    <tex-math><![CDATA[\mu]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Œº</mml:mi></mml:math></alternatives></inline-formula>
    single-objective problems in order to obtain the Pareto front
    (<xref alt="Kim &amp; De Weck, 2005" rid="ref-kim2005adaptive" ref-type="bibr">Kim
    &amp; De Weck, 2005</xref>) where single-objective problems are
    so-called child algorithms linked to the multi-objective
    algorithm.</p>
    <p>The main purpose of these developed algorithms is to show the
    possibilities of operational search algorithm implementations based
    on the minimalist structure of the library.</p>
  </sec>
  <sec id="in-macop.solutions-module">
    <title>In <monospace>macop.solutions</monospace> module:</title>
    <p>Currently, only combinatorial solutions (discrete problem
    modelisation) are offered, with the well-known problem of the
    knapsack as an example. Of course, it‚Äôs easy to add your own
    representations of solutions. Solutions modeling continuous problems
    can also be created by anyone who wants to model his own
    problem.</p>
  </sec>
  <sec id="in-macop.operators-and-macop.policies-modules">
    <title>In <monospace>macop.operators</monospace> and
    <monospace>macop.policies</monospace> modules:</title>
    <p>A few mutation and crossover operators have been implemented.
    However, it remains quite simple. What is interesting here is that
    it is possible to develop one‚Äôs own strategy for choosing operators
    for the next evaluation. The available UCBPolicy class proposes this
    functionality as an example, since it will seek to propose the best
    operator to apply based on a method known as the Adaptive Operator
    Selection (AOS) via the use of the Upper Confidence Bound (UCB)
    algorithm
    (<xref alt="Li et al., 2014" rid="ref-DBLPU003AjournalsU002FtecU002FLiFKZ14" ref-type="bibr">Li
    et al., 2014</xref>).</p>
  </sec>
  <sec id="in-macop.callbacks-module">
    <title>In <monospace>macop.callbacks</monospace> module:</title>
    <p>The use of callback instance allows both to do an action every
    <inline-formula><alternatives>
    <tex-math><![CDATA[k]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math></alternatives></inline-formula>
    evaluations of information, but also to reload them once the run of
    the algorithm is cut. Simply inherit the abstract Callback class and
    implement the <monospace>apply</monospace> method to backup and
    <monospace>load</monospace> to restore. It is possible to add as
    many callbacks as required. As an example, the implemented UCBPolicy
    has its own callback allowing the instance to reload previously
    collected statistics and restart using them.</p>
  </sec>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p><monospace>Macop</monospace> aims to allow the modelling of
  discrete (usually combinatorial) optimisation problems. It is
  therefore open to expansion and not closed specifically to a kind of
  problem.</p>
  <p><monospace>Macop</monospace> proposes a simple structure of
  interaction of the main elements (algorithms, operators, solutions,
  policies, callbacks) for the resolution of operational research
  problems inside an interaction loop. From its generic structure, it is
  possible, thanks to the flexible programming paradigm of the Python
  language, to easily allow the extension and development of new
  algorithms and problems. Based on simple concepts, this package can
  therefore meet the needs of the rapid problem implementation.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work is supported by <italic>Agence Nationale de la
  Recherche</italic> : project ANR-17-CE38-0009</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Louren√ßo2003">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Louren√ßo</surname><given-names>Helena R.</given-names></name>
          <name><surname>Martin</surname><given-names>Olivier C.</given-names></name>
          <name><surname>St√ºtzle</surname><given-names>Thomas</given-names></name>
        </person-group>
        <article-title>Iterated local search</article-title>
        <source>Handbook of metaheuristics</source>
        <person-group person-group-type="editor">
          <name><surname>Glover</surname><given-names>Fred</given-names></name>
          <name><surname>Kochenberger</surname><given-names>Gary A.</given-names></name>
        </person-group>
        <publisher-name>Springer US</publisher-name>
        <publisher-loc>Boston, MA</publisher-loc>
        <year iso-8601-date="2003">2003</year>
        <isbn>978-0-306-48056-0</isbn>
        <uri>https://doi.org/10.1007/0-306-48056-5_11</uri>
        <pub-id pub-id-type="doi">10.1007/0-306-48056-5_11</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DBLPU003AjournalsU002FtecU002FZhangL07">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zhang</surname><given-names>Qingfu</given-names></name>
          <name><surname>Li</surname><given-names>Hui</given-names></name>
        </person-group>
        <article-title>MOEA/D: A multiobjective evolutionary algorithm based on decomposition</article-title>
        <source>IEEE Transactions on Evolutionary Computation</source>
        <year iso-8601-date="2007">2007</year>
        <volume>11</volume>
        <issue>6</issue>
        <uri>https://doi.org/10.1109/TEVC.2007.892759</uri>
        <pub-id pub-id-type="doi">10.1109/TEVC.2007.892759</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DBLPU003AjournalsU002FcorU002FAlvesA07">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Alves</surname><given-names>Maria Jo√£o</given-names></name>
          <name><surname>Almeida</surname><given-names>Marla</given-names></name>
        </person-group>
        <article-title>MOTGA: A multiobjective Tchebycheff based genetic algorithm for the multidimensional knapsack problem</article-title>
        <source>Computers &amp; Operations Research</source>
        <year iso-8601-date="2007">2007</year>
        <volume>34</volume>
        <issue>11</issue>
        <uri>https://doi.org/10.1016/j.cor.2006.02.008</uri>
        <pub-id pub-id-type="doi">10.1016/j.cor.2006.02.008</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DBLPU003AjournalsU002FtecU002FLiFKZ14">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Li</surname><given-names>Ke</given-names></name>
          <name><surname>Fialho</surname><given-names>√Ålvaro</given-names></name>
          <name><surname>Kwong</surname><given-names>Sam</given-names></name>
          <name><surname>Zhang</surname><given-names>Qingfu</given-names></name>
        </person-group>
        <article-title>Adaptive operator selection with bandits for a multiobjective evolutionary algorithm based on decomposition</article-title>
        <source>IEEE Transactions on Evolutionary Computation</source>
        <year iso-8601-date="2014">2014</year>
        <volume>18</volume>
        <issue>1</issue>
        <uri>https://doi.org/10.1109/TEVC.2013.2239648</uri>
        <pub-id pub-id-type="doi">10.1109/TEVC.2013.2239648</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kim2005adaptive">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kim</surname><given-names>Il Yong</given-names></name>
          <name><surname>De Weck</surname><given-names>Oliver L</given-names></name>
        </person-group>
        <article-title>Adaptive weighted-sum method for bi-objective optimization: Pareto front generation</article-title>
        <source>Structural and multidisciplinary optimization</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2005">2005</year>
        <volume>29</volume>
        <issue>2</issue>
        <uri>https://doi.org/10.1007/s00158-004-0465-1</uri>
        <pub-id pub-id-type="doi">10.1007/s00158-004-0465-1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-ceres-solver">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Agarwal</surname><given-names>Sameer</given-names></name>
          <name><surname>Mierle</surname><given-names>Keir</given-names></name>
          <name><surname>Others</surname></name>
        </person-group>
        <article-title>Ceres solver</article-title>
        <publisher-name>http://ceres-solver.org</publisher-name>
        <year iso-8601-date="2020">2020</year>
      </element-citation>
    </ref>
    <ref id="ref-hart2017pyomo">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Hart</surname><given-names>William E.</given-names></name>
          <name><surname>Laird</surname><given-names>Carl D.</given-names></name>
          <name><surname>Watson</surname><given-names>Jean-Paul</given-names></name>
          <name><surname>Woodruff</surname><given-names>David L.</given-names></name>
          <name><surname>Hackebeil</surname><given-names>Gabriel A.</given-names></name>
          <name><surname>Nicholson</surname><given-names>Bethany L.</given-names></name>
          <name><surname>Siirola</surname><given-names>John D.</given-names></name>
        </person-group>
        <source>Pyomo‚Äìoptimization modeling in python</source>
        <publisher-name>Springer Science &amp; Business Media</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <volume>67</volume>
      </element-citation>
    </ref>
    <ref id="ref-pyopt-paper">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Perez</surname><given-names>Ruben E.</given-names></name>
          <name><surname>Jansen</surname><given-names>Peter W.</given-names></name>
          <name><surname>Martins</surname><given-names>Joaquim R. R. A.</given-names></name>
        </person-group>
        <article-title>PyOpt: A Python-based object-oriented framework for nonlinear constrained optimization</article-title>
        <source>Structures and Multidisciplinary Optimization</source>
        <year iso-8601-date="2012">2012</year>
        <volume>45</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1007/s00158-011-0666-3</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-10.1007U002F978-3-319-42432-3_37">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Maher</surname><given-names>Stephen</given-names></name>
          <name><surname>Miltenberger</surname><given-names>Matthias</given-names></name>
          <name><surname>Pedroso</surname><given-names>Jo√£o Pedro</given-names></name>
          <name><surname>Rehfeldt</surname><given-names>Daniel</given-names></name>
          <name><surname>Schwarz</surname><given-names>Robert</given-names></name>
          <name><surname>Serrano</surname><given-names>Felipe</given-names></name>
        </person-group>
        <article-title>PySCIPOpt: Mathematical programming in python with the SCIP optimization suite</article-title>
        <source>Mathematical software ‚Äì ICMS 2016</source>
        <person-group person-group-type="editor">
          <name><surname>Greuel</surname><given-names>Gert-Martin</given-names></name>
          <name><surname>Koch</surname><given-names>Thorsten</given-names></name>
          <name><surname>Paule</surname><given-names>Peter</given-names></name>
          <name><surname>Sommese</surname><given-names>Andrew</given-names></name>
        </person-group>
        <publisher-name>Springer International Publishing</publisher-name>
        <publisher-loc>Cham</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <isbn>978-3-319-42432-3</isbn>
        <pub-id pub-id-type="doi">10.1007/978-3-319-42432-3_37</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-simanneal-solver">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Perry</surname><given-names>Matthew</given-names></name>
        </person-group>
        <article-title>Simanneal</article-title>
        <source>GitHub repository</source>
        <publisher-name>https://github.com/perrygeo/simanneal; GitHub</publisher-name>
        <year iso-8601-date="2019">2019</year>
      </element-citation>
    </ref>
    <ref id="ref-solid-solver">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Soni</surname><given-names>Devin</given-names></name>
        </person-group>
        <article-title>Solid</article-title>
        <source>GitHub repository</source>
        <publisher-name>https://github.com/100/Solid; GitHub</publisher-name>
        <year iso-8601-date="2017">2017</year>
      </element-citation>
    </ref>
    <ref id="ref-10.1145U002F3321707.3321800">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Lepr√™tre</surname><given-names>Florian</given-names></name>
          <name><surname>Verel</surname><given-names>S√©bastien</given-names></name>
          <name><surname>Fonlupt</surname><given-names>Cyril</given-names></name>
          <name><surname>Marion</surname><given-names>Virginie</given-names></name>
        </person-group>
        <article-title>Walsh functions as surrogate model for pseudo-boolean optimization problems</article-title>
        <source>Proceedings of the genetic and evolutionary computation conference</source>
        <publisher-name>Association for Computing Machinery</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2019">2019</year>
        <isbn>9781450361118</isbn>
        <uri>https://doi.org/10.1145/3321707.3321800</uri>
        <pub-id pub-id-type="doi">10.1145/3321707.3321800</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

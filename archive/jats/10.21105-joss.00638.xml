<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">638</article-id>
<article-id pub-id-type="doi">10.21105/joss.00638</article-id>
<title-group>
<article-title>MLxtend: Providing machine learning and data science
utilities and extensions to Python's scientific computing
stack</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6989-4493</contrib-id>
<string-name>Sebastian Raschka</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Michigan State University</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-03-15">
<day>15</day>
<month>3</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>24</issue>
<fpage>638</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>machine learning</kwd>
<kwd>data science</kwd>
<kwd>association rule mining</kwd>
<kwd>ensemble learning</kwd>
<kwd>feature selection</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>MLxtend is a library that implements a variety of core algorithms
  and utilities for machine learning and data mining. The primary goal
  of MLxtend is to make commonly used tools accessible to researchers in
  academia and data scientists in industries focussing on user-friendly
  and intuitive APIs and compatibility to existing machine learning
  libraries, such as scikit-learn, when appropriate. While MLxtend
  implements a large variety of functions, highlights include sequential
  feature selection algorithms
  (<xref alt="Pudil et al., 1994" rid="ref-pudil1994floating" ref-type="bibr">Pudil
  et al., 1994</xref>), implementations of stacked generalization
  (<xref alt="Wolpert, 1992" rid="ref-wolpert1992stacked" ref-type="bibr">Wolpert,
  1992</xref>) for classification and regression, and algorithms for
  frequent pattern mining
  (<xref alt="Agrawal &amp; Ramakrishnan, 1994" rid="ref-agrawal1994fast" ref-type="bibr">Agrawal
  &amp; Ramakrishnan, 1994</xref>). The sequential feature selection
  algorithms cover forward, backward, forward floating, and backward
  floating selection and leverage scikit-learn’s cross-validation API
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa2011scikit" ref-type="bibr">Pedregosa
  et al., 2011</xref>) to ensure satisfactory generalization performance
  upon constructing and selecting feature subsets. Besides,
  visualization functions are provided that allow users to inspect the
  estimated predictive performance, including performance intervals, for
  different feature subsets. The ensemble methods in MLxtend cover
  majority voting, stacking, and stacked generalization, all of which
  are compatible with scikit-learn estimators and other libraries as
  XGBoost
  (<xref alt="Chen &amp; Guestrin, 2016" rid="ref-chen2016xgboost" ref-type="bibr">Chen
  &amp; Guestrin, 2016</xref>). In addition to feature selection,
  classification, and regression algorithms, MLxtend implements model
  evaluation techniques for comparing the performance of two different
  models via McNemar’s test and multiple models via Cochran’s Q test. An
  implementation of the 5x2 cross-validated paired t-test
  (<xref alt="Dietterich, 1998" rid="ref-dietterich1998approximate" ref-type="bibr">Dietterich,
  1998</xref>) allows users to compare the performance of machine
  learning algorithms to each other. Furthermore, different flavors of
  the Bootstrap method
  (<xref alt="Efron &amp; Tibshirani, 1994" rid="ref-efron1994introduction" ref-type="bibr">Efron
  &amp; Tibshirani, 1994</xref>), such as the .632 Bootstrap method
  (<xref alt="Efron, 1983" rid="ref-efron1983estimating" ref-type="bibr">Efron,
  1983</xref>) are implemented to compute confidence intervals of
  performance estimates. All in all, MLxtend provides a large variety of
  different utilities that build upon and extend the capabilities of
  Python’s scientific computing stack.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>I would like to acknowledge all of the contributors and users of
  mlxtend, who helped with valuable feedback, bug fixes, and additional
  functionality to further improve the library: James Bourbeau,
  Reiichiro Nakano, Will McGinnis, Guillaume Poirier-Morency, Colin
  Carrol, Zach Griffith, Anton Loss, Joshua Goerner, Eike Dehling,
  Gilles Armand, Adam Erickson, Mathew Savage, Pablo Fernandez,
  Alejandro Correa Bahnsen, and many others. A comprehensive list of all
  contributors to mlxtend is available at
  https://github.com/rasbt/mlxtend/graphs/contributors.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-pudil1994floating">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pudil</surname><given-names>Pavel</given-names></name>
          <name><surname>Novovičová</surname><given-names>Jana</given-names></name>
          <name><surname>Kittler</surname><given-names>Josef</given-names></name>
        </person-group>
        <article-title>Floating search methods in feature selection</article-title>
        <source>Pattern recognition letters</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="1994">1994</year>
        <volume>15</volume>
        <issue>11</issue>
        <pub-id pub-id-type="doi">https://doi.org/10.1016/0167-8655(94)90127-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-wolpert1992stacked">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wolpert</surname><given-names>David H</given-names></name>
        </person-group>
        <article-title>Stacked generalization</article-title>
        <source>Neural networks</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="1992">1992</year>
        <volume>5</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">https://doi.org/10.1016/S0893-6080(05)80023-1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-agrawal1994fast">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Agrawal</surname><given-names>Rakesh</given-names></name>
          <name><surname>Ramakrishnan</surname><given-names>Srikant</given-names></name>
        </person-group>
        <article-title>Fast algorithms for mining association rules in large databases</article-title>
        <source>VLDB’94, proceedings of 20th international conference on very large data bases, september 12-15, 1994, santiago de chile, chile</source>
        <year iso-8601-date="1994">1994</year>
        <volume>1215</volume>
        <isbn>1-55860-153-8</isbn>
      </element-citation>
    </ref>
    <ref id="ref-pedregosa2011scikit">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Gaël</given-names></name>
          <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
          <name><surname>Michel</surname><given-names>Vincent</given-names></name>
          <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
          <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
          <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
          <name><surname>Weiss</surname><given-names>Ron</given-names></name>
          <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in python</article-title>
        <source>Journal of machine learning research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
        <issue>Oct</issue>
      </element-citation>
    </ref>
    <ref id="ref-chen2016xgboost">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Chen</surname><given-names>Tianqi</given-names></name>
          <name><surname>Guestrin</surname><given-names>Carlos</given-names></name>
        </person-group>
        <article-title>Xgboost: A scalable tree boosting system</article-title>
        <source>Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-dietterich1998approximate">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Dietterich</surname><given-names>Thomas G</given-names></name>
        </person-group>
        <article-title>Approximate statistical tests for comparing supervised classification learning algorithms</article-title>
        <source>Neural computation</source>
        <publisher-name>MIT Press</publisher-name>
        <year iso-8601-date="1998">1998</year>
        <volume>10</volume>
        <issue>7</issue>
        <pub-id pub-id-type="doi">10.1162/089976698300017197</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-efron1994introduction">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Efron</surname><given-names>Bradley</given-names></name>
          <name><surname>Tibshirani</surname><given-names>Robert J</given-names></name>
        </person-group>
        <source>An introduction to the bootstrap</source>
        <publisher-name>CRC press</publisher-name>
        <year iso-8601-date="1994">1994</year>
      </element-citation>
    </ref>
    <ref id="ref-efron1983estimating">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Efron</surname><given-names>Bradley</given-names></name>
        </person-group>
        <article-title>Estimating the error rate of a prediction rule: Improvement on cross-validation</article-title>
        <source>Journal of the American statistical association</source>
        <publisher-name>Taylor &amp; Francis Group</publisher-name>
        <year iso-8601-date="1983">1983</year>
        <volume>78</volume>
        <issue>382</issue>
        <pub-id pub-id-type="doi">10.1080/01621459.1983.10477973</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

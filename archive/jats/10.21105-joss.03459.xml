<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3459</article-id>
<article-id pub-id-type="doi">10.21105/joss.03459</article-id>
<title-group>
<article-title>NiTransforms: A Python tool to read, represent,
manipulate, and apply $n$-dimensional spatial transforms</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7252-7771</contrib-id>
<string-name>Mathias Goncalves</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6533-164X</contrib-id>
<string-name>Christopher J. Markiewicz</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-2553-3327</contrib-id>
<string-name>Stefano Moia</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-5312-6729</contrib-id>
<string-name>Satrajit S. Ghosh</string-name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6755-0259</contrib-id>
<string-name>Russell A. Poldrack</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8435-6191</contrib-id>
<string-name>Oscar Esteban</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Psychology, Stanford University, Stanford,
CA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>McGovern Institute for Brain Research, Massachusetts
Institute of Technology (MIT), Cambridge, MA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Otolaryngology, Harvard Medical School,
Boston, MA, USA</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Basque Center on Cognition Brain and Language, San
Sebastian, Spain</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-11-04">
<day>4</day>
<month>11</month>
<year>2019</year>
</pub-date>
<volume>6</volume>
<issue>65</issue>
<fpage>3459</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>neuroimaging</kwd>
<kwd>image processing</kwd>
<kwd>spatial transform</kwd>
<kwd>nibabel</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>Spatial transforms formalize mappings between coordinates of
  objects in biomedical images. Transforms typically are the outcome of
  image registration methodologies, which estimate the alignment between
  two images. Image registration is a prominent task present in almost
  any image processing workflow.</p>
  <p><bold>Statement of need</bold>. In neuroimaging, the proliferation
  of image registration software implementations has resulted in a
  disparate collection of structures and file formats used to preserve
  and communicate the transformation. This assortment of formats
  presents the challenge of compatibility between tools and endangers
  the reproducibility of results. Some tools are available that permit
  some conversions between formats, either within neuroimaging packages
  or standalone such as Convert3D
  (<xref alt="Yushkevich, n.d." rid="ref-yushkevich_open_nodate" ref-type="bibr">Yushkevich,
  n.d.</xref>). However, they are typically limited either in compatible
  packages and/or application coverage (e.g., only linear
  transforms).</p>
  <p><bold>Summary</bold>. <italic>NiTransforms</italic> is a Python
  tool capable of reading and writing tranforms produced by the most
  popular neuroimaging software (AFNI
  (<xref alt="Cox &amp; Hyde, 1997" rid="ref-cox_software_1997" ref-type="bibr">Cox
  &amp; Hyde, 1997</xref>), FSL
  (<xref alt="Jenkinson et al., 2012" rid="ref-jenkinson_fsl_2012" ref-type="bibr">Jenkinson
  et al., 2012</xref>), FreeSurfer
  (<xref alt="Fischl, 2012" rid="ref-fischl_freesurfer_2012" ref-type="bibr">Fischl,
  2012</xref>), ITK via ANTs
  (<xref alt="Avants et al., 2008" rid="ref-avants_symmetric_2008" ref-type="bibr">Avants
  et al., 2008</xref>), and SPM
  (<xref alt="Friston et al., 2006" rid="ref-friston_statistical_2006" ref-type="bibr">Friston
  et al., 2006</xref>)). Additionally, the tool provides seamless
  conversion between these formats, as well as the ability of applying
  the transforms to other images. The tool has already been integrated
  into <italic>fMRIPrep</italic>
  (<xref alt="Esteban et al., 2019" rid="ref-esteban_fmriprep_2019" ref-type="bibr">Esteban
  et al., 2019</xref>), a popular neuroimaging preprocessing pipeline
  that leverages many of the neuroimaging software already mentioned.
  <italic>NiTransforms</italic> is inspired by <italic>NiBabel</italic>
  (<xref alt="Brett et al., 2006" rid="ref-brett_nibabel_2006" ref-type="bibr">Brett
  et al., 2006</xref>), a Python package with a collection of tools to
  read, write and handle neuroimaging data, and will be included as a
  new module.</p>
  <p><bold>Audience</bold>. Computer vision researchers and experts
  using Python, developers of neuroimaging workflows built on AFNI, FSL,
  FreeSurfer, ITK/ANTs, or SPM, developers of neuroimaging visualization
  tools.</p>
</sec>
<sec id="implementation">
  <title>Implementation</title>
  <p>We first mathematically formulate the problem of spatial alignment
  of images and highlight common pitfalls. We then justify the
  architectural design of <italic>NiTransforms</italic> and describe the
  major elements of the implementation.</p>
  <sec id="methods">
    <title>Methods</title>
    <p>Let <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
    represent the coordinates of a point in the reference coordinate
    system <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>,
    and <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x}']]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    its projection on to another coordinate system
    <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>:</p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[T\colon R \subset \mathbb{R}^n \to M \subset \mathbb{R}^n]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>T</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mo>⊂</mml:mo><mml:msup><mml:mstyle mathvariant="double-struck"><mml:mi>ℝ</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mi>M</mml:mi><mml:mo>⊂</mml:mo><mml:msup><mml:mstyle mathvariant="double-struck"><mml:mi>ℝ</mml:mi></mml:mstyle><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula></p>
    <p><inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x} \mapsto \vec{x}' = f(\vec{x}).]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mo>↦</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mi>′</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></inline-formula></p>
    <p>In an image registration problem, <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>
    is a moving image from which we want to sample data in order to
    bring the image into spatial alignment with the reference image
    <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>.
    Hence, <inline-formula><alternatives>
    <tex-math><![CDATA[f]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>f</mml:mi></mml:math></alternatives></inline-formula>
    here is the spatial transformation function that maps from
    coordinates in <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>
    to coordinates in <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>.
    There are a multiplicity of image registration algorithms and
    corresponding image transformation models to estimate linear and
    nonlinear transforms.</p>
    <p>The problem has been traditionally confused by the need of
    <italic>transforming</italic> or mapping one image (generally
    referred to as <italic>moving</italic>) into another that serves as
    reference, with the goal of <italic>fusing</italic> the information
    from both. An example of image fusion application would be the
    alignment of functional data from one individual’s brain to the same
    individual’s corresponding anatomical MRI scan for visualization.
    Therefore, “applying a transform” entails two operations
    (<xref alt="Figure 1" rid="figU003Aresampling">Figure 1</xref>):
    first, transforming the coordinates of the samples in the reference
    image <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>
    to find their mapping <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x}']]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    on <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>
    via <inline-formula><alternatives>
    <tex-math><![CDATA[T\{\cdot\}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false" form="prefix">{</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false" form="postfix">}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>,
    and second an interpolation step, as <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x}']]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
    will likely fall off-the-grid of the moving image
    <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>.
    These two operations are confusing because, while the spatial
    transformation projects from <inline-formula><alternatives>
    <tex-math><![CDATA[R]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>R</mml:mi></mml:math></alternatives></inline-formula>
    to <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>,
    the data flows in reversed way after the interpolation of the values
    of <inline-formula><alternatives>
    <tex-math><![CDATA[M]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>M</mml:mi></mml:math></alternatives></inline-formula>
    at the mapped coordinates <inline-formula><alternatives>
    <tex-math><![CDATA[\vec{x}']]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo accent="true">⃗</mml:mo></mml:mover><mml:mi>′</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    <fig>
      <caption><p>Resampling a 3D image via a spatial transform to fuse
      the information of one into another image.
      <styled-content id="figU003Aresampling"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="https://github.com/poldracklab/nitransforms/raw/master/docs/_static/figure1-joss.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="software-architecture">
    <title>Software Architecture</title>
    <p>There are four main components within the tool: an
    <monospace>io</monospace> submodule to handle the structure of the
    various file formats, a <monospace>base</monospace> submodule where
    abstract classes are defined, a <monospace>linear</monospace>
    submodule implementing <inline-formula><alternatives>
    <tex-math><![CDATA[n]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>n</mml:mi></mml:math></alternatives></inline-formula>-dimensional
    linear transforms, and a <monospace>nonlinear</monospace> submodule
    for both parametric and non-parametric nonlinear transforms.
    Furthermore, <italic>NiTranforms</italic> provides a straightforward
    <italic>Application Programming Interface</italic> (API) that allows
    researchers to map point sets via transforms, as well as apply
    transforms (i.e., mapping the coordinates and interpolating the
    data) to data structures with ease.</p>
    <p>To ensure the consistency and uniformity of internal operations,
    all transforms are defined using a left-handed coordinate system of
    physical coordinates. In words from the neuroimaging domain, the
    coordinate system of transforms is <italic>RAS+</italic> (or
    positive directions point to the Righthand for the first axis,
    Anterior for the second, and Superior for the third axis). The
    internal representation of transform coordinates is the most
    relevant design decision, and implies that a conversion of
    coordinate system is necessary to correctly interpret transforms
    generated by other software. When a transform that is defined in
    another coordinate system is loaded, it is automatically converted
    into <italic>RAS+</italic> space.</p>
    <p><italic>NiTransforms</italic> was developed using a test-driven
    development paradigm, with the battery of tests being written prior
    to the software implementations. Two categories of tests were used:
    unit tests and cross-tool comparison tests. Unit tests evaluate the
    formal correctness of the implementation, while cross-tool
    comparison tests assess the correct implementation of third-party
    software. The testing suite is incorporated into a continuous
    integration framework, which assesses the continuity of the
    implementation along the development life and ensures that code
    changes and additions do not break existing functionalities.</p>
  </sec>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-cox_software_1997">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Cox</surname><given-names>Robert W.</given-names></name>
          <name><surname>Hyde</surname><given-names>James S.</given-names></name>
        </person-group>
        <article-title>Software tools for analysis and visualization of fMRI data</article-title>
        <source>NMR Biomed</source>
        <year iso-8601-date="1997">1997</year>
        <volume>10</volume>
        <issue>4-5</issue>
        <issn>1099-1492</issn>
        <uri>http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1099-1492(199706/08)10:4/5&lt;171::AID-NBM453&gt;3.0.CO;2-L</uri>
        <pub-id pub-id-type="doi">10.1002/(SICI)1099-1492(199706/08)10:4/5&lt;171::AID-NBM453&gt;3.0.CO;2-L</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-brett_nibabel_2006">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Brett</surname><given-names>Matthew</given-names></name>
          <name><surname>Markiewicz</surname><given-names>Christopher J.</given-names></name>
          <name><surname>Hanke</surname><given-names>Michael</given-names></name>
          <name><surname>Cote</surname><given-names>Marc-Alexandre</given-names></name>
          <name><surname>Cipollini</surname><given-names>Ben</given-names></name>
          <name><surname>McCarthy</surname><given-names>Paul</given-names></name>
          <name><surname>Cheng</surname><given-names>Chris</given-names></name>
          <name><surname>Halchenko</surname><given-names>Yaroslav O.</given-names></name>
          <name><surname>Ghosh</surname><given-names>Satrajit S.</given-names></name>
          <name><surname>Larson</surname><given-names>Eric</given-names></name>
          <name><surname>Wassermann</surname><given-names>Demian</given-names></name>
          <name><surname>Gerhard</surname><given-names>Stephan</given-names></name>
        </person-group>
        <article-title>Open Source Software: NiBabel</article-title>
        <source>Zenodo</source>
        <year iso-8601-date="2006">2006</year>
        <uri>https://zenodo.org/record/3458246\#.XaS82-ZKi5M</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.591597</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-fischl_freesurfer_2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fischl</surname><given-names>B.</given-names></name>
        </person-group>
        <article-title>FreeSurfer</article-title>
        <source>NeuroImage</source>
        <year iso-8601-date="2012">2012</year>
        <volume>62</volume>
        <issue>2</issue>
        <issn>1053-8119</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S1053811912000389</uri>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-jenkinson_fsl_2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jenkinson</surname><given-names>Mark</given-names></name>
          <name><surname>Beckmann</surname><given-names>Christian F.</given-names></name>
          <name><surname>Behrens</surname><given-names>Timothy E. J.</given-names></name>
          <name><surname>Woolrich</surname><given-names>Mark W.</given-names></name>
          <name><surname>Smith</surname><given-names>Stephen M.</given-names></name>
        </person-group>
        <article-title>FSL</article-title>
        <source>NeuroImage</source>
        <year iso-8601-date="2012">2012</year>
        <volume>62</volume>
        <issue>2</issue>
        <issn>1053-8119</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S1053811911010603</uri>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-avants_symmetric_2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Avants</surname><given-names>B. B.</given-names></name>
          <name><surname>Epstein</surname><given-names>C. L.</given-names></name>
          <name><surname>Grossman</surname><given-names>M.</given-names></name>
          <name><surname>Gee</surname><given-names>J. C.</given-names></name>
        </person-group>
        <article-title>Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain</article-title>
        <source>Medical Image Analysis</source>
        <year iso-8601-date="2008">2008</year>
        <volume>12</volume>
        <issue>1</issue>
        <issn>1361-8415</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S1361841507000606</uri>
        <pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-friston_statistical_2006">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Friston</surname><given-names>Karl J.</given-names></name>
          <name><surname>Ashburner</surname><given-names>John</given-names></name>
          <name><surname>Kiebel</surname><given-names>Stefan J.</given-names></name>
          <name><surname>Nichols</surname><given-names>Thomas E.</given-names></name>
          <name><surname>Penny</surname><given-names>William D.</given-names></name>
        </person-group>
        <source>Statistical parametric mapping : The analysis of functional brain images</source>
        <publisher-name>Academic Press</publisher-name>
        <publisher-loc>London</publisher-loc>
        <year iso-8601-date="2006">2006</year>
        <isbn>978-0-12-372560-8</isbn>
      </element-citation>
    </ref>
    <ref id="ref-yushkevich_open_nodate">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Yushkevich</surname><given-names>Paul A.</given-names></name>
        </person-group>
        <article-title>Open Source Software: Convert3D Medical Imaging Processing tool</article-title>
        <source>Sourceforge</source>
        <uri>https://sourceforge.net/p/c3d</uri>
      </element-citation>
    </ref>
    <ref id="ref-esteban_fmriprep_2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Esteban</surname><given-names>Oscar</given-names></name>
          <name><surname>Markiewicz</surname><given-names>Christopher J.</given-names></name>
          <name><surname>Blair</surname><given-names>Ross W.</given-names></name>
          <name><surname>Moodie</surname><given-names>Craig A.</given-names></name>
          <name><surname>Isik</surname><given-names>A. Ilkay</given-names></name>
          <name><surname>Erramuzpe</surname><given-names>Asier</given-names></name>
          <name><surname>Kent</surname><given-names>James D.</given-names></name>
          <name><surname>Goncalves</surname><given-names>Mathias</given-names></name>
          <name><surname>DuPre</surname><given-names>Elizabeth</given-names></name>
          <name><surname>Snyder</surname><given-names>Madeleine</given-names></name>
          <name><surname>Oya</surname><given-names>Hiroyuki</given-names></name>
          <name><surname>Ghosh</surname><given-names>Satrajit S.</given-names></name>
          <name><surname>Wright</surname><given-names>Jessey</given-names></name>
          <name><surname>Durnez</surname><given-names>Joke</given-names></name>
          <name><surname>Poldrack</surname><given-names>Russell A.</given-names></name>
          <name><surname>Gorgolewski</surname><given-names>Krzysztof J.</given-names></name>
        </person-group>
        <article-title>fMRIPrep: A robust preprocessing pipeline for functional MRI</article-title>
        <source>Nat Meth</source>
        <year iso-8601-date="2019-01">2019</year><month>01</month>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-12-10">2018</year><month>12</month><day>10</day></date-in-citation>
        <volume>16</volume>
        <issue>1</issue>
        <issn>1548-7105</issn>
        <uri>https://www.nature.com/articles/s41592-018-0235-4</uri>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">774</article-id>
<article-id pub-id-type="doi">10.21105/joss.00774</article-id>
<title-group>
<article-title>quanteda: An R package for the quantitative analysis of
textual data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0797-564X</contrib-id>
<string-name>Kenneth Benoit</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6519-5265</contrib-id>
<string-name>Kohei Watanabe</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-4992-4311</contrib-id>
<string-name>Haiyan Wang</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7214-4666</contrib-id>
<string-name>Paul Nulty</string-name>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-2906-4775</contrib-id>
<string-name>Adam Obeng</string-name>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6315-4125</contrib-id>
<string-name>Stefan Müller</string-name>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3323-6330</contrib-id>
<string-name>Akitaka Matsuo</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Methodology, London School of Economics and
Political Science</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>De Beers Inc.</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Centre for Research in Arts, Social Science and Humanities,
University of Cambridge</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Facebook, Inc. (work conducted at the Department of
Methodology, London School of Economics and Political
Science)</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Department of Political Science, Trinity College
Dublin</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-10-04">
<day>4</day>
<month>10</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>30</issue>
<fpage>774</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>text mining</kwd>
<kwd>natural language processing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><bold>quanteda</bold> is an R package providing a comprehensive
  workflow and toolkit for natural language processing tasks such as
  corpus management, tokenization, analysis, and visualization. It has
  extensive functions for applying dictionary analysis, exploring texts
  using keywords-in-context, computing document and feature
  similarities, and discovering multi-word expressions through
  collocation scoring. Based entirely on sparse operations, it provides
  highly efficient methods for compiling document-feature matrices and
  for manipulating these or using them in further quantitative analysis.
  Using C++ and multi-threading extensively, <bold>quanteda</bold> is
  also considerably faster and more efficient than other R and Python
  packages in processing large textual data.</p>
  <p>The package is designed for R users needing to apply natural
  language processing to texts, from documents to final analysis. Its
  capabilities match or exceed those provided in many end-user software
  applications, many of which are expensive and not open source. The
  package is therefore of great benefit to researchers, students, and
  other analysts with fewer financial resources. While using
  <bold>quanteda</bold> requires R programming knowledge, its API is
  designed to enable powerful, efficient analysis with a minimum of
  steps. By emphasizing consistent design, furthermore,
  <bold>quanteda</bold> lowers the barriers to learning and using NLP
  and quantitative text analysis even for proficient R programmers.</p>
</sec>
<sec id="corpus-management">
  <title>Corpus management</title>
  <p><bold>quanteda</bold> makes it easy to manage texts in the form of
  a “corpus”, which is defined as a collection of texts that includes
  document-level variables specific to each text, as well as meta-data
  for documents and for the collection as a whole. With the package,
  users can easily segment texts by words, paragraphs, sentences, or
  even user-supplied delimiters and tags, group them into larger
  documents by document-level variables, or subset them based on logical
  conditions or combinations of document-level variables.</p>
</sec>
<sec id="natural-language-processing">
  <title>Natural language processing</title>
  <p><bold>quanteda</bold> is principally designed to allow users a fast
  and convenient method to construct a document-feature matrix from a
  corpus with an ability to perform the most common natural language
  processing tasks such as tokenizing, stemming, forming n-grams, and
  selecting and weighting features. With these functions, users can
  easily remove stop words and stem words in numerous languages, select
  words in a dictionary, and convert frequency counts into weights, for
  instance using <italic>tf-idf</italic> scoring.</p>
  <p>Using the ICU library in the <bold>stringi</bold> package
  (<xref alt="Gagolewski, 2018" rid="ref-stringi" ref-type="bibr">Gagolewski,
  2018</xref>) for text processing, <bold>quanteda</bold> correctly
  handles Unicode character sets for regular expression matching and
  detecting word boundaries for tokenization. Once texts are tokenized,
  <bold>quanteda</bold> maps tokens to a hash table of integers to
  increase processing speed while reducing memory usage. Many of the
  text processing functions are parallelized using the Intel TBB library
  via the <bold>RcppParallel</bold> package
  (<xref alt="Allaire et al., 2018" rid="ref-RcppParallel" ref-type="bibr">Allaire
  et al., 2018</xref>).</p>
</sec>
<sec id="models-and-textual-statistics">
  <title>Models and textual statistics</title>
  <p><bold>quanteda</bold> is especially suited to research because it
  was designed from the outset for the social scientific analysis of
  textual data. Its <monospace>textmodel_*</monospace> functions provide
  native, highly efficient implementations of several text analytic
  scaling methods, such as Wordscores
  (<xref alt="Laver et al., 2003" rid="ref-lbgU003A2003" ref-type="bibr">Laver
  et al., 2003</xref>), Wordfish
  (<xref alt="Slapin &amp; Proksch, 2008" rid="ref-SlapinProksch2008" ref-type="bibr">Slapin
  &amp; Proksch, 2008</xref>), class affinity scaling
  (<xref alt="Perry &amp; Benoit, 2017" rid="ref-PerryBenoit2017" ref-type="bibr">Perry
  &amp; Benoit, 2017</xref>), and correspondence analysis
  (<xref alt="Greenacre, 1984" rid="ref-greenacre1984" ref-type="bibr">Greenacre,
  1984</xref>). More general textmodel functions include efficient
  implementations of a multinomial Naive Bayes classifier designed
  specifically for textual data
  (<xref alt="Manning et al., 2008" rid="ref-Manningetal2008" ref-type="bibr">Manning
  et al., 2008</xref>) and latent semantic analysis
  (<xref alt="Deerwester et al., 1990" rid="ref-deerwester1990" ref-type="bibr">Deerwester
  et al., 1990</xref>). <bold>quanteda</bold> also works flexibly and
  efficiently with dictionaries, and is distributed with the 2015
  version of the Lexicoder Sentiment Dictionary
  (<xref alt="Young &amp; Soroka, 2012" rid="ref-youngsoroka2012" ref-type="bibr">Young
  &amp; Soroka, 2012</xref>).</p>
  <p>In addition to models, the package provides a variety of text
  statistics, such as frequency analysis, “keyness”, lexical diversity,
  readability, and similarity and distance of documents or features.
  These make use of the sparsity of document-feature matrices – often
  over 90% sparse – and parallelism for efficient, fast computation.
  <bold>quanteda</bold> also provides methods for statistically scoring
  collocations, useful in identifying multi-word expressions.</p>
</sec>
<sec id="text-visualization">
  <title>Text visualization</title>
  <p>The package provides extensive methods for visualizing textual
  analyses, via its family of <monospace>textplot_*</monospace>
  functions. These are typically designed to take another package object
  as an input, to produce a specific form of plot. For instance, from a
  feature co-occurrence matrix, or <monospace>fcm</monospace>, we can
  directly plot a network using
  <monospace>textplot_network()</monospace>:</p>
  <code language="r script">library(&quot;quanteda&quot;)

# construct the feature co-occurrence matrix
examplefcm &lt;-
    tokens(data_corpus_irishbudget2010, remove_punct = TRUE) %&gt;%
    tokens_tolower() %&gt;%
    tokens_remove(stopwords(&quot;english&quot;), padding = FALSE) %&gt;%
    fcm(context = &quot;window&quot;, window = 5, tri = FALSE)

# choose 30 most frequency features
topfeats &lt;- names(topfeatures(examplefcm, 30))

# select the top 30 features only, plot the network
set.seed(100)
textplot_network(fcm_select(examplefcm, topfeats), min_freq = 0.8)</code>
  <fig>
    <caption><p>Feature co-occurrence network plot
    example.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="networkplot.png" xlink:title="" />
  </fig>
</sec>
<sec id="package-design">
  <title>Package design</title>
  <p><bold>quanteda</bold> has been carefully designed with several key
  aims in mind.</p>
  <p><italic>Consistency</italic>. <bold>quanteda</bold> functions and
  objects are named systematically such that
  <monospace>corpus()</monospace>, <monospace>tokens()</monospace> and
  <monospace>dfm()</monospace> construct those object types, and that
  <monospace>corpus_*()</monospace>, <monospace>tokens_*()</monospace>
  and <monospace>dfm_*()</monospace> functions return a modified version
  of these objects. Naming consistency applies also to the extensive
  built-in data objects in the package, whose names always start with
  <monospace>data_*</monospace> followed by object types. This not only
  gives the users a clear overview of the package, but also makes the
  package more reliable for other packages that depend on it.</p>
  <p><italic>Accessibility</italic>. <bold>quanteda</bold> contains
  extensive manual pages structured around the naming rules.
  Furthermore, there are references, package vignettes, examples, and
  tutorials on the website at https://quanteda.io. These materials help
  beginner users understand how to use these functions for basic
  operations and expert users how to combine the functions for advanced
  text processing and analysis.</p>
  <p><italic>Performance</italic>. <bold>quanteda</bold>’s performance
  is enhanced by token hashing and parallel computation implemented in
  C++, permitting large and fast text analysis even on computers with
  relatively limited resources (such as laptop computers). Built to use
  sparse data structures, <bold>quanteda</bold> can efficiently performs
  complex textual data analyses, such as computing distances,
  calculating feature discrimination statistics (keyness), or model
  fitting, even for large document-feature matrices.</p>
  <p><italic>Transparency and reproducibility</italic>.
  <bold>quanteda</bold> is designed to facilitate rigorous, transparent,
  and reproducible scientific analysis of text. Being open-source
  software, its source code can be scrutinized and corrected by other
  experts. Its functions are designed to encourage a reproducible
  workflow by linking successive processing tasks in a clear, readable
  manner.</p>
  <p><italic>Compatibility with other packages</italic>. For analysis
  not provided by built-in functions, users can move
  <bold>quanteda</bold> objects seamlessly to other packages, such as
  the <bold>stm</bold> package for structural topic models
  (<xref alt="Roberts et al., 2018" rid="ref-STM" ref-type="bibr">Roberts
  et al., 2018</xref>) or word embedding packages like
  <bold>text2vec</bold>
  (<xref alt="Selivanov &amp; Wang, 2018" rid="ref-text2vec" ref-type="bibr">Selivanov
  &amp; Wang, 2018</xref>). <bold>quanteda</bold> also works well with
  companion packages such as <bold>spacyr</bold>
  (<xref alt="Benoit &amp; Matsuo, 2018" rid="ref-spacyr" ref-type="bibr">Benoit
  &amp; Matsuo, 2018</xref>), an R wrapper to the spaCy Python library
  (<xref alt="Honnibal &amp; Montani, 2017" rid="ref-spacy2" ref-type="bibr">Honnibal
  &amp; Montani, 2017</xref>), and <bold>readtext</bold>
  (<xref alt="Benoit &amp; Obeng, 2018" rid="ref-readtext" ref-type="bibr">Benoit
  &amp; Obeng, 2018</xref>), a package for converting and importing text
  files into R.</p>
</sec>
<sec id="funding-and-support">
  <title>Funding and Support</title>
  <p>Created at the London School of Economics in 2013 with funding from
  the European Research Council (ERC-2011-StG 283794-QUANTESS),
  <bold>quanteda</bold> is now supported by the
  <ext-link ext-link-type="uri" xlink:href="https://quanteda.org">Quanteda
  Initiative</ext-link>, a non-profit organization founded in 2018 to
  provide ongoing support for the “quanteda ecosystem” of open-source
  text analysis software.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-PerryBenoit2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Perry</surname><given-names>Patrick O.</given-names></name>
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
        </person-group>
        <article-title>Scaling Text with the Class Affinity Model</article-title>
        <source>ArXiv e-prints</source>
        <year iso-8601-date="2017-10">2017</year><month>10</month>
        <uri>https://arxiv.org/abs/1710.08963</uri>
      </element-citation>
    </ref>
    <ref id="ref-lbgU003A2003">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Laver</surname><given-names>Michael</given-names></name>
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
          <name><surname>Garry</surname><given-names>John</given-names></name>
        </person-group>
        <article-title>Extracting policy positions from political texts using words as data</article-title>
        <source>American Political Science Review</source>
        <year iso-8601-date="2003">2003</year>
        <volume>97</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1017/S0003055403000698</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-SlapinProksch2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Slapin</surname><given-names>Jonathan B.</given-names></name>
          <name><surname>Proksch</surname><given-names>Sven-Oliver</given-names></name>
        </person-group>
        <article-title>A scaling model for estimating time-series party positions from texts</article-title>
        <source>American Journal of Political Science</source>
        <year iso-8601-date="2008">2008</year>
        <volume>52</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1111/j.1540-5907.2008.00338.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-greenacre1984">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Greenacre</surname><given-names>Michael J</given-names></name>
        </person-group>
        <source>Theory and applications of correspondence analysis</source>
        <publisher-name>Academic Press</publisher-name>
        <publisher-loc>London</publisher-loc>
        <year iso-8601-date="1984">1984</year>
      </element-citation>
    </ref>
    <ref id="ref-Manningetal2008">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Manning</surname><given-names>Christopher D</given-names></name>
          <name><surname>Raghavan</surname><given-names>Prabhakar</given-names></name>
          <name><surname>Schütze</surname><given-names>Hinrich</given-names></name>
        </person-group>
        <source>Introduction to information retrieval</source>
        <publisher-name>Cambridge University Press</publisher-name>
        <publisher-loc>Cambridge</publisher-loc>
        <year iso-8601-date="2008">2008</year>
        <pub-id pub-id-type="doi">10.1017/CBO9780511809071</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-deerwester1990">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Deerwester</surname><given-names>Scott</given-names></name>
          <name><surname>Dumais</surname><given-names>Susan T</given-names></name>
          <name><surname>Furnas</surname><given-names>George W</given-names></name>
          <name><surname>Landauer</surname><given-names>Thomas K</given-names></name>
          <name><surname>Harshman</surname><given-names>Richard</given-names></name>
        </person-group>
        <article-title>Indexing by latent semantic analysis</article-title>
        <source>Journal of the American Society for Information Science</source>
        <year iso-8601-date="1990">1990</year>
        <volume>41</volume>
        <issue>6</issue>
        <pub-id pub-id-type="doi">10.1002/(SICI)1097-4571(199009)41:6%3C391::AID-ASI1%3E3.0.CO;2-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-youngsoroka2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Young</surname><given-names>Lori</given-names></name>
          <name><surname>Soroka</surname><given-names>Stuart</given-names></name>
        </person-group>
        <article-title>Affective news: The automated coding of sentiment in political texts</article-title>
        <source>Political Communication</source>
        <year iso-8601-date="2012">2012</year>
        <volume>29</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1080/10584609.2012.671234</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-spacy2">
      <element-citation publication-type="manuscript">
        <person-group person-group-type="author">
          <name><surname>Honnibal</surname><given-names>Matthew</given-names></name>
          <name><surname>Montani</surname><given-names>Ines</given-names></name>
        </person-group>
        <article-title>spaCy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</article-title>
        <year iso-8601-date="2017">2017</year>
        <pub-id pub-id-type="doi">10.5281/zenodo.1212304</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-STM">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Roberts</surname><given-names>Margaret E.</given-names></name>
          <name><surname>Stewart</surname><given-names>Brandon M.</given-names></name>
          <name><surname>Tingley</surname><given-names>Dustin</given-names></name>
        </person-group>
        <source>Stm: R package for structural topic models</source>
        <year iso-8601-date="2018">2018</year>
        <uri>http://www.structuraltopicmodel.com</uri>
      </element-citation>
    </ref>
    <ref id="ref-text2vec">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Selivanov</surname><given-names>Dmitriy</given-names></name>
          <name><surname>Wang</surname><given-names>Qing</given-names></name>
        </person-group>
        <source>text2vec: Modern text mining framework for r</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=text2vec</uri>
      </element-citation>
    </ref>
    <ref id="ref-stringi">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Gagolewski</surname><given-names>Marek</given-names></name>
        </person-group>
        <source>R package stringi: Character string processing facilities</source>
        <year iso-8601-date="2018">2018</year>
        <uri>http://www.gagolewski.com/software/stringi/</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1292492</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-RcppParallel">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Allaire</surname><given-names>JJ</given-names></name>
          <name><surname>Francois</surname><given-names>Romain</given-names></name>
          <name><surname>Ushey</surname><given-names>Kevin</given-names></name>
          <name><surname>Vandenbrouck</surname><given-names>Gregory</given-names></name>
          <name><surname>Geelnard</surname><given-names>Marcus</given-names></name>
          <string-name>Intel</string-name>
        </person-group>
        <source>RcppParallel: Parallel programming tools for rcpp</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=RcppParallel</uri>
      </element-citation>
    </ref>
    <ref id="ref-readtext">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
          <name><surname>Obeng</surname><given-names>Adam</given-names></name>
        </person-group>
        <source>Readtext: Import and handling for plain and formatted text files</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=readtext</uri>
      </element-citation>
    </ref>
    <ref id="ref-spacyr">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Benoit</surname><given-names>Kenneth</given-names></name>
          <name><surname>Matsuo</surname><given-names>Akitaka</given-names></name>
        </person-group>
        <source>Spacyr: Wrapper to the spaCy NLP library</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=spacyr</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

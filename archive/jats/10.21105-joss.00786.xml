<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">786</article-id>
<article-id pub-id-type="doi">10.21105/joss.00786</article-id>
<title-group>
<article-title>iml: An R package for Interpretable Machine
Learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2331-868X</contrib-id>
<string-name>Christoph Molnar</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-5324-5966</contrib-id>
<string-name>Giuseppe Casalicchio</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6002-6980</contrib-id>
<string-name>Bernd Bischl</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Statistics, LMU Munich</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-06-19">
<day>19</day>
<month>6</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>26</issue>
<fpage>786</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>machine learning</kwd>
<kwd>interpretability</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Complex, non-parametric models, which are typically used in machine
  learning, have proven to be successful in many prediction tasks. But
  these models usually operate as black boxes: While they are good at
  predicting, they are often not interpretable. Many inherently
  interpretable models have been suggested, which come at the cost of
  losing predictive power. Another option is to apply interpretability
  methods to a black box model after model training. Given the velocity
  of research on new machine learning models, it is preferable to have
  model-agnostic tools which can be applied to a random forest as well
  as to a neural network. Tools for model-agnostic interpretability
  methods should improve the adoption of machine learning.</p>
  <p><monospace>iml</monospace> is an R package
  (<xref alt="R Core Team, 2016" rid="ref-R" ref-type="bibr">R Core
  Team, 2016</xref>) that offers a general toolbox for making machine
  learning models interpretable. It implements many model-agnostic
  methods which work for any type of machine learning model. The package
  covers following methods:</p>
  <list list-type="bullet">
    <list-item>
      <p>Partial dependence plots
      (<xref alt="Friedman, 2001" rid="ref-friedman2001greedy" ref-type="bibr">Friedman,
      2001</xref>): Visualizing the learned relationship between
      features and predictions.</p>
    </list-item>
    <list-item>
      <p>Individual conditional expectation
      (<xref alt="Goldstein et al., 2015" rid="ref-ice" ref-type="bibr">Goldstein
      et al., 2015</xref>): Visualizing the learned relationship between
      features and predictions for individual instances of the data.</p>
    </list-item>
    <list-item>
      <p>Feature importance
      (<xref alt="Fisher et al., 2018" rid="ref-Fisher2018" ref-type="bibr">Fisher
      et al., 2018</xref>): Scoring features by contribution to
      predictive performance.</p>
    </list-item>
    <list-item>
      <p>Global surrogate tree: Approximating the black box model with
      an interpretable decision tree.</p>
    </list-item>
    <list-item>
      <p>Local surrogate models
      (<xref alt="Ribeiro et al., 2016" rid="ref-ribeiro2016should" ref-type="bibr">Ribeiro
      et al., 2016</xref>): Explaining single predictions by
      approximating the black box model locally with an interpretable
      model.</p>
    </list-item>
    <list-item>
      <p>Shapley value
      (<xref alt="Strumbelj et al., 2014" rid="ref-strumbelj2014" ref-type="bibr">Strumbelj
      et al., 2014</xref>): Explaining single predictions by fairly
      distributing the predicted value among the features.</p>
    </list-item>
    <list-item>
      <p>Interaction effects
      (<xref alt="Friedman et al., 2008" rid="ref-friedman2008predictive" ref-type="bibr">Friedman
      et al., 2008</xref>): Measuring how strongly features interact
      with each other in the black box model.</p>
    </list-item>
  </list>
  <p><monospace>iml</monospace> was designed to provide a class-based
  and user-friendly way to make black box machine learning models
  interpretable. Internally, the implemented methods inherit from the
  same parent class and share a common framework for the computation.
  Many of the methods are already implemented in other packages (e.g.
  (<xref alt="Greenwell, 2017" rid="ref-pdp1" ref-type="bibr">Greenwell,
  2017</xref>),
  (<xref alt="Goldstein et al., 2015" rid="ref-ice" ref-type="bibr">Goldstein
  et al., 2015</xref>),
  (<xref alt="Pedersen &amp; Benesty, 2017" rid="ref-lime" ref-type="bibr">Pedersen
  &amp; Benesty, 2017</xref>)), but the <monospace>iml</monospace>
  package implements all of the methods in one place, uses the same
  syntax and offers consistent functionality and outputs.
  <monospace>iml</monospace> can be used with models from the R machine
  learning libraries <monospace>mlr</monospace> and
  <monospace>caret</monospace>, but the package is flexible enough to
  work with models from other packages as well. Similar projects are the
  R package <monospace>DALEX</monospace>
  (<xref alt="Biecek, 2018" rid="ref-dalex" ref-type="bibr">Biecek,
  2018</xref>) and the Python package <monospace>Skater</monospace>
  (<xref alt="Choudhary et al., 2018" rid="ref-pramit_choudhary_2018_1198885" ref-type="bibr">Choudhary
  et al., 2018</xref>). The difference to <monospace>iml</monospace> is
  that the other two projects do not implement the methods themselves,
  but depend on other packages. <monospace>DALEX</monospace> focuses
  more on model comparison, and <monospace>Skater</monospace>
  additionally includes interpretable models and has less model-agnostic
  interpretability methods compared to <monospace>iml</monospace>.</p>
  <p>The unified interface provided by the <monospace>iml</monospace>
  package simplifies the analysis and interpretation of black box
  machine learning learning models.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work is funded by the Bavarian State Ministry of Science and
  the Arts in the framework of the Centre Digitisation.Bavaria
  (ZD.B)</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-pramit_choudhary_2018_1198885">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Choudhary</surname><given-names>Pramit</given-names></name>
          <name><surname>Kramer</surname><given-names>Aaron</given-names></name>
          <name><surname>team</surname><given-names>contributors datascience.com</given-names></name>
        </person-group>
        <article-title>Skater: Model Interpretation Library</article-title>
        <year iso-8601-date="2018-03">2018</year><month>03</month>
        <uri>https://doi.org/10.5281/zenodo.1198885</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.1198885</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-dalex">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
        </person-group>
        <source>DALEX: Descriptive mAchine learning EXplanations</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://CRAN.R-project.org/package=DALEX</uri>
      </element-citation>
    </ref>
    <ref id="ref-lime">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Pedersen</surname><given-names>Thomas Lin</given-names></name>
          <name><surname>Benesty</surname><given-names>Michaël</given-names></name>
        </person-group>
        <source>Lime: Local interpretable model-agnostic explanations</source>
        <year iso-8601-date="2017">2017</year>
        <uri>https://CRAN.R-project.org/package=lime</uri>
      </element-citation>
    </ref>
    <ref id="ref-pdp1">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Greenwell</surname><given-names>Brandon M.</given-names></name>
        </person-group>
        <article-title>Pdp: An r package for constructing partial dependence plots</article-title>
        <source>The R Journal</source>
        <year iso-8601-date="2017">2017</year>
        <volume>9</volume>
        <issue>1</issue>
        <uri>https://journal.r-project.org/archive/2017/RJ-2017-016/index.html</uri>
      </element-citation>
    </ref>
    <ref id="ref-ice">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Goldstein</surname><given-names>Alex</given-names></name>
          <name><surname>Kapelner</surname><given-names>Adam</given-names></name>
          <name><surname>Bleich</surname><given-names>Justin</given-names></name>
          <name><surname>Pitkin</surname><given-names>Emil</given-names></name>
        </person-group>
        <article-title>Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year iso-8601-date="2015">2015</year>
        <volume>24</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1080/10618600.2014.907095</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-friedman2008predictive">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>Jerome H</given-names></name>
          <name><surname>Popescu</surname><given-names>Bogdan E</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Predictive learning via rule ensembles</article-title>
        <source>The Annals of Applied Statistics</source>
        <publisher-name>Institute of Mathematical Statistics</publisher-name>
        <year iso-8601-date="2008">2008</year>
        <volume>2</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1214/07-AOAS148</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-strumbelj2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Strumbelj</surname><given-names>Erik</given-names></name>
          <name><surname>Kononenko</surname><given-names>Igor</given-names></name>
          <name><surname>Štrumbelj</surname><given-names>Erik</given-names></name>
          <name><surname>Kononenko</surname><given-names>Igor</given-names></name>
        </person-group>
        <article-title>Explaining prediction models and individual predictions with feature contributions</article-title>
        <source>Knowledge and Information Systems</source>
        <year iso-8601-date="2014">2014</year>
        <volume>41</volume>
        <issue>3</issue>
        <isbn>0219-1377</isbn>
        <issn>02193116</issn>
        <pub-id pub-id-type="doi">10.1007/s10115-013-0679-x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-ribeiro2016should">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Ribeiro</surname><given-names>Marco Tulio</given-names></name>
          <name><surname>Singh</surname><given-names>Sameer</given-names></name>
          <name><surname>Guestrin</surname><given-names>Carlos</given-names></name>
        </person-group>
        <article-title>Why should i trust you?: Explaining the predictions of any classifier</article-title>
        <source>Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.1145/2939672.2939778</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Fisher2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fisher</surname><given-names>Aaron</given-names></name>
          <name><surname>Rudin</surname><given-names>Cynthia</given-names></name>
          <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
        </person-group>
        <article-title>Model Class Reliance: Variable Importance Measures for any Machine Learning Model Class, from the &quot;Rashomon&quot; Perspective</article-title>
        <year iso-8601-date="2018">2018</year>
        <uri>http://arxiv.org/abs/1801.01489</uri>
      </element-citation>
    </ref>
    <ref id="ref-R">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <source>R: A language and environment for statistical computing</source>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <uri>https://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-friedman2001greedy">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>Jerome H</given-names></name>
        </person-group>
        <article-title>Greedy function approximation: A gradient boosting machine</article-title>
        <source>Annals of statistics</source>
        <publisher-name>JSTOR</publisher-name>
        <year iso-8601-date="2001">2001</year>
        <pub-id pub-id-type="doi">10.1214/aos/1013203451 </pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

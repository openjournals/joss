<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1904</article-id>
<article-id pub-id-type="doi">10.21105/joss.01904</article-id>
<title-group>
<article-title>FAT Forensics: A Python Toolbox for Implementing and
Deploying Fairness, Accountability and Transparency Algorithms in
Predictive Systems</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9869-5896</contrib-id>
<string-name>Kacper Sokol</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Alexander Hepburn</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Rafael Poyiadzi</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Matthew Clifford</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Raul Santos-Rodriguez</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6857-5810</contrib-id>
<string-name>Peter Flach</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Computer Science, University of
Bristol</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Engineering Mathematics, University of
Bristol</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-09-01">
<day>1</day>
<month>9</month>
<year>2019</year>
</pub-date>
<volume>5</volume>
<issue>49</issue>
<fpage>1904</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Fairness</kwd>
<kwd>Accountability</kwd>
<kwd>Transparency</kwd>
<kwd>Artificial Intelligence</kwd>
<kwd>Machine Learning</kwd>
<kwd>Software</kwd>
<kwd>Python Toolbox</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="background">
  <title>Background</title>
  <p>Predictive systems, in particular machine learning algorithms, can
  take important decisions – sometimes legally binding – about our
  everyday life. In most cases, however, these systems and decisions are
  neither regulated nor certified. Given the potential harm that these
  systems can cause, qualities such as <bold>fairness</bold>,
  <bold>accountability</bold> and <bold>transparency</bold> (FAT) of
  predictive systems are of paramount importance. To ensure
  high-quality, fair, transparent and reliable predictive systems, we
  developed an open source Python package called <italic>FAT
  Forensics</italic> that can inspect important fairness, accountability
  and transparency aspects of these systems to automatically and
  objectively report them back to their engineers and users. Our toolbox
  offers full functionality for evaluating all aspects of a predictive
  pipeline: data (and their features), models and predictions. Published
  under the BSD 3-Clause open source licence, FAT Forensics is opened up
  for personal and commercial usage.</p>
</sec>
<sec id="summary">
  <title>Summary</title>
  <p>FAT Forensics is designed as an interoperable framework for
  <italic>implementing</italic>, <italic>testing</italic> and
  <italic>deploying</italic> novel algorithms invented by the FAT
  research community and facilitates their evaluation and comparison
  against the state of the art, hence democratising access to these
  techniques. In addition to supporting research in this space, the
  toolbox is capable of analysing all artefacts of a predictive pipeline
  – data, models and predictions – by considering their fairness,
  accountability (robustness, security, safety and privacy) and
  transparency (interpretability and explainability). FAT Forensics
  collates all of these diverse tools and algorithms under a common
  application programming interface (API) using a modular design with
  shared core algorithmic components, thereby making the process of
  creating new algorithm as easy as connecting the right blocks – see
  Figure 1.</p>
  <fig>
    <caption><p>FAT Forensics modular architecture design.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="software_design.png" xlink:title="" />
  </fig>
  <p>The input requirements for data sets and predictive models are kept
  to a minimum, lowering any barriers for adoption of FAT Forensics in
  new and already well-established projects. In this abstraction a data
  set is assumed to be a two-dimensional NumPy array: either a classic
  or a structured array; with the latter being a welcome addition given
  that some of the features may be categorical (string-based). A
  predictive model is assumed to be a plain Python object that has
  <monospace>fit</monospace>, <monospace>predict</monospace> and,
  optionally, <monospace>predict_proba</monospace> methods, making it
  compatible with the most popular Python machine learning toolbox
  scikit-learn without introducing additional dependencies. Moreover,
  this approach makes FAT Forensics compatible with other packages for
  predictive modelling since their predictive functions can be easily
  wrapped inside a Python object with all the required methods.</p>
  <p>Our package improves over existing solutions as it collates
  algorithms across the FAT domains, taking advantage of their common
  functional building blocks. The common interface layer of the toolbox
  supports several “modes of operation”. The <bold>research mode</bold>
  (data in – visualisation out), where the tool can be loaded into an
  interactive Python session (e.g., a Jupyter Notebook), supports
  prototyping and exploratory analysis. This mode is intended for FAT
  researchers who could use it to propose new fairness metrics, compare
  them with the existing ones or use them to inspect a new system or a
  data set. The <bold>deployment mode</bold> (data in – data out) can be
  used as a part of a data processing pipeline to provide a (numerical)
  FAT analytics, supporting automated reporting and dashboarding. This
  mode is intended for machine learning engineers and data scientists
  who may use it to monitor or evaluate a predictive system during
  development and deployment.</p>
  <p>To encourage long-term maintainability, sustainability and
  extensibility, FAT Forensics has been developed employing software
  engineering best practice such as unit testing, continuous
  integration, well-defined package structure and consistent code
  formatting. Furthermore, our toolbox is supported by a thorough and
  beginner-friendly documentation that is based on 4 main pillars, which
  together build up the user’s confidence in using the package:</p>
  <list list-type="bullet">
    <list-item>
      <p>narrative-driven <bold>tutorials</bold> designated for new
      users, which will guide them step-by-step through practical use
      cases of all the main aspects of the package;</p>
    </list-item>
    <list-item>
      <p><bold>how-to guides</bold> created for relatively new users of
      the package, which will showcase the flexibility of the package
      and show how to use it to solve user-specific FAT challenges,
      e.g., how to build your own local surrogate model explainer by
      pairing a data generator and a local glass-box model;</p>
    </list-item>
    <list-item>
      <p>an <bold>API documentation</bold> describing functional aspects
      of the algorithms implemented in the package and designated for a
      technical audience as a reference material complemented by
      task-focused <italic>code examples</italic> that put the
      functions, objects and methods in a context; and</p>
    </list-item>
    <list-item>
      <p>a <bold>user guide</bold> discussing theoretical aspects of the
      algorithms implemented in the package such as their restrictions,
      caveats, computational time and memory complexity, among
      others.</p>
    </list-item>
  </list>
  <p>We hope that this effort will encourage the FAT community to
  contribute their algorithms to FAT Forensics as an attractive
  alternative to releasing yet more standalone packages, keeping the
  toolbox at the frontiers of algorithmic fairness, accountability and
  transparency research. For a more detailed description of FAT
  Forensics, we point the reader to its documentation and the manuscript
  (<xref alt="Sokol et al., 2019" rid="ref-sokol2019fatf" ref-type="bibr">Sokol
  et al., 2019</xref>) describing its design, scope and usage
  examples.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was financially supported by Thales, and is the result of
  a collaborative research agreement between Thales and the University
  of Bristol.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-sokol2019fatf">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Sokol</surname><given-names>Kacper</given-names></name>
          <name><surname>Santos-Rodriguez</surname><given-names>Raul</given-names></name>
          <name><surname>Flach</surname><given-names>Peter</given-names></name>
        </person-group>
        <article-title>FAT forensics: A python toolbox for algorithmic fairness, accountability and transparency</article-title>
        <source>arXiv preprint arXiv:1909.05167</source>
        <year iso-8601-date="2019">2019</year>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">357</article-id>
<article-id pub-id-type="doi">10.21105/joss.00357</article-id>
<title-group>
<article-title>schwimmbad: A uniform interface to parallel processing
pools in Python</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0872-7098</contrib-id>
<string-name>Adrian M. Price-Whelan</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9328-5652</contrib-id>
<string-name>Daniel Foreman-Mackey</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Lyman Spitzer, Jr. Fellow, Princeton
University</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Sagan Fellow, University of Washington</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2017-08-11">
<day>11</day>
<month>8</month>
<year>2017</year>
</pub-date>
<volume>2</volume>
<issue>17</issue>
<fpage>357</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>multiprocessing</kwd>
<kwd>parallel computing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Many scientific and computing problems require doing some
  calculation on all elements of some data set. If the calculations can
  be executed in parallel (i.e. without any communication between
  calculations), these problems are said to be
  <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Embarrassingly_parallel"><italic>perfectly
  parallel</italic></ext-link>. On computers with multiple processing
  cores, these tasks can be distributed and executed in parallel to
  greatly improve performance. A common paradigm for handling these
  distributed computing problems is to use a processing “pool”: the
  “tasks” (the data) are passed in bulk to the pool, and the pool
  handles distributing the tasks to a number of worker processes when
  available.</p>
  <p>In Python, the built-in <monospace>multiprocessing</monospace>
  package provides a <monospace>Pool</monospace> class for exactly this
  design case, but only supports distributing the tasks amongst multiple
  cores of a single processor. To extend to large cluster computing
  environments, other protocols are required, such as the Message
  Passing Interface [MPI; Forum
  (<xref alt="1994" rid="ref-Forum1994" ref-type="bibr">1994</xref>)].
  <monospace>schwimmbad</monospace> provides new
  <monospace>Pool</monospace> classes for a number of parallel
  processing environments with a consistent interface. This enables
  easily switching between local development (e.g., serial processing or
  with Python’s built-in <monospace>multiprocessing</monospace>) and
  deployment on a cluster or supercomputer (via, e.g., MPI or JobLib).
  This library supports processing pools with a number of backends:</p>
  <list list-type="bullet">
    <list-item>
      <p>Serial processing: <monospace>SerialPool</monospace></p>
    </list-item>
    <list-item>
      <p><monospace>Python</monospace> standard-library
      <monospace>multiprocessing</monospace>:
      <monospace>MultiPool</monospace></p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="open-mpi.org"><monospace>OpenMPI</monospace></ext-link>
      (<xref alt="Gabriel et al., 2004" rid="ref-Gabriel2004" ref-type="bibr">Gabriel
      et al., 2004</xref>) and
      <ext-link ext-link-type="uri" xlink:href="https://www.mpich.org/"><monospace>mpich2</monospace></ext-link>
      (<xref alt="Lusk et al., 1996" rid="ref-Lusk1996" ref-type="bibr">Lusk
      et al., 1996</xref>) via the <monospace>mpi4py</monospace> package
      (<xref alt="Dalcín et al., 2005" rid="ref-Dalcin2005" ref-type="bibr">Dalcín
      et al., 2005</xref>,
      <xref alt="2008" rid="ref-Dalcin2008" ref-type="bibr">2008</xref>):
      <monospace>MPIPool</monospace></p>
    </list-item>
    <list-item>
      <p><ext-link ext-link-type="uri" xlink:href="http://pythonhosted.org/joblib/"><monospace>joblib</monospace></ext-link>:
      <monospace>JoblibPool</monospace></p>
    </list-item>
  </list>
  <p>All pool classes provide a <monospace>.map()</monospace> method to
  distribute tasks to a specified worker function (or callable), and
  support specifying a callback function that is executed on the master
  process to enable post-processing or caching the results as they are
  delivered.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Forum1994">
      <element-citation publication-type="report">
        <person-group person-group-type="author">
          <name><surname>Forum</surname><given-names>Message P</given-names></name>
        </person-group>
        <article-title>MPI: A message-passing interface standard</article-title>
        <publisher-name>University of Tennessee</publisher-name>
        <publisher-loc>Knoxville, TN, USA</publisher-loc>
        <year iso-8601-date="1994">1994</year>
      </element-citation>
    </ref>
    <ref id="ref-Gabriel2004">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Gabriel</surname><given-names>Edgar</given-names></name>
          <name><surname>Fagg</surname><given-names>Graham E.</given-names></name>
          <name><surname>Bosilca</surname><given-names>George</given-names></name>
          <name><surname>Angskun</surname><given-names>Thara</given-names></name>
          <name><surname>Dongarra</surname><given-names>Jack J.</given-names></name>
          <name><surname>Squyres</surname><given-names>Jeffrey M.</given-names></name>
          <name><surname>Sahay</surname><given-names>Vishal</given-names></name>
          <name><surname>Kambadur</surname><given-names>Prabhanjan</given-names></name>
          <name><surname>Barrett</surname><given-names>Brian</given-names></name>
          <name><surname>Lumsdaine</surname><given-names>Andrew</given-names></name>
          <name><surname>Castain</surname><given-names>Ralph H.</given-names></name>
          <name><surname>Daniel</surname><given-names>David J.</given-names></name>
          <name><surname>Graham</surname><given-names>Richard L.</given-names></name>
          <name><surname>Woodall</surname><given-names>Timothy S.</given-names></name>
        </person-group>
        <article-title>Open MPI: Goals, concept, and design of a next generation MPI implementation</article-title>
        <source>Proceedings, 11th european PVM/MPI users’ group meeting</source>
        <publisher-loc>Budapest, Hungary</publisher-loc>
        <year iso-8601-date="2004">2004</year>
      </element-citation>
    </ref>
    <ref id="ref-Dalcin2005">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Dalcín</surname><given-names>Lisandro</given-names></name>
          <name><surname>Paz</surname><given-names>Rodrigo</given-names></name>
          <name><surname>Storti</surname><given-names>Mario</given-names></name>
        </person-group>
        <article-title>MPI for python</article-title>
        <source>Journal of Parallel and Distributed Computing</source>
        <year iso-8601-date="2005">2005</year>
        <volume>65</volume>
        <issue>9</issue>
        <issn>0743-7315</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S0743731505000560</uri>
        <pub-id pub-id-type="doi">http://dx.doi.org/10.1016/j.jpdc.2005.03.010</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Dalcin2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Dalcín</surname><given-names>Lisandro</given-names></name>
          <name><surname>Paz</surname><given-names>Rodrigo</given-names></name>
          <name><surname>Storti</surname><given-names>Mario</given-names></name>
          <name><surname>D’Elía</surname><given-names>Jorge</given-names></name>
        </person-group>
        <article-title>MPI for python: Performance improvements and MPI-2 extensions</article-title>
        <source>Journal of Parallel and Distributed Computing</source>
        <year iso-8601-date="2008">2008</year>
        <volume>68</volume>
        <issue>5</issue>
        <issn>0743-7315</issn>
        <uri>http://www.sciencedirect.com/science/article/pii/S0743731507001712</uri>
        <pub-id pub-id-type="doi">http://dx.doi.org/10.1016/j.jpdc.2007.09.005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Lusk1996">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Lusk</surname><given-names>Ewing</given-names></name>
          <name><surname>Doss</surname><given-names>Nathan</given-names></name>
          <name><surname>Skjellum</surname><given-names>Anthony</given-names></name>
        </person-group>
        <article-title>A high-performance, portable implementation of the MPI message passing interface standard</article-title>
        <source>Parallel Computing</source>
        <year iso-8601-date="1996">1996</year>
        <volume>22</volume>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

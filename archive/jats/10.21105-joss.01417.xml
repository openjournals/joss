<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1417</article-id>
<article-id pub-id-type="doi">10.21105/joss.01417</article-id>
<title-group>
<article-title>pymcmcstat: A Python Package for Bayesian Inference Using
Delayed Rejection Adaptive Metropolis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-7501-5114</contrib-id>
<string-name>Paul R. Miles</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Mathematics, North Carolina State
University</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-04-22">
<day>22</day>
<month>4</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>38</issue>
<fpage>1417</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>MCMC</kwd>
<kwd>DRAM</kwd>
<kwd>Bayesian Inference</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Many scientific problems require calibrating a set of model
  parameters to fit a set of data. Various approaches exist for
  performing this calibration, but not all of them account for
  underlying uncertainty within the problem. Examples of this
  uncertainty include random noise within experimental measurements as
  well as errors due to model discrepancy; i.e., missing physics in the
  model. A Bayesian framework provides a natural perspective from which
  to perform model calibration to accommodate this uncertainty. To
  utilize this approach, we make several assumptions regarding the
  problem.</p>
  <list list-type="order">
    <list-item>
      <p>Parameters (<inline-formula><alternatives>
      <tex-math><![CDATA[q]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>q</mml:mi></mml:math></alternatives></inline-formula>)
      are treated as random variables with underlying distributions
      instead of unknown but fixed values.</p>
    </list-item>
    <list-item>
      <p>Observations <inline-formula><alternatives>
      <tex-math><![CDATA[F^{data}(i)]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
      are expected to be equal to the model response
      <inline-formula><alternatives>
      <tex-math><![CDATA[F(i;q)]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>i</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
      plus independent and identically distributed random errors
      <inline-formula><alternatives>
      <tex-math><![CDATA[\epsilon_i \rightarrow]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>œµ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Üí</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
      <inline-formula><alternatives>
      <tex-math><![CDATA[F^{data}(i) = F(i;q) + \epsilon_i]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>i</mml:mi><mml:mo>;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>œµ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>
      where <inline-formula><alternatives>
      <tex-math><![CDATA[\epsilon_i \sim \mathcal{N}(0,\sigma^2)]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:msub><mml:mi>œµ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚àº</mml:mo><mml:mstyle mathvariant="script"><mml:mi>ùí©</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>œÉ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
    </list-item>
  </list>
  <p>The goal of the calibration process is to infer the parameters‚Äô
  posterior distributions given a set of observations -
  <inline-formula><alternatives>
  <tex-math><![CDATA[\pi(q|F^{data}(i))]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>œÄ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.
  Once these parameter distributions are known, the Bayesian approach
  provides a natural framework in which to consider how this uncertainty
  propagates and affects model predictions.</p>
  <p>We designed the <monospace>pymcmcstat</monospace> package for
  engineers and scientists interested in using Bayesian methods to
  quantify model parameter uncertainty. Furthermore, we had the goal of
  providing a Python platform for researchers familiar with the MATLAB
  toolbox
  <ext-link ext-link-type="uri" xlink:href="https://mjlaine.github.io/mcmcstat/">mcmcstat</ext-link>
  developed by Marko Laine. To accommodate a diverse audience, we
  constructed several
  <ext-link ext-link-type="uri" xlink:href="https://nbviewer.jupyter.org/github/prmiles/pymcmcstat/blob/master/tutorials/index.ipynb">tutorials</ext-link>
  to guide the user through the various stages of setting up a problem,
  such as defining the data structure, model parameters, and simulation
  options. Currently, the package is limited to Gaussian likelihood and
  prior functions; however, these are still suitable for a wide variety
  of scientific problems. As many individuals are not necessarily
  familiar with the statistical nomenclature behind the Bayesian
  approach, the package simply requires the user to define a function
  that calculates the sum-of-squares error with respect to the model and
  the observations which is consistent with the second assumption listed
  above. Information known <italic>a priori</italic> about the parameter
  distributions is defined in the prior function; however, the default
  program behavior is to use a uniform prior which is a common approach
  for these types of problems.</p>
  <p>Bayesian inference is a powerful tool for quantifying model input
  uncertainty, and Markov Chain Monte Carlo (MCMC) methods present a
  computationally tractable means for constructing posterior
  distributions for input parameters
  (<xref alt="Smith, 2014" rid="ref-smith2014uncertainty" ref-type="bibr">Smith,
  2014</xref>). Within MCMC, a Metropolis algorithm chooses whether to
  accept or reject proposed parameter values. This approach to parameter
  acceptance allows the algorithm to effectively sample the parameter
  space and avoid issues that often arise due to local minima during the
  calibration process. A variety of Metropolis algorithms can be used
  within MCMC. Ideally, information learned about the posterior
  distribution as candidate parameters are accepted will be used to
  update the proposal distribution. This can be accomplished via a
  variety of adaptive Metropolis (AM) algorithms Roberts &amp; Rosenthal
  (<xref alt="2009" rid="ref-roberts2009examples" ref-type="bibr">2009</xref>).
  In addition to improving the proposal distribution via adaption, it is
  often advantageous to incorporate delayed rejection (DR) in order to
  stimulate mixing
  (<xref alt="Haario et al., 2006" rid="ref-haario2006dram" ref-type="bibr">Haario
  et al., 2006</xref>). Both mechanisms have been demonstrated to
  significantly improve the performance of MCMC simulations.</p>
  <p>In the Python package <monospace>pymcmcstat</monospace>, we offer
  several Metropolis-based algorithms for parameter estimation. These
  algorithms include:</p>
  <list list-type="bullet">
    <list-item>
      <p>Metropolis-Hastings (MH)</p>
    </list-item>
    <list-item>
      <p>Adaptive-Metropolis (AM): Adapts parameter covariance matrix at
      specified intervals.</p>
    </list-item>
    <list-item>
      <p>Delayed-Rejection (DR): Delays rejection by sampling from a
      narrower proposal distribution.</p>
    </list-item>
    <list-item>
      <p>Delayed Rejection Adaptive Metropolis (DRAM): DR + AM</p>
    </list-item>
  </list>
  <p>The default program employs 2-stage DRAM; however, it is capable of
  accommodating <inline-formula><alternatives>
  <tex-math><![CDATA[n]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>n</mml:mi></mml:math></alternatives></inline-formula>-stage
  delayed rejection. The specific algorithms implemented for adaptive
  Metropolis and delayed rejection are outlined in Haario et al.
  (<xref alt="2006" rid="ref-haario2006dram" ref-type="bibr">2006</xref>).</p>
  <p>To the author‚Äôs knowledge, the package is currently being used for
  several scientific projects, including radiation source localization
  using 3D transport models and fractional-order viscoelasticity models
  of dielectric elastomers.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>This work was sponsored in part by the NNSA Office of Defense
  Nuclear Nonproliferation R&amp;D through the Consortium for
  Nonproliferation Enabling Capabilities.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-andrieu2008tutorial">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Andrieu</surname><given-names>Christophe</given-names></name>
          <name><surname>Thoms</surname><given-names>Johannes</given-names></name>
        </person-group>
        <article-title>A tutorial on adaptive MCMC</article-title>
        <source>Statistics and computing</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2008">2008</year>
        <volume>18</volume>
        <issue>4</issue>
        <uri>https://doi.org/10.1007/s11222-008-9110-y</uri>
        <pub-id pub-id-type="doi">10.1007/s11222-008-9110-y</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-smith2014uncertainty">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Smith</surname><given-names>R. C.</given-names></name>
        </person-group>
        <source>Uncertainty quantification: Theory, implementation, and applications</source>
        <publisher-name>SIAM</publisher-name>
        <year iso-8601-date="2014">2014</year>
      </element-citation>
    </ref>
    <ref id="ref-haario2006dram">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Haario</surname><given-names>Heikki</given-names></name>
          <name><surname>Laine</surname><given-names>Marko</given-names></name>
          <name><surname>Mira</surname><given-names>Antonietta</given-names></name>
          <name><surname>Saksman</surname><given-names>Eero</given-names></name>
        </person-group>
        <article-title>DRAM: Efficient adaptive MCMC</article-title>
        <source>Statistics and computing</source>
        <publisher-name>Springer</publisher-name>
        <year iso-8601-date="2006">2006</year>
        <volume>16</volume>
        <issue>4</issue>
        <uri>https://doi.org/10.1007/s11222-006-9438-0</uri>
        <pub-id pub-id-type="doi">10.1007/s11222-006-9438-0</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-haario2001adaptive">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Haario</surname><given-names>Heikki</given-names></name>
          <name><surname>Saksman</surname><given-names>Eero</given-names></name>
          <name><surname>Tamminen</surname><given-names>Johanna</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>An adaptive metropolis algorithm</article-title>
        <source>Bernoulli</source>
        <publisher-name>Bernoulli Society for Mathematical Statistics; Probability</publisher-name>
        <year iso-8601-date="2001">2001</year>
        <volume>7</volume>
        <issue>2</issue>
        <uri>https://projecteuclid.org/euclid.bj/1080222083</uri>
      </element-citation>
    </ref>
    <ref id="ref-roberts2009examples">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Roberts</surname><given-names>Gareth O.</given-names></name>
          <name><surname>Rosenthal</surname><given-names>Jeffrey S.</given-names></name>
        </person-group>
        <article-title>Examples of adaptive MCMC</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2009">2009</year>
        <volume>18</volume>
        <issue>2</issue>
        <uri>https://doi.org/10.1198/jcgs.2009.06134</uri>
        <pub-id pub-id-type="doi">10.1198/jcgs.2009.06134</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

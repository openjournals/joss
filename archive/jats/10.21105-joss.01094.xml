<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1094</article-id>
<article-id pub-id-type="doi">10.21105/joss.01094</article-id>
<title-group>
<article-title>EMViz (Early Music Visualization): MATLAB runtime
application</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-2614-4777</contrib-id>
<string-name>Aaron Carter-Ényì</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Assistant Professor, Morehouse College</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Instructor, Spelman College</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Fellow, Fulbright Scholar Program</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Project Director, Algorithmic Thinking, Analysis and
Visualization in Music (ATAVizM)</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-10-16">
<day>16</day>
<month>10</month>
<year>2018</year>
</pub-date>
<volume>4</volume>
<issue>37</issue>
<fpage>1094</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>MATLAB</kwd>
<kwd>music</kwd>
<kwd>arc diagrams</kwd>
<kwd>visualization</kwd>
<kwd>MIDI</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>EMViz (Early Music Visualization) provides built-in pattern
  recognition for symbolic music (MIDI) based on a contour recursion
  algorithm by Carter-Enyi
  (<xref alt="Carter-Enyi, 2016b" rid="ref-Carter-EnyiU003A2016a" ref-type="bibr">Carter-Enyi,
  2016b</xref>) producing visualizations of musical form using arc
  diagrams, as proposed by Wattenberg
  (<xref alt="Wattenberg, 2002" rid="ref-WattenbergU003A2002" ref-type="bibr">Wattenberg,
  2002</xref>). Currently implemented in MATLAB and deployed as a
  standalone executable (using MATLAB Runtime), EMViz is now available
  at emviz.org and https://github.com/carterenyi/emviz (MIT
  license).</p>
  <p>A primary learning objective in music theory courses is the ability
  to analyze musical form, often using a bracketed diagram. This
  humanistic process often involves listening with a score, stopping the
  recording for a close reading of the score, flipping back and forth
  through the document to make comparisons, and so on. While manual
  analysis is important, the conventional method of summarizing one’s
  analysis as a bracket diagram is reductive without being illustrative.
  A promising digital method for visualization of musical form is found
  in Martin Wattenberg’s Shape of Song, a defunct web app from 2002. The
  arc diagram visualization technique for Shape of Song is innovative
  and useful, but ultimately the project did not live up to its
  potential because of a poor understanding of how composers develop
  musical themes. Wattenberg describes his string-matching method in his
  2002 paper: “Each arc connects two matching passages, where a ‘match’
  means that they contain the same sequence of pitches”
  (<xref alt="Wattenberg, 2002" rid="ref-WattenbergU003A2002" ref-type="bibr">Wattenberg,
  2002</xref>). However, musical themes and motives are often transposed
  or otherwise modified in the course of a piece. A concept learned by
  music majors is the subject and answer of a fugue (an imitative
  polyphonic composition). The subject is the initial statement of a
  fugue’s theme, stated in a monophonic texture (by itself) and the
  answer is the first interpolation stated in a polyphonic texture
  (against counterpoint). Sometimes the answer is an exact transposition
  (real answer) and sometimes the answer is transposed and modified
  (tonal answer). In his paper, Wattenberg offers the possibility of
  matching melodic intervals (instead of pitch-strings), but this too
  would not match a subject to its tonal answer. So, how do we formalize
  the relationship between a subject and tonal answer? Or, the
  improvisational “licks” of Dizzy Gillespie? Such that we could define
  “themes” as a category that may be formalized computationally?
  Especially, when a computer does not know where to look for themes or
  what modifications to expect? Algorithms informed by humanistic
  understanding of music work much better than those that are not.</p>
  <p>There are three primary components of the EMViz MATLAB Runtime
  application: (1) Data Preparation (Pre-Processing); (2) Pattern
  Recognition; and (3) Visualization. These components are compared
  between Shape of Song, EMViz (now available in MATLAB Runtime), and
  ATAVizM (currently being developed in Python) in Table 1.</p>
  <fig>
    <caption><p>Table of features of Wattenberg’s Shape of Song, EMViz
    (released 2017) and ATAVizM (in development)</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="table1.png" xlink:title="" />
  </fig>
  <p>The computationally-efficient addition of the contour level data
  preparation (see Carter-Enyi 2016b)
  (<xref alt="Carter-Enyi, 2016a" rid="ref-Carter-EnyiU003A2016b" ref-type="bibr">Carter-Enyi,
  2016a</xref>) makes equivalence-based pattern recognition
  (e.g. string-matching) much more effective. Notably, this
  pre-processing of the symbolic data makes significant improvements to
  performance with negligible added runtime. The contour algorithm
  behind EMViz and ATAVizM identifies 100% of the subjects and
  approximately 80% of all statements in the 48 Fugues of Bach’s
  Well-Tempered Clavier.</p>
  <p>The algorithm brings together contour theory
  (<xref alt="Morris, 1987" rid="ref-MorrisU003A1987" ref-type="bibr">Morris,
  1987</xref>),
  (<xref alt="Quinn, 1997" rid="ref-QuinnU003A1997" ref-type="bibr">Quinn,
  1997</xref>) with studies of melodic accent
  (<xref alt="Thomassen, 1982" rid="ref-ThomassenU003A1982" ref-type="bibr">Thomassen,
  1982</xref>),
  (<xref alt="Huron, 2006" rid="ref-HuronU003A2006" ref-type="bibr">Huron,
  2006</xref>). Symbolic music data (.midi, .xml) from various sources
  (including ELVIS at McGill and the Yale Classical Archives Corpus) may
  be imported, analyzed and visualized in a matter of minutes. The
  contour algorithm behind EMViz uses local contour comparisons within a
  2-degree radius of each focus pitch. This makes use of Quinn’s binary
  C+ (Contour-Ascent) comparison, where 0 is equal or below and 1 is
  above the reference pitch
  (<xref alt="Quinn, 1997" rid="ref-QuinnU003A1997" ref-type="bibr">Quinn,
  1997</xref>). In Figure 1, the subject and tonal answer of Bach’s
  C-minor Fugue (BWV 847) are shown to be equivalent strings using this
  method (they both produce the same “continuous” matrix).</p>
  <fig>
    <caption><p>Contour level equivalence between the subject and tonal
    answer of Bach’s Fugue in C minor BWV 847 based on Carter-Enyi 2016b
    (<xref alt="Carter-Enyi, 2016a" rid="ref-Carter-EnyiU003A2016b" ref-type="bibr">Carter-Enyi,
    2016a</xref>)</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figure1.png" xlink:title="" />
  </fig>
  <p>Example arc diagram visualizations include music from the Liber
  Usualis, Josquin des Prez and J. S. Bach.</p>
  <fig>
    <caption><p>EMViz analysis and visualization of “Alleluia, Exsultate
    Deo” chant from the Liber Usualis (11th century)</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figure2.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>EMViz analysis and visualization of “Ave Maria” by
    Josquin des Prez (15-16th century)</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figure3.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>EMViz analysis and visualization of Back’s Fugue in C
    minor BWV 847 (18th century) (NB: an octave displacement is removed
    from one of the counter-subject 2 statements</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="figure4.png" xlink:title="" />
  </fig>
  <p>In summary, EMViz (Early Music Visualization) identifies and
  implements three major improvements over Wattenberg’s Shape of Song:
  (1) a pattern-matching algorithm based on heuristics from music
  theory, (2) theme identification by user input or selection integrated
  into the application, and (3) color-coding of arcs (between matched
  patterns) and a legend to make the diagram more comprehensible,
  interpretive and utilitarian for research and teaching. Greater
  accessibility (through Python depoloyment) and enhanced features
  (referred to in Table 1) will be available with the release of ATAVizM
  in the near future (https://github.com/carterenyi/atavizm;
  www.atavizm.org).</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The project was funded by the American Council of Learned Societies
  (ACLS) and the National Endowment for the Humanities (NEH).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Carter-EnyiU003A2016a">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Carter-Enyi</surname><given-names>Aaron</given-names></name>
        </person-group>
        <article-title>Contour Recursion and Auto-Segmentation</article-title>
        <source>Music Theory Online</source>
        <year iso-8601-date="2016">2016</year>
        <volume>22</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.30535/mto.22.1.1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Carter-EnyiU003A2016b">
      <element-citation publication-type="thesis">
        <person-group person-group-type="author">
          <name><surname>Carter-Enyi</surname><given-names>Aaron</given-names></name>
        </person-group>
        <article-title>Contour Levels: An Abstraction of Pitch Space based on African Tone Systems</article-title>
        <year iso-8601-date="2016">2016</year>
        <uri>http://rave.ohiolink.edu/etdc/view?acc_num=osu1461029477</uri>
      </element-citation>
    </ref>
    <ref id="ref-HuronU003A2006">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Huron</surname><given-names>David</given-names></name>
        </person-group>
        <source>Sweet Anticipation: Music and the Psychology of Expectation</source>
        <publisher-name>MIT Press</publisher-name>
        <publisher-loc>Cambridge</publisher-loc>
        <year iso-8601-date="2006">2006</year>
        <isbn>9780262275965</isbn>
        <pub-id pub-id-type="doi">10.7551/mitpress/6575.001.0001</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-MorrisU003A1987">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Morris</surname><given-names>Robert D</given-names></name>
        </person-group>
        <source>Composition with pitch-classes: a theory of compositional design</source>
        <publisher-name>Yale University Press</publisher-name>
        <year iso-8601-date="1987">1987</year>
        <isbn>0300036841</isbn>
        <pub-id pub-id-type="doi">10.2307/j.ctt1xp3ss4</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-QuinnU003A1997">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Quinn</surname><given-names>Ian</given-names></name>
        </person-group>
        <article-title>Fuzzy Extensions to the Theory of Contour</article-title>
        <source>Music Theory Spectrum</source>
        <year iso-8601-date="1997">1997</year>
        <volume>19</volume>
        <issue>2</issue>
        <issn>01956167</issn>
        <uri>http://www.jstor.org.proxy.lib.ohio-state.edu/stable/745755</uri>
        <pub-id pub-id-type="doi">10.2307/745755</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-ThomassenU003A1982">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Thomassen</surname><given-names>Joseph M</given-names></name>
        </person-group>
        <article-title>Melodic accent: Experiments and a tentative model</article-title>
        <source>The Journal of the Acoustical Society of America</source>
        <year iso-8601-date="1982">1982</year>
        <volume>71</volume>
        <issue>6</issue>
        <issn>0001-4966</issn>
        <pub-id pub-id-type="doi">10.1121/1.387814</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-WattenbergU003A2002">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Wattenberg</surname><given-names>Martin</given-names></name>
        </person-group>
        <article-title>Arc diagrams: Visualizing structure in strings</article-title>
        <source>Information visualization, 2002. INFOVIS 2002. IEEE symposium on</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2002">2002</year>
        <isbn>076951751X</isbn>
        <pub-id pub-id-type="doi">10.1109/INFVIS.2002.1173155</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

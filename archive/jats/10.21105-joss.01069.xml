<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1069</article-id>
<article-id pub-id-type="doi">10.21105/joss.01069</article-id>
<title-group>
<article-title>hotsub: A batch job engine for cloud services with ETL
framework</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6636-856X</contrib-id>
<string-name>Hiromu Ochiai</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Kenichi Chiba</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-9782-5900</contrib-id>
<string-name>Ai Okada</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6144-5845</contrib-id>
<string-name>Yuichi Shiraishi</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>National Cancer Center Research Institute, Tokyo,
Japan</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2018-11-12">
<day>12</day>
<month>11</month>
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>31</issue>
<fpage>1069</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>cloud</kwd>
<kwd>Docker</kwd>
<kwd>AWS</kwd>
<kwd>GCP</kwd>
<kwd>ETL</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Because of the rapid accumulation of biomedical data all over the
  world, developing a platform for analzing them using high-performance
  computational infrastructure has become increasingly important in many
  biological and medical fields. Nowadays, cloud computing is getting a
  lot of attention since they can promote the sharing of data and
  reproducible analytical workflows across institutions. On the other
  hand, there has yet been no decisive practice on how to set up
  analytical workflows in cloud computing resources.</p>
  <p>One possible approach is what we call on-demand Extraction
  Transformation Load (ETL) framework. The overview of this framework is
  as follows:</p>
  <list list-type="order">
    <list-item>
      <p>Each input file (e.g., FASTQ file) is first extracted from a
      storage area (e.g., Amazon Simple Storage Service) to each virtual
      machine within a computing area (e.g. Amazon Elastic Compute Cloud
      (Amazon EC2))</p>
    </list-item>
    <list-item>
      <p>Each input file is transformed into an output file (e.g., FASTQ
      to BAM conversion).</p>
    </list-item>
    <list-item>
      <p>Each generated output file is loaded to the storage area
      stopping and deleting each VMs.</p>
    </list-item>
  </list>
  <p>There are several frameworks which realize on-demand ETL framework
  in the cloud computing environment, which is often provided by cloud
  computing vendors (AWS Batch by Amazon Web Service
  (<xref alt="Services, n.d." rid="ref-AWSBatch" ref-type="bibr">Services,
  n.d.</xref>) or Azure Batch by Microsoft
  (<xref alt="Azure, n.d." rid="ref-AzureBatch" ref-type="bibr">Azure,
  n.d.</xref>)) or third parties (dsub by Google Genomics
  (<xref alt="DataBiosphere, n.d." rid="ref-DataBiosphereU002Fdsub" ref-type="bibr">DataBiosphere,
  n.d.</xref>)). However, with these current ETL implementations, since
  commonly used data across VMs (e.g., reference genomes) is downloaded
  to individual VMs, we need to pay particular attention to the
  excessive load of network and storage, and deployment and transferring
  of data according to cost charging policy of each provider.</p>
  <p>Here we propose a novel framework, on-demand Extended Extraction
  Transform Load (ExETL), in which commonly necessary data is first
  loaded to a pre-built shared data instance, mounted by each computing
  VM and used across VMs. We demonstrate that this framework reduces the
  payment cost a lot in several cases. Besides, we would like to argue
  that sharing of analytical workflows will be enhanced since users can
  safely try the workflows without special caution of the location of
  the associated database.</p>
  <p>We have developed a software implementing the proposed ExETL
  framework, hotsub (https://github.com/otiai10/hotsub).</p>
  <p>Since ‘hotsub’ uses Docker
  (<xref alt="Inc., n.d.-b" rid="ref-Docker" ref-type="bibr">Inc.,
  n.d.-b</xref>) and Docker Machine
  (<xref alt="Inc., n.d.-a" rid="ref-DockerMachine" ref-type="bibr">Inc.,
  n.d.-a</xref>), users of ‘hotsub’ don’t have to care about acquiring
  VMs on cloud services nor setting up environment for computing.
  Handling infrastructures and runtimes are automated by ‘hotsub’.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Even just for basic ETL framework provided by cloud services, it’s
  necessary to configure the managed services on web-console of each
  cloud service. By using <monospace>hotsub</monospace>, on the other
  hand, users don’t have to configure VMs on web-console.</p>
  <p>In addition, <monospace>hotsub</monospace> suggests and implements
  <bold>ExTL</bold> framework, which solves potential problems simple
  ETL frameworks by AWS Batch, ECS, and dsub have. By using simple ETL
  framework for bio-informatics, downloading huge reference genome on
  <bold>each computing instance</bold> could be inefficiency of network
  traffic and instance time.</p>
  <p>If your resources are located on Google Cloud Storage, you can just
  use <monospace>--provider</monospace> option to change which platform
  your computing resources will be launched on, with the same command
  line interface of <monospace>hotsub</monospace>. It helps the
  ecosystem of sharing workflows with someone using different cloud
  services.</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>This work was supported by Grant-in-Aid from the Japan Agency for
  Medical Research and Development (Advanced Genome Research and
  Bioinformatics Study to Facilitate Medical Innovation
  [17km0405207h0002]).</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-AWSBatch">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>Services</surname><given-names>Amazon Web</given-names></name>
        </person-group>
        <article-title>AWS batch — easy and efficient batch computing capabilities - AWS</article-title>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-10-31">2018</year><month>10</month><day>31</day></date-in-citation>
        <uri>https://aws.amazon.com/batch/</uri>
      </element-citation>
    </ref>
    <ref id="ref-AzureBatch">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>Azure</surname><given-names>Microsoft</given-names></name>
        </person-group>
        <article-title>Batch - compute job scheduling service | microsoft azure</article-title>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-10-31">2018</year><month>10</month><day>31</day></date-in-citation>
        <uri>https://azure.microsoft.com/en-us/services/batch/</uri>
      </element-citation>
    </ref>
    <ref id="ref-DataBiosphereU002Fdsub">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>DataBiosphere</surname></name>
        </person-group>
        <article-title>DataBiosphere/dsub - open-source command-line tool to run batch computing tasks and workflows on backend services such as google cloud.</article-title>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-10-31">2018</year><month>10</month><day>31</day></date-in-citation>
        <uri>https://github.com/DataBiosphere/dsub</uri>
      </element-citation>
    </ref>
    <ref id="ref-Docker">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>Inc.</surname><given-names>Docker</given-names></name>
        </person-group>
        <article-title>Enterprise container platform | docker</article-title>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-10-31">2018</year><month>10</month><day>31</day></date-in-citation>
        <uri>https://www.docker.com/</uri>
      </element-citation>
    </ref>
    <ref id="ref-DockerMachine">
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name><surname>Inc.</surname><given-names>Docker</given-names></name>
        </person-group>
        <article-title>Docker machine | docker documentation</article-title>
        <date-in-citation content-type="access-date"><year iso-8601-date="2018-10-31">2018</year><month>10</month><day>31</day></date-in-citation>
        <uri>https://docs.docker.com/machine/</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2676</article-id>
<article-id pub-id-type="doi">10.21105/joss.02676</article-id>
<title-group>
<article-title>SCALAR - A Platform for Real-time Machine Learning
Competitions on Data Streams</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Nedeljko Radulovic</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Dihia Boulegane</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<string-name>Albert Bifet</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>LTCI, Télécom Paris, IP-Paris, Paris, France</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Orange Labs, Grenoble, France</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>University of Waikato, New Zealand</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-08-26">
<day>26</day>
<month>8</month>
<year>2020</year>
</pub-date>
<volume>5</volume>
<issue>56</issue>
<fpage>2676</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Stream Data Mining</kwd>
<kwd>Real-time Machine Learning</kwd>
<kwd>Information Flow Processing</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>SCALAR</monospace> is a new platform for running
  real-time machine learning competitions on data streams. Following the
  intent of Kaggle, which serves as a platform for organizing machine
  learning competitions adapted for batch learning, we propose
  <monospace>SCALAR</monospace> as a novel platform explicitly designed
  for stream learning in real-time. <monospace>SCALAR</monospace>
  supports both classification and regression problems in the data
  streaming setting. It has been developed in
  <monospace>Python</monospace>, using state of the art open-source
  solutions: <monospace>Apache Kafka</monospace>,
  <monospace>Apache Spark</monospace>, <monospace>gRPC</monospace>,
  <monospace>Protobuf</monospace>, and
  <monospace>Docker</monospace>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Existing machine learning platforms for research and competitions,
  such as
  <ext-link ext-link-type="uri" xlink:href="https://www.kaggle.com/"><monospace>Kaggle</monospace></ext-link>
  and
  <ext-link ext-link-type="uri" xlink:href="https://tianchi.aliyun.com/"><monospace>Alibaba Tianchi</monospace></ext-link>
  provide static data sets that users leverage to do batch training and
  scoring. These popular platforms, especially
  <monospace>Kaggle</monospace>, enable users to propose better
  solutions for a wide range of machine learning problems and
  applications, pushing forward the whole research community.</p>
  <p>While these platforms enable collaborative model building, they do
  not provide real-time settings and data streaming instead of static
  data sets. Inspired by the great reception and adoption that these
  platforms have had, <monospace>SCALAR</monospace> was built for
  real-time environments by supporting data streaming to fill this gap,
  helping users test and improve their methodologies in a real-time
  machine learning scenario.</p>
  <p>On <monospace>SCALAR</monospace>, data are continuously released in
  batches during defined time intervals. Predictions for each current
  batch sent before designated deadline are evaluated in real-time, and
  the results are shown on a live leaderboard.</p>
  <p><monospace>SCALAR</monospace> can be applied to provide real-time
  machine learning support in multiple scenarios, one of the more
  notable and recent ones was its role as the core organizing and
  coordination platform for the first Real-time Machine Learning
  Competition on Data Streams
  (<xref alt="Boulegane et al., 2019" rid="ref-boulegane2019real" ref-type="bibr">Boulegane
  et al., 2019</xref>) as part of the
  <ext-link ext-link-type="uri" xlink:href="http://bigdataieee.org/BigData2019/BigDataCupChallenges.html">IEEE
  Big Data 2019 Cup Challenges</ext-link>.</p>
</sec>
<sec id="streaming-learning-setting">
  <title>Streaming learning setting</title>
  <p>Most of the existing platforms for data science competitions are
  tailored to offline learning where a static dataset is made available
  to the participants before the competition starts. This dataset is
  divided into training and test sets. The training set is used to build
  and train the model, which is then scored on the test set.</p>
  <p>In online learning, data arrive in a stream of records (instances)
  and the model needs to be trained incrementally as new instances are
  released. Since the data arrive at high speed, predictions have to be
  issued within a short time. Considering this specific setup of the
  data stream mining scenario (Figure
  <xref alt="1" rid="figU003Astream_mining">1</xref>), every model
  should use a limited amount of time and memory, process one instance
  at a time and inspect it only once. The model must be able to predict
  at any time
  (<xref alt="Bifet et al., 2010" rid="ref-bifet2010moa" ref-type="bibr">Bifet
  et al., 2010</xref>).</p>
  <fig>
    <caption><p>Stream data mining
    scenario<styled-content id="figU003Astream_mining"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="stream_mining.png" xlink:title="" />
  </fig>
  <p>The model is continuosly updated using the labeled instances and
  then evaluated on new unlabeled instances. This scenario represents
  the prequential evaluation scenario or “test-then-train” setting, to
  make it possible we first assume that the records in the data stream
  arrive in batches and that each batch can be of size
  <monospace>1</monospace> or more. Then, we define two different kinds
  of batches:</p>
  <list list-type="bullet">
    <list-item>
      <p>Initial batch: This batch is used to build and train the
      initial model. It is aimed to avoid the cold start problem and as
      such, contains both features and targets. The initial batch
      usually has a large number of instances.</p>
    </list-item>
    <list-item>
      <p>Regular batch: The regular batch contains new test instances
      while providing training instances of previous batches that are
      used to evaluate the quality of the model up to the current
      time.</p>
    </list-item>
  </list>
  <fig>
    <caption><p>Initial and regular batches in the data
    stream<styled-content id="figU003Aonline_learning"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="jpeg" xlink:href="online_learning.jpg" xlink:title="" />
  </fig>
</sec>
<sec id="architecture">
  <title>Architecture</title>
  <p>To support all the aforementioned requirements for stream data
  mining and to be able to organize competitions in such a scenario, a
  specifically dedicated platform was needed. To the best of our
  knowledge, there doesn’t exist such a platform. Thus we propose
  <monospace>SCALAR</monospace>. Figure
  <xref alt="[architecture]" rid="architecture">[architecture]</xref>
  highlights the architecture of the platform that includes a web
  application, and a streaming engine following the fundamentals of
  Information Flow Processing
  (IFP)(<xref alt="Cugola &amp; Margara, 2012" rid="ref-CugolaU003A12" ref-type="bibr">Cugola
  &amp; Margara, 2012</xref>).</p>
  <fig>
    <caption><p>Architecture of the
    platform<styled-content id="figU003Aarchitecture"></styled-content></p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="Architecture.png" xlink:title="" />
  </fig>
  <p>Layers and components’ descriptions:</p>
  <list list-type="bullet">
    <list-item>
      <p>Data sources: <monospace>SCALAR</monospace> enables
      competitions by providing data in the form of a
      <monospace>CSV</monospace> file, which is then used to recreate a
      continuous stream following predefined competition settings such
      as the time interval between two releases, and the number of
      instances at a time.</p>
    </list-item>
    <list-item>
      <p>Data layer: represents the persistence node in the system where
      different kinds of information are stored.
      <monospace>MongoDB</monospace> is used for unstructured data
      (e.g., user’s predictions, records from the stream, evaluation
      metrics, etc.) and <monospace>MySQL</monospace> for structured
      data (competition information, user information).</p>
    </list-item>
    <list-item>
      <p>Streaming Engine: this layer is responsible for handling the
      streams. From the <monospace>CSV</monospace> files,
      <monospace>Kafka</monospace> recreates multiple streams to be sent
      to multiple users. <monospace>SCALAR</monospace> provides a secure
      and independent bi-directional streaming communication between the
      user and the streaming engine. This allows each user to consume
      training and test instances and submit the respective predictions
      according to the competition predefined data format. The resource
      server is the <monospace>API</monospace> that handles all
      authenticated requests from the client application, whereas the
      authorization server is in charge of users’ identification. The
      Online evaluation engine handles both the stream of instances, and
      the streams of participants’ predictions in order to compute and
      update the evaluation metrics online before storing them into the
      dedicated database.</p>
    </list-item>
    <list-item>
      <p>Application layer: consists of two parts the web application,
      and client application. The web application represents a
      user-friendly interface that allows participants to register,
      subscribe to competitions, and follow leaderboard and model
      performance online. The client application is provided to
      accommodate participants’ code to solve the machine learning
      problem at hand. It delivers a secure communication channel to
      receive the stream of training and test instances and send their
      respective predictions to the server.</p>
    </list-item>
  </list>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We would like to thank Nenad Stojanovic for his contribution to the
  project and to acknowledge support for this project from the EDF
  (Electricité de France) and OpenML.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-bifet2010moa">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bifet</surname><given-names>Albert</given-names></name>
          <name><surname>Holmes</surname><given-names>Geoff</given-names></name>
          <name><surname>Kirkby</surname><given-names>Richard</given-names></name>
          <name><surname>Pfahringer</surname><given-names>Bernhard</given-names></name>
        </person-group>
        <article-title>Moa: Massive online analysis</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2010">2010</year>
        <volume>11</volume>
        <issue>May</issue>
      </element-citation>
    </ref>
    <ref id="ref-CugolaU003A12">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Cugola</surname><given-names>Gianpaolo</given-names></name>
          <name><surname>Margara</surname><given-names>Alessandro</given-names></name>
        </person-group>
        <article-title>Processing flows of information: From data stream to complex event processing</article-title>
        <source>ACM Comput. Surv.</source>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year iso-8601-date="2012-06">2012</year><month>06</month>
        <volume>44</volume>
        <issue>3</issue>
        <issn>0360-0300</issn>
        <uri>http://doi.acm.org/10.1145/2187671.2187677</uri>
        <pub-id pub-id-type="doi">10.1145/2187671.2187677</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-boulegane2019real">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Boulegane</surname><given-names>Dihia</given-names></name>
          <name><surname>Radulovic</surname><given-names>Nedeljko</given-names></name>
          <name><surname>Bifet</surname><given-names>Albert</given-names></name>
          <name><surname>Fievet</surname><given-names>Ghislain</given-names></name>
          <name><surname>Sohn</surname><given-names>Jimin</given-names></name>
          <name><surname>Nam</surname><given-names>Yeonwoo</given-names></name>
          <name><surname>Yu</surname><given-names>Seojeong</given-names></name>
          <name><surname>Choi</surname><given-names>Dong-Wan</given-names></name>
        </person-group>
        <article-title>Real-time machine learning competition on data streams at the IEEE big data 2019</article-title>
        <source>2019 IEEE international conference on big data (big data)</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2019">2019</year>
        <pub-id pub-id-type="doi">10.1109/BigData47090.2019.9006357</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kreps2011kafka">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Kreps</surname><given-names>Jay</given-names></name>
          <name><surname>Narkhede</surname><given-names>Neha</given-names></name>
          <name><surname>Rao</surname><given-names>Jun</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Kafka: A distributed messaging system for log processing</article-title>
        <source>Proceedings of the NetDB</source>
        <year iso-8601-date="2011">2011</year>
        <volume>11</volume>
      </element-citation>
    </ref>
    <ref id="ref-garg2013apache">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Garg</surname><given-names>Nishant</given-names></name>
        </person-group>
        <source>Apache kafka</source>
        <publisher-name>Packt Publishing Ltd</publisher-name>
        <year iso-8601-date="2013">2013</year>
      </element-citation>
    </ref>
    <ref id="ref-zaharia2010spark">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zaharia</surname><given-names>Matei</given-names></name>
          <name><surname>Chowdhury</surname><given-names>Mosharaf</given-names></name>
          <name><surname>Franklin</surname><given-names>Michael J</given-names></name>
          <name><surname>Shenker</surname><given-names>Scott</given-names></name>
          <name><surname>Stoica</surname><given-names>Ion</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>Spark: Cluster computing with working sets.</article-title>
        <source>HotCloud</source>
        <year iso-8601-date="2010">2010</year>
        <volume>10</volume>
        <issue>10-10</issue>
      </element-citation>
    </ref>
    <ref id="ref-armbrust2018structured">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Armbrust</surname><given-names>Michael</given-names></name>
          <name><surname>Das</surname><given-names>Tathagata</given-names></name>
          <name><surname>Torres</surname><given-names>Joseph</given-names></name>
          <name><surname>Yavuz</surname><given-names>Burak</given-names></name>
          <name><surname>Zhu</surname><given-names>Shixiong</given-names></name>
          <name><surname>Xin</surname><given-names>Reynold</given-names></name>
          <name><surname>Ghodsi</surname><given-names>Ali</given-names></name>
          <name><surname>Stoica</surname><given-names>Ion</given-names></name>
          <name><surname>Zaharia</surname><given-names>Matei</given-names></name>
        </person-group>
        <article-title>Structured streaming: A declarative API for real-time applications in apache spark</article-title>
        <source>Proceedings of the 2018 international conference on management of data</source>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-merkel2014docker">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Merkel</surname><given-names>Dirk</given-names></name>
        </person-group>
        <article-title>Docker: Lightweight linux containers for consistent development and deployment</article-title>
        <source>Linux journal</source>
        <year iso-8601-date="2014">2014</year>
        <volume>2014</volume>
        <issue>239</issue>
      </element-citation>
    </ref>
    <ref id="ref-montiel2018scikit">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Montiel</surname><given-names>Jacob</given-names></name>
          <name><surname>Read</surname><given-names>Jesse</given-names></name>
          <name><surname>Bifet</surname><given-names>Albert</given-names></name>
          <name><surname>Abdessalem</surname><given-names>Talel</given-names></name>
        </person-group>
        <article-title>Scikit-multiflow: A multi-output streaming framework</article-title>
        <source>The Journal of Machine Learning Research</source>
        <publisher-name>JMLR. org</publisher-name>
        <year iso-8601-date="2018">2018</year>
        <volume>19</volume>
        <issue>1</issue>
      </element-citation>
    </ref>
    <ref id="ref-team2013r">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Team</surname><given-names>R Core</given-names></name>
          <string-name>others</string-name>
        </person-group>
        <article-title>R: A language and environment for statistical computing</article-title>
        <publisher-name>Vienna, Austria</publisher-name>
        <year iso-8601-date="2013">2013</year>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1778</article-id>
<article-id pub-id-type="doi">10.21105/joss.01778</article-id>
<title-group>
<article-title>GaitPy: An Open-Source Python Package for Gait Analysis
Using an Accelerometer on the Lower Back</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-9954-7003</contrib-id>
<string-name>Matthew D. Czech</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-4369-3033</contrib-id>
<string-name>Shyamal Patel</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Pfizer, Inc.</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-07-25">
<day>25</day>
<month>7</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>43</issue>
<fpage>1778</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>GaitPy</kwd>
<kwd>Accelerometer</kwd>
<kwd>Actigraphy</kwd>
<kwd>Algorithms</kwd>
<kwd>Lumbar</kwd>
<kwd>Gait</kwd>
<kwd>Digital Medicine</kwd>
<kwd>Wearable Sensors</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>Gait impairments are present across a broad range of conditions and
  often have a significant impact on the functional mobility and quality
  of life of an individual. Clinicians and researchers commonly assess
  gait using either observational scales (e.g. Unified Parkinson’s
  Disease Rating Scale) or performance-based tests
  (e.g. timed-up-and-go). However, these assessments can only be
  performed intermittently because of the need for a trained clinician.
  In contrast, wearable devices can be used for continuously capturing
  data from sensors (e.g. accelerometer, ECG) outside the clinic.
  Recently, several groups
  (<xref alt="Del Din et al., 2016" rid="ref-DelDin2016" ref-type="bibr">Del
  Din et al., 2016</xref>;
  <xref alt="McCamley et al., 2012" rid="ref-McCamley2012" ref-type="bibr">McCamley
  et al., 2012</xref>;
  <xref alt="Trojaniello et al., 2014" rid="ref-Trojaniello2014" ref-type="bibr">Trojaniello
  et al., 2014</xref>;
  <xref alt="Zijlstra &amp; Hof, 2003" rid="ref-Zijlstra2003" ref-type="bibr">Zijlstra
  &amp; Hof, 2003</xref>) have published algorithms for deriving
  features of gait from data collected using inertial sensors like
  accelerometers. However, an implementation of these algorithms is not
  readily available to researchers, thus hindering progress.</p>
  <p>GaitPy is an open-source Python package that implements several
  published algorithms in a modular framework for extracting clinical
  features of gait from a single accelerometer device mounted on the
  lower back (L5 vertebra, illustrated in figure 1). The package has
  been developed to make it easy for researchers to derive measures of
  gait from raw accelerometer data. As shown in figure 2, the package
  includes modules with three main functions: 1) classify bouts of gait;
  2) extract clinical features of gait from each bout; and 3) visualize
  detected gait events.</p>
  <fig>
    <caption><p>Location of the wearable device on the lower back and
    orientation of the vertical acceleration axis of the accelerometer
    relative to the body</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="Figure1.png" xlink:title="" />
  </fig>
  <fig>
    <caption><p>A high-level overview of GaitPy API and functions
    associated with various modules.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="Figure2.png" xlink:title="" />
  </fig>
</sec>
<sec id="processing-pipeline">
  <title>Processing Pipeline</title>
  <p>GaitPy can be used to derive gait features from data collected in
  the clinic as well as under free-living conditions (e.g. at home). The
  package accepts input data in a customizable format, thereby not
  restricting the user to a standard file type. GaitPy utilizes vertical
  acceleration data from a wearable device located on the lower back
  (lumbar region) and consists of three main processing modules.</p>
  <p><bold>classify_bouts</bold> is an optional module intended to be
  used for processing data collected under free-living or unsupervised
  conditions. The module uses a pre-trained gait classification model to
  detect bouts of gait from a continuous stream of raw accelerometer
  data. It first converts data to units of gravity (g) and down-samples
  it to 50Hz. Data is then segmented into non-overlapping 3-second
  epochs and signals features are derived for each epoch. The
  pre-trained gait classification model then classifies each 3-second
  epoch as gait or not-gait.</p>
  <p><bold>extract_features</bold> module utilizes a Gaussian continuous
  wavelet transform based approach
  (<xref alt="McCamley et al., 2012" rid="ref-McCamley2012" ref-type="bibr">McCamley
  et al., 2012</xref>) and inverted pendulum model
  (<xref alt="Zijlstra &amp; Hof, 2003" rid="ref-Zijlstra2003" ref-type="bibr">Zijlstra
  &amp; Hof, 2003</xref>) to calculate spatial and temporal gait
  features. Vertical acceleration data is first converted from units of
  gravity (g) to meters per second squared (m/s2) and down-sampled to
  50Hz. Using the approach described in Del Din et al. 2016
  (<xref alt="Del Din et al., 2016" rid="ref-DelDin2016" ref-type="bibr">Del
  Din et al., 2016</xref>), we then derive spatial and temporal features
  of gait. Additionally, an optimization procedure is performed to
  remove extraneous event detections and is described in more detail
  below. The extract_features module expects data segments that only
  contain gait. So, if input data consists of both gait and non-gait
  data, it is recommended to first apply the classify_bouts function in
  order to identify periods of gait at the resolution of 3-second
  epochs. extract_features will then concatenate concurrent 3-second
  epochs of gait into bouts and extract features for each bout.</p>
  <p><bold>plot_contacts</bold> module generates an interactive plot of
  raw data along with the initial and final contact events detected by
  the gait event detection algorithm
  (<xref alt="McCamley et al., 2012" rid="ref-McCamley2012" ref-type="bibr">McCamley
  et al., 2012</xref>). The plot facilitates debugging and presentation
  of results.</p>
</sec>
<sec id="outputs">
  <title>Outputs</title>
  <p>As shown in figure 2, the outputs of GaitPy modules include
  classification of gait bouts, a set of gait feature values extracted
  for each bout, and a plot of raw sensor data marked with detected gait
  events (initial contact/heel strike and final contact/toe off). We
  describe outputs of each of the processing modules below:</p>
  <p><bold>classify_bouts</bold> generates a pandas dataframe or a h5
  file containing the following columns:</p>
  <list list-type="alpha-lower">
    <list-item>
      <p>window_start_time: Unix timestamp associated with the beginning
      of each 3-second epoch in the data.</p>
    </list-item>
    <list-item>
      <p>window_end_time: Unix timestamp associated with the end of each
      3-second epoch in the data.</p>
    </list-item>
    <list-item>
      <p>prediction: Output of the gait classification model (1=gait or
      0=not gait) for each 3-second epoch in the data.</p>
    </list-item>
  </list>
  <p><bold>extract_features</bold> generates a pandas dataframe or a csv
  file containing:</p>
  <list list-type="alpha-lower">
    <list-item>
      <p>Bout number for each bout detected by classify_bouts (column
      name: bout_number).</p>
    </list-item>
    <list-item>
      <p>Length of bout in seconds (column name: bout_length_sec).
      </p>
    </list-item>
    <list-item>
      <p>Start time of bout (column name: bout_start_time).</p>
    </list-item>
    <list-item>
      <p>Total number of steps detected within each bout (column name:
      steps).</p>
    </list-item>
    <list-item>
      <p>Initial and final contact event timestamps in Unix time (column
      names: IC and FC respectively).</p>
    </list-item>
    <list-item>
      <p>Values of the following gait features are derived per stride:
      stride duration, step duration, cadence, initial double support,
      terminal double support, double support, single limb support,
      stance, swing, step length, stride length, gait speed. In
      addition, we calculate variability and asymmetry associated with a
      set of features.</p>
    </list-item>
  </list>
  <p><bold>plot_contacts</bold> generates a HTML file containing an
  interactive time-series plot of raw vertical acceleration data labeled
  with detected gait events and bouts (shown in figure 3).</p>
  <list list-type="alpha-lower">
    <list-item>
      <p>Initial contact: The moment in the gait cycle when foot touches
      the ground (i.e. heel strike)</p>
    </list-item>
    <list-item>
      <p>Final contact: The moment in the gait cycle when foot lifts off
      the ground (i.e. toe off)</p>
    </list-item>
    <list-item>
      <p>Gait bouts: A green vertical line marks the beginning of each
      detected gait bout and a red vertical line marks the end of the
      bout (Figure 3).</p>
    </list-item>
  </list>
  <fig>
    <caption><p>Time-series plot generated by plot_contacts module of
    the raw vertical acceleration data labeled with detected gait events
    (initial contact/heel strike and final contact/toe off) and bout
    classifications. The start and end times of classified bouts are
    labeled by green and red vertical lines respectively. During the
    period shown, the participant walked for about 30 seconds, paused,
    performed 5 sit-to-stand repetitions, paused again, and continued
    walking for about 30 seconds.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="Figure3.png" xlink:title="" />
  </fig>
</sec>
<sec id="algorithms">
  <title>Algorithms</title>
  <p>GaitPy includes two key algorithms for processing raw accelerometer
  data to derive gait features. The first algorithm is used for
  detecting bouts of gait from continuous accelerometer data collected
  under free-living conditions and the second algorithm derives temporal
  and spatial features of gait from pre-identified bouts of gait. Below
  is a brief description of the algorithms.</p>
  <p><bold>Gait Classification</bold>
  In order to derive gait features from data collected under free-living
  conditions, it is essential to identify periods of walking activity.
  GaitPy includes a pre-trained random forest
  (<xref alt="Breiman, 2001" rid="ref-Breiman2001" ref-type="bibr">Breiman,
  2001</xref>) binary classifier that operates on time and frequency
  domain features extracted from 3-second epochs of vertical
  acceleration data. Prior to feature extraction, raw vertical
  acceleration data is down-sampled to 50Hz and band-pass filtered using
  a 0.5-3Hz 1st order Butterworth filter. Extracted signal features
  include dominant frequency, the ratio of the energy associated with
  the dominant frequency component to the total energy, the range of
  amplitude, the root mean square value of the signal, and the signal
  entropy. Gaitpy’s classify_bouts module applies this binary classifier
  to input data to classify each non-overlapping 3-second epoch as
  either gait or not-gait.</p>
  <p><bold>Gait Features</bold>
  GaitPy implements a slightly modified version of a Gaussian continuous
  wavelet-based method
  (<xref alt="McCamley et al., 2012" rid="ref-McCamley2012" ref-type="bibr">McCamley
  et al., 2012</xref>) and an inverted pendulum model
  (<xref alt="Zijlstra &amp; Hof, 2003" rid="ref-Zijlstra2003" ref-type="bibr">Zijlstra
  &amp; Hof, 2003</xref>) to extract features from data collected during
  bouts of gait.</p>
  <p>Three post-processing steps are applied to remove extraneous stride
  detections beyond physiological limits. Step 1: Strides longer than
  2.25 seconds or shorter than 0.25 seconds are removed.
  (<xref alt="Najafi et al., 2003" rid="ref-Najafi2003" ref-type="bibr">Najafi
  et al., 2003</xref>) Step 2: Strides with stance times exceeding 70%
  of the maximal stride time of 2.25 seconds are removed.
  (<xref alt="Hollman et al., 2011" rid="ref-Hollman2011" ref-type="bibr">Hollman
  et al., 2011</xref>) Step 3: Strides with an initial double support
  that exceed 20% of the maximal stride time of 2.25 seconds are
  removed.
  (<xref alt="Hollman et al., 2011" rid="ref-Hollman2011" ref-type="bibr">Hollman
  et al., 2011</xref>)</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>The Digital Medicine &amp; Translational Imaging group at Pfizer,
  Inc supported the development of this package.</p>
</sec>
<sec id="license">
  <title>License</title>
  <p>This project is licensed under the MIT License - see the LICENSE.md
  file for details</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-McCamley2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>McCamley</surname><given-names>John</given-names></name>
          <name><surname>Donati</surname><given-names>Marco</given-names></name>
          <name><surname>Grimpampi</surname><given-names>Eleni</given-names></name>
          <name><surname>Mazzà</surname><given-names>Claudia</given-names></name>
        </person-group>
        <article-title>An enhanced estimate of initial contact and final contact instants of time using lower trunk inertial sensor data</article-title>
        <source>Gait and Posture</source>
        <year iso-8601-date="2012">2012</year>
        <volume>36</volume>
        <issue>2</issue>
        <isbn>0966-6362</isbn>
        <issn>09666362</issn>
        <pub-id pub-id-type="doi">10.1016/j.gaitpost.2012.02.019</pub-id>
        <pub-id pub-id-type="pmid">22465705</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Zijlstra2003">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zijlstra</surname><given-names>Wiebren</given-names></name>
          <name><surname>Hof</surname><given-names>At L.</given-names></name>
        </person-group>
        <article-title>Assessment of spatio-temporal gait parameters from trunk accelerations during human walking</article-title>
        <source>Gait and Posture</source>
        <year iso-8601-date="2003">2003</year>
        <volume>18</volume>
        <issue>2</issue>
        <isbn>0966-6362</isbn>
        <issn>09666362</issn>
        <pub-id pub-id-type="doi">10.1016/S0966-6362(02)00190-X</pub-id>
        <pub-id pub-id-type="pmid">14654202</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Hollman2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hollman</surname><given-names>John</given-names></name>
          <name><surname>McDade</surname><given-names>Eric</given-names></name>
          <name><surname>Peterson</surname><given-names>Ronald</given-names></name>
        </person-group>
        <article-title>Normative Spatiotemporal Gait Parameters in Older Adults</article-title>
        <source>Gait &amp; Posture</source>
        <year iso-8601-date="2011">2011</year>
        <volume>34</volume>
        <issue>1</issue>
        <isbn>2036884555</isbn>
        <pub-id pub-id-type="doi">10.1016/j.cll.2010.01.003.Lyme</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Najafi2003">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Najafi</surname><given-names>Bijan</given-names></name>
          <name><surname>Aminian</surname><given-names>Kamiar</given-names></name>
          <name><surname>Paraschiv-Ionescu</surname><given-names>Anisoara</given-names></name>
          <name><surname>Loew</surname><given-names>François</given-names></name>
          <name><surname>Büla</surname><given-names>Christophe J.</given-names></name>
          <name><surname>Robert</surname><given-names>Philippe</given-names></name>
        </person-group>
        <article-title>Ambulatory system for human motion analysis using a kinematic sensor: Monitoring of daily physical activity in the elderly</article-title>
        <source>IEEE Transactions on Biomedical Engineering</source>
        <year iso-8601-date="2003">2003</year>
        <volume>50</volume>
        <issue>6</issue>
        <isbn>0-7803-6603-4</isbn>
        <issn>00189294</issn>
        <pub-id pub-id-type="doi">10.1109/TBME.2003.812189</pub-id>
        <pub-id pub-id-type="pmid">12814238</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DelDin2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Del Din</surname><given-names>Silvia</given-names></name>
          <name><surname>Godfrey</surname><given-names>Alan</given-names></name>
          <name><surname>Rochester</surname><given-names>Lynn</given-names></name>
        </person-group>
        <article-title>Validation of an Accelerometer to Quantify a Comprehensive Battery of Gait Characteristics in Healthy Older Adults and Parkinson’s Disease: Toward Clinical and at Home Use</article-title>
        <source>IEEE Journal of Biomedical and Health Informatics</source>
        <year iso-8601-date="2016">2016</year>
        <volume>20</volume>
        <issue>3</issue>
        <issn>21682194</issn>
        <pub-id pub-id-type="doi">10.1109/JBHI.2015.2419317</pub-id>
        <pub-id pub-id-type="pmid">25850097</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Breiman2001">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Breiman</surname><given-names>Leo</given-names></name>
        </person-group>
        <article-title>Random Forests</article-title>
        <source>Machine Learning</source>
        <year iso-8601-date="2001">2001</year>
        <issue>45</issue>
      </element-citation>
    </ref>
    <ref id="ref-Trojaniello2014">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Trojaniello</surname><given-names>Diana</given-names></name>
          <name><surname>Cereatti</surname><given-names>Andrea</given-names></name>
          <name><surname>Della Croce</surname><given-names>Ugo</given-names></name>
        </person-group>
        <article-title>Accuracy, sensitivity and robustness of five different methods for the estimation of gait temporal parameters using a single inertial sensor mounted on the lower trunk</article-title>
        <source>Gait and Posture</source>
        <publisher-name>Elsevier B.V.</publisher-name>
        <year iso-8601-date="2014">2014</year>
        <volume>40</volume>
        <issue>4</issue>
        <issn>18792219</issn>
        <uri>http://dx.doi.org/10.1016/j.gaitpost.2014.07.007</uri>
        <pub-id pub-id-type="doi">10.1016/j.gaitpost.2014.07.007</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

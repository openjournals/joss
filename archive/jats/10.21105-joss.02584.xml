<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">2584</article-id>
<article-id pub-id-type="doi">10.21105/joss.02584</article-id>
<title-group>
<article-title>pirecorder: Controlled and automated image and video
recording with the raspberry pi</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-0872-7098</contrib-id>
<string-name>Jolle W. Jolles</string-name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Collective Behaviour, Max Planck Institute of
Animal Behaviour, Konstanz, Germany</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Zukunftskolleg, Institute of Advanced Study, University of
Konstanz, Germany</institution>
</institution-wrap>
</aff>
</contrib-group>
<volume>5</volume>
<issue>54</issue>
<fpage>2584</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>raspberry pi</kwd>
<kwd>camera</kwd>
<kwd>recording</kwd>
<kwd>video</kwd>
<kwd>automation</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>A fundamental component of empirical research is the acquisition of
  accurate, consistent, and often significant amounts of data.
  Specifically, researchers often require large numbers of controlled
  and often parallel image and video recordings. For this the raspberry
  pi, a small, single-board computer that brings together open-source
  principles with sensor and controller interfaces, and highly
  customisable programming capabilities, provides a great, low cost
  solution. Indeed, in recent years, the raspberry pi has been
  increasingly taken up by the scientific community
  (<xref alt="Fletcher &amp; Mura, 2019" rid="ref-Fletcher2019" ref-type="bibr">Fletcher
  &amp; Mura, 2019</xref>) and used in a wide range of projects that
  required the collection of high quality image data, from sub-micron
  resolution microscopy
  (<xref alt="Aidukas et al., 2019" rid="ref-Aidukas2019" ref-type="bibr">Aidukas
  et al., 2019</xref>), and deep sea video recordings
  (<xref alt="Phillips et al., 2019" rid="ref-Phillips2019" ref-type="bibr">Phillips
  et al., 2019</xref>), to motion-triggered camera trapping
  (<xref alt="Nazir et al., 2017" rid="ref-Nazir2017" ref-type="bibr">Nazir
  et al., 2017</xref>;
  <xref alt="Prinz et al., 2016" rid="ref-Prinz2016" ref-type="bibr">Prinz
  et al., 2016</xref>), high-throughput behavioural assessments
  (<xref alt="Geissmann et al., 2017" rid="ref-Geissmann2017" ref-type="bibr">Geissmann
  et al., 2017</xref>;
  <xref alt="Jolles et al., 2019" rid="ref-Jolles2019" ref-type="bibr">Jolles
  et al., 2019</xref>;
  <xref alt="Todd et al., 2017" rid="ref-Todd2017" ref-type="bibr">Todd
  et al., 2017</xref>), long-term home cage monitoring
  (<xref alt="Singh et al., 2019" rid="ref-Singh2019" ref-type="bibr">Singh
  et al., 2019</xref>), and the automated tracking of animal groups
  (<xref alt="Alarcón-Nieto et al., 2018" rid="ref-Alarcon-Nieto2018" ref-type="bibr">Alarcón-Nieto
  et al., 2018</xref>;
  <xref alt="Jolles et al., 2018" rid="ref-Jolles2018" ref-type="bibr">Jolles
  et al., 2018</xref>,
  <xref alt="2020" rid="ref-Jolles2020" ref-type="bibr">2020</xref>).</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>So far, researchers have often relied on writing their own
  recordings scripts to take still photographs and videos from the
  command line (using <monospace>raspistill</monospace> and
  <monospace>raspivid</monospace>), control the camera module with
  <monospace>picamera</monospace> in Python
  (<xref alt="Jones, 2017" rid="ref-Jones2017" ref-type="bibr">Jones,
  2017</xref>), or trigger recordings by motion-detection
  (<ext-link ext-link-type="uri" xlink:href="https://motion-project.github.io">Motion</ext-link>).
  Also some specific solutions exist, such as a web-based interface to
  run recordings
  (<xref alt="Singh et al., 2019" rid="ref-Singh2019" ref-type="bibr">Singh
  et al., 2019</xref>) and advanced software that converts the raspberry
  pi in a dedicated behavioural profiling machine
  (<xref alt="Geissmann et al., 2017" rid="ref-Geissmann2017" ref-type="bibr">Geissmann
  et al., 2017</xref>). However, there is still a need for a complete
  solution that helps researchers, especially those with limited coding
  skills, to easily set up and configure their raspberry pi and run
  large numbers of controlled and automated image and video recordings.
  Here I present <monospace>pirecorder</monospace> to overcome this
  need.</p>
</sec>
<sec id="functionality">
  <title>Functionality</title>
  <p><monospace>pirecorder</monospace> is a Python package, built on the
  picamera
  (<xref alt="Jones, 2017" rid="ref-Jones2017" ref-type="bibr">Jones,
  2017</xref>) and OpenCV
  (<xref alt="Bradski, 2000" rid="ref-Bradski2000" ref-type="bibr">Bradski,
  2000</xref>) libraries, that provides a flexible solution for the
  collection of consistent image and video data. It consists of a number
  of interconnected modules to facilitate key aspects of media
  recording: 1) setting-up and configuring the camera, 2) recording
  images, videos, time-lapses, and standardised video sequences with
  automatic file-naming, 3) easy scheduling of future recordings, and 4)
  converting of recorded media with resize, timestamp, and monitoring
  options. All functionalities are designed to make it very
  straightforward, even for users with limited coding experience, to
  configure, initiate, schedule, and convert recordings. In particular,
  <monospace>pirecorder</monospace> offers interactive streaming
  functionalities to facilitate users in positioning and focusing the
  camera, selecting the desired white-balance and other image parameters
  using trackbars, and set the ideal camera shutter speed. Furthermore,
  <monospace>pirecorder</monospace> comes with a dedicated documentation
  website with detailed information and tutorials
  (<ext-link ext-link-type="uri" xlink:href="https://jollejolles.github.io/pirecorder/">jollejolles.github.io/pirecorder</ext-link>)
  as well as a set of annotated
  <ext-link ext-link-type="uri" xlink:href="https://github.com/JolleJolles/pirecorder/tree/master/notebooks">Jupyter
  Notebooks</ext-link> to help users integrate the raspberry pi and
  <monospace>pirecorder</monospace> in their work.</p>
  <fig>
    <caption><p>Screenshots of pirecorder in action, from configuring
    the camera with the interactive video stream, running recordings,
    testing and scheduling future recordings, and converting recorded
    media.</p></caption>
    <graphic mimetype="image" mime-subtype="jpeg" xlink:href="Figure1.jpg" xlink:title="" />
  </fig>
  <p>A core functionality of <monospace>pirecorder</monospace> is that
  it works with configuration files. These files make it possible to
  store a wide range of camera and recording settings that are then
  automatically used for recordings without requiring further user
  input. Furthermore, multiple configuration files can be stored and
  used, such as to easily start recordings for different experimental
  contexts or treatments. Configuration files can be edited directly, or
  parameters can be set in python or using the interactive video stream
  functionalities. Recordings can be easily initiated remotely, such as
  via an SSH connection, and scheduled to automatically start and stop
  at specific times in the future. By its use of configuration files and
  the automatic naming of files, <monospace>pirecorder</monospace> also
  makes it possible to start controlled recordings on multiple raspberry
  pi’s simultaneously, such as with
  <ext-link ext-link-type="uri" xlink:href="https://github.com/brockgr/csshx">csshX</ext-link>,
  which sends a command to multiple computers at once.</p>
</sec>
<sec id="use-cases">
  <title>Use cases</title>
  <p><monospace>pirecorder</monospace> has already been used
  successfully in a number of studies, such as to facilitate the
  high-throughput recording of large numbers of individuals and shoals
  of fish
  (<xref alt="Jolles et al., 2018" rid="ref-Jolles2018" ref-type="bibr">Jolles
  et al., 2018</xref>,
  <xref alt="2019" rid="ref-Jolles2019" ref-type="bibr">2019</xref>,
  <xref alt="2020" rid="ref-Jolles2020" ref-type="bibr">2020</xref>) and
  more recently, the autonomous long-term recording of fish each day,
  every day, for the first four-month of their life (in prep). By
  facilitating and streamlining controlled and automated image and video
  recordings, I hope <monospace>pirecorder</monospace> will be used by
  scientists to help simplify and improve their collection of high
  quality data and thereby ultimately enhance their research.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>I would like to thank Lucas Koerner and Jan Heuschele for helpful
  feedback on the package and paper. This work was made possible by a
  Postdoctoral Fellowship from the Alexander von Humboldt Foundation, a
  Postdoctoral Fellowship from the Zukunftskolleg, Institute of Advanced
  Study at the University of Konstanz, and a research grant from the
  Dr. J.L. Dobberke Foundation.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Aidukas2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Aidukas</surname><given-names>Tomas</given-names></name>
          <name><surname>Eckert</surname><given-names>Regina</given-names></name>
          <name><surname>Harvey</surname><given-names>Andrew R.</given-names></name>
          <name><surname>Waller</surname><given-names>Laura</given-names></name>
          <name><surname>Konda</surname><given-names>Pavan C.</given-names></name>
        </person-group>
        <article-title>Low-cost, sub-micron resolution, wide-field computational microscopy using opensource hardware</article-title>
        <source>Scientific Reports</source>
        <year iso-8601-date="2019">2019</year>
        <volume>9</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1038/s41598-019-43845-9</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Alarcon-Nieto2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Alarcón-Nieto</surname><given-names>Gustavo</given-names></name>
          <name><surname>Graving</surname><given-names>Jacob M.</given-names></name>
          <name><surname>Klarevas-Irby</surname><given-names>James A.</given-names></name>
          <name><surname>Maldonado-Chaparro</surname><given-names>Adriana A.</given-names></name>
          <name><surname>Mueller</surname><given-names>Inge</given-names></name>
          <name><surname>Farine</surname><given-names>Damien R</given-names></name>
        </person-group>
        <article-title>An automated barcode tracking system for behavioural studies in birds</article-title>
        <source>Methods in Ecology and Evolution</source>
        <year iso-8601-date="2018">2018</year>
        <volume>9</volume>
        <issue>6</issue>
        <pub-id pub-id-type="doi">10.1111/2041-210X.13005</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Bradski2000">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bradski</surname><given-names>G.</given-names></name>
        </person-group>
        <article-title>The OpenCV Library</article-title>
        <source>Dr. Dobb’s Journal of Software Tools</source>
        <year iso-8601-date="2000">2000</year>
      </element-citation>
    </ref>
    <ref id="ref-Fletcher2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fletcher</surname><given-names>Anthony C.</given-names></name>
          <name><surname>Mura</surname><given-names>Cameron</given-names></name>
        </person-group>
        <article-title>Ten quick tips for using a raspberry Pi</article-title>
        <source>PLoS Computational Biology</source>
        <year iso-8601-date="2019">2019</year>
        <volume>15</volume>
        <issue>5</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006959</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Geissmann2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Geissmann</surname><given-names>Quentin</given-names></name>
          <name><surname>Garcia Rodriguez</surname><given-names>Luis</given-names></name>
          <name><surname>Beckwith</surname><given-names>Esteban J</given-names></name>
          <name><surname>French</surname><given-names>Alice S</given-names></name>
          <name><surname>Jamasb</surname><given-names>Arian R</given-names></name>
          <name><surname>Gilestro</surname><given-names>Giorgio F</given-names></name>
        </person-group>
        <article-title>Ethoscopes: An open platform for high-throughput ethomics</article-title>
        <source>PLOS Biology</source>
        <year iso-8601-date="2017">2017</year>
        <volume>15</volume>
        <issue>10</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.2003026</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Jolles2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jolles</surname><given-names>Jolle W</given-names></name>
          <name><surname>Laskowski</surname><given-names>Kate L</given-names></name>
          <name><surname>Boogert</surname><given-names>Neeltje J</given-names></name>
          <name><surname>Manica</surname><given-names>Andrea</given-names></name>
        </person-group>
        <article-title>Repeatable group differences in the collective behaviour of stickleback shoals across ecological contexts</article-title>
        <source>Proceedings of the Royal Society B</source>
        <year iso-8601-date="2018">2018</year>
        <volume>285</volume>
        <issue>1872</issue>
        <pub-id pub-id-type="doi">10.1098/rspb.2017.2629</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Jolles2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jolles</surname><given-names>Jolle W</given-names></name>
          <name><surname>Briggs</surname><given-names>Helen D.</given-names></name>
          <name><surname>Araya-Ajoy</surname><given-names>Yimen G.</given-names></name>
          <name><surname>Boogert</surname><given-names>Neeltje J.</given-names></name>
        </person-group>
        <article-title>Personality, plasticity and predictability in sticklebacks: bold fish are less plastic and more predictable than shy fish</article-title>
        <source>Animal Behaviour</source>
        <year iso-8601-date="2019">2019</year>
        <volume>154</volume>
        <pub-id pub-id-type="doi">10.1016/j.anbehav.2019.06.022</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Jolles2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Jolles</surname><given-names>Jolle W</given-names></name>
          <name><surname>Mazué</surname><given-names>Geoffrey P F</given-names></name>
          <name><surname>Davidson</surname><given-names>Jacob</given-names></name>
          <name><surname>Behrmann-Godel</surname><given-names>Jasminca</given-names></name>
          <name><surname>Couzin</surname><given-names>Iain D</given-names></name>
        </person-group>
        <article-title>Schistocephalus parasite infection alters sticklebacks’ movement ability and thereby shapes social interactions</article-title>
        <source>Scientific Reports</source>
        <year iso-8601-date="2020">2020</year>
        <volume>10</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1038/s41598-020-69057-0</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Jones2017">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Jones</surname><given-names>D</given-names></name>
        </person-group>
        <article-title>Picamera 1.13 Documentation</article-title>
        <year iso-8601-date="2017">2017</year>
        <uri>https://picamera.readthedocs.io/en/release-1.13/</uri>
      </element-citation>
    </ref>
    <ref id="ref-Nazir2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Nazir</surname><given-names>Sajid</given-names></name>
          <name><surname>Newey</surname><given-names>Scott</given-names></name>
          <name><surname>Justin Irvine</surname><given-names>R.</given-names></name>
          <name><surname>Verdicchio</surname><given-names>Fabio</given-names></name>
          <name><surname>Davidson</surname><given-names>Paul</given-names></name>
          <name><surname>Fairhurst</surname><given-names>Gorry</given-names></name>
          <name><surname>Van Der Wal</surname><given-names>Rene</given-names></name>
        </person-group>
        <article-title>WiseEye: Next generation expandable and programmable camera trap platform for wildlife research</article-title>
        <source>PLoS ONE</source>
        <year iso-8601-date="2017">2017</year>
        <volume>12</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0169758</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Phillips2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Phillips</surname><given-names>Brennan T.</given-names></name>
          <name><surname>Licht</surname><given-names>Stephen</given-names></name>
          <name><surname>Haiat</surname><given-names>Karla S.</given-names></name>
          <name><surname>Bonney</surname><given-names>Jake</given-names></name>
          <name><surname>Allder</surname><given-names>Josh</given-names></name>
          <name><surname>Chaloux</surname><given-names>Nicholas</given-names></name>
          <name><surname>Shomberg</surname><given-names>Russell</given-names></name>
          <name><surname>Noyes</surname><given-names>Tim J.</given-names></name>
        </person-group>
        <article-title>DEEPi: A miniaturized, robust, and economical camera and computer system for deep-sea exploration</article-title>
        <source>Deep-Sea Research Part I</source>
        <year iso-8601-date="2019">2019</year>
        <volume>153</volume>
        <pub-id pub-id-type="doi">10.1016/j.dsr.2019.103136</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Prinz2016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Prinz</surname><given-names>Anna C. B.</given-names></name>
          <name><surname>Taank</surname><given-names>Vikas K.</given-names></name>
          <name><surname>Voegeli</surname><given-names>Vincent</given-names></name>
          <name><surname>Walters</surname><given-names>Eric L.</given-names></name>
        </person-group>
        <article-title>A novel nest-monitoring camera system using a Raspberry Pi micro-computer</article-title>
        <source>Journal of Field Ornithology</source>
        <year iso-8601-date="2016">2016</year>
        <volume>87</volume>
        <issue>4</issue>
        <pub-id pub-id-type="doi">10.1111/jofo.12182</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Singh2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Singh</surname><given-names>Surjeet</given-names></name>
          <name><surname>Bermudez-Contreras</surname><given-names>Edgar</given-names></name>
          <name><surname>Nazari</surname><given-names>Mojtaba</given-names></name>
          <name><surname>Sutherland</surname><given-names>Robert J.</given-names></name>
          <name><surname>Mohajerani</surname><given-names>Majid H.</given-names></name>
        </person-group>
        <article-title>Low-cost solution for rodent home-cage behaviour monitoring</article-title>
        <source>PLoS ONE</source>
        <year iso-8601-date="2019">2019</year>
        <volume>14</volume>
        <issue>8</issue>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0220751</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Todd2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Todd</surname><given-names>Douglas W.</given-names></name>
          <name><surname>Philip</surname><given-names>Rohit C.</given-names></name>
          <name><surname>Niihori</surname><given-names>Maki</given-names></name>
          <name><surname>Ringle</surname><given-names>Ryan A.</given-names></name>
          <name><surname>Coyle</surname><given-names>Kelsey R.</given-names></name>
          <name><surname>Zehri</surname><given-names>Sobia F.</given-names></name>
          <name><surname>Zabala</surname><given-names>Leanne</given-names></name>
          <name><surname>Mudery</surname><given-names>Jordan A.</given-names></name>
          <name><surname>Francis</surname><given-names>Ross H.</given-names></name>
          <name><surname>Rodriguez</surname><given-names>Jeffrey J.</given-names></name>
          <name><surname>Jacob</surname><given-names>Abraham</given-names></name>
        </person-group>
        <article-title>A fully automated high-throughput zebrafish behavioral ototoxicity assay</article-title>
        <source>Zebrafish</source>
        <year iso-8601-date="2017">2017</year>
        <volume>14</volume>
        <issue>4</issue>
        <pub-id pub-id-type="doi">10.1089/zeb.2016.1412</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

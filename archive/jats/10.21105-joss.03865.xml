<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3865</article-id>
<article-id pub-id-type="doi">10.21105/joss.03865</article-id>
<title-group>
<article-title>GGLasso - a Python package for General Graphical Lasso
computation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-0673-9944</contrib-id>
<string-name>Fabian Schaipp</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<string-name>Oleg Vlasovets</string-name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-3821-7083</contrib-id>
<string-name>Christian L. Müller</string-name>
<xref ref-type="aff" rid="aff-2"/>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Technische Universität München</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Institute of Computational Biology, Helmholtz Zentrum
München</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Statistics, Ludwig-Maximilians-Universität
München</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Center for Computational Mathematics, Flatiron Institute,
New York</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2021-11-17">
<day>17</day>
<month>11</month>
<year>2021</year>
</pub-date>
<volume>6</volume>
<issue>68</issue>
<fpage>3865</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>graphical lasso</kwd>
<kwd>latent graphical model</kwd>
<kwd>structured sparsity</kwd>
<kwd>convex optimization</kwd>
<kwd>ADMM</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>We introduce <monospace>GGLasso</monospace>, a Python package for
  solving General Graphical Lasso problems. The Graphical Lasso scheme,
  introduced by Friedman et al.
  (<xref alt="2007" rid="ref-Friedman2007" ref-type="bibr">2007</xref>)
  (see also Yuan &amp; Lin
  (<xref alt="2007" rid="ref-Yuan2007" ref-type="bibr">2007</xref>),
  Banerjee et al.
  (<xref alt="2008" rid="ref-Banerjee2008" ref-type="bibr">2008</xref>)),
  estimates a sparse inverse covariance matrix
  <inline-formula><alternatives>
  <tex-math><![CDATA[\Theta]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>Θ</mml:mi></mml:math></alternatives></inline-formula>
  from multivariate Gaussian data <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{X} \sim \mathcal{N}(\mu, \Sigma) \in \mathbb{R}^p]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>𝒳</mml:mi></mml:mstyle><mml:mo>∼</mml:mo><mml:mstyle mathvariant="script"><mml:mi>𝒩</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>Σ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="double-struck"><mml:mi>ℝ</mml:mi></mml:mstyle><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.
  Originally proposed by Dempster
  (<xref alt="1972" rid="ref-Dempster1972" ref-type="bibr">1972</xref>)
  under the name Covariance Selection, this estimation framework has
  been extended to include latent variables in Chandrasekaran et al.
  (<xref alt="2012" rid="ref-Chandrasekaran2012" ref-type="bibr">2012</xref>).
  Recent extensions also include the joint estimation of multiple
  inverse covariance matrices, see, e.g., in Danaher et al.
  (<xref alt="2013" rid="ref-Danaher2013" ref-type="bibr">2013</xref>),
  Tomasi et al.
  (<xref alt="2018" rid="ref-Tomasi2018" ref-type="bibr">2018</xref>).
  The <monospace>GGLasso</monospace> package contains methods for
  solving the general problem formulation:</p>
  <boxed-text>
    <p><named-content id="eqU003Aproblem" content-type="equation"><disp-formula><alternatives>
    <tex-math><![CDATA[\begin{aligned}
    \label{eq:problem}
    \min_{\Theta, L \in \mathbb{S}_{++}^K }\quad \sum_{k=1}^{K} \left(-\log\det(\Theta^{(k)} - L^{(k)}) + \langle S^{(k)},  \Theta^{(k)} - L^{(k)} \rangle \right)+ \mathcal{P}(\Theta) +\sum_{k=1}^{K} \mu_{1,k} \|L^{(k)}\|_{\star}.\end{aligned}]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:munder><mml:mo>min</mml:mo><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mstyle mathvariant="double-struck"><mml:mi>𝕊</mml:mi></mml:mstyle><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:mrow></mml:munder><mml:mspace width="1.0em"></mml:mspace><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo>−</mml:mo><mml:mo>log</mml:mo><mml:mo>det</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>Θ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false" form="prefix">⟨</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>Θ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false" form="postfix">⟩</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle mathvariant="script"><mml:mi>𝒫</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Θ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mo stretchy="false" form="postfix">∥</mml:mo><mml:mo>⋆</mml:mo></mml:msub><mml:mi>.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></named-content></p>
  </boxed-text>
  <p>Here, we denote with <inline-formula><alternatives>
  <tex-math><![CDATA[\mathbb{S}_{++}^K]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msubsup><mml:mstyle mathvariant="double-struck"><mml:mi>𝕊</mml:mi></mml:mstyle><mml:mrow><mml:mo>+</mml:mo><mml:mo>+</mml:mo></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>
  the <inline-formula><alternatives>
  <tex-math><![CDATA[K]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>K</mml:mi></mml:math></alternatives></inline-formula>-product
  of the space of symmetric, positive definite matrices. Moreover, we
  write <inline-formula><alternatives>
  <tex-math><![CDATA[\Theta = (\Theta^{(1)},\dots,\Theta^{(K)})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>Θ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>Θ</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  for the sparse component of the inverse covariances and
  <inline-formula><alternatives>
  <tex-math><![CDATA[L = (L^{(1)},\dots,L^{(K)})]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>K</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
  for the low rank components, formed by potential latent variables.
  Here, <inline-formula><alternatives>
  <tex-math><![CDATA[\mathcal{P}]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mstyle mathvariant="script"><mml:mi>𝒫</mml:mi></mml:mstyle></mml:math></alternatives></inline-formula>
  is a regularization function that induces a desired sparsity
  structure. The above problem formulation subsumes important special
  cases, including the single (latent variable) Graphical Lasso, the
  Group, and the Fused Graphical Lasso.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Currently, there is no Python package available for solving general
  Graphical Lasso instances. The standard single Graphical Lasso problem
  (SGL) can be solved in <monospace>scikit-learn</monospace>
  (<xref alt="Pedregosa et al., 2011" rid="ref-Pedregosa2011" ref-type="bibr">Pedregosa
  et al., 2011</xref>). The <monospace>skggm</monospace> package
  provides several algorithmic and model selection extensions for the
  single Graphical Lasso problem
  (<xref alt="Laska &amp; Narayan, 2017" rid="ref-Laska2017" ref-type="bibr">Laska
  &amp; Narayan, 2017</xref>). The package <monospace>regain</monospace>
  (<xref alt="Tomasi et al., 2018" rid="ref-Tomasi2018" ref-type="bibr">Tomasi
  et al., 2018</xref>) comprises solvers for single and Fused Graphical
  Lasso problems, with and without latent variables. With
  <monospace>GGLasso</monospace>, we make the following
  contributions:</p>
  <list list-type="bullet">
    <list-item>
      <p>Proposing a uniform framework for solving Graphical Lasso
      problems.</p>
    </list-item>
    <list-item>
      <p>Providing solvers for Group Graphical Lasso problems (with and
      without latent variables).</p>
    </list-item>
    <list-item>
      <p>Providing a solver for – what we call – <italic>nonconforming
      GGL</italic> problems where not all variables need to be present
      in every instance. We detail a use case of this novel extension on
      synthetic data.</p>
    </list-item>
    <list-item>
      <p>Implementing a block-wise ADMM solver for SGL problems
      following Witten et al.
      (<xref alt="2011" rid="ref-Witten2011" ref-type="bibr">2011</xref>)
      as well as proximal point solvers for FGL and GGL problems
      (<xref alt="N. Zhang et al., 2021" rid="ref-Zhang2021" ref-type="bibr">N.
      Zhang et al., 2021</xref>;
      <xref alt="Y. Zhang et al., 2020" rid="ref-Zhang2020" ref-type="bibr">Y.
      Zhang et al., 2020</xref>).</p>
    </list-item>
  </list>
  <p>In the table below we give an overview of existing functionalities
  and the <monospace>GGLasso</monospace> package.</p>
  <table-wrap>
    <table>
      <colgroup>
        <col width="20%" />
        <col width="20%" />
        <col width="20%" />
        <col width="20%" />
        <col width="20%" />
      </colgroup>
      <thead>
        <tr>
          <th></th>
          <th>scikit-learn</th>
          <th>regain</th>
          <th>GGLasso</th>
          <th>comment</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>SGL</td>
          <td><bold>yes</bold></td>
          <td><bold>yes</bold></td>
          <td><bold>yes</bold></td>
          <td>new: block-wise solver</td>
        </tr>
        <tr>
          <td>SGL + latent</td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td><bold>yes</bold></td>
          <td></td>
        </tr>
        <tr>
          <td>GGL</td>
          <td><bold>no</bold></td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td></td>
        </tr>
        <tr>
          <td>GGL + latent</td>
          <td><bold>no</bold></td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td></td>
        </tr>
        <tr>
          <td>FGL</td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td><bold>yes</bold></td>
          <td>new: proximal point solver</td>
        </tr>
        <tr>
          <td>FGL + latent</td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td><bold>yes</bold></td>
          <td></td>
        </tr>
        <tr>
          <td>GGL nonconforming (+latent)</td>
          <td><bold>no</bold></td>
          <td><bold>no</bold></td>
          <td><bold>yes</bold></td>
          <td></td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</sec>
<sec id="functionalities">
  <title>Functionalities</title>
  <sec id="installation-and-problem-instantiation">
    <title>Installation and problem instantiation</title>
    <p><monospace>GGLasso</monospace> can be installed via
    <monospace>pip</monospace>.</p>
    <preformat>pip install gglasso</preformat>
    <p>The central object of <monospace>GGLasso</monospace> is the class
    <monospace>glasso_problem</monospace>, which streamlines the solving
    or model selection procedure for SGL, GGL, and FGL problems with or
    without latent variables.</p>
    <p>As an example, we instantiate a single Graphical Lasso problem
    (see the problem formulation below). We input the empirical
    covariance matrix <monospace>S</monospace> and the number of samples
    <monospace>N</monospace>. We can choose to model latent variables
    and set the regularization parameters via the other input
    arguments.</p>
    <code language="python"># Import the main class of the package
from gglasso.problem import glasso_problem

# Define a SGL problem instance with given data S
problem  = glasso_problem(S, N, reg = None,
                          reg_params = {'lambda1': 0.01}, latent = False)</code>
    <p>As a second example, we instantiate a Group Graphical Lasso
    problem with latent variables. Typically, the optimal choice of the
    regularization parameters are not known and are determined via model
    selection.</p>
    <code language="python"># Define a GGL problem instance with given data S
problem  = glasso_problem(S, N, reg = &quot;GGL&quot;, reg_params = None, latent = True)</code>
    <p>Depending on the input arguments,
    <monospace>glasso_problem</monospace> comprises two main modes:</p>
    <list list-type="bullet">
      <list-item>
        <p>if regularization parameters are specified, the
        problem-dependent default solver is called.</p>
      </list-item>
      <list-item>
        <p>if regularization parameters are <italic>not</italic>
        specified, <monospace>GGLasso</monospace> performs model
        selection via grid search and the extended BIC criterion
        (<xref alt="Foygel &amp; Drton, 2010" rid="ref-Foygel2010" ref-type="bibr">Foygel
        &amp; Drton, 2010</xref>)).</p>
      </list-item>
    </list>
    <code language="python">problem.solve()
problem.model_selection()</code>
    <p>For further information on the input arguments and methods, we
    refer to the
    <ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/problem-object.html">detailled
    documentation</ext-link>.</p>
    <fig>
      <caption><p>Illustration of the latent SGL: The estimated inverse
      covariance matrix <inline-formula><alternatives>
      <tex-math><![CDATA[\hat \Omega]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>Ω</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
      decomposes into a sparse component <inline-formula><alternatives>
      <tex-math><![CDATA[\hat \Theta]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>Θ</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
      (central) and a low-rank component <inline-formula><alternatives>
      <tex-math><![CDATA[\hat L]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mover><mml:mi>L</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover></mml:math></alternatives></inline-formula>
      (right). <styled-content id="fig1"></styled-content></p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="../docs/source/pictures/SLRDecomp.pdf" xlink:title="" />
    </fig>
  </sec>
  <sec id="problem-formulation">
    <title>Problem formulation</title>
    <p>We list important special cases of the problem formulation given
    in <xref alt="Equation 1" rid="eqU003Aproblem">Equation 1</xref>.
    For a mathematical formulation of each special case, we refer to the
    <ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/math-description.html">documentation</ext-link>.</p>
    <sec id="SGL">
      <title>Single Graphical Lasso (<italic>SGL</italic>):</title>
      <p>For <inline-formula><alternatives>
      <tex-math><![CDATA[K=1]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
      the problem reduces to the single (latent variable) Graphical
      Lasso where <disp-formula><alternatives>
      <tex-math><![CDATA[
      \mathcal{P}(\Theta) = \lambda_1 \sum_{i \neq j} |\Theta_{ij}|.
      ]]></tex-math>
      <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>𝒫</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Θ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="true" form="prefix">|</mml:mo><mml:msub><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">|</mml:mo></mml:mrow><mml:mi>.</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>
      An illustration of the single latent variable Graphical Lasso
      model output is shown in
      <xref alt="Figure 1" rid="fig1">Figure 1</xref>.</p>
    </sec>
    <sec id="GGL">
      <title>Group Graphical Lasso (<italic>GGL</italic>):</title>
      <p>For <disp-formula><alternatives>
      <tex-math><![CDATA[
      \mathcal{P}(\Theta) = \lambda_1 \sum_{k=1}^{K} \sum_{i \neq j} |\Theta_{ij}^{(k)}| + \lambda_2  \sum_{i \neq j} \left(\sum_{k=1}^{K} |\Theta_{ij}^{(k)}|^2 \right)^{\frac{1}{2}}
      ]]></tex-math>
      <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>𝒫</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Θ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="true" form="prefix">|</mml:mo><mml:msubsup><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="true" form="postfix">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">|</mml:mo><mml:msubsup><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="true" form="postfix">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:msup></mml:mrow></mml:math></alternatives></disp-formula>
      we obtain the Group Graphical Lasso as formulated in Danaher et
      al.
      (<xref alt="2013" rid="ref-Danaher2013" ref-type="bibr">2013</xref>).</p>
    </sec>
    <sec id="FGL">
      <title>Fused Graphical Lasso (<italic>FGL</italic>):</title>
      <p>For <disp-formula><alternatives>
      <tex-math><![CDATA[
      \mathcal{P}(\Theta) = \lambda_1 \sum_{k=1}^{K} \sum_{i \neq j} |\Theta_{ij}^{(k)}| + \lambda_2  \sum_{k=2}^{K}   \sum_{i \neq j} |\Theta_{ij}^{(k)} - \Theta_{ij}^{(k-1)}|
      ]]></tex-math>
      <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mstyle mathvariant="script"><mml:mi>𝒫</mml:mi></mml:mstyle><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Θ</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="true" form="prefix">|</mml:mo><mml:msubsup><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="true" form="postfix">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="true" form="prefix">|</mml:mo><mml:msubsup><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="true" form="postfix">|</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
      we obtain Fused (also called Time-Varying) Graphical Lasso
      (<xref alt="Danaher et al., 2013" rid="ref-Danaher2013" ref-type="bibr">Danaher
      et al., 2013</xref>;
      <xref alt="Hallac et al., 2017" rid="ref-Hallac2017" ref-type="bibr">Hallac
      et al., 2017</xref>;
      <xref alt="Tomasi et al., 2018" rid="ref-Tomasi2018" ref-type="bibr">Tomasi
      et al., 2018</xref>).</p>
    </sec>
    <sec id="nonconforming-ggl">
      <title>Nonconforming GGL:</title>
      <p>Consider the GGL case in a situation where not all variables
      are observed in every instance <inline-formula><alternatives>
      <tex-math><![CDATA[k=1,\dots,K]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>.
      <monospace>GGLasso</monospace> is able to solve these problems and
      include latent variables. We provide the mathematical details in
      the
      <ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/math-description.html#ggl-the-nonconforming-case">documentation</ext-link>
      and give an
      <ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/auto_examples/plot_nonconforming_ggl.html#sphx-glr-auto-examples-plot-nonconforming-ggl-py">example</ext-link>.</p>
    </sec>
  </sec>
  <sec id="optimization-algorithms">
    <title>Optimization algorithms</title>
    <p>The <monospace>GGLasso</monospace> package implements several
    methods with provable convergence guarantees for solving the
    optimization problems formulated above.</p>
    <list list-type="bullet">
      <list-item>
        <p><italic>ADMM</italic>: for all problem formulations we
        implemented the ADMM algorithm
        (<xref alt="Boyd et al., 2011" rid="ref-Boyd2011" ref-type="bibr">Boyd
        et al., 2011</xref>). ADMM is a flexible and efficient
        optimization scheme which is specifically suited for Graphical
        Lasso problems as it only relies on efficient computation of the
        proximal operators of the involved functions
        (<xref alt="Danaher et al., 2013" rid="ref-Danaher2013" ref-type="bibr">Danaher
        et al., 2013</xref>;
        <xref alt="Ma et al., 2013" rid="ref-Ma2013" ref-type="bibr">Ma
        et al., 2013</xref>;
        <xref alt="Tomasi et al., 2018" rid="ref-Tomasi2018" ref-type="bibr">Tomasi
        et al., 2018</xref>).</p>
      </list-item>
      <list-item>
        <p><italic>PPDNA</italic>: for GGL and FGL problems without
        latent variables, we included the proximal point solver proposed
        in N. Zhang et al.
        (<xref alt="2021" rid="ref-Zhang2021" ref-type="bibr">2021</xref>)
        and Y. Zhang et al.
        (<xref alt="2020" rid="ref-Zhang2020" ref-type="bibr">2020</xref>).
        According to the numerical experiments in Y. Zhang et al.
        (<xref alt="2020" rid="ref-Zhang2020" ref-type="bibr">2020</xref>),
        PPDNA can be an efficient alternative to ADMM especially for
        fast local convergence.</p>
      </list-item>
      <list-item>
        <p><italic>block-ADMM</italic>: for SGL problems without latent
        variables, we implemented a method which solves the problem
        block-wise, following the proposal in Witten et al.
        (<xref alt="2011" rid="ref-Witten2011" ref-type="bibr">2011</xref>).
        This wrapper simply applies the ADMM solver to all connected
        components of the empirical covariance matrix after
        thresholding.</p>
      </list-item>
    </list>
    <fig>
      <caption><p>Runtime comparison for SGL problems of varying
      dimension and sample size at three different
      <inline-formula><alternatives>
      <tex-math><![CDATA[\lambda_1]]></tex-math>
      <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
      values. The left column shows the runtime at low accuracy, the
      right column at high accuracy.
      <styled-content id="fig2"></styled-content></p></caption>
      <graphic mimetype="application" mime-subtype="pdf" xlink:href="../docs/source/pictures/runtime_merged.pdf" xlink:title="" />
    </fig>
  </sec>
  <sec id="benchmarks-and-applications">
    <title>Benchmarks and applications</title>
    <p>In our example gallery, we included benchmarks comparing the
    solvers in <monospace>GGLasso</monospace> to state-of-the-art
    software as well as illustrative examples explaining the usage and
    functionalities of the package. We want to emphasize the following
    examples:</p>
    <list list-type="bullet">
      <list-item>
        <p><ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/auto_examples/plot_benchmarks.html#sphx-glr-auto-examples-plot-benchmarks-py">Benchmarks</ext-link>
        for SGL problems: our solver is competitive with
        <monospace>scikit-learn</monospace> and
        <monospace>regain</monospace>. The newly implemented block-wise
        solver is highly efficient for large sparse networks (see
        <xref alt="Figure 2" rid="fig2">Figure 2</xref> for runtime
        comparison at
        <ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/auto_examples/plot_benchmarks.html#calculating-the-accuracy">low
        and high accuracy</ext-link>, respectively).</p>
      </list-item>
      <list-item>
        <p><ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/auto_examples/plot_soil_example.html#sphx-glr-auto-examples-plot-soil-example-py">Soil
        microbiome application</ext-link>: following Kurtz et al.
        (<xref alt="2019" rid="ref-Kurtz2019" ref-type="bibr">2019</xref>),
        we demonstrate how latent variables can be used to identify
        hidden confounders in microbial network inference.</p>
      </list-item>
      <list-item>
        <p><ext-link ext-link-type="uri" xlink:href="https://gglasso.readthedocs.io/en/latest/auto_examples/plot_nonconforming_ggl.html#sphx-glr-auto-examples-plot-nonconforming-ggl-py">Nonconforming
        GGL</ext-link>: we illustrate how to use
        <monospace>GGLasso</monospace> for GGL problems with missing
        variables.</p>
      </list-item>
    </list>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank Prof. Dr. Michael Ulbrich, TU Munich, for supervising the
  Master’s thesis of FS that led to the development of the software. We
  also thank Dr. Zachary D. Kurtz for helping with testing of the latent
  graphical model implementation.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-Dempster1972">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Dempster</surname><given-names>Arthur P.</given-names></name>
        </person-group>
        <article-title>Covariance selection</article-title>
        <source>Biometrics</source>
        <publisher-name>JSTOR</publisher-name>
        <year iso-8601-date="1972">1972</year>
        <volume>28</volume>
        <issue>1</issue>
        <issn>0006341X</issn>
        <pub-id pub-id-type="doi">10.2307/2528966</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Zhang2021">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zhang</surname><given-names>Ning</given-names></name>
          <name><surname>Zhang</surname><given-names>Yangjing</given-names></name>
          <name><surname>Sun</surname><given-names>Defeng</given-names></name>
          <name><surname>Toh</surname><given-names>Kim-Chuan</given-names></name>
        </person-group>
        <article-title>An efficient linearly convergent regularized proximal point algorithm for fused multiple graphical Lasso problems</article-title>
        <source>SIAM J. Math. Data Sci.</source>
        <year iso-8601-date="2021">2021</year>
        <volume>3</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1137/20M1344160</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Kurtz2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kurtz</surname><given-names>Zachary D</given-names></name>
          <name><surname>Bonneau</surname><given-names>Richard</given-names></name>
          <name><surname>Müller</surname><given-names>Christian L</given-names></name>
        </person-group>
        <article-title>Disentangling microbial associations from hidden environmental and technical factors via latent graphical models</article-title>
        <source>bioRxiv</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://www.biorxiv.org/content/10.1101/2019.12.21.885889v1.abstract</uri>
        <pub-id pub-id-type="doi">10.1101/2019.12.21.885889</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Laska2017">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Laska</surname><given-names>Jason</given-names></name>
          <name><surname>Narayan</surname><given-names>Manjari</given-names></name>
        </person-group>
        <article-title>Skggm 0.2.7: A scikit-learn compatible package for Gaussian and related graphical models</article-title>
        <publisher-name>Zenodo</publisher-name>
        <year iso-8601-date="2017-07">2017</year><month>07</month>
        <uri>https://doi.org/10.5281/zenodo.830033</uri>
        <pub-id pub-id-type="doi">10.5281/zenodo.830033</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Banerjee2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Banerjee</surname><given-names>Onureena</given-names></name>
          <name><surname>El Ghaoui</surname><given-names>Laurent</given-names></name>
          <name><surname>D’Aspremont</surname><given-names>Alexandre</given-names></name>
        </person-group>
        <article-title>Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year iso-8601-date="2008">2008</year>
        <volume>9</volume>
        <uri>http://dl.acm.org/citation.cfm?id=1390696</uri>
      </element-citation>
    </ref>
    <ref id="ref-Friedman2007">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>J.</given-names></name>
          <name><surname>Hastie</surname><given-names>T.</given-names></name>
          <name><surname>Tibshirani</surname><given-names>R.</given-names></name>
        </person-group>
        <article-title>Sparse inverse covariance estimation with the graphical lasso</article-title>
        <source>Biostatistics</source>
        <publisher-name>Oxford University Press (OUP)</publisher-name>
        <year iso-8601-date="2007-12">2007</year><month>12</month>
        <volume>9</volume>
        <issue>3</issue>
        <pub-id pub-id-type="doi">10.1093/biostatistics/kxm045</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Yuan2007">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Yuan</surname><given-names>M.</given-names></name>
          <name><surname>Lin</surname><given-names>Y.</given-names></name>
        </person-group>
        <article-title>Model selection and estimation in the Gaussian graphical model</article-title>
        <source>Biometrika</source>
        <publisher-name>Oxford University Press (OUP)</publisher-name>
        <year iso-8601-date="2007-02">2007</year><month>02</month>
        <volume>94</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1093/biomet/asm018</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Danaher2013">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Danaher</surname><given-names>Patrick</given-names></name>
          <name><surname>Wang</surname><given-names>Pei</given-names></name>
          <name><surname>Witten</surname><given-names>Daniela M.</given-names></name>
        </person-group>
        <article-title>The joint graphical lasso for inverse covariance estimation across multiple classes</article-title>
        <source>J. R. Stat. Soc. B</source>
        <publisher-name>Wiley</publisher-name>
        <year iso-8601-date="2013-08">2013</year><month>08</month>
        <volume>76</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1111/rssb.12033</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Ma2013">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Ma</surname><given-names>Shiqian</given-names></name>
          <name><surname>Xue</surname><given-names>Lingzhou</given-names></name>
          <name><surname>Zou</surname><given-names>Hui</given-names></name>
        </person-group>
        <article-title>Alternating direction methods for latent variable Gaussian graphical model selection</article-title>
        <source>Neural Comput.</source>
        <publisher-name>MIT Press - Journals</publisher-name>
        <year iso-8601-date="2013-08">2013</year><month>08</month>
        <volume>25</volume>
        <issue>8</issue>
        <pub-id pub-id-type="doi">10.1162/neco_a_00379</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Tomasi2018">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Tomasi</surname><given-names>Federico</given-names></name>
          <name><surname>Tozzo</surname><given-names>Veronica</given-names></name>
          <name><surname>Salzo</surname><given-names>Saverio</given-names></name>
          <name><surname>Verri</surname><given-names>Alessandro</given-names></name>
        </person-group>
        <article-title>Latent variable time-varying network inference</article-title>
        <source>Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2018-07">2018</year><month>07</month>
        <pub-id pub-id-type="doi">10.1145/3219819.3220121</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Hallac2017">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Hallac</surname><given-names>David</given-names></name>
          <name><surname>Park</surname><given-names>Youngsuk</given-names></name>
          <name><surname>Boyd</surname><given-names>Stephen</given-names></name>
          <name><surname>Leskovec</surname><given-names>Jure</given-names></name>
        </person-group>
        <article-title>Network inference via the time-varying graphical lasso</article-title>
        <source>Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2017-08">2017</year><month>08</month>
        <pub-id pub-id-type="doi">10.1145/3097983.3098037</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Chandrasekaran2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chandrasekaran</surname><given-names>Venkat</given-names></name>
          <name><surname>Parrilo</surname><given-names>Pablo A.</given-names></name>
          <name><surname>Willsky</surname><given-names>Alan S.</given-names></name>
        </person-group>
        <article-title>Latent variable graphical model selection via convex optimization</article-title>
        <source>Ann. Statist.</source>
        <publisher-name>Institute of Mathematical Statistics</publisher-name>
        <year iso-8601-date="2012-08">2012</year><month>08</month>
        <volume>40</volume>
        <issue>4</issue>
        <pub-id pub-id-type="doi">10.1214/11-aos949</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Pedregosa2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>F.</given-names></name>
          <name><surname>Varoquaux</surname><given-names>G.</given-names></name>
          <name><surname>Gramfort</surname><given-names>A.</given-names></name>
          <name><surname>Michel</surname><given-names>V.</given-names></name>
          <name><surname>Thirion</surname><given-names>B.</given-names></name>
          <name><surname>Grisel</surname><given-names>O.</given-names></name>
          <name><surname>Blondel</surname><given-names>M.</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>P.</given-names></name>
          <name><surname>Weiss</surname><given-names>R.</given-names></name>
          <name><surname>Dubourg</surname><given-names>V.</given-names></name>
          <name><surname>Vanderplas</surname><given-names>J.</given-names></name>
          <name><surname>Passos</surname><given-names>A.</given-names></name>
          <name><surname>Cournapeau</surname><given-names>D.</given-names></name>
          <name><surname>Brucher</surname><given-names>M.</given-names></name>
          <name><surname>Perrot</surname><given-names>M.</given-names></name>
          <name><surname>Duchesnay</surname><given-names>E.</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine learning in Python</article-title>
        <source>J Mach Learn Res</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
      </element-citation>
    </ref>
    <ref id="ref-Boyd2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Boyd</surname><given-names>Stephen</given-names></name>
          <name><surname>Parikh</surname><given-names>Neal</given-names></name>
          <name><surname>Chu</surname><given-names>Eric</given-names></name>
          <name><surname>Peleato</surname><given-names>Borja</given-names></name>
          <name><surname>Eckstein</surname><given-names>Jonathan</given-names></name>
        </person-group>
        <article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>
        <source>Found. Trends Mach. Learn.</source>
        <publisher-name>Now Publishers Inc.</publisher-name>
        <publisher-loc>Hanover, MA, USA</publisher-loc>
        <year iso-8601-date="2011-01">2011</year><month>01</month>
        <volume>3</volume>
        <issue>1</issue>
        <issn>1935-8237</issn>
        <pub-id pub-id-type="doi">10.1561/2200000016</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Zhang2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Zhang</surname><given-names>Yangjing</given-names></name>
          <name><surname>Zhang</surname><given-names>Ning</given-names></name>
          <name><surname>Sun</surname><given-names>Defeng</given-names></name>
          <name><surname>Toh</surname><given-names>Kim-Chuan</given-names></name>
        </person-group>
        <article-title>A proximal point dual Newton algorithm for solving group graphical lasso problems</article-title>
        <source>SIAM J. Optim.</source>
        <year iso-8601-date="2020">2020</year>
        <volume>30</volume>
        <issue>3</issue>
        <issn>1052-6234</issn>
        <pub-id pub-id-type="doi">10.1137/19M1267830</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Witten2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Witten</surname><given-names>Daniela M.</given-names></name>
          <name><surname>Friedman</surname><given-names>Jerome H.</given-names></name>
          <name><surname>Simon</surname><given-names>Noah</given-names></name>
        </person-group>
        <article-title>New insights and faster computations for the graphical lasso</article-title>
        <source>J. Comput. Graph. Statist.</source>
        <publisher-name>Taylor &amp; Francis</publisher-name>
        <year iso-8601-date="2011">2011</year>
        <volume>20</volume>
        <issue>4</issue>
        <uri>https://doi.org/10.1198/jcgs.2011.11051a</uri>
        <pub-id pub-id-type="doi">10.1198/jcgs.2011.11051a</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Foygel2010">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Foygel</surname><given-names>Rina</given-names></name>
          <name><surname>Drton</surname><given-names>Mathias</given-names></name>
        </person-group>
        <article-title>Extended Bayesian information criteria for Gaussian graphical models</article-title>
        <source>Advances in neural information processing systems</source>
        <person-group person-group-type="editor">
          <name><surname>Lafferty</surname><given-names>J.</given-names></name>
          <name><surname>Williams</surname><given-names>C.</given-names></name>
          <name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name>
          <name><surname>Zemel</surname><given-names>R.</given-names></name>
          <name><surname>Culotta</surname><given-names>A.</given-names></name>
        </person-group>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2010">2010</year>
        <volume>23</volume>
        <uri>https://proceedings.neurips.cc/paper/2010/file/072b030ba126b2f4b2374f342be9ed44-Paper.pdf</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

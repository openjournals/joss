<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">3073</article-id>
<article-id pub-id-type="doi">10.21105/joss.03073</article-id>
<title-group>
<article-title>mikropml: User-Friendly R Package for Supervised Machine
Learning Pipelines</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3140-537X</contrib-id>
<string-name>Begüm D. Topçuoğlu</string-name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-4"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-4674-2176</contrib-id>
<string-name>Zena Lapp</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0003-3283-829X</contrib-id>
<string-name>Kelly L. Sovacool</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8409-278X</contrib-id>
<string-name>Evan Snitkin</string-name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="aff" rid="aff-5"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-1057-7722</contrib-id>
<string-name>Jenna Wiens</string-name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-6935-4275</contrib-id>
<string-name>Patrick D. Schloss</string-name>
<xref ref-type="aff" rid="aff-3"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Department of Computational Medicine &amp; Bioinformatics,
University of Michigan</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Department of Electrical Engineering &amp; Computer
Science, University of Michigan</institution>
</institution-wrap>
</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Department of Microbiology &amp; Immunology, University of
Michigan</institution>
</institution-wrap>
</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Exploratory Science Center, Merck &amp; Co., Inc.,
Cambridge, Massachusetts, USA.</institution>
</institution-wrap>
</aff>
<aff id="aff-5">
<institution-wrap>
<institution>Department of Internal Medicine/Division of Infectious
Diseases, University of Michigan</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2020-01-01">
<day>1</day>
<month>1</month>
<year>2020</year>
</pub-date>
<volume>6</volume>
<issue>61</issue>
<fpage>3073</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>machine learning</kwd>
<kwd>regression</kwd>
<kwd>classification</kwd>
<kwd>decision trees</kwd>
<kwd>random forest</kwd>
<kwd>xgboost</kwd>
<kwd>support vector machines</kwd>
<kwd>microbiology</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <graphic mimetype="image" mime-subtype="png" xlink:href="mikropml-logo.png" />
  <p>Machine learning (ML) for classification and prediction based on a
  set of features is used to make decisions in healthcare, economics,
  criminal justice and more. However, implementing an ML pipeline
  including preprocessing, model selection, and evaluation can be
  time-consuming, confusing, and difficult. Here, we present
  <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/"><monospace>mikropml</monospace></ext-link>
  (prononced “meek-ROPE em el”), an easy-to-use R package that
  implements ML pipelines using regression, support vector machines,
  decision trees, random forest, or gradient-boosted trees. The package
  is available on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/SchlossLab/mikropml/">GitHub</ext-link>,
  <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=mikropml">CRAN</ext-link>,
  and
  <ext-link ext-link-type="uri" xlink:href="https://anaconda.org/conda-forge/r-mikropml">conda</ext-link>.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Most applications of machine learning (ML) require reproducible
  steps for data pre-processing, cross-validation, testing, model
  evaluation, and often interpretation of why the model makes particular
  predictions. Performing these steps is important, as failure to
  implement them can result in incorrect and misleading results
  (<xref alt="Teschendorff, 2019" rid="ref-teschendorff_avoiding_2019" ref-type="bibr">Teschendorff,
  2019</xref>;
  <xref alt="Wiens et al., 2019" rid="ref-wiens_no_2019" ref-type="bibr">Wiens
  et al., 2019</xref>).</p>
  <p>Supervised ML is widely used to recognize patterns in large
  datasets and to make predictions about outcomes of interest. Several
  packages including <monospace>caret</monospace>
  (<xref alt="Kuhn, 2008" rid="ref-kuhn_building_2008" ref-type="bibr">Kuhn,
  2008</xref>) and <monospace>tidymodels</monospace>
  (<xref alt="Kuhn et al., 2020" rid="ref-kuhn_tidymodels_2020" ref-type="bibr">Kuhn
  et al., 2020</xref>) in R, <monospace>scikitlearn</monospace>
  (<xref alt="Pedregosa et al., 2011" rid="ref-pedregosa_scikit-learn_2011" ref-type="bibr">Pedregosa
  et al., 2011</xref>) in Python, and the H2O
  <monospace>autoML</monospace> platform
  (<xref alt="H2O.ai, 2020" rid="ref-h2o_platform" ref-type="bibr">H2O.ai,
  2020</xref>) allow scientists to train ML models with a variety of
  algorithms. While these packages provide the tools necessary for each
  ML step, they do not implement a complete ML pipeline according to
  good practices in the literature. This makes it difficult for
  practitioners new to ML to easily begin to perform ML analyses.</p>
  <p>To enable a broader range of researchers to apply ML to their
  problem domains, we created
  <ext-link ext-link-type="uri" xlink:href="https://github.com/SchlossLab/mikropml/"><monospace>mikropml</monospace></ext-link>,
  an easy-to-use R package
  (<xref alt="R Core Team, 2020" rid="ref-r_core_team_r_2020" ref-type="bibr">R
  Core Team, 2020</xref>) that implements the ML pipeline created by
  Topçuoğlu <italic>et al.</italic>
  (<xref alt="Topçuoğlu et al., 2020" rid="ref-topcuoglu_framework_2020" ref-type="bibr">Topçuoğlu
  et al., 2020</xref>) in a single function that returns a trained
  model, model performance metrics and feature importance.
  <monospace>mikropml</monospace> leverages the
  <monospace>caret</monospace> package to support several ML algorithms:
  linear regression, logistic regression, support vector machines with a
  radial basis kernel, decision trees, random forest, and gradient
  boosted trees. It incorporates good practices in ML training, testing,
  and model evaluation
  (<xref alt="Teschendorff, 2019" rid="ref-teschendorff_avoiding_2019" ref-type="bibr">Teschendorff,
  2019</xref>;
  <xref alt="Topçuoğlu et al., 2020" rid="ref-topcuoglu_framework_2020" ref-type="bibr">Topçuoğlu
  et al., 2020</xref>). Furthermore, it provides data preprocessing
  steps based on the FIDDLE (FlexIble Data-Driven pipeLinE) framework
  outlined in Tang <italic>et al.</italic>
  (<xref alt="Tang et al., 2020" rid="ref-tang_democratizing_2020" ref-type="bibr">Tang
  et al., 2020</xref>) and post-training permutation importance steps to
  estimate the importance of each feature in the models trained
  (<xref alt="Breiman, 2001" rid="ref-breiman_random_2001" ref-type="bibr">Breiman,
  2001</xref>;
  <xref alt="Fisher et al., 2018" rid="ref-fisher_all_2018" ref-type="bibr">Fisher
  et al., 2018</xref>).</p>
  <p><monospace>mikropml</monospace> can be used as a starting point in
  the application of ML to datasets from many different fields. It has
  already been applied to microbiome data to categorize patients with
  colorectal cancer
  (<xref alt="Topçuoğlu et al., 2020" rid="ref-topcuoglu_framework_2020" ref-type="bibr">Topçuoğlu
  et al., 2020</xref>), to identify differences in genomic and clinical
  features associated with bacterial infections
  (<xref alt="Lapp et al., 2020" rid="ref-lapp_machine_2020" ref-type="bibr">Lapp
  et al., 2020</xref>), and to predict gender-based biases in academic
  publishing
  (<xref alt="Hagan et al., 2020" rid="ref-hagan_women_2020" ref-type="bibr">Hagan
  et al., 2020</xref>).</p>
</sec>
<sec id="mikropml-package">
  <title>mikropml package</title>
  <p>The <monospace>mikropml</monospace> package includes functionality
  to preprocess the data, train ML models, evaluate model performance,
  and quantify feature importance (Figure 1). We also provide
  <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/articles/index.html">vignettes</ext-link>
  and an
  <ext-link ext-link-type="uri" xlink:href="https://github.com/SchlossLab/mikropml-snakemake-workflow">example
  Snakemake workflow</ext-link>
  (<xref alt="Köster &amp; Rahmann, 2012" rid="ref-koster_snakemakescalable_2012" ref-type="bibr">Köster
  &amp; Rahmann, 2012</xref>) to showcase how to run an ideal ML
  pipeline with multiple different train/test data splits. The results
  can be visualized using helper functions that use
  <monospace>ggplot2</monospace>
  (<xref alt="Wickham, 2016" rid="ref-wickham_ggplot2_2016" ref-type="bibr">Wickham,
  2016</xref>).</p>
  <p>While mikropml allows users to get started quickly and facilitates
  reproducibility, it is not a replacement for understanding the ML
  workflow which is still necessary when interpreting results
  (<xref alt="Pollard et al., 2019" rid="ref-pollard_turning_2019" ref-type="bibr">Pollard
  et al., 2019</xref>). To facilitate understanding and enable one to
  tailor the code to their application, we have heavily commented the
  code and have provided supporting documentation which can be read
  <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/">online</ext-link>.</p>
  <sec id="preprocessing-data">
    <title>Preprocessing data</title>
    <p>We provide the function <monospace>preprocess_data()</monospace>
    to preprocess features using several different functions from the
    <monospace>caret</monospace> package.
    <monospace>preprocess_data()</monospace> takes continuous and
    categorical data, re-factors categorical data into binary features,
    and provides options to normalize continuous data, remove features
    with near-zero variance, and keep only one instance of perfectly
    correlated features. We set the default options based on those
    implemented in FIDDLE
    (<xref alt="Tang et al., 2020" rid="ref-tang_democratizing_2020" ref-type="bibr">Tang
    et al., 2020</xref>). More details on how to use
    <monospace>preprocess_data()</monospace> can be found in the
    accompanying
    <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/articles/preprocess.html">vignette</ext-link>.</p>
  </sec>
  <sec id="running-ml">
    <title>Running ML</title>
    <p>The main function in mikropml, <monospace>run_ml()</monospace>,
    minimally takes in the model choice and a data frame with an outcome
    column and feature columns. For model choice,
    <monospace>mikropml</monospace> currently supports logistic and
    linear regression (<monospace>glmnet</monospace>:
    <xref alt="Friedman et al., 2010" rid="ref-friedman_regularization_2010" ref-type="bibr">Friedman
    et al., 2010</xref>), support vector machines with a radial basis
    kernel (<monospace>kernlab</monospace>:
    <xref alt="Karatzoglou et al., 2004" rid="ref-karatzoglou_kernlab_2004" ref-type="bibr">Karatzoglou
    et al., 2004</xref>), decision trees (<monospace>rpart</monospace>:
    <xref alt="Therneau et al., 2019" rid="ref-therneau_rpart_2019" ref-type="bibr">Therneau
    et al., 2019</xref>), random forest
    (<monospace>randomForest</monospace>:
    <xref alt="Liaw &amp; Wiener, 2002" rid="ref-liaw_classication_2002" ref-type="bibr">Liaw
    &amp; Wiener, 2002</xref>), and gradient-boosted trees
    (<monospace>xgboost</monospace>:
    <xref alt="Chen et al., 2020" rid="ref-chen_xgboost_2020" ref-type="bibr">Chen
    et al., 2020</xref>). <monospace>run_ml()</monospace> randomly
    splits the data into train and test sets while maintaining the
    distribution of the outcomes found in the full dataset. It also
    provides the option to split the data into train and test sets based
    on categorical variables (e.g. batch, geographic location, etc.).
    <monospace>mikropml</monospace> uses the
    <monospace>caret</monospace> package
    (<xref alt="Kuhn, 2008" rid="ref-kuhn_building_2008" ref-type="bibr">Kuhn,
    2008</xref>) to train and evaluate the models, and optionally
    quantifies feature importance. The output includes the best model
    built based on tuning hyperparameters in an internal and repeated
    cross-validation step, model evaluation metrics, and optional
    feature importances. Feature importances are calculated using a
    permutation test, which breaks the relationship between the feature
    and the true outcome in the test data, and measures the change in
    model performance. This provides an intuitive metric of how
    individual features influence model performance and is comparable
    across model types, which is particularly useful for model
    interpretation
    (<xref alt="Topçuoğlu et al., 2020" rid="ref-topcuoglu_framework_2020" ref-type="bibr">Topçuoğlu
    et al., 2020</xref>). Our
    <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/articles/introduction.html">introductory
    vignette</ext-link> contains a comprehensive tutorial on how to use
    <monospace>run_ml()</monospace>.</p>
    <fig>
      <caption><p>mikropml pipeline</p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="mikRopML-pipeline.png" xlink:title="" />
    </fig>
  </sec>
  <sec id="ideal-workflow-for-running-mikropml-with-many-different-traintest-splits">
    <title>Ideal workflow for running mikropml with many different
    train/test splits</title>
    <p>To investigate the variation in model performance depending on
    the train and test set used
    (<xref alt="Lapp et al., 2020" rid="ref-lapp_machine_2020" ref-type="bibr">Lapp
    et al., 2020</xref>;
    <xref alt="Topçuoğlu et al., 2020" rid="ref-topcuoglu_framework_2020" ref-type="bibr">Topçuoğlu
    et al., 2020</xref>), we provide examples of how to
    <monospace>run_ml()</monospace> many times with different train/test
    splits and how to get summary information about model performance on
    <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/articles/parallel.html">a
    local computer</ext-link> or on a high-performance computing cluster
    using a
    <ext-link ext-link-type="uri" xlink:href="https://github.com/SchlossLab/mikropml-snakemake-workflow">Snakemake
    workflow</ext-link>.</p>
  </sec>
  <sec id="tuning-visualization">
    <title>Tuning &amp; visualization</title>
    <p>One particularly important aspect of ML is hyperparameter tuning.
    We provide a reasonable range of default hyperparameters for each
    model type. However practitioners should explore whether that range
    is appropriate for their data, or if they should customize the
    hyperparameter range. Therefore, we provide a function
    <monospace>plot_hp_performance()</monospace> to plot the
    cross-validation performance metric of a single model or models
    built using different train/test splits. This helps evaluate if the
    hyperparameter range is being searched exhaustively and allows the
    user to pick the ideal set. We also provide summary plots of test
    performance metrics for the many train/test splits with different
    models using <monospace>plot_model_performance()</monospace>.
    Examples are described in the accompanying
    <ext-link ext-link-type="uri" xlink:href="http://www.schlosslab.org/mikropml/articles/tuning.html">vignette
    on hyperparameter tuning</ext-link>.</p>
  </sec>
  <sec id="dependencies">
    <title>Dependencies</title>
    <p>mikropml is written in R
    (<xref alt="R Core Team, 2020" rid="ref-r_core_team_r_2020" ref-type="bibr">R
    Core Team, 2020</xref>) and depends on several packages:
    <monospace>dplyr</monospace>
    (<xref alt="Wickham et al., 2020" rid="ref-wickham_dplyr_2020" ref-type="bibr">Wickham
    et al., 2020</xref>), <monospace>rlang</monospace>
    (<xref alt="Henry et al., 2020" rid="ref-henry_rlang_2020" ref-type="bibr">Henry
    et al., 2020</xref>) and <monospace>caret</monospace>
    (<xref alt="Kuhn, 2008" rid="ref-kuhn_building_2008" ref-type="bibr">Kuhn,
    2008</xref>). The ML algorithms supported by
    <monospace>mikropml</monospace> require:
    <monospace>glmnet</monospace>
    (<xref alt="Friedman et al., 2010" rid="ref-friedman_regularization_2010" ref-type="bibr">Friedman
    et al., 2010</xref>), <monospace>e1071</monospace>
    (<xref alt="Meyer et al., 2020" rid="ref-meyer_e1071_2020" ref-type="bibr">Meyer
    et al., 2020</xref>), and <monospace>MLmetrics</monospace>
    (<xref alt="Yan, 2016" rid="ref-yan_mlmetrics_2016" ref-type="bibr">Yan,
    2016</xref>) for logistic regression, <monospace>rpart2</monospace>
    (<xref alt="Therneau et al., 2019" rid="ref-therneau_rpart_2019" ref-type="bibr">Therneau
    et al., 2019</xref>) for decision trees,
    <monospace>randomForest</monospace>
    (<xref alt="Liaw &amp; Wiener, 2002" rid="ref-liaw_classication_2002" ref-type="bibr">Liaw
    &amp; Wiener, 2002</xref>) for random forest,
    <monospace>xgboost</monospace>
    (<xref alt="Chen et al., 2020" rid="ref-chen_xgboost_2020" ref-type="bibr">Chen
    et al., 2020</xref>) for xgboost, and <monospace>kernlab</monospace>
    (<xref alt="Karatzoglou et al., 2004" rid="ref-karatzoglou_kernlab_2004" ref-type="bibr">Karatzoglou
    et al., 2004</xref>) for support vector machines. We also allow for
    parallelization of cross-validation and other steps using the
    <monospace>foreach</monospace>, <monospace>doFuture</monospace>,
    <monospace>future.apply</monospace>, and
    <monospace>future</monospace> packages
    (<xref alt="Bengtsson &amp; Team, 2020" rid="ref-bengtsson_futureapply_2020" ref-type="bibr">Bengtsson
    &amp; Team, 2020</xref>). Finally, we use
    <monospace>ggplot2</monospace> for plotting
    (<xref alt="Wickham, 2016" rid="ref-wickham_ggplot2_2016" ref-type="bibr">Wickham,
    2016</xref>).</p>
  </sec>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>We thank members of the Schloss Lab who participated in code clubs
  related to the initial development of the pipeline, made documentation
  improvements, and provided general feedback. We also thank Nick
  Lesniak for designing the mikropml logo.</p>
  <p>We thank the US Research Software Sustainability Institute (NSF
  #1743188) for providing training to KLS at the Winter School in
  Research Software Engineering.</p>
</sec>
<sec id="funding">
  <title>Funding</title>
  <p>Salary support for PDS came from NIH grant 1R01CA215574. KLS
  received support from the NIH Training Program in Bioinformatics (T32
  GM070449). ZL received support from the National Science Foundation
  Graduate Research Fellowship Program under Grant No. DGE 1256260. Any
  opinions, findings, and conclusions or recommendations expressed in
  this material are those of the authors and do not necessarily reflect
  the views of the National Science Foundation.</p>
</sec>
<sec id="author-contributions">
  <title>Author contributions</title>
  <p>BDT, ZL, and KLS contributed equally. Author order among the
  co-first authors was determined by time since joining the project.</p>
  <p>BDT, ZL, and KLS conceptualized the study and wrote the code. KLS
  structured the code in R package form. BDT, ZL, JW, and PDS developed
  methodology. PDS, ES, and JW supervised the project. BDT, ZL, and KLS
  wrote the original draft. All authors reviewed and edited the
  manuscript.</p>
</sec>
<sec id="conflicts-of-interest">
  <title>Conflicts of interest</title>
  <p>None.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-bengtsson_futureapply_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bengtsson</surname><given-names>Henrik</given-names></name>
          <name><surname>Team</surname><given-names>R Core</given-names></name>
        </person-group>
        <article-title>Future.apply: Apply Function to Elements in Parallel using Futures</article-title>
        <year iso-8601-date="2020-07">2020</year><month>07</month>
      </element-citation>
    </ref>
    <ref id="ref-breiman_random_2001">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Breiman</surname><given-names>Leo</given-names></name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Machine Learning</source>
        <year iso-8601-date="2001-10">2001</year><month>10</month>
        <volume>45</volume>
        <issue>1</issue>
        <issn>1573-0565</issn>
        <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-chen_xgboost_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Chen</surname><given-names>Tianqi</given-names></name>
          <name><surname>He</surname><given-names>Tong</given-names></name>
          <name><surname>Benesty</surname><given-names>Michael</given-names></name>
          <name><surname>Khotilovich</surname><given-names>Vadim</given-names></name>
          <name><surname>Tang</surname><given-names>Yuan</given-names></name>
          <name><surname>Cho</surname><given-names>Hyunsu</given-names></name>
          <name><surname>Chen</surname><given-names>Kailong</given-names></name>
          <name><surname>Mitchell</surname><given-names>Rory</given-names></name>
          <name><surname>Cano</surname><given-names>Ignacio</given-names></name>
          <name><surname>Zhou</surname><given-names>Tianyi</given-names></name>
          <name><surname>Li</surname><given-names>Mu</given-names></name>
          <name><surname>Xie</surname><given-names>Junyuan</given-names></name>
          <name><surname>Lin</surname><given-names>Min</given-names></name>
          <name><surname>Geng</surname><given-names>Yifeng</given-names></name>
          <name><surname>Li</surname><given-names>Yutian</given-names></name>
          <name><surname>implementation)</surname><given-names>XGBoost contributors (base XGBoost</given-names></name>
        </person-group>
        <article-title>Xgboost: Extreme Gradient Boosting</article-title>
        <year iso-8601-date="2020-06">2020</year><month>06</month>
      </element-citation>
    </ref>
    <ref id="ref-fisher_all_2018">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fisher</surname><given-names>Aaron</given-names></name>
          <name><surname>Rudin</surname><given-names>Cynthia</given-names></name>
          <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
        </person-group>
        <article-title>All models are wrong, but many are useful: Learning a variable’s importance by studying an entire class of prediction models simultaneously</article-title>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-friedman_regularization_2010">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Friedman</surname><given-names>Jerome H.</given-names></name>
          <name><surname>Hastie</surname><given-names>Trevor</given-names></name>
          <name><surname>Tibshirani</surname><given-names>Rob</given-names></name>
        </person-group>
        <article-title>Regularization Paths for Generalized Linear Models via Coordinate Descent</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2010-02">2010</year><month>02</month>
        <volume>33</volume>
        <issue>1</issue>
        <issn>1548-7660</issn>
        <pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-h2o_platform">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>H2O.ai</string-name>
        </person-group>
        <source>H2O: Scalable machine learning platform</source>
        <year iso-8601-date="2020">2020</year>
      </element-citation>
    </ref>
    <ref id="ref-hagan_women_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hagan</surname><given-names>Ada K.</given-names></name>
          <name><surname>Topçuoğlu</surname><given-names>Begüm D.</given-names></name>
          <name><surname>Gregory</surname><given-names>Mia E.</given-names></name>
          <name><surname>Barton</surname><given-names>Hazel A.</given-names></name>
          <name><surname>Schloss</surname><given-names>Patrick D.</given-names></name>
        </person-group>
        <article-title>Women Are Underrepresented and Receive Differential Outcomes at ASM Journals: A Six-Year Retrospective Analysis</article-title>
        <source>mBio</source>
        <publisher-name>American Society for Microbiology</publisher-name>
        <year iso-8601-date="2020-12">2020</year><month>12</month>
        <volume>11</volume>
        <issue>6</issue>
        <issn>2150-7511</issn>
        <pub-id pub-id-type="doi">10.1128/mBio.01680-20</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-henry_rlang_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Henry</surname><given-names>Lionel</given-names></name>
          <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
          <string-name>RStudio</string-name>
        </person-group>
        <article-title>Rlang: Functions for Base Types and Core R and ’Tidyverse’ Features</article-title>
        <year iso-8601-date="2020-07">2020</year><month>07</month>
      </element-citation>
    </ref>
    <ref id="ref-karatzoglou_kernlab_2004">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Karatzoglou</surname><given-names>Alexandros</given-names></name>
          <name><surname>Smola</surname><given-names>Alexandros</given-names></name>
          <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
          <name><surname>Zeileis</surname><given-names>Achim</given-names></name>
        </person-group>
        <article-title>Kernlab - An S4 Package for Kernel Methods in R</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2004-11">2004</year><month>11</month>
        <volume>11</volume>
        <issue>1</issue>
        <issn>1548-7660</issn>
        <pub-id pub-id-type="doi">10.18637/jss.v011.i09</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-koster_snakemakescalable_2012">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Köster</surname><given-names>Johannes</given-names></name>
          <name><surname>Rahmann</surname><given-names>Sven</given-names></name>
        </person-group>
        <article-title>Snakemakea scalable bioinformatics workflow engine</article-title>
        <source>Bioinformatics</source>
        <year iso-8601-date="2012-10">2012</year><month>10</month>
        <volume>28</volume>
        <issue>19</issue>
        <issn>1367-4803</issn>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts480</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kuhn_building_2008">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kuhn</surname><given-names>Max</given-names></name>
        </person-group>
        <article-title>Building Predictive Models in R Using the caret Package</article-title>
        <source>Journal of Statistical Software</source>
        <year iso-8601-date="2008-11">2008</year><month>11</month>
        <volume>28</volume>
        <issue>1</issue>
        <issn>1548-7660</issn>
        <pub-id pub-id-type="doi">10.18637/jss.v028.i05</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kuhn_tidymodels_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kuhn</surname><given-names>Max</given-names></name>
          <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
          <string-name>RStudio</string-name>
        </person-group>
        <article-title>Tidymodels: Easily Install and Load the ’Tidymodels’ Packages</article-title>
        <year iso-8601-date="2020-07">2020</year><month>07</month>
      </element-citation>
    </ref>
    <ref id="ref-lapp_machine_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Lapp</surname><given-names>Zena</given-names></name>
          <name><surname>Han</surname><given-names>Jennifer</given-names></name>
          <name><surname>Wiens</surname><given-names>Jenna</given-names></name>
          <name><surname>Goldstein</surname><given-names>Ellie JC</given-names></name>
          <name><surname>Lautenbach</surname><given-names>Ebbing</given-names></name>
          <name><surname>Snitkin</surname><given-names>Evan</given-names></name>
        </person-group>
        <article-title>Machine learning models to identify patient and microbial genetic factors associated with carbapenem-resistant Klebsiella pneumoniae infection</article-title>
        <source>medRxiv</source>
        <year iso-8601-date="2020-07">2020</year><month>07</month>
        <pub-id pub-id-type="doi">10.1101/2020.07.06.20147306</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-liaw_classication_2002">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Liaw</surname><given-names>Andy</given-names></name>
          <name><surname>Wiener</surname><given-names>Matthew</given-names></name>
        </person-group>
        <article-title>Classification and Regression by randomForest</article-title>
        <year iso-8601-date="2002">2002</year>
        <volume>2</volume>
      </element-citation>
    </ref>
    <ref id="ref-meyer_e1071_2020">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Meyer</surname><given-names>David</given-names></name>
          <name><surname>Dimitriadou</surname><given-names>Evgenia</given-names></name>
          <name><surname>Hornik</surname><given-names>Kurt</given-names></name>
          <name><surname>Weingessel</surname><given-names>Andreas</given-names></name>
          <name><surname>Leisch</surname><given-names>Friedrich</given-names></name>
          <name><surname>C++-code)</surname><given-names>Chih-Chung Chang (libsvm</given-names></name>
          <name><surname>C++-code)</surname><given-names>Chih-Chen Lin (libsvm</given-names></name>
        </person-group>
        <article-title>E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien</article-title>
        <year iso-8601-date="2020-10">2020</year><month>10</month>
      </element-citation>
    </ref>
    <ref id="ref-pedregosa_scikit-learn_2011">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>
          <name><surname>Varoquaux</surname><given-names>Gaël</given-names></name>
          <name><surname>Gramfort</surname><given-names>Alexandre</given-names></name>
          <name><surname>Michel</surname><given-names>Vincent</given-names></name>
          <name><surname>Thirion</surname><given-names>Bertrand</given-names></name>
          <name><surname>Grisel</surname><given-names>Olivier</given-names></name>
          <name><surname>Blondel</surname><given-names>Mathieu</given-names></name>
          <name><surname>Prettenhofer</surname><given-names>Peter</given-names></name>
          <name><surname>Weiss</surname><given-names>Ron</given-names></name>
          <name><surname>Dubourg</surname><given-names>Vincent</given-names></name>
          <name><surname>Vanderplas</surname><given-names>Jake</given-names></name>
          <name><surname>Passos</surname><given-names>Alexandre</given-names></name>
          <name><surname>Cournapeau</surname><given-names>David</given-names></name>
          <name><surname>Brucher</surname><given-names>Matthieu</given-names></name>
          <name><surname>Perrot</surname><given-names>Matthieu</given-names></name>
          <name><surname>Duchesnay</surname><given-names>Édouard</given-names></name>
        </person-group>
        <article-title>Scikit-learn: Machine Learning in Python</article-title>
        <source>Journal of Machine Learning Research</source>
        <year iso-8601-date="2011">2011</year>
        <volume>12</volume>
        <issue>85</issue>
      </element-citation>
    </ref>
    <ref id="ref-pollard_turning_2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Pollard</surname><given-names>Tom J.</given-names></name>
          <name><surname>Chen</surname><given-names>Irene</given-names></name>
          <name><surname>Wiens</surname><given-names>Jenna</given-names></name>
          <name><surname>Horng</surname><given-names>Steven</given-names></name>
          <name><surname>Wong</surname><given-names>Danny</given-names></name>
          <name><surname>Ghassemi</surname><given-names>Marzyeh</given-names></name>
          <name><surname>Mattie</surname><given-names>Heather</given-names></name>
          <name><surname>Lindemer</surname><given-names>Emily</given-names></name>
          <name><surname>Panch</surname><given-names>Trishan</given-names></name>
        </person-group>
        <article-title>Turning the crank for machine learning: Ease, at what expense?</article-title>
        <source>The Lancet Digital Health</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2019-09">2019</year><month>09</month>
        <volume>1</volume>
        <issue>5</issue>
        <issn>2589-7500</issn>
        <pub-id pub-id-type="doi">10.1016/S2589-7500(19)30112-8</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-r_core_team_r_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <article-title>R: A Language and Environment for Statistical Computing</article-title>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2020">2020</year>
      </element-citation>
    </ref>
    <ref id="ref-tang_democratizing_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Tang</surname><given-names>Shengpu</given-names></name>
          <name><surname>Davarmanesh</surname><given-names>Parmida</given-names></name>
          <name><surname>Song</surname><given-names>Yanmeng</given-names></name>
          <name><surname>Koutra</surname><given-names>Danai</given-names></name>
          <name><surname>Sjoding</surname><given-names>Michael W.</given-names></name>
          <name><surname>Wiens</surname><given-names>Jenna</given-names></name>
        </person-group>
        <article-title>Democratizing EHR analyses with FIDDLE: A flexible data-driven preprocessing pipeline for structured clinical data</article-title>
        <source>J Am Med Inform Assoc</source>
        <year iso-8601-date="2020-10">2020</year><month>10</month>
        <pub-id pub-id-type="doi">10.1093/jamia/ocaa139</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-teschendorff_avoiding_2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Teschendorff</surname><given-names>Andrew E.</given-names></name>
        </person-group>
        <article-title>Avoiding common pitfalls in machine learning omic data science</article-title>
        <source>Nature Materials</source>
        <year iso-8601-date="2019-05">2019</year><month>05</month>
        <volume>18</volume>
        <issue>5</issue>
        <issn>1476-4660</issn>
        <pub-id pub-id-type="doi">10.1038/s41563-018-0241-z</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-therneau_rpart_2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Therneau</surname><given-names>Terry</given-names></name>
          <name><surname>Atkinson</surname><given-names>Beth</given-names></name>
          <name><surname>port</surname><given-names>Brian Ripley (producer of the initial R.</given-names></name>
          <name><surname>1999-2017)</surname><given-names>maintainer</given-names></name>
        </person-group>
        <article-title>Rpart: Recursive Partitioning and Regression Trees</article-title>
        <year iso-8601-date="2019-04">2019</year><month>04</month>
      </element-citation>
    </ref>
    <ref id="ref-topcuoglu_framework_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Topçuoğlu</surname><given-names>Begüm D.</given-names></name>
          <name><surname>Lesniak</surname><given-names>Nicholas A.</given-names></name>
          <name><surname>Ruffin</surname><given-names>Mack T.</given-names></name>
          <name><surname>Wiens</surname><given-names>Jenna</given-names></name>
          <name><surname>Schloss</surname><given-names>Patrick D.</given-names></name>
        </person-group>
        <article-title>A Framework for Effective Application of Machine Learning to Microbiome-Based Classification Problems</article-title>
        <source>mBio</source>
        <publisher-name>American Society for Microbiology</publisher-name>
        <year iso-8601-date="2020-06">2020</year><month>06</month>
        <volume>11</volume>
        <issue>3</issue>
        <issn>2150-7511</issn>
        <pub-id pub-id-type="doi">10.1128/mBio.00434-20</pub-id>
        <pub-id pub-id-type="pmid">32518182</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-wickham_dplyr_2020">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
          <name><surname>François</surname><given-names>Romain</given-names></name>
          <name><surname>Henry</surname><given-names>Lionel</given-names></name>
          <name><surname>Müller</surname><given-names>Kirill</given-names></name>
          <string-name>RStudio</string-name>
        </person-group>
        <article-title>Dplyr: A Grammar of Data Manipulation</article-title>
        <year iso-8601-date="2020-08">2020</year><month>08</month>
      </element-citation>
    </ref>
    <ref id="ref-wickham_ggplot2_2016">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Wickham</surname><given-names>Hadley</given-names></name>
        </person-group>
        <source>Ggplot2: Elegant Graphics for Data Analysis</source>
        <publisher-name>Springer International Publishing</publisher-name>
        <publisher-loc>Cham</publisher-loc>
        <year iso-8601-date="2016">2016</year>
        <isbn>978-3-319-24275-0 978-3-319-24277-4</isbn>
        <pub-id pub-id-type="doi">10.1007/978-3-319-24277-4</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-wiens_no_2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Wiens</surname><given-names>Jenna</given-names></name>
          <name><surname>Saria</surname><given-names>Suchi</given-names></name>
          <name><surname>Sendak</surname><given-names>Mark</given-names></name>
          <name><surname>Ghassemi</surname><given-names>Marzyeh</given-names></name>
          <name><surname>Liu</surname><given-names>Vincent X.</given-names></name>
          <name><surname>Doshi-Velez</surname><given-names>Finale</given-names></name>
          <name><surname>Jung</surname><given-names>Kenneth</given-names></name>
          <name><surname>Heller</surname><given-names>Katherine</given-names></name>
          <name><surname>Kale</surname><given-names>David</given-names></name>
          <name><surname>Saeed</surname><given-names>Mohammed</given-names></name>
          <name><surname>Ossorio</surname><given-names>Pilar N.</given-names></name>
          <name><surname>Thadaney-Israni</surname><given-names>Sonoo</given-names></name>
          <name><surname>Goldenberg</surname><given-names>Anna</given-names></name>
        </person-group>
        <article-title>Do no harm: A roadmap for responsible machine learning for health care</article-title>
        <source>Nat. Med.</source>
        <year iso-8601-date="2019">2019</year>
        <volume>25</volume>
        <issue>9</issue>
        <issn>1546-170X</issn>
        <pub-id pub-id-type="doi">10.1038/s41591-019-0548-6</pub-id>
        <pub-id pub-id-type="pmid">31427808</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-yan_mlmetrics_2016">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Yan</surname><given-names>Yachen</given-names></name>
        </person-group>
        <article-title>MLmetrics: Machine Learning Evaluation Metrics</article-title>
        <year iso-8601-date="2016-05">2016</year><month>05</month>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1620</article-id>
<article-id pub-id-type="doi">10.21105/joss.01620</article-id>
<title-group>
<article-title>Eyestream: An Open WebSocket-based Middleware for
Serializing and Streaming Eye Tracker Event Data from Gazepoint GP3 HD
Research Hardware</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0002-8433-2744</contrib-id>
<string-name>Matthew L. Hale</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>School of Interdisciplinary Informatics, University of
Nebraska at Omaha</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-04-21">
<day>21</day>
<month>4</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>43</issue>
<fpage>1620</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>eye tracker</kwd>
<kwd>Gazepoint</kwd>
<kwd>websocket</kwd>
<kwd>JSON</kwd>
<kwd>streaming</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Eye trackers enable a wide range of research and development
  activities in academia, medicine, and industry. Researchers and
  developers using eye trackers are able to collect rich user
  interaction data such as user fixation durations, points of gaze, and
  3D models of user pupils that enable unique analysis and applications
  in areas such as user-interaction design, rehabilitative/restorative
  medicine, and marketing. Most eye trackers, including the two with the
  largest market share <monospace>Gazepoint GP3 HD</monospace>
  (<xref alt="“Gp3 HD Eye Tracker 150Hz,” 2018" rid="ref-gazepoint" ref-type="bibr">“Gp3
  HD Eye Tracker 150Hz,” 2018</xref>) and the
  <monospace>Tobii Pro X3-120</monospace>
  (<xref alt="Olsen, 2012" rid="ref-olsen2012tobii" ref-type="bibr">Olsen,
  2012</xref>), ship with proprietary desktop software packages that
  collect, house, and analyze captured data. This closed source delivery
  model makes it difficult for researchers and developers to directly
  interact with raw eye tracker data, which prevents custom analysis and
  hinders application development and integration efforts. Further, most
  closed-source eye tracker analysis tools do not support streaming and
  real-time analysis applications.</p>
  <p>While the Gazepoint GP3 HD
  (<xref alt="“Gp3 HD Eye Tracker 150Hz,” 2018" rid="ref-gazepoint" ref-type="bibr">“Gp3
  HD Eye Tracker 150Hz,” 2018</xref>) is designed to work with
  Gazepoint’s proprietary analysis software, it also provides an
  underutilized alternative low-level XML-based API called OpenGaze for
  extracting data from the hardware. We have created a tool on top of
  OpenGaze called <monospace>Eyestream</monospace>.
  <monospace>Eyestream</monospace> is capable of serializing
  hardware-captured eye tracker data as JSON and streaming it in
  real-time, at frequencies up to 150hz, to desktop, web, or mobile
  applications. <monospace>Eyestream</monospace> is an open source
  package designed to operate as middleware between the Gazepoint GP3
  and applications that consume eye tracker data for analysis or
  visualization purposes. It was implemented using Python 2.7, a web
  socket server framework called <monospace>Django Channels</monospace>
  (<xref alt="“Django Channels,” 2018" rid="ref-djangochannels" ref-type="bibr">“Django
  Channels,” 2018</xref>), an in-memory database caching tool called
  <monospace>Redis</monospace>
  (<xref alt="Carlson, 2013" rid="ref-carlson2013redis" ref-type="bibr">Carlson,
  2013</xref>), and a modified version of
  <monospace>PyOpenGaze</monospace>
  (<xref alt="Dalmaijer, 2017" rid="ref-esdalmaijer2017" ref-type="bibr">Dalmaijer,
  2017</xref>). <monospace>Eyestream</monospace> is containerized using
  <monospace>Docker</monospace>
  (<xref alt="Boettiger, 2015" rid="ref-boettiger2015docker" ref-type="bibr">Boettiger,
  2015</xref>).</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="assets/paper-040a5e2f.png" />
  Figure 1: System-level architecture of eyestream</p>
</sec>
<sec id="eyestream-and-its-uses">
  <title>Eyestream and Its Uses</title>
  <p><monospace>Eyestream</monospace> provides a real-time streaming
  interface to other software applications that enable a wide-variety of
  applications. The streaming interface is built using websockets. Any
  application on any platform or written in any language can interact
  with <monospace>Eyestream</monospace> provided that it can establish a
  websocket. All major languages (C/C++/C#, Python, Java, JavaScript,
  Ruby, Go, etc) have direct or library support for websockets, making
  <monospace>Eyestream</monospace>’s approach widely open. Figures 2, 3,
  and 4 show the <monospace>Eyestream</monospace> platform from three
  perspectives: 2) The <monospace>Eyestream</monospace> server running
  in the command line, 3) Eyestream’s invocation of the underlying
  Gazepoint eye monitoring software, and 4) a console, in Google Chrome
  Developer Tools, printing streaming eye data it is receiving from the
  server.</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="assets/paper-9af5c794.png" />
  Figure 2: Eyestream’s websocket server running on console</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="assets/paper-b1451bff.png" />
  Figure 3: Gazepoint real-time eye monitor invoked by Eyestream</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="assets/paper-aa2d526c.png" />
  Figure 4: Data streaming to a browser is printed in the console</p>
  <p>One common use for real-time eyetracker data is the generation of
  real-time heatmaps showing the temporal progression of user eye
  movements. An example application using
  <monospace>Eyestream</monospace> to build real-time heatmaps is shown
  in Figure 5. This application, called
  <monospace>Cybertrust</monospace>, is a research and training platform
  that helps users identify phishing attempts. In this example, as the
  user’s gaze travels across the screen (depicted as the black line),
  the heatmap overlay gradually changes color to reflect the amount of
  time spent fixating on a particular area. Heatmap data is rendered
  using a D3 plot so that users and trainers can see what they are
  focusing on within phishing content.</p>
  <p>Other possible applications for <monospace>Eyestream</monospace>
  include medical tools for restorative eye or stroke care
  (<xref alt="Kasten et al., 2006" rid="ref-kasten2006visual" ref-type="bibr">Kasten
  et al., 2006</xref>), examining areas of interest within a page for UI
  design or marketing
  (<xref alt="Goldberg et al., 2002" rid="ref-goldberg2002eye" ref-type="bibr">Goldberg
  et al., 2002</xref>), and as an interaction modality for video games
  (<xref alt="Corcoran et al., 2012" rid="ref-corcoran2012real" ref-type="bibr">Corcoran
  et al., 2012</xref>) or virtual reality systems.</p>
  <p><inline-graphic mimetype="image" mime-subtype="png" xlink:href="assets/paper-d53b90c0.png" />
  Figure 5: Heatmap of eye movements as viewed in a phishing training
  app</p>
</sec>
<sec id="on-going-research-projects-using-eyestream">
  <title>On-going Research Projects Using Eyestream</title>
  <p>Eyestream is currently in use within the
  <monospace>Cybertrust</monospace> phishing research platform
  (<xref alt="Hale, Gamble, &amp; Gamble, 2015" rid="ref-hale2015cyberphishing" ref-type="bibr">Hale,
  Gamble, &amp; Gamble, 2015</xref>;
  <xref alt="Hale, Gamble, Hale, et al., 2015" rid="ref-hale2015measuring" ref-type="bibr">Hale,
  Gamble, Hale, et al., 2015</xref>;
  <xref alt="Hale et al., 2016" rid="ref-hale2016apriori" ref-type="bibr">Hale
  et al., 2016</xref>;
  <xref alt="Hefley et al., 2018" rid="ref-hefley2018multimodal" ref-type="bibr">Hefley
  et al., 2018</xref>). <monospace>Cybertrust</monospace> is a gamified
  experimentation platform used to identify factors related to phishing
  victimization.</p>
</sec>
<sec id="license">
  <title>License</title>
  <p>Eyestream is licensed under the GNU General Public License and can
  be found on the following GitHub repository:
  https://github.com/MLHale/eyestream.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We acknowledge contributions by Gabi Wethor
  (<ext-link ext-link-type="uri" xlink:href="https://github.com/gewethor">gewethor
  on GitHub</ext-link>) for her work in testing the installation and
  usage instructions.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-gazepoint">
      <element-citation>
        <article-title>GP3 HD Eye Tracker 150Hz</article-title>
        <source>Gazepoint</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://www.gazept.com/product/gp3hd/</uri>
      </element-citation>
    </ref>
    <ref id="ref-olsen2012tobii">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Olsen</surname><given-names>Anneli</given-names></name>
        </person-group>
        <article-title>The Tobii I-VT fixation filter</article-title>
        <source>Tobii Technology</source>
        <year iso-8601-date="2012">2012</year>
      </element-citation>
    </ref>
    <ref id="ref-djangochannels">
      <element-citation>
        <article-title>Django Channels</article-title>
        <source>Django Channels - 2.1.7 documentation</source>
        <year iso-8601-date="2018">2018</year>
        <uri>https://channels.readthedocs.io/en/latest/</uri>
      </element-citation>
    </ref>
    <ref id="ref-carlson2013redis">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Carlson</surname><given-names>Josiah L</given-names></name>
        </person-group>
        <source>Redis in Action</source>
        <publisher-name>Manning Publications Co.</publisher-name>
        <year iso-8601-date="2013">2013</year>
      </element-citation>
    </ref>
    <ref id="ref-esdalmaijer2017">
      <element-citation>
        <person-group person-group-type="author">
          <name><surname>Dalmaijer</surname><given-names>Edwin</given-names></name>
        </person-group>
        <article-title>Esdalmaijer/PyOpenGaze</article-title>
        <source>GitHub</source>
        <year iso-8601-date="2017-05">2017</year><month>05</month>
        <uri>https://github.com/esdalmaijer/PyOpenGaze</uri>
      </element-citation>
    </ref>
    <ref id="ref-boettiger2015docker">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Boettiger</surname><given-names>Carl</given-names></name>
        </person-group>
        <article-title>An Introduction to Docker for Reproducible Research</article-title>
        <source>ACM SIGOPS Operating Systems Review</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <volume>49</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1145/2723872.2723882</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hefley2018multimodal">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hefley</surname><given-names>Michael</given-names></name>
          <name><surname>Wethor</surname><given-names>Gabrielle</given-names></name>
          <name><surname>Hale</surname><given-names>Matthew L</given-names></name>
        </person-group>
        <article-title>Multimodal Data Fusion and Behavioral Analysis Tooling for Exploring trust, Trust-propensity, and Phishing Victimization in Online Environments</article-title>
        <year iso-8601-date="2018">2018</year>
        <pub-id pub-id-type="doi">10.24251/HICSS.2018.108</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hale2016apriori">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Hale</surname><given-names>Matthew L</given-names></name>
          <name><surname>Walter</surname><given-names>Charles</given-names></name>
          <name><surname>Lin</surname><given-names>Jessica</given-names></name>
          <name><surname>Gamble</surname><given-names>Rose F</given-names></name>
        </person-group>
        <article-title>Apriori Prediction of Phishing Victimization Based on Structural Content Factors</article-title>
        <source>International Journal of Services Computing</source>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">https://doi.org/10.29268/stsc.2017.5.1.1</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hale2015measuring">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Hale</surname><given-names>Matthew L</given-names></name>
          <name><surname>Gamble</surname><given-names>R</given-names></name>
          <name><surname>Hale</surname><given-names>John</given-names></name>
          <name><surname>Haney</surname><given-names>M</given-names></name>
          <name><surname>Lin</surname><given-names>Jessica</given-names></name>
          <name><surname>Walter</surname><given-names>Charles</given-names></name>
        </person-group>
        <article-title>Measuring the Potential for Victimization in Malicious Content</article-title>
        <source>2015 IEEE International Conference on Web Services</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1109/ICWS.2015.49</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-hale2015cyberphishing">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Hale</surname><given-names>Matthew L</given-names></name>
          <name><surname>Gamble</surname><given-names>Rose F</given-names></name>
          <name><surname>Gamble</surname><given-names>Philip</given-names></name>
        </person-group>
        <article-title>CyberPhishing: A Game-based Platform for Phishing Awareness Testing</article-title>
        <source>2015 48th Hawaii International Conference on System Sciences</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2015">2015</year>
        <pub-id pub-id-type="doi">10.1109/HICSS.2015.670</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-kasten2006visual">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Kasten</surname><given-names>Erich</given-names></name>
          <name><surname>Bunzenthal</surname><given-names>Ulrike</given-names></name>
          <name><surname>Sabel</surname><given-names>Bernhard A</given-names></name>
        </person-group>
        <article-title>Visual Field Recovery After Vision Restoration Therapy (VRT) is Independent of Eye Movements: An Eye Tracker Study</article-title>
        <source>Behavioural brain research</source>
        <publisher-name>Elsevier</publisher-name>
        <year iso-8601-date="2006">2006</year>
        <volume>175</volume>
        <issue>1</issue>
        <pub-id pub-id-type="doi">10.1016/j.bbr.2006.07.024</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-goldberg2002eye">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Goldberg</surname><given-names>Joseph H</given-names></name>
          <name><surname>Stimson</surname><given-names>Mark J</given-names></name>
          <name><surname>Lewenstein</surname><given-names>Marion</given-names></name>
          <name><surname>Scott</surname><given-names>Neil</given-names></name>
          <name><surname>Wichansky</surname><given-names>Anna M</given-names></name>
        </person-group>
        <article-title>Eye Tracking in Web Search Tasks: Design Implications</article-title>
        <source>Proceedings of the 2002 symposium on eye tracking research &amp; applications</source>
        <publisher-name>ACM</publisher-name>
        <year iso-8601-date="2002">2002</year>
        <pub-id pub-id-type="doi">10.1145/507079.507082</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-corcoran2012real">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Corcoran</surname><given-names>Peter M</given-names></name>
          <name><surname>Nanu</surname><given-names>Florin</given-names></name>
          <name><surname>Petrescu</surname><given-names>Stefan</given-names></name>
          <name><surname>Bigioi</surname><given-names>Petronel</given-names></name>
        </person-group>
        <article-title>Real-time Eye Gaze Tracking for Gaming Design and Consumer Electronics Systems</article-title>
        <source>IEEE Transactions on Consumer Electronics</source>
        <publisher-name>IEEE</publisher-name>
        <year iso-8601-date="2012">2012</year>
        <volume>58</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.1109/TCE.2012.6227433</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>

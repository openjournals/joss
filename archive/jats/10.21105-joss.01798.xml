<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">1798</article-id>
<article-id pub-id-type="doi">10.21105/joss.01798</article-id>
<title-group>
<article-title>modelStudio: Interactive Studio with Explanations for ML
Predictive Models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-6661-5364</contrib-id>
<string-name>Hubert Baniecki</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">0000-0001-8423-1823</contrib-id>
<string-name>Przemyslaw Biecek</string-name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Faculty of Mathematics and Information Science, Warsaw
University of Technology</institution>
</institution-wrap>
</aff>
</contrib-group>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2019-10-22">
<day>22</day>
<month>10</month>
<year>2019</year>
</pub-date>
<volume>4</volume>
<issue>43</issue>
<fpage>1798</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2021</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>automated data analysis</kwd>
<kwd>model visualization</kwd>
<kwd>explainable artificial intelligence</kwd>
<kwd>predictive modeling</kwd>
<kwd>interpretable machine learning</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>Machine learning predictive models are widely used in many areas of
  business and research. Their rising popularity is due to them being
  effective but often leads to problems with explaining their
  prediction. This has led to development of many Interpretable Machine
  Learning tools, e.g., <monospace>DALEX</monospace>
  (<xref alt="Przemysław Biecek, 2018" rid="ref-DALEX" ref-type="bibr">Przemysław
  Biecek, 2018</xref>) R package, <monospace>lime</monospace>
  (<xref alt="Ribeiro et al., 2016" rid="ref-lime" ref-type="bibr">Ribeiro
  et al., 2016</xref>) and <monospace>shap</monospace>
  (<xref alt="Lundberg &amp; Lee, 2017" rid="ref-NIPS2017_7062" ref-type="bibr">Lundberg
  &amp; Lee, 2017</xref>) Python packages and
  <monospace>H2o.ai Driverless AI</monospace>
  (<xref alt="Hall et al., 2017" rid="ref-Gill2017MachineLI" ref-type="bibr">Hall
  et al., 2017</xref>).</p>
  <p>Nowadays, we can see a huge demand for automation in many areas.
  This is how Automated Machine Learning and Automated Exploratory Data
  Analysis came to existence. AutoML
  (<xref alt="Truong et al., 2019" rid="ref-Truong2019TowardsAM" ref-type="bibr">Truong
  et al., 2019</xref>) and AutoEDA
  (<xref alt="Staniak &amp; Biecek, 2018" rid="ref-2018arXiv180401955S" ref-type="bibr">Staniak
  &amp; Biecek, 2018</xref>) tools not only speed up the model
  development process but also often lead to new discoveries or higher
  quality of models.</p>
  <p>Explaining predictive models might be a time consuming and tedious
  task. Libraries for interpretable machine learning
  (<xref alt="Przemysław Biecek, 2018" rid="ref-DALEX" ref-type="bibr">Przemysław
  Biecek, 2018</xref>;
  <xref alt="Carme, 2019" rid="ref-sklearnexplain" ref-type="bibr">Carme,
  2019</xref>;
  <xref alt="Jenkins et al., 2019" rid="ref-InterpretML" ref-type="bibr">Jenkins
  et al., 2019</xref>;
  <xref alt="Meudec, 2019" rid="ref-tfexplain" ref-type="bibr">Meudec,
  2019</xref>;
  <xref alt="Molnar et al., 2018" rid="ref-iml" ref-type="bibr">Molnar
  et al., 2018</xref>) require high programing skills and endless
  exploration of different aspects of a predictive model.</p>
  <p>There are tools for automation of the XAI process like
  <monospace>modelDown</monospace>
  (<xref alt="Romaszko et al., 2019" rid="ref-Romaszko2019" ref-type="bibr">Romaszko
  et al., 2019</xref>) which produces static HTML site to compare and
  explain various models. Unfortunately, such tools are focused on
  global level explanations and deliver monotonous experience.</p>
</sec>
<sec id="the-modelstudio-package">
  <title>The <monospace>modelStudio</monospace> package</title>
  <p>The <monospace>modelStudio</monospace> R package automates the
  process of model exploration. It generates advanced interactive and
  animated model explanations in the form of a serverless HTML site. It
  combines <bold>R</bold>
  (<xref alt="R Core Team, 2019" rid="ref-R" ref-type="bibr">R Core
  Team, 2019</xref>) with <bold>D3.js</bold>
  (<xref alt="Bostock, 2016" rid="ref-bostock2016d3" ref-type="bibr">Bostock,
  2016</xref>) to produce plots and descriptions for various local and
  global explanations. Tools for model exploration unite with tools for
  EDA to give a broad overview of the model behaviour.</p>
  <p>The usage of <monospace>modelStudio</monospace> is meant to be
  intuitive and simple. The computation time needed to produce the
  output might not be short though. The main goal of this tool is to
  make model explaining more automated and achieve higher quality
  explanations by juxtaposition of complementary aspects of a model.</p>
  <p>Comparing instance level explanations and model level explanations
  side by side adds wider context and allows for deeper understanding.
  <monospace>modelStudio</monospace> helps to study relations between
  various methods for model explanation like <italic>Break
  Down</italic>, <italic>SHAP</italic>, <italic>Partial Dependency
  Plots</italic>, <italic>Feature Importance</italic>, and others.</p>
</sec>
<sec id="example">
  <title>Example</title>
  <p>The package <monospace>modelStudio</monospace> is available on
  <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=modelStudio">CRAN</ext-link>.
  It can be installed using the
  <monospace>install.packages('modelStudio')</monospace> command. This
  package is based on <monospace>DALEX</monospace> explainers created
  with <monospace>DALEX::explain()</monospace>. Below there is a basic
  code example, which produces
  <ext-link ext-link-type="uri" xlink:href="https://modeloriented.github.io/modelStudio/demo.html">demo</ext-link>.</p>
  <code language="r script">library(&quot;modelStudio&quot;)

# Create a model
model &lt;- glm(survived ~., data = DALEX::titanic_imputed, family = &quot;binomial&quot;)
                 
# Wrap it into an explainer        
explainer &lt;- DALEX::explain(model, data = DALEX::titanic_imputed[,-8],
                            y = DALEX::titanic_imputed[,8], label = &quot;glm&quot;)
                   
# Pick some data points
new_observations &lt;- DALEX::titanic_imputed[1:4,]
rownames(new_observations) &lt;- c(&quot;Lucas&quot;, &quot;James&quot;, &quot;Thomas&quot;, &quot;Nancy&quot;)

# Make a studio for the model
modelStudio(explainer, new_observations)</code>
  <fig>
    <caption><p>Examplary HTML output layout.</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="images/demo.png" xlink:title="" />
  </fig>
</sec>
<sec id="key-features">
  <title>Key Features</title>
  <p>The generated HTML site has many interactive features. One can
  choose which plots are displayed on the grid and change them at any
  given moment by clicking the X symbol. A drop down list may be used to
  pick the observation that will be considered for local explanation
  plots. One may manipulate plots having a variable-based dimension by
  selecting corresponding bars on the other plots. Mousing over the D
  symbol displays a description of the plot. Finally, mousing over lines
  and bars displays the tooltip.</p>
  <fig>
    <caption><p>1. Open in browser or save as HTML document or PNG image
    2. Click on bars to choose which feature will be used for other
    plots 3. Mouse over the D symbol to display a description of the
    plot and click X to close the plot 4. Choose which observation will
    be used for local explanations 5. Mouse over lines and bars to
    display the tooltip 6. Click on the text to choose the plot 7.
    Interact with other elements like a slider</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="images/cheatsheetcut.png" xlink:title="" />
  </fig>
</sec>
<sec id="explanations">
  <title>Explanations</title>
  <p>Seven possible plots to choose from are implemented. There are
  three local explanation plots, three global explanation plots and a
  feature density plot.</p>
  <p><bold>Local explanations</bold> are designed to better understand
  model behaviour around a single observation.</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Break Down</bold> plot and <bold>SHAP Values</bold>
      (<xref alt="Lundberg &amp; Lee, 2017" rid="ref-NIPS2017_7062" ref-type="bibr">Lundberg
      &amp; Lee, 2017</xref>) plot present variable contributions to a
      model prediction
      (<xref alt="Gosiewska &amp; Biecek, 2019" rid="ref-gosiewska2019ibreakdown" ref-type="bibr">Gosiewska
      &amp; Biecek, 2019</xref>). Both of them come from the
      <monospace>iBreakDown</monospace>
      (<xref alt="Przemyslaw Biecek, Gosiewska, et al., 2019" rid="ref-iBreakDown" ref-type="bibr">Przemyslaw
      Biecek, Gosiewska, et al., 2019</xref>) R package.</p>
    </list-item>
    <list-item>
      <p><bold>Ceteris Paribus</bold> plot presents model responses
      around a single point in the feature space
      (<xref alt="Przemyslaw Biecek, 2019" rid="ref-ceterisParibus" ref-type="bibr">Przemyslaw
      Biecek, 2019</xref>).</p>
    </list-item>
  </list>
  <p><bold>Global explanations</bold> are designed to allow for better
  understanding of how the model works in general, for some population
  of interest.</p>
  <list list-type="bullet">
    <list-item>
      <p><bold>Feature Importance</bold> plot presents permutation based
      feature importance
      (<xref alt="Fisher et al., 2018" rid="ref-fisher2018all" ref-type="bibr">Fisher
      et al., 2018</xref>).</p>
    </list-item>
    <list-item>
      <p><bold>Partial Dependency</bold> plot presents averages from N
      number of Ceteris Paribus Profiles
      (<xref alt="Greenwell, 2017" rid="ref-RJ-2017-016" ref-type="bibr">Greenwell,
      2017</xref>).</p>
    </list-item>
    <list-item>
      <p><bold>Accumulated Dependency</bold> plot presents accumulated
      local changes in Ceteris Paribus Profiles
      (<xref alt="Apley, 2016" rid="ref-apley2016visualizing" ref-type="bibr">Apley,
      2016</xref>).</p>
    </list-item>
  </list>
  <p>Detailed overview of these methods can be found in “Predictive
  Models: Explore, Explain, and Debug”
  (<xref alt="Przemyslaw Biecek &amp; Burzykowski, 2019" rid="ref-pmeed" ref-type="bibr">Przemyslaw
  Biecek &amp; Burzykowski, 2019</xref>). The last explanations are
  implemented in the <monospace>ingredients</monospace>
  (<xref alt="Przemyslaw Biecek, Baniecki, et al., 2019" rid="ref-ingredients" ref-type="bibr">Przemyslaw
  Biecek, Baniecki, et al., 2019</xref>) R package.</p>
</sec>
<sec id="conclusions">
  <title>Conclusions</title>
  <p>The <monospace>modelStudio</monospace> package is easy to use and
  its output is intuitive to explore. Automation is convenient and
  interactivity adds an another dimension to visualisations. All of this
  enhance explanation of machine learning predictive models. More
  features and examples can be found in the vignette:
  <ext-link ext-link-type="uri" xlink:href="https://modeloriented.github.io/modelStudio/articles/vignette_modelStudio.html">modelStudio
  - perks and features</ext-link> and on
  <ext-link ext-link-type="uri" xlink:href="https://github.com/ModelOriented/modelStudio">GitHub</ext-link>.</p>
</sec>
<sec id="acknowledgments">
  <title>Acknowledgments</title>
  <p>Work on this package was financially supported by the ‘NCN Opus
  grant 2016/21/B/ST6/02176’.</p>
</sec>
</body>
<back>
<ref-list>
  <ref-list>
    <ref id="ref-lime">
      <element-citation publication-type="paper-conference">
        <person-group person-group-type="author">
          <name><surname>Ribeiro</surname><given-names>Marco Tulio</given-names></name>
          <name><surname>Singh</surname><given-names>Sameer</given-names></name>
          <name><surname>Guestrin</surname><given-names>Carlos</given-names></name>
        </person-group>
        <article-title>&quot;Why should I trust you?&quot;: Explaining the predictions of any classifier</article-title>
        <source>Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, san francisco, CA, USA, august 13-17, 2016</source>
        <year iso-8601-date="2016">2016</year>
        <pub-id pub-id-type="doi">10.18653/v1/n16-3020</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-DALEX">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemysław</given-names></name>
        </person-group>
        <article-title>DALEX: explainers for complex predictive models</article-title>
        <year iso-8601-date="2018">2018</year>
        <uri>http://arxiv.org/abs/1806.08915</uri>
      </element-citation>
    </ref>
    <ref id="ref-NIPS2017_7062">
      <element-citation publication-type="chapter">
        <person-group person-group-type="author">
          <name><surname>Lundberg</surname><given-names>Scott M</given-names></name>
          <name><surname>Lee</surname><given-names>Su-In</given-names></name>
        </person-group>
        <article-title>A unified approach to interpreting model predictions</article-title>
        <source>Advances in neural information processing systems 30</source>
        <person-group person-group-type="editor">
          <name><surname>Guyon</surname><given-names>I.</given-names></name>
          <name><surname>Luxburg</surname><given-names>U. V.</given-names></name>
          <name><surname>Bengio</surname><given-names>S.</given-names></name>
          <name><surname>Wallach</surname><given-names>H.</given-names></name>
          <name><surname>Fergus</surname><given-names>R.</given-names></name>
          <name><surname>Vishwanathan</surname><given-names>S.</given-names></name>
          <name><surname>Garnett</surname><given-names>R.</given-names></name>
        </person-group>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <year iso-8601-date="2017">2017</year>
        <uri>http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</uri>
      </element-citation>
    </ref>
    <ref id="ref-Gill2017MachineLI">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Hall</surname><given-names>Patrick</given-names></name>
          <name><surname>Gill</surname><given-names>Navdeep</given-names></name>
          <name><surname>Kurka</surname><given-names>Megan</given-names></name>
          <name><surname>Phan</surname><given-names>Wen</given-names></name>
        </person-group>
        <source>Machine learning interpretability with H2O driverless AI</source>
        <person-group person-group-type="editor">
          <name><surname>Bartz</surname><given-names>Angela</given-names></name>
        </person-group>
        <publisher-name>H2O.ai, Inc.</publisher-name>
        <publisher-loc>Mountain View, CA</publisher-loc>
        <year iso-8601-date="2017-02">2017</year><month>02</month>
        <uri>http://docs.h2o.ai</uri>
      </element-citation>
    </ref>
    <ref id="ref-2018arXiv180401955S">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Staniak</surname><given-names>Mateusz</given-names></name>
          <name><surname>Biecek</surname><given-names>Przemysław</given-names></name>
        </person-group>
        <article-title>Explanations of Model Predictions with live and breakDown Packages</article-title>
        <source>The R Journal</source>
        <year iso-8601-date="2018">2018</year>
        <volume>10</volume>
        <issue>2</issue>
        <pub-id pub-id-type="doi">10.32614/RJ-2018-072</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-Truong2019TowardsAM">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Truong</surname><given-names>Anh</given-names></name>
          <name><surname>Walters</surname><given-names>Austin</given-names></name>
          <name><surname>Goodsitt</surname><given-names>Jeremy</given-names></name>
          <name><surname>Hines</surname><given-names>Keegan</given-names></name>
          <name><surname>Bruss</surname><given-names>C. Bayan</given-names></name>
          <name><surname>Farivar</surname><given-names>Reza</given-names></name>
        </person-group>
        <article-title>Towards automated machine learning: Evaluation and comparison of AutoML approaches and tools</article-title>
        <source>ArXiv</source>
        <year iso-8601-date="2019">2019</year>
        <volume>abs/1908.05557</volume>
      </element-citation>
    </ref>
    <ref id="ref-R">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <string-name>R Core Team</string-name>
        </person-group>
        <source>R: A language and environment for statistical computing</source>
        <publisher-name>R Foundation for Statistical Computing</publisher-name>
        <publisher-loc>Vienna, Austria</publisher-loc>
        <year iso-8601-date="2019">2019</year>
        <uri>https://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-bostock2016d3">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Bostock</surname><given-names>Mike</given-names></name>
        </person-group>
        <article-title>D3.js-data-driven documents (2016)</article-title>
        <source>URL: https://d3js.org</source>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-Romaszko2019">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Romaszko</surname><given-names>Kamil</given-names></name>
          <name><surname>Tatarynowicz</surname><given-names>Magda</given-names></name>
          <name><surname>Urbański</surname><given-names>Mateusz</given-names></name>
          <name><surname>Biecek</surname><given-names>Przemysław</given-names></name>
        </person-group>
        <article-title>modelDown: Automated website generator with interpretable documentation for predictive machine learning models</article-title>
        <source>Journal of Open Source Software</source>
        <publisher-name>The Open Journal</publisher-name>
        <year iso-8601-date="2019-06">2019</year><month>06</month>
        <volume>4</volume>
        <issue>38</issue>
        <uri>https://doi.org/10.21105/joss.01444</uri>
        <pub-id pub-id-type="doi">10.21105/joss.01444</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-gosiewska2019ibreakdown">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Gosiewska</surname><given-names>Alicja</given-names></name>
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
        </person-group>
        <article-title>iBreakDown: Uncertainty of model explanations for non-additive predictive models</article-title>
        <source>arXiv preprint arXiv:1903.11420</source>
        <year iso-8601-date="2019">2019</year>
      </element-citation>
    </ref>
    <ref id="ref-iBreakDown">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
          <name><surname>Gosiewska</surname><given-names>Alicja</given-names></name>
          <name><surname>Baniecki</surname><given-names>Hubert</given-names></name>
          <name><surname>Izdebski</surname><given-names>Adam</given-names></name>
        </person-group>
        <source>iBreakDown: Model agnostic instance level variable attributions</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://CRAN.R-project.org/package=iBreakDown</uri>
      </element-citation>
    </ref>
    <ref id="ref-ingredients">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
          <name><surname>Baniecki</surname><given-names>Hubert</given-names></name>
          <name><surname>Izdebski</surname><given-names>Adam</given-names></name>
          <name><surname>Pekala</surname><given-names>Katarzyna</given-names></name>
        </person-group>
        <source>Ingredients: Effects and importances of model ingredients</source>
        <year iso-8601-date="2019">2019</year>
        <uri>http://CRAN.R-project.org/package=ingredients</uri>
      </element-citation>
    </ref>
    <ref id="ref-iml">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Molnar</surname><given-names>Christoph</given-names></name>
          <name><surname>Casalicchio</surname><given-names>Giuseppe</given-names></name>
          <name><surname>Bischl</surname><given-names>Bernd</given-names></name>
        </person-group>
        <article-title>iml: An R package for Interpretable Machine Learning</article-title>
        <source>Journal of Open Source Software</source>
        <year iso-8601-date="2018">2018</year>
        <volume>3</volume>
        <issue>26</issue>
        <pub-id pub-id-type="doi">10.21105/joss.00786</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-tfexplain">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Meudec</surname><given-names>Raphael</given-names></name>
        </person-group>
        <source>Interpretability methods for tf.keras models with tensorflow 2.0</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://tf-explain.readthedocs.io</uri>
      </element-citation>
    </ref>
    <ref id="ref-sklearnexplain">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Carme</surname><given-names>Antoine</given-names></name>
        </person-group>
        <source>Sklearn explain</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://github.com/antoinecarme/sklearn_explain</uri>
      </element-citation>
    </ref>
    <ref id="ref-InterpretML">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Jenkins</surname><given-names>Samuel</given-names></name>
          <name><surname>Nori</surname><given-names>Harsha</given-names></name>
          <name><surname>Koch</surname><given-names>Paul</given-names></name>
          <name><surname>Caruana</surname><given-names>Rich</given-names></name>
        </person-group>
        <source>InterpretML</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://github.com/microsoft/interpret</uri>
      </element-citation>
    </ref>
    <ref id="ref-ceterisParibus">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
        </person-group>
        <source>ceterisParibus: Ceteris paribus profiles</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://CRAN.R-project.org/package=ceterisParibus</uri>
      </element-citation>
    </ref>
    <ref id="ref-fisher2018all">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Fisher</surname><given-names>Aaron</given-names></name>
          <name><surname>Rudin</surname><given-names>Cynthia</given-names></name>
          <name><surname>Dominici</surname><given-names>Francesca</given-names></name>
        </person-group>
        <article-title>All models are wrong but many are useful: Variable importance for black-box, proprietary, or misspecified prediction models, using model class reliance</article-title>
        <source>arXiv preprint arXiv:1801.01489</source>
        <year iso-8601-date="2018">2018</year>
      </element-citation>
    </ref>
    <ref id="ref-RJ-2017-016">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Greenwell</surname><given-names>Brandon M.</given-names></name>
        </person-group>
        <article-title>pdp: An R Package for Constructing Partial Dependence Plots</article-title>
        <source>The R Journal</source>
        <year iso-8601-date="2017">2017</year>
        <volume>9</volume>
        <issue>1</issue>
        <uri>http://journal.r-project.org/archive/2017/RJ-2017-016/index.html</uri>
        <pub-id pub-id-type="doi">10.32614/rj-2017-016</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-apley2016visualizing">
      <element-citation publication-type="article-journal">
        <person-group person-group-type="author">
          <name><surname>Apley</surname><given-names>Daniel W</given-names></name>
        </person-group>
        <article-title>Visualizing the effects of predictor variables in black box supervised learning models</article-title>
        <source>arXiv preprint arXiv:1612.08468</source>
        <year iso-8601-date="2016">2016</year>
      </element-citation>
    </ref>
    <ref id="ref-pmeed">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name><surname>Biecek</surname><given-names>Przemyslaw</given-names></name>
          <name><surname>Burzykowski</surname><given-names>Tomasz</given-names></name>
        </person-group>
        <source>Predictive models: Explore, explain, and debug</source>
        <year iso-8601-date="2019">2019</year>
        <uri>https://pbiecek.github.io/PM_VEE/</uri>
      </element-citation>
    </ref>
  </ref-list>
</ref-list>
</back>
</article>
